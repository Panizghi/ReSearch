[
  {
    "Title": "Computing 2002",
    "URL": "https://dl.acm.org/doi/10.1145/543812.543816",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Efficient program transformations for resilient parallel computation via randomization (preliminary version)",
    "URL": "https://dl.acm.org/doi/10.1145/129712.129742",
    "Full Abstract": "In this paper, we address the problem of automatically transforming"
  },
  {
    "Title": "Decision procedures for queues with integer constraints",
    "URL": "https://dl.acm.org/doi/10.1007/11590156_18",
    "Full Abstract": "Queues are a widely used data structure in programming languages. They also provide an important synchronization mechanism in modeling distributed protocols. In this paper we extend the theory of queues with a length function that maps a queue to its size, resulting in a combined theory of queues and Presburger arithmetic. This extension provides a natural but tight coupling between the two theories, and hence the general Nelson-Oppen combination method for decision procedures is not applicable. We present a decision procedure for the quantifier-free theory and a quantifier elimination procedure for the first-order theory that can remove a block of existential quantifiers in one step."
  },
  {
    "Title": "Interactive Theorem Proving and Program Development",
    "URL": "https://dl.acm.org/doi/book/10.5555/993954",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Visualizing Geometrical Statements with GeoView",
    "URL": "https://dl.acm.org/doi/10.1016/j.entcs.2004.09.013",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "A structured approach to proving compiler optimizations based on dataflow analysis",
    "URL": "https://dl.acm.org/doi/10.1007/11617990_5",
    "Full Abstract": "This paper reports on the correctness proof of compiler optimizations based on data-flow analysis. We formulate the optimizations and analyses as instances of a general framework for data-flow analyses and transformations, and prove that the optimizations preserve the behavior of the compiled programs. This development is a part of a larger effort of certifying an optimizing compiler by proving semantic equivalence between source and compiled code."
  },
  {
    "Title": "Filters on coinductive streams, an application to eratosthenes' sieve",
    "URL": "https://dl.acm.org/doi/10.1007/11417170_9",
    "Full Abstract": "We present the formal description of an algorithm to filter values from an infinite steam using a type theory based prover. The key aspect is that filters are partial co-recursive functions and we solve the problem of expressing partiality. We then show how to prove properties of this filter algorithm and we study an application computing the stream of all prime numbers."
  },
  {
    "Title": "Dependent Types, Theorem Proving, and Applications for a Verifying Compiler",
    "URL": "https://dl.acm.org/doi/10.1007/978-3-540-69149-5_19",
    "Full Abstract": "One approach to Prof. Hoare's challenge is to view the development of verified software from the perspective of interactive theorem provers. This idea is not new and many medium-scale software systems have been developed and verified in this manner. Developments based on HOL, ACL2, or PVS have already been described and advocated and our position stands on the same line: most powerful (higher-order) theorem proving systems already contain a programming language, programs can be developed and the correctness of these programs can be specified and verified, they can then be compiled into traditional executable code. In this sense, we already have a small scale example of a verification aware programming language."
  },
  {
    "Title": "Affine functions and series with co-inductive real numbers",
    "URL": "https://dl.acm.org/doi/10.1017/S0960129506005809",
    "Full Abstract": "We extend the work of A. Ciaffaglione and P. di Gianantonio on the mechanical verification of algorithms for exact computation on real numbers, using infinite streams of digits implemented as a co-inductive type. Four aspects are studied. The first concerns the proof that digit streams correspond to axiomatised real numbers when they are already present in the proof system. The second re-visits the definition of an addition function, looking at techniques to let the proof search engine perform the effective construction of an algorithm that is correct by construction. The third concerns the definition of a function to compute affine formulas with positive rational coefficients. This is an example where we need to combine co-recursion and recursion. Finally, the fourth aspect concerns the definition of a function to compute series, with an application on the series that is used to compute Euler's number"
  },
  {
    "Title": "Inductive and Coinductive Components of Corecursive Functions in Coq",
    "URL": "https://dl.acm.org/doi/10.1016/j.entcs.2008.05.018",
    "Full Abstract": "In Constructive Type Theory, recursive and corecursive definitions are subject to syntactic restrictions which guarantee termination for recursive functions and productivity for corecursive functions. However, many terminating and productive functions do not pass the syntactic tests. Bove proposed in her thesis an elegant reformulation of the method of accessibility predicates that widens the range of terminative recursive functions formalisable in Constructive Type Theory. In this paper, we pursue the same goal for productive corecursive functions. Notably, our method of formalisation of coinductive definitions of productive functions in Coq requires not only the use of ad-hoc predicates, but also a systematic algorithm that separates the inductive and coinductive parts of functions."
  },
  {
    "Title": "Fixed point semantics and partial recursion in Coq",
    "URL": "https://dl.acm.org/doi/10.1145/1389449.1389461",
    "Full Abstract": "We propose to use the Knaster-Tarski least fixed point theorem as a basis to define recursive functions in the Calculus of Inductive Constructions. This widens the class of functions that can be modelled in type-theory based theorem proving tools to potentially nonterminating functions. This is only possible if we extend the logical framework by adding some axioms of classical logic.We claim that the extended framework makes it possible to reason about terminating or non-terminating computations and we show that extraction can also be extended to handle the new functions"
  },
  {
    "Title": "Canonical Big Operators",
    "URL": "https://dl.acm.org/doi/10.1007/978-3-540-71067-7_11",
    "Full Abstract": "In this paper, we present an approach to describe uniformly iterated \"big\" operations, like $\\sum_{i=0}^n f(i)$ or max"
  },
  {
    "Title": "On relations between input and communication/computation in VLSI",
    "URL": "https://dl.acm.org/doi/10.1109/SFCS.1981.26",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "An Efficient Deadlock Removal Scheme for Non-Two-Phase Locking Protocols",
    "URL": "https://dl.acm.org/doi/10.5555/645910.673597",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Implementation of an interpreter for a parallel language in Centaur",
    "URL": "https://dl.acm.org/doi/10.5555/92011.92016",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Implementation of an Interpreter for a Parallel Language in Centaur",
    "URL": "https://dl.acm.org/doi/10.5555/645388.651572",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Occurrences in debugger specifications",
    "URL": "https://dl.acm.org/doi/10.1145/113446.113473",
    "Full Abstract": "Copyright © 1991 ACM."
  },
  {
    "Title": "Origin Functions in Lambda-Calculus and Term Rewriting Systems",
    "URL": "https://dl.acm.org/doi/10.5555/648221.751377",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Real theorem provers deserve real user-interfaces",
    "URL": "https://dl.acm.org/doi/10.1145/142868.143760",
    "Full Abstract": "This paper explains how to add a modern user interface to existing theorem provers, using principles and tools designed for programming environments."
  },
  {
    "Title": "A canonical calculus of residuals",
    "URL": "https://dl.acm.org/doi/10.5555/185881.185911",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Proof by Pointing",
    "URL": "https://dl.acm.org/doi/10.5555/645868.668515",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Reasoning with Executable Specifications",
    "URL": "https://dl.acm.org/doi/10.5555/646619.697409",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "CtCoq",
    "URL": "https://dl.acm.org/doi/10.5555/646057.678192",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "CtCoq",
    "URL": "https://dl.acm.org/doi/10.5555/648232.752990",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Program Checkers for Probability Generation",
    "URL": "https://dl.acm.org/doi/10.5555/646245.684535",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Combining dimensionality and rate of growth arguments for establishing lower bounds on the number of multiplications",
    "URL": "https://dl.acm.org/doi/10.1145/800119.803912",
    "Full Abstract": "In this paper we describe a new method for establishing lower bounds for the number of multiplications and divisions required to compute rational functions. We shall start by reminding the reader of some standard notations."
  },
  {
    "Title": "COMBINING DIMENSIONALITY AND RATE OF GROWTH ARGUMENTS FOR ESTABLISHING LOWER BOUNDS ON THE NUMBER OF MULTIPLICATIONS",
    "URL": "https://dl.acm.org/doi/book/10.5555/889589",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Verification of parameterized programs",
    "URL": "https://dl.acm.org/doi/10.5555/233976.233988",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Automatic Generation of Invariants and Assertions",
    "URL": "https://dl.acm.org/doi/10.5555/647484.760398",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Temporal verification of reactive systems",
    "URL": "https://dl.acm.org/doi/book/10.5555/211468",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "STeP: The Stanford Temporal Prover (Educational Release) User''s Manual",
    "URL": "https://dl.acm.org/doi/book/10.5555/892587",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Generalized Temporal Verification Diagrams",
    "URL": "https://dl.acm.org/doi/10.5555/646833.708045",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Clocked Transition Systems",
    "URL": "https://dl.acm.org/doi/book/10.5555/892591",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Verifying clocked transition systems",
    "URL": "https://dl.acm.org/doi/10.5555/239587.239589",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "STeP",
    "URL": "https://dl.acm.org/doi/10.5555/647765.735848",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Temporal Verification by Diagram Transformations",
    "URL": "https://dl.acm.org/doi/10.5555/647765.735983",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Deductive Model Checking",
    "URL": "https://dl.acm.org/doi/10.5555/647765.735990",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Design considerations for microprogramming languages",
    "URL": "https://dl.acm.org/doi/10.1145/1500175.1500283",
    "Full Abstract": "Historically, microprograms have been developed using tools which are appropriate to logic designers (block diagrams, register transfer languages), or systems programmers (microcode assemblers). With the growth of user microprogramming, and the increased demands placed upon computer manufacturers for firmware support, improved tools and techniques have been suggested. In particular, microprogram compilers, i.e., compilers which translate high level source statements into sequences of microprogram control words, have been proposed and implemented. The larger issue to be faced is the nebulous task of supporting the needs of a community which includes:"
  },
  {
    "Title": "On Parallel Computation for the Knapsack Problem",
    "URL": "https://dl.acm.org/doi/10.1145/322326.322342",
    "Full Abstract": "Copyright © 1982 ACM."
  },
  {
    "Title": "On the Average-Case Complexity of Selecting the ",
    "URL": "https://dl.acm.org/doi/10.1137/0211034",
    "Full Abstract": "Let $\\bar V_k (n)$ be the minimum average number of pairwise comparisons needed to find the"
  },
  {
    "Title": "Fundamentals of Deductive Program Synthesis",
    "URL": "https://dl.acm.org/doi/10.1109/32.153379",
    "Full Abstract": "An informal tutorial for program synthesis is presented, with an emphasis on deductive methods. According to this approach, to construct a program meeting a given specification, the authors prove the existence of an object meeting the specified conditions. The proof is restricted to be sufficiently constructive, in the sense that, in establishing the existence of the desired output, the proof is forced to indicate a computational method for finding it. That method becomes the basis for a program that can be extracted from the proof. The exposition is based on the deductive-tableau system, a theorem-proving framework particularly suitable for program synthesis. The system includes a nonclausal resolution rule, facilities for reasoning about equality, and a well-founded induction rule."
  },
  {
    "Title": "Time for Concurrency",
    "URL": "https://dl.acm.org/doi/10.5555/646324.756790",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Verifying Hybrid Systems",
    "URL": "https://dl.acm.org/doi/10.5555/646874.709969",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Towards Refining Temporal Specifications into Hybrid Systems",
    "URL": "https://dl.acm.org/doi/10.5555/646874.709981",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "The deductive foundations of computer programming",
    "URL": "https://dl.acm.org/doi/book/10.5555/174817",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Temporal Verification of Simulation and Refinement",
    "URL": "https://dl.acm.org/doi/10.5555/648145.750144",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "A Decision Algorithm for Full Propositional Temporal Logic",
    "URL": "https://dl.acm.org/doi/10.5555/647762.735505",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Models for reactivity",
    "URL": "https://dl.acm.org/doi/10.5555/2697441.2697671",
    "Full Abstract": "A hierarchy of models that capture realistic aspects of reactive, real-time, and hybrid systems is introduced. On the most abstract level, the qualitative (non-quantitative) model of"
  },
  {
    "Title": "Temporal Verification Diagrams",
    "URL": "https://dl.acm.org/doi/10.5555/645868.670943",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "STeP: The Stanford Temporal Prover",
    "URL": "https://dl.acm.org/doi/book/10.5555/891757",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Beyond Model Checking",
    "URL": "https://dl.acm.org/doi/10.5555/647763.735670",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Realizability and Synthesis of Reactive Modules",
    "URL": "https://dl.acm.org/doi/10.5555/647763.760718",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "A compact data structure for storing, retrieving and manipulating line drawings",
    "URL": "https://dl.acm.org/doi/10.1145/1465482.1465580",
    "Full Abstract": "The field of graphical man/machine interaction is customarily split into hardware and software areas. The former can be considered to have come of age: there are over twenty-five brands of off-the-shelf consoles with all the requisite input devices, and new techniques and improvements are constantly being developed. Many consoles are also provided with primitive supporting software which allow one to draw points, lines, arcs, etc., in a symbolic language of some sort. Less well understood and developed, however, is that aspect of display software concerned with representing and manipulating the problem model from which these primitive point/line/arc pictures are derived. The \"data structure\" is the machine representation of the often complex and hierarchical problem model. It must be judiciously derived from the model on the one hand and, on the other, lead readily to the reduced console display file of points, lines and arcs which cause the actual visual display. Furthermore, the data structure must be efficiently stored and processed (usually contradictory requirements)."
  },
  {
    "Title": "Data and storage structures for interactive graphics",
    "URL": "https://dl.acm.org/doi/10.1145/1115880.1115891",
    "Full Abstract": "This is a tutorial paper that shows the relationship between the data structure and the rest of an interactive graphics system. The distinction between data structures and storage structures is emphasized, as is the problem of data structure segmentation. The implementation of typical graphical applications is described, along with analysis of various trade-off decisions. Finally, some high-level data structure specification languages are discussed."
  },
  {
    "Title": "Parallel hashing—an efficient implementation of shared memory",
    "URL": "https://dl.acm.org/doi/10.1145/12130.12146",
    "Full Abstract": "Copyright © 1986 ACM."
  },
  {
    "Title": "Completing the temporal picture",
    "URL": "https://dl.acm.org/doi/book/10.5555/892484",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "The logical basis for computer programming: vol. 2, deductive systems",
    "URL": "https://dl.acm.org/doi/book/10.5555/78091",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Nonclausal deduction in first-order temporal logic",
    "URL": "https://dl.acm.org/doi/10.1145/77600.77617",
    "Full Abstract": "This paper presents a proof system for first-order temporal logic. The system extends the nonclausal resolution method for ordinary first-order logic with equality, to handle quantifiers and temporal operators. Soundness and completeness issues are considered. The use of the system for verifying concurrent programs is discussed and variants of the system for other modal logics are also described."
  },
  {
    "Title": "Tools and rules for the practicing verifier",
    "URL": "https://dl.acm.org/doi/book/10.5555/892493",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "An exercise in the verification of multi-process programs",
    "URL": "https://dl.acm.org/doi/10.5555/119872.119905",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "A hierarchy of temporal properties (invited paper, 1989)",
    "URL": "https://dl.acm.org/doi/10.1145/93385.93442",
    "Full Abstract": "Copyright © 1990 ACM."
  },
  {
    "Title": "An interleaving model for real time.",
    "URL": "https://dl.acm.org/doi/book/10.5555/892496",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "An interleaving model for real time",
    "URL": "https://dl.acm.org/doi/10.5555/100512.100633",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "A temporal proof methodology for reactive systems",
    "URL": "https://dl.acm.org/doi/10.5555/100512.100637",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Temporal proof methodologies for real-time systems",
    "URL": "https://dl.acm.org/doi/10.1145/99583.99629",
    "Full Abstract": "Copyright © 1991 ACM."
  },
  {
    "Title": "Timed Transition Systems",
    "URL": "https://dl.acm.org/doi/10.5555/648143.749987",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "From Timed to Hybrid Systems",
    "URL": "https://dl.acm.org/doi/10.5555/648143.749988",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Completing the temporal picture",
    "URL": "https://dl.acm.org/doi/10.1016/0304-3975%2891%2990041-Y",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Completing the temporal picture",
    "URL": "https://dl.acm.org/doi/10.5555/111774.111780",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Experience with a regular expression compiler",
    "URL": "https://dl.acm.org/doi/book/10.5555/892299",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Competitive snoopy caching",
    "URL": "https://dl.acm.org/doi/10.1109/SFCS.1986.14",
    "Full Abstract": "In a snoopy cache multiprocessor system, each processor has a cache in which it stores blocks of data. Each cache is connected to a bus used to communicate with the other caches and with main memory. For several of the proposed models of snoopy caching, we present new on-line algorithms which decide, for each cache, which blocks to retain and which to drop in order to minimize communication over the bus. We prove that, for any sequence of operations, our algorithms' communication costs are within a constant factor of the minimum required for that sequence; for some of our algorithms we prove that no on-line algorithm has this property with a smaller constant."
  },
  {
    "Title": "Special relations in automated deduction",
    "URL": "https://dl.acm.org/doi/10.1145/4904.4905",
    "Full Abstract": "Two deduction rules are introduced to give streamlined treatment to relations of special importance in an automated theorem-proving system. These rules, the"
  },
  {
    "Title": "A timely resolution",
    "URL": "https://dl.acm.org/doi/book/10.5555/892378",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Model theorem proving",
    "URL": "https://dl.acm.org/doi/book/10.5555/892375",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "How to Clear a Block",
    "URL": "https://dl.acm.org/doi/10.5555/648227.749317",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Modal Theorem Proving",
    "URL": "https://dl.acm.org/doi/10.5555/648227.751971",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "A deductive approach to program synthesis",
    "URL": "https://dl.acm.org/doi/10.5555/31870.31871",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Modal theorem proving",
    "URL": "https://dl.acm.org/doi/10.5555/22289.22302",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "How to clear a block: plan formation in situational logic",
    "URL": "https://dl.acm.org/doi/10.5555/22289.22337",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Specification and Verification of Concurrent Programs by forall-Automata",
    "URL": "https://dl.acm.org/doi/10.5555/647236.720395",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "The deductive synthesis of imperative LISP programs",
    "URL": "https://dl.acm.org/doi/10.5555/1856670.1856698",
    "Full Abstract": "A framework is described for the automatic synthesis of imperative programs, which may alter data structures and produce destructive side effects as part of their intended behavior. A program meeting a given specification is extracted from the proof of a theorem in a variant of situational logic, in which the states of a computation are explicit objects. As an example, an in-place reverse program has been derived in an imperative LISP, which includes assignment and destructive list operations (rplaca and rplacd)."
  },
  {
    "Title": "The deductive synthesis of imperative LISP programs",
    "URL": "https://dl.acm.org/doi/10.5555/1863696.1863724",
    "Full Abstract": "A framework is described for the automatic synthesis of imperative programs, which may alter data structures and produce destructive side effects as part of their intended behavior. A program meeting a given specification is extracted from the proof of a theorem in a variant of situational logic, in which the states of a computation are explicit objects. As an example, an in-place reverse program has been derived in an imperative LISP, which includes assignment and destructive list operations (rplaca and rplacd)."
  },
  {
    "Title": "The origin of a binary-search paradigm",
    "URL": "https://dl.acm.org/doi/10.1016/0167-6423%2887%2990025-6",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "A Hierarchy of Temporal Properties",
    "URL": "https://dl.acm.org/doi/book/10.5555/892426",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Specification and verification of concurrent programs by A ∀ automata",
    "URL": "https://dl.acm.org/doi/10.1145/41625.41626",
    "Full Abstract": "∀-automata are non-deterministic finite-state automata over infinite sequences. They differ from conventional automata in that a sequence is accepted if"
  },
  {
    "Title": "How to clear a block: A theory of plans",
    "URL": "https://dl.acm.org/doi/10.5555/41391.41392",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "A hierarchy of temporal properties",
    "URL": "https://dl.acm.org/doi/10.1145/41840.41857",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "A hardware semantics based on temporal intervals",
    "URL": "https://dl.acm.org/doi/book/10.5555/892293",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Proving precedence properties: the temporal way",
    "URL": "https://dl.acm.org/doi/book/10.5555/892294",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Verification of concurrent programs: a temporal proof system",
    "URL": "https://dl.acm.org/doi/book/10.5555/892296",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Reasoning in Interval Temporal Logic",
    "URL": "https://dl.acm.org/doi/10.5555/648064.747582",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Reasoning in interval temporal logic",
    "URL": "https://dl.acm.org/doi/book/10.5555/892297",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "A Hardware Semantics Based on Temporal Intervals",
    "URL": "https://dl.acm.org/doi/10.5555/646237.683015",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Proving Precedence Properties",
    "URL": "https://dl.acm.org/doi/10.5555/646237.683020",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "The temporal logic of branching time",
    "URL": "https://dl.acm.org/doi/10.1007/BF01257083",
    "Full Abstract": "A temporal logic is defined which contains both linear and branching operators. The underlying model is the tree of all possible computations. The following metatheoretical results are proven: 1) an exponential decision procedure for satisfiability; 2) a finite model property; 3) the completeness of an axiomatization."
  },
  {
    "Title": "Synthesis of Communicating Processes from Temporal Logic Specifications",
    "URL": "https://dl.acm.org/doi/10.1145/357233.357237",
    "Full Abstract": "Copyright © 1984 ACM."
  },
  {
    "Title": "Adequate proof principles for invariance and liveness properties of concurrent programs",
    "URL": "https://dl.acm.org/doi/book/10.5555/892313",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "TABLOG: the deductive-tableau programming language",
    "URL": "https://dl.acm.org/doi/book/10.5555/892317",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "TABLOG",
    "URL": "https://dl.acm.org/doi/10.1145/800055.802049",
    "Full Abstract": "TABLOG (Tableau Logic Programming Language) is a language combining functional and logic programming using first-order (quantifier-free) predicate logic with equality. TABLOG incorporates advantages of LISP and PROLOG."
  },
  {
    "Title": "Adequate proof principles for invariance and liveness properties of concurrent programs",
    "URL": "https://dl.acm.org/doi/10.1016/0167-6423%2884%2990003-0",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "The logical basis for computer programming. Volume 1:  deductive reasoning",
    "URL": "https://dl.acm.org/doi/book/10.5555/3510",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Special relations in automated deduction",
    "URL": "https://dl.acm.org/doi/book/10.5555/892351",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Nonclausal temporal deduction",
    "URL": "https://dl.acm.org/doi/book/10.5555/892354",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Structured programming with recursion",
    "URL": "https://dl.acm.org/doi/book/10.5555/892162",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Is “sometime” sometimes better than “always”?",
    "URL": "https://dl.acm.org/doi/10.1145/359340.359353",
    "Full Abstract": "This paper explores a technique for proving the correctness and termination of programs simultaneously. This approach, the"
  },
  {
    "Title": "Proving termination and multiset orderings",
    "URL": "https://dl.acm.org/doi/book/10.5555/892168",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Inference rules for program annotation",
    "URL": "https://dl.acm.org/doi/10.5555/800099.803206",
    "Full Abstract": "Methods are presented whereby an Algol-like program, given together with its specifications, can be documented automatically. The program is incrementally annotated with invariant relationships that hold between program variables at intermediate points in the program and explain the actual workings of the program regardless of whether the program is correct. Thus this documentation can be used for proving the correctness of the program or may serve as an aid in the debugging of an incorrect program."
  },
  {
    "Title": "The synthesis of structure-changing programs",
    "URL": "https://dl.acm.org/doi/10.5555/800099.803208",
    "Full Abstract": "Deductive techniques are presented for deriving programs systematically from given specifications. The specifications express the purpose of the desired program without giving any hint of the algorithm to be employed. The desired program is intended to achieve this purpose by means of such low-level primitives as assignment statements, the conditional statements, and recursion. The basic approach is to transform the specifications repeatedly according to certain rules, until a satisfactory program is produced. The rules are guided by a number of strategic controls."
  },
  {
    "Title": "A deductive approach to program synthesis",
    "URL": "https://dl.acm.org/doi/book/10.5555/892190",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "The translation of 'go to' programs to 'while' programs",
    "URL": "https://dl.acm.org/doi/10.5555/1241515.1241521",
    "Full Abstract": "Some of the papers presented in this book already have been widely circulated; others were published in well-known journals, like IBM Systems Journal but largely were ignored when they first appeared; and then there are the obscure papers like this one by Ashcroft and Manna, which was presented at the 1971 IFIP Conference in Ljubljana, Yugoslavia. It's not that the ideas in the paper are obscure -- it's just that very few people in the mainstream EDP community attended the Conference, and precious few copies of the conference proceedings ever found their way into American libraries. It is, however, a paper that many people over the years have wanted to read, particularly since it deals with a subject also mentioned by Knuth (\"Structured Programming with go to State, ments\" [see Paper 20]), Wulf (\"A Case Against the GOTO\" [Paper 8]), and Böm and Jacopini (\"Flow Diagrams, Turing Machines and Languages with Only Two Formation Rules\" [Paper 2])."
  },
  {
    "Title": "The Modal Logic of Programs",
    "URL": "https://dl.acm.org/doi/10.5555/646233.682234",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Proving termination with Multiset Orderings",
    "URL": "https://dl.acm.org/doi/10.5555/646233.682248",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Proving termination with multiset orderings",
    "URL": "https://dl.acm.org/doi/10.1145/359138.359142",
    "Full Abstract": "A common tool for proving the termination of programs is the"
  },
  {
    "Title": "A deductive approach to program synthesis",
    "URL": "https://dl.acm.org/doi/10.5555/1624861.1624985",
    "Full Abstract": "Program synthesis is the systematic derivation of a program from a given specification. A deductive approach to program synthesis is presented for the construction of recursive programs. This approach regards program synthesis as a theorem-proving task and relies on a theorem-proving method that combines the features of transformation rules, unification, and mathematical induction within a single framework."
  },
  {
    "Title": "A Deductive Approach to Program Synthesis",
    "URL": "https://dl.acm.org/doi/10.1145/357084.357090",
    "Full Abstract": "Program synthesis is the systematic derivation of a program from a given specification. A deductive approach to program synthesis is presented for the construction of recursive programs. This approach regards program synthesis as a theorem-proving task and relies on a theorem-proving method that combines the features of transformation rules, unification, and mathematical induction within a single framework."
  },
  {
    "Title": "Synchronous schemes and their decision problems",
    "URL": "https://dl.acm.org/doi/10.1145/567446.567453",
    "Full Abstract": "A class of schemes called synchronous schemes is defined. A synchronous scheme can have several variables, but all the active ones are required to keep a synchronized rate of computation as measured by the height of their respective Herbrand values. A \"reset\" statement, which causes all the variables to restart a new computation, is admitted. It is shown that equivalence, convergence, and other properties are decidable for schemes in this class. The class of synchronous schemes contains, as special cases, the known decidable classes of Ianov schemes, one-variable schemes with resets, and progressive schemes."
  },
  {
    "Title": "Problematic features of programming languages: a situational-calculus approach",
    "URL": "https://dl.acm.org/doi/book/10.5555/892247",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "The temporal logic of branching time",
    "URL": "https://dl.acm.org/doi/10.1145/567532.567551",
    "Full Abstract": "A temporal language and system are presented which are based on branching time structure. By the introduction of symmetrically dual sets of temporal operators, it is possible to discuss properties which hold either along one path or along all paths. Consequently it is possible to express in this system all the properties that were previously expressible in linear time or branching time systems. We present an exponential decision procedure for satisfiability in the language based on tableaux methods, and a complete deduction system. As associated temporal semantics is illustrated for both structured and graph representation of programs."
  },
  {
    "Title": "Verification of Concurrent Programs",
    "URL": "https://dl.acm.org/doi/10.5555/648063.747433",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Synthesis of Communicating Processes from Temporal Logic Specifications",
    "URL": "https://dl.acm.org/doi/10.5555/648063.747434",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Towards automatic debugging of programs",
    "URL": "https://dl.acm.org/doi/10.1145/390016.808434",
    "Full Abstract": "We present the germ of an idea for automatically correcting logical errors in programs by manipulating the invariants of the program. An invariant tree is defined, and we show how it can be used to change the program in order to guarantee correctness."
  },
  {
    "Title": "The optimal fixedpoint of recursive programs",
    "URL": "https://dl.acm.org/doi/10.1145/800116.803769",
    "Full Abstract": "In this paper a new fixedpoint approach towards the semantics of recursive programs is presented. The fixedpoint defined by a recursive program under this semantics contains, in some sense, the maximal amount of “interesting” information which can be extracted from the program. This optimal fixedpoint (which always uniquely exists) may be strictly more defined than the program's least fixedpoint. We consider both the theoretical and the computational aspects of the approach, as well as some techniques for proving properties of the optimal fixedpoint of a given recursive program."
  },
  {
    "Title": "Translating Program Schemas to While-Schemas",
    "URL": "https://dl.acm.org/doi/10.1137/0204011",
    "Full Abstract": "While-schemas are defined as program schemas without goto statements, in which iteration is achieved using while statements. We present two translations of program schemas into equivalent while-schemas, the first one by adding extra program variables, and the second one by adding extra logical variables. In both cases we aim to preserve as much of the structure of the original program schemas as possible."
  },
  {
    "Title": "Knowledge and reasoning in program synthesis",
    "URL": "https://dl.acm.org/doi/10.5555/1624626.1624670",
    "Full Abstract": "Prograin synthesis is the construction of a computer program from given specifications. An automatic program synthesis system must combine reasoning and programming ability with a good deal of knowledge about the subject matter of the program. This ability and knowledge must be manifested both procedurally (by programs) and structurally (by choice of representation)."
  },
  {
    "Title": "A new approach to recursive programs.",
    "URL": "https://dl.acm.org/doi/book/10.5555/892089",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "The theoretical aspects of the optimal fixedpoint",
    "URL": "https://dl.acm.org/doi/book/10.5555/892093",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Logical analysis of programs",
    "URL": "https://dl.acm.org/doi/10.1145/360032.360048",
    "Full Abstract": "Most present systems for verification of computer programs are incomplete in that intermediate inductive assertions must be provided manually by the user, termination is not proven, and incorrect programs are not treated. As a unified solution to these problems, this paper suggests conducting a logical analysis of programs by using invariants which express what is actually occurring in the program."
  },
  {
    "Title": "The Theoretical Aspects of the Optimal Fixedpoint",
    "URL": "https://dl.acm.org/doi/10.1137/0205033",
    "Full Abstract": "In this paper we define a new type of fixedpoint of recursive definitions and investigate some of its properties. This optimal fixedpoint (which always uniquely exists) contains, in some sense, the maximal amount of “interesting” information which can be extracted from the recursive definition, and it may be strictly more defined than the program’s least fixedpoint. This fixedpoint can be the basis for assigning a new semantics to recursive programs."
  },
  {
    "Title": "Is “sometime” sometimes better than “always”?",
    "URL": "https://dl.acm.org/doi/10.5555/800253.807645",
    "Full Abstract": "This paper explores a technique for proving the correctness and termination of programs simultaneously. This approach, which we call the"
  },
  {
    "Title": "The evolution of programs: a system for automatic program modification",
    "URL": "https://dl.acm.org/doi/book/10.5555/892128",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Studies in Automatic Programming Logic",
    "URL": "https://dl.acm.org/doi/book/10.5555/578683",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Studies in Automatic Programming Logic",
    "URL": "https://dl.acm.org/doi/book/10.5555/578684",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "The evolution of programs",
    "URL": "https://dl.acm.org/doi/10.1145/512950.512964",
    "Full Abstract": "A programmer spends more time modifying already existing programs than constructing original ones. An attempt is made to formulate techniques of program modification, whereby a program that achieves one result can be transformed into a new program that uses the same principles to achieve a different goal. For example, a program that uses the binary search paradigm to divide two numbers may be modified to calculate the square-root of a number in a similar manner.Program debugging is considered as a special case of modification if a program computers wrong results, it must be modified to achieve the intended results The application of abstract program schemata to concrete problems is also viewed from the perspective of modification techniques.We, have embedded this approach in a running implementation; our methods are illustrated with several examples that have been performed by it."
  },
  {
    "Title": "Is \"sometime\" sometimes better than \"always\"? Intermittent assertions in proving program correctness",
    "URL": "https://dl.acm.org/doi/book/10.5555/892103",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "The convergence of functions to fixedpoints of recursive definitions",
    "URL": "https://dl.acm.org/doi/book/10.5555/892143",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "The automatic synthesis of recursive programs",
    "URL": "https://dl.acm.org/doi/10.1145/872734.806929",
    "Full Abstract": "We describe a deductive technique for the automatic construction of recursive programs to meet given input-output specifications. These specifications express what conditions the output of the desired program is expected to satisfy. The deductive technique involves transforming the specifications by a collection of rules, summoned by pattern-directed function invocation. Some of these transformation rules express the semantics of the subject domain; others represent more general programming techniques. The rules that introduce conditional expressions and recursive calls into the program are discussed in some detail."
  },
  {
    "Title": "Formalization of Properties of Functional Programs",
    "URL": "https://dl.acm.org/doi/10.1145/321592.321606",
    "Full Abstract": "The problems of convergence, correctness, and equivalence of computer programs can be formulated by means of the satisfiability or validity of certain first-order formulas. An algorithm is presented for constructing such formulas for functional programs, i.e. programs defined by LISP-like conditional recursive expressions."
  },
  {
    "Title": "Towards automatic program synthesis",
    "URL": "https://dl.acm.org/doi/book/10.5555/891872",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "The translation of ''go to'' programs to ''while'' programs",
    "URL": "https://dl.acm.org/doi/book/10.5555/891881",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Toward automatic program synthesis",
    "URL": "https://dl.acm.org/doi/10.1145/362566.362568",
    "Full Abstract": "An elementary outline of the theorem-proving approach to automatic program synthesis is given, without dwelling on technical details. The method is illustrated by the automatic construction of both recursive and iterative programs operating on natural numbers, lists, and trees."
  },
  {
    "Title": "Decidable properties of monadic functional schemas",
    "URL": "https://dl.acm.org/doi/book/10.5555/891910",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Computation of recursive programs",
    "URL": "https://dl.acm.org/doi/10.1145/1478873.1478902",
    "Full Abstract": "This note is actually an informal exposition of a part of a recent paper by Manna, Ness and Vuillemin. We have two main purposes in this note. First, we present some known results about computation of recursive programs, emphasizing some differences between the theoretical and practical approaches. Second, we introduce the computational induction method for proving properties of recursive programs. It turns out that most known methods for proving properties of programs are very closely related to the computational induction method. We illustrate this point by showing how Floyd's inductive assertions method for proving properties of \"flowchart programs\" can be expressed in terms of computational induction on recursive programs."
  },
  {
    "Title": "Program schemas with equality",
    "URL": "https://dl.acm.org/doi/book/10.5555/891927",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Recursive definitions of partial functions and their computations",
    "URL": "https://dl.acm.org/doi/10.1145/942578.807072",
    "Full Abstract": "The object of this paper is to present a syntactic and semantic model for recursive definitions, and to study the relation between their computed functions and their fixpoints. The recursive definitions that we consider are syntactic generalizations of those introduced in [2] by Kleene and in [5] by McCarthy."
  },
  {
    "Title": "Inductive methods for proving properties of programs",
    "URL": "https://dl.acm.org/doi/10.1145/942580.807070",
    "Full Abstract": "We have two main purposes in this paper. First, we clarify and extend known results about computation of recursive programs, emphasizing the difference between the theoretical and practical approaches. Secondly, we present and examine various known methods for proving properties of recursive programs. We discuss in detail two powerful inductive methods, computational induction and structural induction, illustrating their applications by various examples. We also briefly discuss some other related methods."
  },
  {
    "Title": "Fixpoint approach to the theory of computation.",
    "URL": "https://dl.acm.org/doi/book/10.5555/891944",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Program schemas with equality",
    "URL": "https://dl.acm.org/doi/10.1145/800152.804896",
    "Full Abstract": "We discuss the class of program schemas augmented with equality tests, that is, tests of equality between terms."
  },
  {
    "Title": "Fixpoint approach to the theory of computation",
    "URL": "https://dl.acm.org/doi/10.1145/361454.361460",
    "Full Abstract": "Following the fixpoint theory of Scott, the semantics of computer programs are defined in terms of the least fixpoints of recursive programs. This allows not only the justification of all existing verification techniques, but also their extension to the handling, in a uniform manner of various properties of computer programs, including correctness, termination, and equivalence."
  },
  {
    "Title": "On the power of programming features.",
    "URL": "https://dl.acm.org/doi/book/10.5555/891979",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "A heuristic approach to program verification.",
    "URL": "https://dl.acm.org/doi/book/10.5555/891986",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Decidable Properties of Monadic Functional Schemas",
    "URL": "https://dl.acm.org/doi/10.1145/321765.321780",
    "Full Abstract": "A class of (monadic) functional schemas which properly includes “Ianov” flowchart schemas is defined. It is shown that the termination, divergence, and freedom problems for functional schemas are decidable. Although it is possible to translate a large class of non-free functional schemas into equivalent free functional schemas, it is shown that in general this cannot be done. It is also shown that the equivalence problem for free functional schemas is decidable. Most of the results are obtained from well-known results in formal languages and automata theory."
  },
  {
    "Title": "Axiomatic approach to total correctness of programs.",
    "URL": "https://dl.acm.org/doi/book/10.5555/891989",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Termination of algorithms",
    "URL": "https://dl.acm.org/doi/book/10.5555/904866",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Properties of Programs and the First-Order Predicate Calculus",
    "URL": "https://dl.acm.org/doi/10.1145/321510.321516",
    "Full Abstract": "This paper is concerned with the relationship of the termination problem for programs and abstract programs to the validity of certain formulas in the first-order predicate calculus. By exploiting this relationship, subclasses of abstract programs for which the termination problem is decidable can be isolated. Moreover, known proof procedures for the first-order predicate calculus (e.g. resolution) can be applied to prove the termination of both programs and abstract programs. The correctness and equivalence problems of abstract programs are shown to be reducible to the termination problem."
  },
  {
    "Title": "Formalization of properties of recursively defined functions",
    "URL": "https://dl.acm.org/doi/10.1145/800169.805434",
    "Full Abstract": "This paper is concerned with the relationship between the convergence, correctness and equivalence of recursively defined functions and the satisfiability (or unsatisfiability) of certain first-order formulas."
  },
  {
    "Title": "Second-order mathematical theory of computation",
    "URL": "https://dl.acm.org/doi/10.1145/800161.805161",
    "Full Abstract": "In this work we show that it is possible to formalize all properties regularly observed in (deterministic and non-deterministic) algorithms in second-order predicate calculus."
  },
  {
    "Title": "Inductive methods for proving properties of programs",
    "URL": "https://dl.acm.org/doi/10.1145/355609.362336",
    "Full Abstract": "There are two main purposes in this paper: first, clarification and extension of known results about computation of recursive programs, with emphasis on the difference between the theoretical and practical approaches; second, presentation and examination of various known methods for proving properties of recursive programs. Discussed in detail are two powerful inductive methods, computational induction and structural induction, including examples of their applications."
  },
  {
    "Title": "A heuristic approach to program verification",
    "URL": "https://dl.acm.org/doi/10.5555/1624775.1624837",
    "Full Abstract": "We present various heuristic techniques for use in proving the correctness of computer programs. The techniques are designed to obtain automatically the \"inductive assertions\" attached to the loops of the program which previously required human \"understanding\" of the program's performance. We distinguish between two general approaches: one in which we obtain the inductive assertion by analyzing predicates which are known to be true at the entrances and exits of the loop (top-down approach), and another in which we generate the inductive assertion directly from the statements of the loop (bottom-up approach)."
  },
  {
    "Title": "Knowledge and Reasoning in Program Synthesis",
    "URL": "https://dl.acm.org/doi/10.5555/647950.742874",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Introduction to Mathematical Theory of Computation",
    "URL": "https://dl.acm.org/doi/book/10.5555/542899",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "The logic of computer programming",
    "URL": "https://dl.acm.org/doi/book/10.5555/892142",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "The automatic synthesis of systems of recursive programs",
    "URL": "https://dl.acm.org/doi/10.5555/1624435.1624526",
    "Full Abstract": "A technique is presented for constructing, a program from given specifications. The basic approach is to transform the specifications repeatedly, according to certain rules, until the desired program is produced. Two important transformation rules are those responsible for introducing conditional expressions and recursion into the target program. These transformations have been introduced in previous publications, and are discussed here briefly."
  },
  {
    "Title": "Inference rules for program annotation",
    "URL": "https://dl.acm.org/doi/book/10.5555/892155",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "The optimal approach to recursive programs",
    "URL": "https://dl.acm.org/doi/10.1145/359863.359885",
    "Full Abstract": "The classical fixedpoint approach toward recursive programs suggests choosing the “least defined fixedpoint” as the most appropriate solution to a recursive program. A new approach is described which introduces an “optimal fixedpoint,” which, in contrast to the least defined fixedpoint, embodies the maximal amount of valuable information embedded in the program. The practical implications of this approach are discussed and techniques for proving properties of optimal fixedpoints are given. The presentation is informal, with emphasis on examples."
  },
  {
    "Title": "Verification of concurrent programs, Part I: The temporal framework",
    "URL": "https://dl.acm.org/doi/book/10.5555/892270",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Verification of concurrent programs: proving eventualities by well-founded ranking",
    "URL": "https://dl.acm.org/doi/book/10.5555/892275",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "How to cook a temporal proof system for your pet language",
    "URL": "https://dl.acm.org/doi/10.1145/567067.567082",
    "Full Abstract": "An abstract temporal proof system is presented whose program-dependent part has a high-level interface with the programming language actually studied. Given a new language, it is sufficient to deline the interface notions of atomic transitions, justice, and fairness in order to obtain a full temporal proof system for this language. This construction is particularly useful for the analysis of concurrent systems. We illustrate the construction on the shared-variable model and on CSP. The generic proof system is shown to be relatively complete with respect to pure first-order temporal logic."
  },
  {
    "Title": "Nonclausal Temporal Deduction",
    "URL": "https://dl.acm.org/doi/10.5555/648065.747731",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Special Relations in Automated Deduction",
    "URL": "https://dl.acm.org/doi/10.5555/646239.683367",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "The origin of the binary-search paradigm",
    "URL": "https://dl.acm.org/doi/10.5555/1625135.1625176",
    "Full Abstract": "In a binary-search algorithm for the computation of a numerical function, the interval in which the desired output is sought is divided in half at each iteration. The paper considers how such algorithms might be derived from their specifications by an automatic program-synthesis system. The derivation of the binary-search concept has been found to be surprisingly straightforward. The programs obtained, though reasonably simple and efficient, are quite different from those that would have been constructed by informal means."
  },
  {
    "Title": "Deduction with Relation Matching",
    "URL": "https://dl.acm.org/doi/10.5555/646823.706894",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "The anchored version of the temporal framework",
    "URL": "https://dl.acm.org/doi/10.5555/648140.749663",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Specification and Verification of Concurrent Programs by For-All Automata",
    "URL": "https://dl.acm.org/doi/book/10.5555/892457",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Completing the Temporal Picture",
    "URL": "https://dl.acm.org/doi/10.5555/646243.681453",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Temporal logic programming",
    "URL": "https://dl.acm.org/doi/10.1016/S0747-7171%2889%2980070-7",
    "Full Abstract": "Temporal logic, often used as a specification language for programs, can serve directly as a programming language. We propose a specific programming language TEMPLOG, which extends the classical PROLOG-like languages to include temporal operators. PROLOG progams are collections of classical Horn clauses and they are efficiently interpreted by SLD-resolution. Similarly, TEMPLOG programs are collections of temporal Horn clauses and we interpret them with temporal SLD-resolution, a restricted form of a general temporal resolution method."
  },
  {
    "Title": "Temporal proof methodologies for real-time systems",
    "URL": "https://dl.acm.org/doi/book/10.5555/892514",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Monotonicity properties in automated deduction",
    "URL": "https://dl.acm.org/doi/10.5555/132218.132234",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "The temporal logic of reactive and concurrent systems",
    "URL": "https://dl.acm.org/doi/book/10.5555/128869",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "The Special-Relation Rules are Incomplete",
    "URL": "https://dl.acm.org/doi/10.5555/648230.752615",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "What Good Are Digital Clocks?",
    "URL": "https://dl.acm.org/doi/10.5555/646246.684870",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Characterization of Temporal Property Classes",
    "URL": "https://dl.acm.org/doi/10.5555/646246.684871",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Sharing memory in distributed systems—methods and applications",
    "URL": "https://dl.acm.org/doi/book/10.5555/37653",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Algorithms for the compilation of regular expressions into PLAs",
    "URL": "https://dl.acm.org/doi/10.1007/BF01840364",
    "Full Abstract": "The language of regular expressions is a useful one for specifying certain sequential processes at a very high level. They allow easy modification of designs for circuits, like controllers, that are described by patterns of events they must recognize and the responses they must make to those patterns. This paper discusses the compilation of such expressions into specifications for programmable logic arrays (PLAs) that will implement the required function. A regular expression is converted into a nondeterministic finite automaton, and then the automaton states are encoded as values on wires that are inputs and outputs of a PLA. The translation of regular expressions into nondeterministic automata by two different methods is discussed, along with the advantages of each method. A major part of the compilation problem is selection of good state codes for the nondeterministic automata; one successful strategy and its application to microcode compaction is explained in the paper."
  },
  {
    "Title": "Parallel hashing",
    "URL": "https://dl.acm.org/doi/10.1145/48014.350550",
    "Full Abstract": "Copyright © 1988 ACM."
  },
  {
    "Title": "Bounds on the cover time",
    "URL": "https://dl.acm.org/doi/10.1109/SFCS.1988.21964",
    "Full Abstract": "A particle that moves on a connected unidirected graph G with n vertices is considered. At each step the particle goes from the current vertex to one of its neighbors, chosen uniformly at random. The cover time is the first time when the particle has visited all the vertices in the graph, starting from a given vertex. Upper and lower bounds are presented that relate the expected cover time for a graph to the eigenvalues of the Markov chain that describes the above random walk. An interesting consequence is that regular expander graphs have expected cover time theta (n log n)."
  },
  {
    "Title": "Dynamic perfect hashing",
    "URL": "https://dl.acm.org/doi/10.1109/SFCS.1988.21968",
    "Full Abstract": "A randomized algorithm is given for the dictionary problem with O(1) worst-case time for lookup and O(1) amortized expected time for insertion and deletion. An Omega (log n) lower bound is proved for the amortized worst-case time complexity of any deterministic algorithm in a class of algorithms encompassing realistic hashing-based schemes. If the worst-case lookup time is restricted to k, then the lower bound for insertion becomes Omega (kn/sup 1/k/)."
  },
  {
    "Title": "Competitive snoopy caching",
    "URL": "https://dl.acm.org/doi/10.1007/BF01762111",
    "Full Abstract": "In a snoopy cache multiprocessor system, each processor has a cache in which it stores blocks of data. Each cache is connected to a bus used to communicate with the other caches and with main memory. Each cache monitors the activity on the bus and in its own processor and decides which blocks of data to keep and which to discard. For several of the proposed architectures for snoopy caching systems, we present new on-line algorithms to be used by the caches to decide which blocks to retain and which to drop in order to minimize communication over the bus. We prove that, for any sequence of operations, our algorithms' communication costs are within a constant factor of the minimum required for that sequence; for some of our algorithms we prove that no on-line algorithm has this property with a smaller constant."
  },
  {
    "Title": "Trading space for time in undirected ",
    "URL": "https://dl.acm.org/doi/10.1145/73007.73059",
    "Full Abstract": "Aleliunas"
  },
  {
    "Title": "Multilevel adaptive hashing",
    "URL": "https://dl.acm.org/doi/10.5555/320176.320181",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Competitive randomized algorithms for non-uniform problems",
    "URL": "https://dl.acm.org/doi/10.5555/320176.320216",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Asymptotically tight bounds for computing with faulty arrays of processors",
    "URL": "https://dl.acm.org/doi/10.1109/FSCS.1990.89547",
    "Full Abstract": "The computational power of 2-D and 3-D processor arrays that contain a potentially large number of faults is analyzed. Both a random and a worst-case fault model are considered, and it is proved that in either scenario low-dimensional arrays are surprisingly fault tolerant. It is also shown how to route, sort, and perform systolic algorithms for problems such as matrix multiplication in optimal time on faulty arrays. In many cases, the running time is the same as if there were no faults in the array (up to constant factors). On the negative side, it is shown that any constant congestion embedding of an n*n fault-free array on an n*n array with Theta (n/sup 2/) random faults (or Theta (log n) worst-case faults) requires dilation Theta (log n). For 3-D arrays, knot theory is used to prove that the required dilation is Omega ( square root log n)."
  },
  {
    "Title": "On the parallel complexity of evaluating game trees",
    "URL": "https://dl.acm.org/doi/10.5555/127787.127858",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Empirical studies of competitve spinning for a shared-memory multiprocessor",
    "URL": "https://dl.acm.org/doi/10.1145/121132.286599",
    "Full Abstract": "A common operation in multiprocessor programs is acquiring a lock to protect access to shared data. Typically, the requesting thread is blocked if the lock it needs is held by another thread. The cost of blocking one thread and activating another can be a substantial part of program execution time. Alternatively, the thread could spin until the lock is free, or spin for a while and then block. This may avoid context-switch overhead, but processor cycles may be wasted in unproductive spinning. This paper studies seven strategies for determining whether and how long to spin before blocking. Of particular interest are"
  },
  {
    "Title": "Factors in the performance of the AN1 computer network",
    "URL": "https://dl.acm.org/doi/10.1145/133057.133102",
    "Full Abstract": "AN1 (formerly known as Autonet) is a local area network composed of crossbar switches interconnected by 100Mbit/second, full-duplex links. In this paper, we evaluate the performance impact of certain choices in the AN1 design. These include the use of FIFO input buffering in the crossbar switch, the deadlock-avoidance mechanism, cut-through routing, back-pressure for flow control, and multi-path routing. AN1's performance goals were to provide low latency and high bandwidth in a lightly loaded network. In this it is successful. Under heavy load, the most serious impediment to good performance is the use of FIFO input buffers. The deadlock-avoidance technique has an adverse effect on the performance of some topologies, but it seems to be the best alternative, given the goals and constraints of the AN1 design. Cut-through switching performs well relative to store-and-forward switching, even under heavy load. Back-pressure deals adequately with congestion in a lightly-loaded network; under moderate load, performance is acceptable when coupled with end-to-end flow control for bursts. Multi-path routing successfully exploits redundant paths between hosts to improve performance in the face of congestion."
  },
  {
    "Title": "Biased random walks",
    "URL": "https://dl.acm.org/doi/10.1145/129712.129713",
    "Full Abstract": "How much can an imperfect source of randomness affect an algorithm? We examine several simple questions of this type concerning the long-term behavior of a random walk on a finite graph. In our setup, each step of the random walk a “controller” can, with a certain small probability, fix the next step, thus introducing a bias. We analyze the extent to which the bias can affect the limit behavior of the walk. The controller is assumed to associate a real, nonnegative, “benefit” with each state, and to strive to maximize the long-term expected benefit. We derive tight bounds on the maximum of this objective function over all controller's strategies, and present polynomial time algorithms for computing the optimal controller strategy."
  },
  {
    "Title": "Strongly competitive algorithms for paging with locality of reference",
    "URL": "https://dl.acm.org/doi/10.5555/139404.139455",
    "Full Abstract": "What is the best paging algorithm if one has partial information about the possible sequences of page requests? We give a partial answer to this question, by presenting the analysis of strongly competitive paging algorithms in the access graph model. This model restricts page requests so that they conform to a notion of locality of reference, given by an arbitrary access graph."
  },
  {
    "Title": "On-line load balancing",
    "URL": "https://dl.acm.org/doi/10.1109/SFCS.1992.267770",
    "Full Abstract": "The setup for the authors' problem consists of n servers that must complete a set of tasks. Each task can be handled only by a subset of the servers, requires a different level of service, and once assigned can not be re-assigned. They make the natural assumption that the level of service is known at arrival time, but that the duration of service is not. The on-line load balancing problem is to assign each task to an appropriate server in such a way that the maximum load on the servers is minimized. The authors derive matching upper and lower bounds for the competitive ratio of the on-line greedy algorithm for this problem, namely /sup (3n)2/3///sub 2/(1+o(1)), and derive a lower bound, Omega ( square root n), for any other deterministic or randomized on-line algorithm."
  },
  {
    "Title": "Markov paging",
    "URL": "https://dl.acm.org/doi/10.1109/SFCS.1992.267771",
    "Full Abstract": "This paper considers the problem of paging under the assumption that the sequence of pages accessed is generated by a Markov chain. The authors use this model to study the fault-rate of paging algorithms, a quantity of interest to practitioners. They first draw on the theory of Markov decision processes to characterize the paging algorithm that achieves optimal fault-rate on any Markov chain. They address the problem of efficiently devising a paging strategy with low fault-rate for a given Markov chain. They show that a number of intuitively good approaches fail. Their main result is an efficient procedure that, on any Markov chain, will give a paging algorithm with fault-rate at most a constant times optimal. Their techniques also show that some algorithms that do poorly in practice fail in the Markov setting, despite known (good) performance guarantees when the requests are generated independently from a probability distribution."
  },
  {
    "Title": "Trading Space for Time in Undirected $s-t$ Connectivity",
    "URL": "https://dl.acm.org/doi/10.1137/S0097539790190144",
    "Full Abstract": "Aleliunas et al. [20th Annual Symposium on Foundations of Computer Science, IEEE Computer Society Press, Los Alamitos, CA, 1979, pp. 218--223] posed the following question: \"The reachability problem for undirected graphs can be solved in log space and $O(mn)$ time [$m$ is the number of edges and $n$ is the number of vertices] by a probabilistic algorithm that simulates a random walk, or in linear time and space by a conventional deterministic graph traversal algorithm. Is there a spectrum of time-space trade-offs between these extremes?\" This question is answered in the affirmative for sparse graphs by presentation of an algorithm that is faster than the random walk by a factor essentially proportional to the size of its workspace. For denser graphs, this algorithm is faster than the random walk but the speed-up factor is smaller."
  },
  {
    "Title": "On the fault tolerance of the butterfly",
    "URL": "https://dl.acm.org/doi/10.1145/195058.195117",
    "Full Abstract": "Copyright © 1994 ACM."
  },
  {
    "Title": "On the average-case complexity of selecting the k-th best",
    "URL": "https://dl.acm.org/doi/book/10.5555/892214",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Some complexity questions related to distributive computing(Preliminary Report)",
    "URL": "https://dl.acm.org/doi/10.1145/800135.804414",
    "Full Abstract": "Let"
  },
  {
    "Title": "Should tables by sorted?",
    "URL": "https://dl.acm.org/doi/book/10.5555/892229",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "The Complexity of Pattern Matching for a Random String",
    "URL": "https://dl.acm.org/doi/10.1137/0208029",
    "Full Abstract": "We study the average-case complexity of finding all occurrences of a given pattern $\\alpha $ in an input text string. Over an alphabet of"
  },
  {
    "Title": "On the time-space tradeoff for sorting with linear queries",
    "URL": "https://dl.acm.org/doi/book/10.5555/892226",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Some monotonicity properties of partial orders",
    "URL": "https://dl.acm.org/doi/book/10.5555/892231",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Storing a sparse table",
    "URL": "https://dl.acm.org/doi/10.1145/359168.359175",
    "Full Abstract": "The problem of storing and searching large sparse tables is ubiquitous in computer science. The standard technique for storing such tables is hashing, but hashing has poor worst-case performance. We propose a good worst-case method for storing a static table of"
  },
  {
    "Title": "External Hashing Schemes for Collections of Data Structures",
    "URL": "https://dl.acm.org/doi/10.1145/322169.322177",
    "Full Abstract": "Copyright © 1980 ACM."
  },
  {
    "Title": "New Algorithms for Bin Packing",
    "URL": "https://dl.acm.org/doi/10.1145/322186.322187",
    "Full Abstract": "In the bin-packing problem a list"
  },
  {
    "Title": "On the parallel computation for the knapsack problem",
    "URL": "https://dl.acm.org/doi/book/10.5555/892256",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Information Bounds Are Weak in the Shortest Distance Problem",
    "URL": "https://dl.acm.org/doi/10.1145/322203.322206",
    "Full Abstract": "Copyright © 1980 ACM."
  },
  {
    "Title": "Bounds on Selection Networks",
    "URL": "https://dl.acm.org/doi/10.1137/0209043",
    "Full Abstract": "We investigate the complexity of network selection by measuring it in terms of $U(t,N)$, the minimum number of comparators needed, and $T(t,N)$, the minimum delay time possible, for networks selecting the smallest"
  },
  {
    "Title": "On the security of public key protocols",
    "URL": "https://dl.acm.org/doi/book/10.5555/891726",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Optimal Expected-Time Algorithms for Closest Point Problems",
    "URL": "https://dl.acm.org/doi/10.1145/355921.355927",
    "Full Abstract": "Copyright © 1980 ACM."
  },
  {
    "Title": "On the parallel computation for the knapsack problem",
    "URL": "https://dl.acm.org/doi/10.1145/800076.802465",
    "Full Abstract": "We are interested in the complexity of solving the knapsack problem with"
  },
  {
    "Title": "The entropic limitations on VLSI computations(Extended Abstract)",
    "URL": "https://dl.acm.org/doi/10.1145/800076.802483",
    "Full Abstract": "In this paper we will explore the limitations imposed by entropic constraints, both in generality and for specific problems. We list below the main questions that we will address."
  },
  {
    "Title": "A study of concrete computational complexity.",
    "URL": "https://dl.acm.org/doi/book/10.5555/907570",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "On computing the minima of quadratic forms (Preliminary Report)",
    "URL": "https://dl.acm.org/doi/10.1145/800116.803749",
    "Full Abstract": "The following problem was recently raised by C. William Gear [1]: Let F(x"
  },
  {
    "Title": "Addition chains with multiplicative cost",
    "URL": "https://dl.acm.org/doi/book/10.5555/892092",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "On the average behavior of set merging algorithms (Extended Abstract)",
    "URL": "https://dl.acm.org/doi/10.1145/800113.803648",
    "Full Abstract": "In this paper we study the expected running time of a variety of algorithms that perform set merging. The set merging problem (for example, see AHU [1]) is concerned with using suitable data structures to represent partition of a set S = { 1,2, ....,n} so that a sequence of instructions of the form “x Ξ y”, meaning"
  },
  {
    "Title": "Lower Bounds on Merging Networks",
    "URL": "https://dl.acm.org/doi/10.1145/321958.321976",
    "Full Abstract": "Let"
  },
  {
    "Title": "K + 1 heads are better than K",
    "URL": "https://dl.acm.org/doi/10.1109/SFCS.1976.18",
    "Full Abstract": "There are languages which can be recognized by a deterministic (k + 1)-headed oneway finite automaton but which cannot be recognized by a k-headed one-way (deterministic or non-deterministic) finite automaton. Furthermore, there is a language accepted by a 2-headed nondeterministic finite automaton which is accepted by no k-headed deterministic finite automaton."
  },
  {
    "Title": "The complexity of searching an ordered random table",
    "URL": "https://dl.acm.org/doi/10.1109/SFCS.1976.32",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "An Ω(n",
    "URL": "https://dl.acm.org/doi/10.1145/800105.803391",
    "Full Abstract": "Let P be a polyhedron with f"
  },
  {
    "Title": "On the loop switching addressing problem",
    "URL": "https://dl.acm.org/doi/book/10.5555/892151",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "The complexity of pattern matching for a random string",
    "URL": "https://dl.acm.org/doi/book/10.5555/892154",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "A lower bound to palindrome recognition by probabilistic Turing machines",
    "URL": "https://dl.acm.org/doi/book/10.5555/892157",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "On constructing minimum spanning trees in k-dimensional spaces and related problems",
    "URL": "https://dl.acm.org/doi/book/10.5555/892163",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "k",
    "URL": "https://dl.acm.org/doi/10.1145/322063.322076",
    "Full Abstract": "Copyright © 1978 ACM."
  },
  {
    "Title": "New algorithms in bin packing",
    "URL": "https://dl.acm.org/doi/book/10.5555/892175",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Information bounds are weak in the shortest distance problem",
    "URL": "https://dl.acm.org/doi/book/10.5555/892180",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "On the average-case complexity of selecting k-th best",
    "URL": "https://dl.acm.org/doi/10.1109/SFCS.1978.29",
    "Full Abstract": "Let Vk (n) be the minimum average number of pairwise comparisons needed to find the k-th largest of n numbers (k≥2), assuming that all n! orderings are equally likely. D. W. Matula proved that, for some absolute constant c, Vk(n)- n ≤ ck log log n as n → ∞. In the present paper, we show that there exists an absolute constant c′ > 0 such that Vk(n) - n ≥ c′k log log n as n → ∞, proving a conjecture by Matula."
  },
  {
    "Title": "Scheduling Unit-Time Tasks with Limited Resources",
    "URL": "https://dl.acm.org/doi/10.5555/647406.724133",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "An analysis of a memory allocation scheme for implementing stacks",
    "URL": "https://dl.acm.org/doi/book/10.5555/892201",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "On fault-tolerant networks for sorting",
    "URL": "https://dl.acm.org/doi/book/10.5555/892209",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "An analysis of (h,k,l)-shellsort",
    "URL": "https://dl.acm.org/doi/book/10.5555/892211",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "A lower bound to finding convex hulls",
    "URL": "https://dl.acm.org/doi/book/10.5555/891707",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Should Tables Be Sorted?",
    "URL": "https://dl.acm.org/doi/10.1145/322261.322274",
    "Full Abstract": "Copyright © 1981 ACM."
  },
  {
    "Title": "A Lower Bound to Finding Convex Hulls",
    "URL": "https://dl.acm.org/doi/10.1145/322276.322289",
    "Full Abstract": "Copyright © 1981 ACM."
  },
  {
    "Title": "On the security of public key protocols",
    "URL": "https://dl.acm.org/doi/10.1109/SFCS.1981.32",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Space-time tradeoff for answering range queries (Extended Abstract)",
    "URL": "https://dl.acm.org/doi/10.1145/800070.802185",
    "Full Abstract": "In this paper, we raise and investigate the question of (storage) space- (retrieval) time tradeoff for a static database, in the general framework of Fredman's. As will be seen, such tradeoff results also lead to lower bounds on the complexity of processing a sequence of m INSERT and QUERY instructions. The latter results are incomparable to Fredman's, since the presence of DELETE instructions was crucial for his proof technique. We will present our results in detail in the next few sections. Here we will only mention three main conclusions. Firstly, circular query is shown to be intrinsically hard in the sense that, for some static database with n records, there is a space-time tradeoff TS > n"
  },
  {
    "Title": "A Microprogrammed Intelligent Graphics Terminal",
    "URL": "https://dl.acm.org/doi/10.1109/T-C.1971.223346",
    "Full Abstract": "This paper describes a small computer, Interdata Model 3, that has been microprogrammed to serve as an intelligent terminal. The Interdata is connected to a System/360 multiplexor channel with a high-speed interface, and uses an ARDS direct view storage tube as a display console. The new Interdata target machine is patterned after the /360 (including all five instruction formats), but also has instructions particularly designed for intelligent terminal programming. These include instructions for character string manipulation, code conversion, list processing, coordinate manipulation, and virtual addressing. A powerful multiplexor channel, which allows the programmer to \"overlap\" I/O to several devices with a CPU program, has also been microprogrammed."
  },
  {
    "Title": "On-line Text Editing: A Survey",
    "URL": "https://dl.acm.org/doi/10.1145/356589.356591",
    "Full Abstract": "This paper is a survey of current methods for the on-line creation and editing of computer programs and of ordinary manuscripts text. The characteristics of on-line editing systems are examined and examples of various implementations are described in three categories: program editors, text editors, and terminals with local editing facilities."
  },
  {
    "Title": "Language for Systems Development",
    "URL": "https://dl.acm.org/doi/10.1145/800234.807060",
    "Full Abstract": "Well-designed efficient systems programming languages are an absolute necessity if programmers are to keep pace with the demand for systems. This paper presents briefly some criteria to be applied to the design of a general purpose systems programming language and a description of the Language for Systems Development that is being implemented at Brown University for the IBM S/360. The paper is a revised and condensed version of a much larger survey paper [3]. The research and writing of this paper and the design of LSD were partially supported by a National Science Foundation grant (No. GJ-181) and by Brown University. We would like to acknowledge the help and invaluable suggestions given us by Richard Wexelblat of Bell Laboratories, Robert Balzer of the RAND Corporation, John Brackett and Douglas Ross of Softech, Inc., and Robert Rosin of the State University of New York at Buffalo. Special thanks should be given to Paul Knueven of Digital Equipment Corporation who helped initiate the entire effort and has been a source of help and encouragement through many iterations. The authors would also like to thank Frank Tompa of the University of Toronto and Diane Shecter who were among the original designers of LSD."
  },
  {
    "Title": "Microprogramming for computer graphics",
    "URL": "https://dl.acm.org/doi/10.1145/1316535.1316536",
    "Full Abstract": "Interactive computer graphics (graphics) is the construction, storage, retrieval, manipulation, alteration and analysis of pictorial data, using an on-line display console with manual input (interaction) devices. Among such input devices are the alphanumeric and function keyboards for typing text and activating preprogrammed subroutines respectively, and the light pen and data tablet for identifying and entering graphic data by means of pointing and drawing."
  },
  {
    "Title": "Computer assisted tracing of text evolution",
    "URL": "https://dl.acm.org/doi/10.1145/1479064.1479160",
    "Full Abstract": "Many situations exist in which convenient access to the detailed evolutionary information associated with a text's development is desirable:"
  },
  {
    "Title": "Intelligent satellites for interactive graphics",
    "URL": "https://dl.acm.org/doi/10.1145/1499586.1499655",
    "Full Abstract": "In the last four or five years it has become increasingly fashionable to speak of \"intelligent,\" \"smart,\" or \"programmable\" terminals and systems. Very few mainframe or peripheral manufacturers omit such a device from their standard product line. Although \"intelligence,\" like beauty or pornography, is in the eye of the beholder, the adjective generally connotes that the device has a degree of autonomy or processing ability which allows it to perform certain (classes of) tasks without assistance from the mainframe to which it is connected. Many such devices are programmable by virtue of including a mini, microprogrammable or micro computer."
  },
  {
    "Title": "Computer architecture and instruction set design",
    "URL": "https://dl.acm.org/doi/10.1145/1499586.1499720",
    "Full Abstract": "A group of computer scientists and mathematicians at Brown University has been engaged in the study of computer graphics for the past eight years. During the course of these studies a variety of topics has been investigated, in particular, during the last few years, the use of microprogramming for implementing graphics systems. In early 1971, Professor Andries van Dam and his associates submitted a threefold research proposal to the National Science Foundation."
  },
  {
    "Title": "Operating system design considerations for microprogrammed mini-computer satellite systems",
    "URL": "https://dl.acm.org/doi/10.1145/1499586.1499724",
    "Full Abstract": "The operating system described in this paper was developed as part of research sponsored by The National Science Foundation and the Office of Naval Research on satellite processing and symbolic debugging of data structures. This system runs on a small (32K bytes), dual processor, microprogrammable computer equipped with a high-speed graphic display unit and attached in satellite mode to the multiplexor channel of an IBM System/360-67."
  },
  {
    "Title": "A survey of introductory and advanced programming courses",
    "URL": "https://dl.acm.org/doi/10.1145/800183.810465",
    "Full Abstract": "In the process of establishing equitable and practical computer time allocations for our computer science courses this fall, we compared our seemingly high request with standards in other universities. Twenty-three private and state universities were chosen for the comparison and a questionnaire (appendix 1) was designed to elicit information about large introductory programming courses and more specialized systems programming/software engineering courses."
  },
  {
    "Title": "Design considerations for microprogramming languages",
    "URL": "https://dl.acm.org/doi/10.1145/1217149.1217152",
    "Full Abstract": "The growing acceptance of user-microprogrammable computers indicates that microprogramming, as a discipline, will require development of user-oriented microprogramming support. A number of approaches (definition of sophisticated target machines, microcode assemblers, and higher level microprogramming languages) have been proposed. The issues involved in choosing support tools include the range of proposed applications, hardware parallelism (horizental or minimally encoded control vs. vertically encoded control) and constraints on performance. After reviewing some of these tradeoffs, design considerations for higher level microprogramming languages are considered. One of the most important design decisions is fixing the level of the language, defined on a continuum from symbolic assemblers, through general purpose programming languages such as PL/I. A tailored language concept is defined and illustrated, using as an example a microprogramming language for a horizontally encoded microprogrammable computer currently under development."
  },
  {
    "Title": "Annotation-Based Deduction in Temporal Logic",
    "URL": "https://dl.acm.org/doi/10.5555/645548.659006",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Temporal Proof Methodologies for Timed Transition-Systems",
    "URL": "https://dl.acm.org/doi/10.1006/inco.1994.1060",
    "Full Abstract": "We extend the specification language of temporal logic, the corresponding verification framework, and the underlying computational model to deal with real-;time properties of reactive systems. The abstract notion of timed transition systems generalizes traditional transition systems conservatively: qualitative fairness requirements are replaced (and superseded) by quantitative lower-bound and upper-bound timing constraints on transitions. This framework can model real-time systems that communicate either through shared variables or by message passing and real-time issues such as timeouts, process priorities (interrupts), and process scheduling. We exhibit two styles for the specification of real-time systems. While the first approach uses time-bounded versions of the temporal operators, the second approach allows explicit references to time through a special clock variable. Corresponding to the two styles of specification, we present and compare two different proof methodologies for the verification of timing requirements that are expressed in these styles. For the bounded-operator style, we provide a set of proof rules for establishing bounded-invariance and bounded-responce properties of timed transition systems. This approach generalizes the standard temporal proof rules for verifying invariance and response properties conservatively. For the explicit-clock style, we exploit the observation that every time-bounded property is a safety property and use the standard temporal proof rules for establishing safety properties."
  },
  {
    "Title": "Continuous Verification by Discrete Reasoning",
    "URL": "https://dl.acm.org/doi/book/10.5555/891763",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Differential BDDs",
    "URL": "https://dl.acm.org/doi/book/10.5555/891764",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Prooving Safety Properties of Hybrid Systems",
    "URL": "https://dl.acm.org/doi/10.5555/646843.706648",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Specification and Verification of Controlled Systems",
    "URL": "https://dl.acm.org/doi/10.5555/646843.706772",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "STeP",
    "URL": "https://dl.acm.org/doi/10.5555/646619.697420",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Verification in Continuous Time by Discrete Reasoning",
    "URL": "https://dl.acm.org/doi/10.5555/646056.678059",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Protocols for secure computations",
    "URL": "https://dl.acm.org/doi/10.5555/1382436.1382751",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Strong signature schemes",
    "URL": "https://dl.acm.org/doi/10.1145/800061.808774",
    "Full Abstract": "The notion of digital signature based on trapdoor functions has been introduced by Diffie and Hellman[3]. Rivest, Shamir and Adleman[8] gave the first number theoretic implementation of a signature scheme based on a trapdoor function. If"
  },
  {
    "Title": "Uniform hashing is optimal",
    "URL": "https://dl.acm.org/doi/book/10.5555/892340",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "On the expected performance of path compression algorithms",
    "URL": "https://dl.acm.org/doi/10.1137/0214010",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "On the Complexity of Maintaining Partial Sums",
    "URL": "https://dl.acm.org/doi/10.1137/0214022",
    "Full Abstract": "Let $F = \\{ ({\\bf r}_i,s_i )|0 \\leqq i < n\\} $ be a file of"
  },
  {
    "Title": "On optimal arrangements of keys with double hashing",
    "URL": "https://dl.acm.org/doi/10.1016/0196-6774%2885%2990042-2",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Uniform hashing is optimal",
    "URL": "https://dl.acm.org/doi/10.1145/3828.3836",
    "Full Abstract": "It was conjectured by J. Ullman that uniform hashing is optimal in its expected retrieval cost among all open-address hashing schemes [4]. In this paper, we show that, for any open-address hashing scheme, the expected cost of retrieving a record from a large table that is α-fraction full is at least (1/α) log (1/(1 - α)) +"
  },
  {
    "Title": "Separating the polynomial-time hierarchy by oracles",
    "URL": "https://dl.acm.org/doi/10.5555/4479.4487",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "A general approach to d-dimensional geometric queries",
    "URL": "https://dl.acm.org/doi/10.1145/22145.22163",
    "Full Abstract": "It is shown that any bounded region in"
  },
  {
    "Title": "Lower bounds to randomized algorithms for graph properties",
    "URL": "https://dl.acm.org/doi/10.1109/SFCS.1987.39",
    "Full Abstract": "For any property P on n-vertex graphs, let C(P) be the minimum number of edges that need to be examined by any decision tree algorithm for determining P. In 1975 Rivest and Vuillemin settled the Aanderra-Rosenberg Conjecture, proving that C(P) = Ω(n2) for every nontrivial monotone graph property P. An intriguing open question is whether the theorem remains true when randomized algorithms are allowed. In this paper we report progress on this problem, showing that Ω(n(log n)1/12) edges must be examined by a randomized algorithm for determining any nontrivial monotone graph property."
  },
  {
    "Title": "Monotone bipartite graph properties are evasive",
    "URL": "https://dl.acm.org/doi/10.1137/0217031",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Computational information theory",
    "URL": "https://dl.acm.org/doi/10.5555/60364.60365",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Circuits and local computation",
    "URL": "https://dl.acm.org/doi/10.1145/73007.73025",
    "Full Abstract": "This paper contains two parts. In Part I, we show that polynomial-size monotone threshold circuits of depth"
  },
  {
    "Title": "On the improbability of reaching Byzantine agreements",
    "URL": "https://dl.acm.org/doi/10.1145/73007.73052",
    "Full Abstract": "It is well known that for the Byzantine Generals Problem, no deterministic protocol can exist for an"
  },
  {
    "Title": "On the complexity of partial order productions",
    "URL": "https://dl.acm.org/doi/10.1137/0218047",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Coherent functions and program checkers",
    "URL": "https://dl.acm.org/doi/10.1145/100216.100226",
    "Full Abstract": "Copyright © 1990 ACM."
  },
  {
    "Title": "Lower bounds to randomized algorithms for graph properties",
    "URL": "https://dl.acm.org/doi/10.1016/0022-0000%2891%2990003-N",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Program checkers for probability generation",
    "URL": "https://dl.acm.org/doi/10.5555/111713.111724",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Toward the development of machine",
    "URL": "https://dl.acm.org/doi/10.1145/1500175.1500301",
    "Full Abstract": "One of the reasons for developing high level languages has been the desire for program portability from one type of machine to another. To achieve the high degree of machine independence necessary for program portability, these languages have included general features such as arithmetic expressions, arrays, and subroutine calls which can be implemented on many machines. Facilities such as the interrupt mechanism, program status word, and device dependent input/output which are available to the assembly language programmer are hidden from the high level programmer. Unfortunately, the code generated by compilers for these high level languages is often very inefficient compared to that produced by experienced assembly language programmers. However, the added expressiveness and the ability to leave details to the compiler usually offset the inefficiency of generated code, particularly for non-systems applications. For such applications, the facilities which the high level programmer cannot use are not needed anyway."
  },
  {
    "Title": "Intelligent satellites for interactive graphics",
    "URL": "https://dl.acm.org/doi/10.1145/988026.988039",
    "Full Abstract": "The spectrum of remote user stations with local processing ability, ranging from simple \"smart\" terminals to nearly self-sufficient intelligent systems called satellites, is considered. The emphasis is on the latter category, drawing on the authors' research on intelligent satellites for interactive graphics. The necessity of meeting a \"critical intelligence threshold\" criterion for the satellite is stressed, and some difficult problems and potential solutions in the division of labor between mainframe and satellite are briefly examined. It is hoped that many of the problems and solutions in satellite graphics apply to other areas such as network or satellite process control, experiment control, and signal processing."
  },
  {
    "Title": "STRUCT programming analysis system",
    "URL": "https://dl.acm.org/doi/10.1109/TSE.1975.6312869",
    "Full Abstract": "The STRUCT system utilizes the flexibility of a powerful graphics display system to provide a set of tools for program analysis. These tools allow the analysis of the static prograin structure and the dynamic execution behavior. of programs within the entire operating system/user program environment of the Brown University Graphics System (BUGS). Information is collected and presented in a manner which fully exploits two aspects of this environment. First, the operating system has been developed in a well-structured hierarcal manner following principles laid down by other researchers (2), (3). Second the programs under analysis have been written in a structured programming language following coding conventions which make available, at the source code level, valuable program control information. A new set of pictorial constructs is introduced for presenting a. program structure (static or dynamic) for inspection. These constructs combine the best features of an indented structured source code listing and the box odented nature of traditional flow charts. The graphical tools available are USed to provide for swift changes in. the desired level of detail displayed within a program structure, for traveling linearly through a program structure, for traveling through a complex program structure (following subroutine or system calls), for concurrently viewing multiple related program structures, and for presenting dynamic program behavior data using three-dimensional projections, The volume of a three-dimensional box representing a program block is proportional to the block's resource utilization. The scope of this paper is limited to a description of the STRUCT system. This system is currently being used to predict and analyze the performance advantages available through the migration of function (program modules) between levels of software and between software and firmware within BUGS. The results of this research on migration will be included in a doctoral dissertation currently being written."
  },
  {
    "Title": "Experience with distributed processing on a host/satellite graphics system",
    "URL": "https://dl.acm.org/doi/10.1145/563274.563310",
    "Full Abstract": "The problem cf distributing an application between two processors has been investigated by studying an interactive graphics application that is divided between a time-shared host computer and a dedicated satellite system. The division of labor in the application is determined by a network flow assignment algorithm. The effect of variation in availability of the host computer on the distribution of the application is also studied. In particular, host availability is an important factor in determining the task distribution. As host availability decreased, procedures miqrate from the host to the satellite."
  },
  {
    "Title": "Structured programming in assembly language",
    "URL": "https://dl.acm.org/doi/10.1145/382222.382464",
    "Full Abstract": "Structured design and programming techniques can be extended from high-level languages to assembly language. Over the past three years at Brown University, beginning assembly language programmers have been successfully taught these techniques using clearly defined standards. These standards and the solutions to several of the typical problems that arise in structured assembly language programming are discussed in this paper."
  },
  {
    "Title": "A multi-microprocessor implementation of a general purpose pipelined CPU",
    "URL": "https://dl.acm.org/doi/10.1145/800255.810649",
    "Full Abstract": "This paper discusses and shows by example the potential of a network of microprogrammable microprocessors as a cost-effective alternative to traditional hardwired medium- and large-scale mainframes. While biased towards vector processing, this system is not intended to compete with multi-million dollar supercomputers such as the 360/195, CDC STAR, Illiac IV, CRAY-1, TI ASC, etc., which use special algorithms and the fastest circuitry available."
  },
  {
    "Title": "GPGS",
    "URL": "https://dl.acm.org/doi/10.1145/563858.563878",
    "Full Abstract": "GPGS is a subroutine package offering powerful and versatile support for passive and interactive vector graphics, for time-sharing, batch, and stand-alone minicomputer systems. The package is computer, language, and operating system, as well as display device independent. Its key purpose is to allow for transportabiliit of programs and programmers by providing easy to learn, high level features. The applications programmer writes his program once and then executes it on any supported graphics equipment without recompiling or relinking it. Device-independence was implemented by dividing GPGS into a device-independent part invoked by the applications programmer, and internal, \"device drivers\", one per display device. Like the GSPC \"Core System\" whose design it influenced, GPGS is a general purpose package. It has a subset of graphics facilities to handle output of line and character primitives with attributes such as line style and character size, and input from interaction tools such as lightpens, keyboards, valuators, and function keys. It also supports 2D and 3D viewin transformationss for clipping and window to viewport mapping, and coordinate transformations.Unlike the GSPC Core System, GPGS also includes a set of basic features for modelling objects which allows definition of device independent masters called seudo picture segment. These are distinguished from normal, device (DPU) dependent pictur segments into which primitives and their attribute-value settings are ordinarily compiled. These masters may be instanced subject to affine transformations (translate, rotate, and scale) to create a typical master-instance hierarchy. The hierarchy may be stored in a disk based library or compiled into a normal picture segment for output to a display device.The images of objects stored in device dependent picture segments may be transformed on the display surface by v port (image) transformations. These typically allow use of hardware transformation capabilities for dragging or tumbling object images.Host/satellite graphics is accommodated by having the device independent part of GPGS in the host and splitting the device drivers across host and satellite. At the source code level it therefore makes no difference on which.configuration a program will be executed.Among the existing implementations are versions written in assembler for the IB 360/370 and the PDP 11, in both stand-alone and satellite mode, and under a variety of operating systems. They support plotters, storage tubes, and high performance refresh displays. FORTRAN based implementations exist for the Univac 1108, the PDP 10, and a Harris minicomputer."
  },
  {
    "Title": "Distributed Processing",
    "URL": "https://dl.acm.org/doi/10.1109/C-M.1978.217899",
    "Full Abstract": "This issue of Computer is based on two workshops in distributed processing held at Brown University August 17-19, 1976, and August 3-5, 1977. Sponsored by the Army Research Office, the National Science Foundation, and the Office of Naval Research, the workshops attempted to define what distributed processing means and to develop a taxonomy of distributed processing applications and techniques. Achievements to date and outstanding research problems were examined in an attempt to find either commonality of problems and solutions or substantial differences."
  },
  {
    "Title": "Issues in Distributed Processing - an Overview of Two Workshops",
    "URL": "https://dl.acm.org/doi/10.1109/C-M.1978.217902",
    "Full Abstract": "Two workshops on distributed processing were held at Brown University in 1976 and 1977, sponsored by the Army Research Office, the National Science Foundation, and the Office of Naval Research. The workshops had three goals:"
  },
  {
    "Title": "Vertical Migration for Performance Enhancement in Layered Hardware/Firmware/Software Systems",
    "URL": "https://dl.acm.org/doi/10.1109/C-M.1978.218182",
    "Full Abstract": "Vertical migration is a technique which improves system performance by moving software primitives through layers of application program and operating system software and microcode."
  },
  {
    "Title": "Recent Efforts Towards Graphics Standardization",
    "URL": "https://dl.acm.org/doi/10.1145/356744.356746",
    "Full Abstract": "Copyright © 1978 ACM."
  },
  {
    "Title": "Functional Overview of the Core System with Glossary",
    "URL": "https://dl.acm.org/doi/10.1145/356744.356747",
    "Full Abstract": "Copyright © 1978 ACM."
  },
  {
    "Title": "Architectural considerations for a microprogrammable emulating engine using bit-slices",
    "URL": "https://dl.acm.org/doi/10.1145/800053.801936",
    "Full Abstract": "This paper describes architectural considerations which led to the design of a fast programmable processor made from ECL bit-slioes. The processor will be used as an on-line data filtering engine for high energy physics experiments. Unlike prior designs of such engines, the processor supports both user (horizontal) microcode and emulation of the PDP-11 fixed point instruction set (without memory management and multiple interrupt levels). In addition to an overview of the techniques used to achieve an execution speed of roughly three times that of the PDP-11/70 CPU, strengths and weaknesses of bit- slices are discussed, as are the use of a Signetics meta assembler and the ISPS Architecture simulation system."
  },
  {
    "Title": "BUMPS",
    "URL": "https://dl.acm.org/doi/10.1145/800250.807498",
    "Full Abstract": "BUMPS (Brown University Multiple Projection System) is a program that illustrates the implementation of viewing transformations using animation. The program uses the viewing model defined in the Core Graphics System. BUMPS employs interactive computer graphics to demonstrate how planar geometric projections are generated, what the effects of different projections and projection parameters are on the projected object, and how the viewing functions of the Core Graphics System work. After presenting background material on projections, the features of BUMPS are described, followed by a pictorial user scenario of BUMPS in action. The paper concludes with a discussion of the merits of user controlled animation for teaching and possible improvements to the program."
  },
  {
    "Title": "MIDAS",
    "URL": "https://dl.acm.org/doi/10.1109/TE.1981.4321464",
    "Full Abstract": "An interactive graphics program has been developed to simulate and animate the operation of a typical microcomputer system. MIDAS, a microprocessor interpreter display and animation system, allows the user full control over the simulation and the display and provides several auxiliary functions that enhance its capabilities as an instructional tool. The illustration of the activity of the computer, based on the Intel 8080 microprocessor, takes the form of an animated block diagram of the CPU and its peripherals. It shows the operation of the system at various levels of detail, down to the level of the devices' internal registers, buffers, control lines, and buses. This paper describes the design, implementation, and use of MIDAS. It discusses its effectiveness as a tool for teaching the complex, asynchronous interaction between devices of a computer system (known as \"handshaking\"). It also discusses a strategy for developing a generalized tool for simulating and animating arbitrary computer systems."
  },
  {
    "Title": "Vertical and outboard migration",
    "URL": "https://dl.acm.org/doi/10.1145/1500412.1500422",
    "Full Abstract": "The primary method for gaining performance improvement on a fixed-hardware architecture is to tailor the soft components, i.e. the application program, the operating system, or the firmware, to the performance requirements. This paper deals with two specific forms of performance tuning called"
  },
  {
    "Title": "Simulation of a Horizontal Bit-Sliced Processor Using the ISPS Architecture Simulation Facility",
    "URL": "https://dl.acm.org/doi/10.1109/TC.1981.1675830",
    "Full Abstract": "The microprogrammed filter engine (MICE) is a fast, microprogrammable processor built with ECL bit slices (Motorola ECL 10800 series) intended primarily to be used as an on-line data filtering engine for high energy physics experiments. In this note we describe the use of a hardware description language used to model and simulate the hardware during its development. We treat the problem of describing a pipelined, horizontal (112 bits wide) host machine, implemented using bit slices with considerable potential for parallelism. Several levels of modeling are conceptually applicable to a problem of this nature and the note describes the thorough process followed before we decided on a particular style of description and simulation."
  },
  {
    "Title": "An integrated system for creating and presenting complex computer-based documents",
    "URL": "https://dl.acm.org/doi/10.1145/800224.806805",
    "Full Abstract": "An experimental system is described for the design, development, and presentation of computer-based documents that combine pictures and text on a high-resolution raster color display. Such documents can be used, for example, for maintenance and repair tasks or computer-aided instruction."
  },
  {
    "Title": "An experimental system for creating and presenting interactive graphical documents",
    "URL": "https://dl.acm.org/doi/10.1145/357290.357296",
    "Full Abstract": "Copyright © 1982 ACM."
  },
  {
    "Title": "Balanced allocations (extended abstract)",
    "URL": "https://dl.acm.org/doi/10.1145/195058.195412",
    "Full Abstract": "Copyright © 1994 ACM."
  },
  {
    "Title": "Competitive randomized algorithms for nonuniform problems",
    "URL": "https://dl.acm.org/doi/10.1007/BF01189993",
    "Full Abstract": "Competitive analysis is concerned with comparing the performance of on-line algorithms with that of optimal off-line algorithms. In some cases randomization can lead to algorithms with improved performance ratios on worst-case sequences. In this paper we present new randomized on-line algorithms for snoopy caching and the spin-block problem. These algorithms achieve competitive ratios approachinge/(eź1) ź 1.58 against an oblivious adversary. These ratios are optimal and are a surprising improvement over the best possible ratio in the deterministic case, which is 2. We also consider the situation when the request sequences for these problems are generated according to an unknown probability distribution. In this case we show that deterministic algorithms that adapt to the observed request statistics also have competitive factors approachinge/(eź1). Finally, we obtain randomized algorithms for the 2-server problem on a class of isosceles triangles. These algorithms are optimal against an oblivious adversary and have competitive ratios that approache/(eź1). This compares with the ratio of 3/2 that can be achieved on an equilateral triangle."
  },
  {
    "Title": "On-line load balancing",
    "URL": "https://dl.acm.org/doi/10.1016/0304-3975%2894%2990153-8",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Dynamic Perfect Hashing",
    "URL": "https://dl.acm.org/doi/10.1137/S0097539791194094",
    "Full Abstract": "The dynamic dictionary problem is considered: provide an algorithm for storing a dynamic set, allowing the operations insert, delete, and lookup. A dynamic perfect hashing strategy is given: a randomized algorithm for the dynamic dictionary problem that takes $O(1)$ worst-case time for lookups and $O(1)$ amortized expected time for insertions and deletions; it uses space proportional to the size of the set stored. Furthermore, lower bounds for the time complexity of a class of deterministic algorithms for the dictionary problem are proved. This class encompasses realistic hashing-based schemes that use linear space. Such algorithms have amortized worst-case time complexity $\\Omega(\\log n)$ for a sequence of $n$ insertions and lookups; if the worst-case lookup time is restricted to $k$, then the lower bound becomes $\\Omega(k\\cdot n^{1/k})$."
  },
  {
    "Title": "Balanced Allocations (Extended abstract)",
    "URL": "https://dl.acm.org/doi/book/10.5555/903741",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "A study of integrated prefetching and caching strategies",
    "URL": "https://dl.acm.org/doi/10.1145/223587.223608",
    "Full Abstract": "Prefetching and caching are effective techniques for improving the performance of file systems, but they have not been studied in an integrated fashion. This paper proposes four properties that optimal integrated strategies for prefetching and caching must satisfy, and then presents and studies two such integrated strategies, called"
  },
  {
    "Title": "Reducing TLB and memory overhead using online superpage promotion",
    "URL": "https://dl.acm.org/doi/10.1145/223982.224419",
    "Full Abstract": "Modern microprocessors contain small TLBs that maintain a cache of recently used translations. A TLB's"
  },
  {
    "Title": "Randomized and multipointer paging with locality of reference",
    "URL": "https://dl.acm.org/doi/10.1145/225058.225280",
    "Full Abstract": "Copyright © 1995 ACM."
  },
  {
    "Title": "Implementing global memory management in a workstation cluster",
    "URL": "https://dl.acm.org/doi/10.1145/224056.224072",
    "Full Abstract": "Copyright © 1995 ACM."
  },
  {
    "Title": "Two Adaptive Hybrid Cache Coherency Protocols",
    "URL": "https://dl.acm.org/doi/10.5555/525424.822636",
    "Full Abstract": "We present and evaluate adaptive, hybrid cache coherence protocols for bus-based, shared-memory multiprocessors. Such protocols are motivated by the observation that sharing patterns vary substantially between different programs and even cache blocks within the same program. Performance measurements across a range of parallel applications indicate that the adaptive protocols we present perform well compared to both Write-Invalidate and Write-Update protocols."
  },
  {
    "Title": "Integrated parallel prefetching and caching",
    "URL": "https://dl.acm.org/doi/10.1145/233013.233052",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Strongly Competitive Algorithms for Paging with Locality of Reference",
    "URL": "https://dl.acm.org/doi/10.1137/S0097539792236353",
    "Full Abstract": "What is the best paging algorithm if one has partial information about the possible sequences of page requests__ __ We give a partial answer to this question by presenting the analysis of strongly competitive paging algorithms in the access graph model. This model restricts page requests so that they conform to a notion of locality of reference given by an arbitrary access graph."
  },
  {
    "Title": "Online computation",
    "URL": "https://dl.acm.org/doi/10.5555/241938.241951",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Reducing network latency using subpages in a global memory environment",
    "URL": "https://dl.acm.org/doi/10.1145/237090.237198",
    "Full Abstract": "New high-speed networks greatly encourage the use of network memory as a cache for virtual memory and file pages, thereby reducing the need for disk access. Because pages are the fundamental transfer and access units in remote memory systems, page size is a key performance factor. Recently, page sizes of modern processors have been increasing in order to provide more TLB coverage and amortize disk access costs. Unfortunately, for high-speed networks,"
  },
  {
    "Title": "Near-optimal parallel prefetching and caching",
    "URL": "https://dl.acm.org/doi/10.5555/874062.875485",
    "Full Abstract": "The authors consider algorithms for integrated prefetching and caching in a model with a fixed-size cache and any number of backing storage devices (disks). Previously, the single disk case was considered by Cao et al. (1995). They show that the natural extension of their aggressive algorithm to the parallel disk case is suboptimal by a factor near the number of disks in the worst case. The main result is a new algorithm, reverse aggressive, with near-optimal performance in the presence of multiple disks."
  },
  {
    "Title": "A trace-driven comparison of algorithms for parallel prefetching and caching",
    "URL": "https://dl.acm.org/doi/10.1145/238721.238737",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Implementation and performance of integrated application-controlled file caching, prefetching, and disk scheduling",
    "URL": "https://dl.acm.org/doi/10.1145/235543.235544",
    "Full Abstract": "As the performance gap between disks and micropocessors continues to increase, effective utilization of the file cache becomes increasingly immportant. Application-controlled file caching and prefetching can apply application-specific knowledge to improve file cache management. However, supporting application-controlled file caching and prefetching is nontrivial because caching and prefetching need to be integrated carefully, and the kernel needs to allocate cache blocks among processes appropriately. This article presents the design, implementation, and performance of a file system that integrates application-controlled caching, prefetching, and disk scheduling. We use a two-level cache management strategy. The kernel uses the LRU-SP (Least-Recently-Used with Swapping and Placeholders) policy to allocate blocks to processes, and each process integrates application-specific caching and prefetching based on the"
  },
  {
    "Title": "On the Performance of Competitive Algorithms in Practice",
    "URL": "https://dl.acm.org/doi/10.5555/647371.724037",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Implementing cooperative prefetching and caching in a globally-managed memory system",
    "URL": "https://dl.acm.org/doi/10.1145/277851.277869",
    "Full Abstract": "This paper presents"
  },
  {
    "Title": "A Note on the Influence of an ε-Biased Random Source",
    "URL": "https://dl.acm.org/doi/10.1006/jcss.1997.1551",
    "Full Abstract": "An -biased random source is a sequenceX=(X1,X2,Xn) of 0, 1-valued random variables such that the conditional probability PrXi=1|X1,X2,Xi 1 is always between 12 and 12+ . Given a familyS {0,1}nof binary strings of lengthn, its -enhanced probability Pr (S) is defined as the maximum of PrX(S) over all -biased random sourcesX. In this paper we establish a tight lower bound on Pr (S) as a function of |S|,nand ."
  },
  {
    "Title": "Verification of Clocked and Hybrid Systems",
    "URL": "https://dl.acm.org/doi/10.5555/647870.737275",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Hierarchical Verification Using Verification Diagrams",
    "URL": "https://dl.acm.org/doi/10.5555/646063.676473",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Automatic generation of invariants and intermediate assertions",
    "URL": "https://dl.acm.org/doi/10.1016/S0304-3975%2896%2900191-0",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Hybrid Diagrams",
    "URL": "https://dl.acm.org/doi/10.5555/646512.695481",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Visual Verification of Reactive Systems",
    "URL": "https://dl.acm.org/doi/10.5555/646481.691436",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Deductive Verification of Real-Time Systems Using STeP",
    "URL": "https://dl.acm.org/doi/10.5555/648201.749120",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Deductive Verification of Modular Systems",
    "URL": "https://dl.acm.org/doi/10.5555/646738.701965",
    "Full Abstract": "Effective verification methods, both deductive and algorithmic, exist for the verification of global system properties. In this paper, we introduce a formal framework for the modular description and verification of parameterized fair transition systems. The framework allows us to apply existing global verification methods, such as verification rules and diagrams, in a modular setting. Transition systems and transition modules can be described by recursive module expressions, allowing the description of hierarchical systems of unbounded depth. Apart from the usual parallel composition, hiding and renaming operations, our module description language provides constructs to augment and restrict the module interface, capablilities that are essential for recursive descriptions. We present proof rules for property inheritance between modules. Finally, module abstraction and induction allow the verification of recursively defined systems. Our approach is illustrated with a recursively defined arbiter for which we verify mutual exclusion and eventual access."
  },
  {
    "Title": "Abstraction and Modular Verification of Infinite-State Reactive Systems",
    "URL": "https://dl.acm.org/doi/10.5555/645866.670769",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Deductive Verification of Hybrid Systems Using STeP",
    "URL": "https://dl.acm.org/doi/10.5555/646878.710285",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Decomposing, Transforming and Composing Diagrams: The Joys of Modular Verification",
    "URL": "https://dl.acm.org/doi/book/10.5555/892633",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "THE REDUCTION METHOD FOR ESTABLISHING LOWER BOUNDS ON THE NUMBER OF ADDITIONS",
    "URL": "https://dl.acm.org/doi/book/10.5555/889600",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Addition Requirements for Rational Functions",
    "URL": "https://dl.acm.org/doi/book/10.5555/867356",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Addition Requirements for Rational Functions",
    "URL": "https://dl.acm.org/doi/10.1137/0206015",
    "Full Abstract": "A notion of rank or independence for arbitrary sets of rational functions is developed, which bounds from below the number of additions and subtractions required of all straight-line algorithms which compute those functions. This permits a uniform derivation of the best lower bounds known for a number of familiar sets of rational functions."
  },
  {
    "Title": "Optimal surface reconstruction from planar contours",
    "URL": "https://dl.acm.org/doi/10.1145/563858.563899",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Optimal surface reconstruction from planar contours",
    "URL": "https://dl.acm.org/doi/10.1145/359842.359846",
    "Full Abstract": "In many scientific and technical endeavors, a three-dimensional solid must be reconstructed from serial sections, either to aid in the comprehension of the object's structure or to facilitate its automatic manipulation and analysis. This paper presents a general solution to the problem of constructing a surface over a set of cross-sectional contours. This surface, to be composed of triangular tiles, is constructed by separately determining an optimal surface between each pair of consecutive contours. Determining such a surface is reduced to the problem of finding certain minimum cost cycles in a directed toroidal graph. A new fast algorithm for finding such cycles is utilized. Also developed is a closed-form expression, in terms of the number of contour points, for an upper bound on the number of operations required to execute the algorithm. An illustrated example which involves the construction of a minimum area surface describing a human head is included."
  },
  {
    "Title": "The “highly intelligent” tablet as an efficient pointing device for interactive graphics (Preliminary Report)",
    "URL": "https://dl.acm.org/doi/10.1145/800178.810125",
    "Full Abstract": "Described is a simple, efficient algorithm for determining the nearest displayed point on a screen to an arbitrary cursor position. The algorithm seems particularly appropriate for interactive systems using a data tablet with a “smart” controller. The algorithm is based on partitioning the screen among the currently displayed points and minimally modifing this structure as points are added and deleted. Finding the nearest point for cursor position consists then of moving through this partitioning structure until the region is determined. A divide-and-conquer method is used for both inclusion testing in a particular region and also for speeding the search for the proper nearest point."
  },
  {
    "Title": "Combining Dimensionality and Rate of Growth Arguments for Establishing Lower Bounds on the Number of Multiplications and Divisions",
    "URL": "https://dl.acm.org/doi/10.1145/322139.322153",
    "Full Abstract": "Copyright © 1979 ACM."
  },
  {
    "Title": "Predetermining visibility priority in 3-D scenes (Preliminary Report)",
    "URL": "https://dl.acm.org/doi/10.1145/800249.807441",
    "Full Abstract": "The principal calculation performed by all visible surface algorithms is the determination of the visible polygon at each pixel in the image. Of the many possible speedups and efficiencies found for this problem, only one published algorithm (developed almost a decade ago by a group at General Electric) took advantage of an observation that many visibility calculations could be performed without knowledge of the eventual viewing position and orientation—"
  },
  {
    "Title": "Controlling concurrency using locking protocols",
    "URL": "https://dl.acm.org/doi/10.1109/SFCS.1979.12",
    "Full Abstract": "This paper is concerned with the problem of developing locking protocols for ensuring the consistency of database systems that are accessed concurrently by a number of independent transactions. It is assumed that the database is modelled by a directed acyclic graph whose vertices correspond to the database entities, and whose arcs correspond to certain locking restrictions. Several locking protocols are presented. The weak protocol is shown to ensure consistency and deadlock-freedom only for databases that are organized as trees. For the databases that are organized as directed acyclic graphs, the strong protocol is presented. Discussion of SHARED and EXCLUSIVE locks is also included."
  },
  {
    "Title": "Consistency in Hierarchical Database Systems",
    "URL": "https://dl.acm.org/doi/10.1145/322169.322176",
    "Full Abstract": "Copyright © 1980 ACM."
  },
  {
    "Title": "On visible surface generation by a priori tree structures",
    "URL": "https://dl.acm.org/doi/10.1145/800250.807481",
    "Full Abstract": "This paper describes a new algorithm for solving the hidden surface (or line) problem, to more rapidly generate realistic images of 3-D scenes composed of polygons, and presents the development of theoretical foundations in the area as well as additional related algorithms. As in many applications the environment to be displayed consists of polygons many of whose relative geometric relations are static, we attempt to capitalize on this by preprocessing the environment's database so as to decrease the run-time computations required to generate a scene. This preprocessing is based on generating a “binary space partitioning” tree whose in order traversal of visibility priority at run-time will produce a linear order, dependent upon the viewing position, on (parts of) the polygons, which can then be used to easily solve the hidden surface problem. In the application where the entire environment is static with only the viewing-position changing, as is common in simulation, the results presented will be sufficient to solve completely the hidden surface problem."
  },
  {
    "Title": "Non-two-phase locking protocols with shared and exclusive locks",
    "URL": "https://dl.acm.org/doi/10.5555/1286887.1286920",
    "Full Abstract": "This paper is concerned with the problem of developing a family of locking protocols which employ both SHARED and EXCLUSIVE locks and which ensure the consistency of database systems that are accessed concurrently by a number of asynchronously running transactions. The protocols in the family are not two-phase. They are applicable to database systems which are hierarchically organized as well as database systems which are modeled by directed acyclic graphs. A comparison with other previously published protocols is also presented."
  },
  {
    "Title": "Deadlock removal using partial rollback in database systems",
    "URL": "https://dl.acm.org/doi/10.1145/582318.582329",
    "Full Abstract": "The problem of removing deadlocks from concurrent database systems using the two-phase locking protocol is considered. In particular, for systems which use no a priori information about transaction behavior in order to avoid deadlocks, it has generally been assumed necessary to totally remove and restart some transaction involved in a deadlock in order to relieve the situation. In this paper, a new approach to deadlock removal in such systems based on partial rollbacks is introduced. This approach does not in general require the total removal of a transaction to eliminate a deadlock. The task of optimizing deadlock removal using this method is discussed for systems allowing both exclusive and shared locking. A method is given for implementing this approach with no more storage overhead than that required for total removal and restart."
  },
  {
    "Title": "A theory of correct locking protocols for database systems",
    "URL": "https://dl.acm.org/doi/10.5555/1286831.1286843",
    "Full Abstract": "In database systems which allow concurrent processing, it is necessary to control the interaction among the concurrent transactions in order to prevent them from destroying the consistency of the database. The most common mechanism proposed to achieve this involves the use of locking and unlocking instrucions to provide controlled access to units of shared data. These instructions are embedded in the transactions according to rules which are called locking protocols. A correct locking protocol assures that the consistency of the database is preserved and that no deadlocks occur to prevent termination of the transactions. In this paper, a theory is developed of how a priori syntactic information about the behavior of the transactions in a system can be used to construct correct protocols. The relationship between the problems of assuring correctness and deadlock-freedom is explored in a unified model which applies to systems which allow only exclusive locks as well as to systems which allow both exclusive and shared access nodes."
  },
  {
    "Title": "Lower bounds for algebraic computation trees with integer inputs",
    "URL": "https://dl.acm.org/doi/10.1137/0220041",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Recent Progress in Circuit and Communication Complexity (Abstract)",
    "URL": "https://dl.acm.org/doi/10.5555/647895.740433",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Weighted Random Assignments with Application to Hashing",
    "URL": "https://dl.acm.org/doi/10.5555/648003.743107",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Linear decision trees",
    "URL": "https://dl.acm.org/doi/10.1145/129712.129730",
    "Full Abstract": "Copyright © 1992 ACM."
  },
  {
    "Title": "A circuit-based proof of Toda's theorem",
    "URL": "https://dl.acm.org/doi/10.1006/inco.1993.1033",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Groups and Algebraic Complexity (Abstract)",
    "URL": "https://dl.acm.org/doi/10.5555/645929.672557",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "A randomized algorithm for finding maximum with ",
    "URL": "https://dl.acm.org/doi/10.1016/0020-0190%2894%2990052-3",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Decision tree complexity and Betti numbers",
    "URL": "https://dl.acm.org/doi/10.1145/195058.195414",
    "Full Abstract": "Copyright © 1994 ACM."
  },
  {
    "Title": "Near-Optimal Time-Space Tradeoff for Element Distinctness",
    "URL": "https://dl.acm.org/doi/10.1137/S0097539788148959",
    "Full Abstract": "It was conjectured in Borodin et al. ["
  },
  {
    "Title": "On Computing Algebraic Functions using Logarithms andExponentials",
    "URL": "https://dl.acm.org/doi/10.1137/S0097539793245015",
    "Full Abstract": "Let $\\rho$ be a set of algebraic expressions constructed with radicals and arithmetic operations, and which generate the splitting field $F$ of some polynomial. Let $N_{\\beta}(\\rho)$ be the minimum total number of root-takings and exponentiations used in any straightline program for computing the functions in $\\rho$ by taking roots, exponentials, logarithms, and performing arithmetic operations. In this paper it is proved that $N_{\\beta}(\\rho) = \\nu(G)$, where $\\nu(G)$ is the minimum length of any cyclic Jordan--Holder tower for the Galois group $G$ of $F$. This generalizes a result of Ja'Ja' ["
  },
  {
    "Title": "On the shrinkage exponent for read-once formulae",
    "URL": "https://dl.acm.org/doi/10.1016/0304-3975%2894%2900081-S",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Algebraic decision trees and Euler characteristics",
    "URL": "https://dl.acm.org/doi/10.1016/0304-3975%2894%2900082-T",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Security of quantum protocols against coherent measurements",
    "URL": "https://dl.acm.org/doi/10.1145/225058.225085",
    "Full Abstract": "Copyright © 1995 ACM."
  },
  {
    "Title": "A Lower Bound on the Size of Algebraic Decision Trees for the MAX Problem",
    "URL": "https://dl.acm.org/doi/book/10.5555/895380",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Hypergraphs and Decision Trees (Abstract)",
    "URL": "https://dl.acm.org/doi/10.5555/647677.731843",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Read-once branching programs, rectangular proofs of the pigeonhole principle and the transversal calculus",
    "URL": "https://dl.acm.org/doi/10.1145/258533.258673",
    "Full Abstract": "Copyright © 1997 ACM."
  },
  {
    "Title": "Decision Tree Complexity and Betti Numbers",
    "URL": "https://dl.acm.org/doi/10.1006/jcss.1997.1495",
    "Full Abstract": "We show that any algebraic computation tree or any fixed-degree algebraic tree for solving the membership question of a compact setS Rnmust have height greater than (log( i(S))) cnfor eachi, where i(S) is theith Betti number. This generalizes a well-known result by Ben-Or who proved this lower bound for the casei=0, and a recent result by Bj rner and Lov sz who proved this lower bound for allifor linear decision trees."
  },
  {
    "Title": "RAPID",
    "URL": "https://dl.acm.org/doi/10.1145/262839.262993",
    "Full Abstract": "Copyright © 1997 ACM."
  },
  {
    "Title": "Dictionary Look-Up with One Error",
    "URL": "https://dl.acm.org/doi/10.1006/jagm.1997.0875",
    "Full Abstract": "LetWbe a set ofnbinary strings of lengthmeach. We are interested in designing data structures forWthat can answerd-queriesquickly; that is, given in a binary string, decide whether there is any member ofWwithin Hamming distancedof . The problem, originally raised by Minsky and Papert, remains a challenge in data structure design. In this paper, we make an initial effort toward a theoretical study of the smalldcase. Our main result is a data structure that achievesO(mloglogn) query time withO(nmlogm) space for thed=1 case."
  },
  {
    "Title": "Interactive Editing Systems: Part I",
    "URL": "https://dl.acm.org/doi/10.1145/356887.356889",
    "Full Abstract": "Copyright © 1982 ACM."
  },
  {
    "Title": "Interactive Editing Systems: Part II",
    "URL": "https://dl.acm.org/doi/10.1145/356887.356890",
    "Full Abstract": "Copyright © 1982 ACM."
  },
  {
    "Title": "Fundamentals of interactive computer graphics",
    "URL": "https://dl.acm.org/doi/book/10.5555/6684",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Computer graphics in higher education (Panel Session)",
    "URL": "https://dl.acm.org/doi/10.1145/800059.801129",
    "Full Abstract": "Copyright © 1983 ACM."
  },
  {
    "Title": "Meeting the Crisis in Computer Science",
    "URL": "https://dl.acm.org/doi/10.1109/MC.1983.1654271",
    "Full Abstract": "First Page of the Article"
  },
  {
    "Title": "Meeting the crisis in computer science",
    "URL": "https://dl.acm.org/doi/10.1145/358476.358488",
    "Full Abstract": "Copyright © 1983 ACM."
  },
  {
    "Title": "The electronic classroom",
    "URL": "https://dl.acm.org/doi/10.1145/800014.808141",
    "Full Abstract": "Continuing advances in hardware have made it possible to replace mainframe time-sharing systems (with their inherent performance limitations and poor user interfaces based on low-speed alphanumeric terminals) by powerful personal computers. When these personal computers have high-resolution bit-mapped graphics displays, fast processors, and virtual memory, and are linked in networks, they combine the best of dedicated computing (e.g., immediate response) with the best of time-sharing (e.g., resource-sharing of programs, data and peripherals). Personal computers so configured are typically called workstations. Such workstations have been introduced in the last few years primarily for professionals in productivity-sensitive areas like engineering design and office automation, but recent price/performance improvement has made it possible to consider them for use in education as well."
  },
  {
    "Title": "Computer graphics comes of age",
    "URL": "https://dl.acm.org/doi/10.1145/358105.358190",
    "Full Abstract": "Copyright © 1984 ACM."
  },
  {
    "Title": "The electronic classroom:  workstations for teaching",
    "URL": "https://dl.acm.org/doi/10.1016/S0020-7373%2884%2980053-X",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "1984 Snowbird Report",
    "URL": "https://dl.acm.org/doi/10.1109/MC.1985.1662897",
    "Full Abstract": "First Page of the Article"
  },
  {
    "Title": "Reading and Writing the Electronic Book",
    "URL": "https://dl.acm.org/doi/10.1109/MC.1985.1662710",
    "Full Abstract": "First Page of the Article"
  },
  {
    "Title": "High performance graphics systems (panel session)",
    "URL": "https://dl.acm.org/doi/10.1145/320435.320518",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Pascal on the Macintosh: a graphical approach",
    "URL": "https://dl.acm.org/doi/book/10.5555/21671",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Hypertext '87: keynote address",
    "URL": "https://dl.acm.org/doi/10.1145/48511.48519",
    "Full Abstract": "Copyright © 1988 ACM."
  },
  {
    "Title": "PHIGS+ functional description revision",
    "URL": "https://dl.acm.org/doi/10.1145/51683.51684",
    "Full Abstract": "This is a set of proposed extensions to the proposed PHIGS graphics standard (dpANS X3.144-198x. DIS 9592) to cover the areas of lighting, shading and advanced primitives which have thus far not been addressed by that standard. This document is organized to promote its eventual integration with the existing PHIGS documentation and is therefore not tutorial in nature. It assumes that the reader is familiar with PHIGS. with rendering and with curves and surfaces. This specification has been made available to standards bodies for their consideration."
  },
  {
    "Title": "The Application Visualization System",
    "URL": "https://dl.acm.org/doi/10.1109/38.31462",
    "Full Abstract": "A software system for developing interactive scientific visualization applications quickly, with a minimum of programming effort, is described. This application visualization system (AVS) is an application framework targeted at scientists and engineers. The goal of the system is to make applications that combine interactive graphics and high computational requirements easier to develop for both programmers and nonprogrammers. AVS is designed around the concept of software building blocks, or modules, which can be interconnected to form visualization applications. AVS allows flow networks of existing modules to be constructed using a direct-manipulation user interface, and it automatically generates a simple user interface to each module."
  },
  {
    "Title": "Simulation of a horizontal bit-sliced processor using the ISPS architecture simulation facility",
    "URL": "https://dl.acm.org/doi/10.5555/72832.72865",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Trends in Computer Graphics",
    "URL": "https://dl.acm.org/doi/10.5555/645819.669395",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Computer graphics: principles and practice (2nd ed.)",
    "URL": "https://dl.acm.org/doi/book/10.5555/83821",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "An Object-Oriented Framework for the Integration of Interactive Animation Techniques",
    "URL": "https://dl.acm.org/doi/book/10.5555/864881",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Potentials and limitations of fault-based Markov prefetching for virtual memory pages",
    "URL": "https://dl.acm.org/doi/10.1145/301453.301572",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "On List Update and Work Function Algorithms",
    "URL": "https://dl.acm.org/doi/10.5555/647909.740306",
    "Full Abstract": "The list update problem, a well-studied problem in dynamic data structures, can be described abstractly as a metrical task system. In this paper, we prove that a generic metrical task system algorithm, called the work function algorithm, has constant competitive ratio for list update. In the process, we present a new formulation of the well-known \"list factoring\" technique in terms of a partial order on the elements of the list. This approach leads to a new simple proof that a large class of online algorithms, including Move-To-Front, is (2 - 1/"
  },
  {
    "Title": "Balanced Allocations",
    "URL": "https://dl.acm.org/doi/10.1137/S0097539795288490",
    "Full Abstract": "Suppose that we sequentially place $n$ balls into"
  },
  {
    "Title": "Organization-based analysis of web-object sharing and caching",
    "URL": "https://dl.acm.org/doi/10.5555/1251480.1251483",
    "Full Abstract": "Performance-enhancing mechanisms in the World Wide Web primarily exploit repeated requests to Web documents by multiple clients. However, little is known about patterns of shared document access, particularly from diverse client populations. The principal goal of this paper is to examine the sharing of Web documents from an organizational point of view. An organizational analysis of sharing is important, because caching is often performed on an organizational basis; i.e., proxies are typically placed in front of large and small companies, universities, departments, and so on. Unfortunately, simultaneous multi-organizational traces do not currently exist and are difficult to obtain in practice."
  },
  {
    "Title": "On the scale and performance of cooperative Web proxy caching",
    "URL": "https://dl.acm.org/doi/10.1145/319151.319153",
    "Full Abstract": "While algorithms for cooperative proxy caching have been widely studied, little is understood about cooperative-caching performance in the large-scale World Wide Web environment. This paper uses both trace-based analysis and analytic modelling to show the potential advantages and drawbacks of inter-proxy cooperation. With our traces, we evaluate quantitatively the performance-improvement potential of cooperation between 200 small-organization proxies within a university environment, and between two large-organization proxies handling 23,000 and 60,000 clients, respectively. With our model, we extend beyond these populations to project cooperative caching behavior in regions with millions of clients. Overall, we demonstrate that cooperative caching has performance benefits only within limited population bounds. We also use our model to examine the implications of future trends in Web-access behavior and traffic."
  },
  {
    "Title": "Near-Optimal Parallel Prefetching and Caching",
    "URL": "https://dl.acm.org/doi/10.1137/S0097539797326976",
    "Full Abstract": "Recently there has been a great deal of interest in the operating systems research community in prefetching and caching data from parallel disks, as a technique for enabling serial applications to improve input--output (I/O) performance. In this paper, algorithms are considered for integrated prefetching and caching in a model with a fixed-size cache and any number of backing storage devices (disks). The integration of caching and prefetching with a single disk was previously considered by Cao, Felten, Karlin, and Li. Here, it is shown that the natural extension of their"
  },
  {
    "Title": "On the scale and performance of cooperative Web proxy caching",
    "URL": "https://dl.acm.org/doi/10.1145/346152.346166",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Markov Paging",
    "URL": "https://dl.acm.org/doi/10.1137/S0097539794268042",
    "Full Abstract": "This paper considers the problem of paging under the assumption that the sequence of pages accessed is generated by a Markov chain. We use this model to study the fault-rate of paging algorithms. We first draw on the theory of Markov decision processes to characterize the paging algorithm that achieves optimal fault-rate on any Markov chain. Next, we address the problem of devising a paging strategy with low fault-rate for a given Markov chain. We show that a number of intuitive approaches fail. Our main result is a polynomial-time procedure that, on any Markov chain, will give a paging algorithm with fault-rate at most a constant times optimal. Our techniques show also that some algorithms that do poorly in practice fail in the Markov setting, despite known (good) performance guarantees when the requests are generated independently from a probability distribution."
  },
  {
    "Title": "Random walks with “back buttons” (extended abstract)",
    "URL": "https://dl.acm.org/doi/10.1145/335305.335362",
    "Full Abstract": "Copyright © 2000 ACM."
  },
  {
    "Title": "Practical network support for IP traceback",
    "URL": "https://dl.acm.org/doi/10.1145/347059.347560",
    "Full Abstract": "This paper describes a technique for tracing anonymous packet flooding attacks in the Internet back towards their source. This work is motivated by the increased frequency and sophistication of denial-of-service attacks and by the difficulty in tracing packets with incorrect, or ``spoofed'', source addresses. In this paper we describe a general purpose traceback mechanism based on probabilistic packet marking in the network. Our approach allows a victim to identify the network path(s) traversed by attack traffic without requiring interactive operational support from Internet Service Providers (ISPs). Moreover, this traceback can be performed ``post-mortem'' -- after an attack has completed. We present an implementation of this technology that is incrementally deployable, (mostly) backwards compatible and can be efficiently implemented using conventional technology."
  },
  {
    "Title": "Spectral Analysis for Data Mining",
    "URL": "https://dl.acm.org/doi/10.5555/646679.702315",
    "Full Abstract": "Experimental evidence suggests that spectral techniques are valuable for a wide range of applications. A partial list of such applications include (i) semantic analysis of documents used to cluster documents into areas of interest, (ii) collaborative filtering -- the reconstruction of missing data items, and (iii) determining the relative importance of documents based on citation/link structure. Intuitive arguments can explain some of the phenomena that has been observed but little theoretical study has been done. In this talk, we present a model for framing data mining tasks and a unified approach to solving the resulting data mining problems using spectral analysis. In particular we describe the solution to an open problem of Papadimitriou, Ragha van, Tamaki and Vempala in the context of modeling latent semantic indexing. We also give theoretical justification for the use of spectral algorithms for collaborative filtering, and show how a reasonable model of web links justifies the robustness of Kleinberg's web authority/hub algorithm. A major focus of the talk will be a description of the tight feedback loop between theory and empirical work and how it has led on this project to both new theory and new empirical questions of interest."
  },
  {
    "Title": "On algorithms for efficient data migration",
    "URL": "https://dl.acm.org/doi/10.5555/365411.365549",
    "Full Abstract": "The"
  },
  {
    "Title": "Network support for IP traceback",
    "URL": "https://dl.acm.org/doi/10.1109/90.929847",
    "Full Abstract": "This paper describes a technique for tracing anonymous packet flooding attacks in the Internet back toward their source. This work is motivated by the increased frequency and sophistication of denial-of-service attacks and by the difficulty in tracing packets with incorrect, or “spoofed,” source addresses. In this paper, we describe a general purpose traceback mechanism based on probabilistic packet marking in the network. Our approach allows a victim to identify the network path(s) traversed by attack traffic without requiring interactive operational support from Internet Service Providers (ISPs). Moreover, this traceback can be performed “post mortem”—after an attack has completed. We present an implementation of this technology that is incrementally deployable, (mostly) backward compatible, and can be efficiently implemented using conventional technology."
  },
  {
    "Title": "Dynamic TCP acknowledgement and other stories about e/(e-1)",
    "URL": "https://dl.acm.org/doi/10.1145/380752.380845",
    "Full Abstract": "We present the first optimal randomized online algorithms for the TCP acknowledgment problem [5] and the Bahncard problem [7]. These problems are well-known to be generalizations of the classical online ski rental problem, however, they appeared to be harder. In this paper, we demonstrate that a number of online algorithms which have optimal competitive ratios of"
  },
  {
    "Title": "Spectral analysis of data",
    "URL": "https://dl.acm.org/doi/10.1145/380752.380859",
    "Full Abstract": "Experimental evidence suggests that spectral techniques are valuable for a wide range of applications. A partial list of such applications include (i) semantic analysis of documents used to cluster documents into areas of interest, (ii) collaborative filtering --- the reconstruction of missing data items, and (iii) determining the relative importance of documents based on citation/link structure. Intuitive arguments can explain some of the phenomena that has been observed but little theoretical study has been done. In this paper we present a model for framing data mining tasks and a unified approach to solving the resulting data mining problems using spectral analysis. These results give strong justification to the use of spectral techniques for latent semantic indexing, collaborative filtering, and web site ranking."
  },
  {
    "Title": "Web Search via Hub Synthesis",
    "URL": "https://dl.acm.org/doi/10.5555/646977.711699",
    "Full Abstract": "We present a probabilistic generative model for web search which captures in a unified manner three critical components of web search: how the link structure of the web is generated, how the content of a web document is generated, and how a human searcher generates a query. The key to this unification lies in capturing the correlations between each of these components in terms of proximity in latent semantic space. Given such a combined model, the correct answer to a search query is well defined, and thus it becomes possible to evaluate web search algorithms rigorously. We present a new web search algorithm, based on spectral techniques, and prove that it is guaranteed to produce an approximately correct answer in our model. The algorithm assumes no knowledge of the model, and is well-defined regardless of the accuracy of the model."
  },
  {
    "Title": "An Experimental Study of Data Migration Algorithms",
    "URL": "https://dl.acm.org/doi/10.5555/647258.720796",
    "Full Abstract": "The data migration problem is the problem ofc omputing a plan for moving data objects stored on devices in a network from one configuration to another. Load balancing or changing usage patterns might necessitate such a rearrangement ofda ta. In this paper, we consider the case where the objects are fixed-size and the network is complete. We introduce two new data migration algorithms, one ofwh ich has provably good bounds. We empirically compare the performance of these new algorithms against similar algorithms from Hall et al. [7] which have better theoretical guarantees and find that in almost all cases, the new algorithms perform better. We also find that both the new algorithms and the ones from Hall et al. perform much better in practice than the theoretical bounds suggest."
  },
  {
    "Title": "Web Search via Hub Synthesis",
    "URL": "https://dl.acm.org/doi/10.5555/874063.875586",
    "Full Abstract": "We present a model for web search that captures in a unified manner three critical components of the problem: how the link structure of the web is generated, how the contentof a web document is generated, and how a human searcher generates a query. The key to this unification lies in capturing the correlations between these components in terms of proximity in a shared latent semantic space. Given such a combined model, the correct answer to a search query is well defined, and thus it becomes possible to evaluate web search algorithms rigorously. We present a new web search algorithm, based on spectral techniques, and prove that it is guaranteed to produce an approximately correct answer in our model. The algorithm assumes no knowledge of the model, and is well-defined regardless of the model's accuracy."
  },
  {
    "Title": "A quantitative evaluation of traffic-aware routing strategies",
    "URL": "https://dl.acm.org/doi/10.1145/510726.510741",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Dynamically Fault-Tolerant Content Addressable Networks",
    "URL": "https://dl.acm.org/doi/10.5555/646334.687807",
    "Full Abstract": "We describe a content addressable network which is robust in the face of massive adversarial attacks and in a highly dynamic environment. Our network is robust in the sense that at any time, an arbitrarily large fraction of the peers can reach an arbitrarily large fraction of the data items. The network can be created and maintained in a completely distributed fashion."
  },
  {
    "Title": "Head-Tactics Simplification",
    "URL": "https://dl.acm.org/doi/10.5555/646058.678365",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "A Generic Approach to Building User Interfaces for Theorem Provers",
    "URL": "https://dl.acm.org/doi/10.1006/jsco.1997.0171",
    "Full Abstract": "In this paper, we present the results of an ongoing effort in building user interfaces for proof systems. Our approach is generic: we are not constructing a user interface for a particular proof system, rather we have developed techniques and tools that have been applied to several proof systems. We first propose and motivate a distributed architecture, where the proof system and the interface are two separate processes communicating through a protocol. Then we describe three high-level features:proof-by-pointing,script management, andtextual explanation. Altogether, they take advantage of the underlying architecture and yield a more user-friendly proof environment."
  },
  {
    "Title": "Fix-Point Equations for Well-Founded Recursion in Type Theory",
    "URL": "https://dl.acm.org/doi/10.5555/646527.695036",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Changing Data Structures in Type Theory",
    "URL": "https://dl.acm.org/doi/10.5555/646540.696039",
    "Full Abstract": "In type-theory based proof systems that provide inductive structures, computation tools are automatically associated to inductive definitions. Choosing a particular representation for a given concept has a strong influence on proof structure. We propose a method to make the change from one representation to another easier, by systematically translating proofs from one context to another. Weshow how this method works by using it on natural numbers, for which a unary representation (based on Peano axioms) and a binary representation are available. This method leads to an automatic translation tool that we have implemented in Coq and successfully applied to several arithmetical theorems."
  },
  {
    "Title": "Formalizing a JVML Verifier for Initialization in a Theorem Prover",
    "URL": "https://dl.acm.org/doi/10.5555/647770.734123",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Formalizing Convex Hull Algorithms",
    "URL": "https://dl.acm.org/doi/10.5555/646528.695057",
    "Full Abstract": "We study the development of formally proved algorithms for computational geometry. The result of this work is a formal description of the basic principles that make convex hull algorithms work and two programs that implement convex hull computation and have been automatically obtained from formally verified mathematical proofs. A special attention has been given to handling degenerate cases that are often overlooked by conventional algorithm presentations."
  },
  {
    "Title": "Type-Theoretic Functional Semantics",
    "URL": "https://dl.acm.org/doi/10.5555/646529.695218",
    "Full Abstract": "We describe the operational and denotational semantics of a small imperative language in type theory with inductive and recursive definitions. The operational semantics is given by natural inference rules, implemented as an inductive relation. The realization of the denotational semantics is more delicate: The nature of the language imposes a few difficulties on us. First, the language is Turing-complete, and therefore the interpretation function we consider is necessarily partial. Second, the language contains strict sequential operators, and therefore the function necessarily exhibits nested recursion. Our solution combines and extends recent work by the authors and others on the treatment of general recursive functions and partial and nested recursive functions. The first new result is a technique to encode the approach of Bove and Capretta for partial and nested recursive functions in type theories that do not provide simultaneous induction-recursion. A second result is a clear understanding of the characterization of the definition domain for general recursive functions, a key aspect in the approach by iteration of Balaa and Bertot. In this respect, the work on operational semantics is a meaningful example, but the applicability of the technique should extend to other circumstances where complex recursive functions need to be described formally."
  },
  {
    "Title": "A Proof of GMP Square Root",
    "URL": "https://dl.acm.org/doi/10.1023/A%3A1021987403425",
    "Full Abstract": "We present a formal proof (at the implementation level) of an efficient algorithm proposed by P. Zimmermann in 1999 to compute square roots of arbitrarily large integers. This program, which is part of the GNU Multiple Precision Arithmetic Library, is completely proven within the COQ system. Proofs are developed using the CORRECTNESS tool to deal with imperative features of the program. The formalization is rather large (more than 13,000 lines) and requires some advanced techniques for proof management and reuse."
  },
  {
    "Title": "Visual Abstractions for Temporal Verification",
    "URL": "https://dl.acm.org/doi/10.5555/646059.678540",
    "Full Abstract": "Generalized Verification Diagrams combine deductive and algorithmic verification to establish general temporal properties of finite-and infinite-state reactive systems. The diagram serves as an abstraction of the system. This abstraction is deductively justified and algorithmically model checked. We present a new simple class of verification diagrams, using Müller acceptance conditions, and show how they can be used to verify general temporal properties of reactive systems."
  },
  {
    "Title": "Visual Verification of Temporal Properties",
    "URL": "https://dl.acm.org/doi/10.5555/832247.832527",
    "Full Abstract": "The deductive approach to verifying temporal properties of reactive systems is based on verification rules, which reduce the system validity of a temporal property to the general validity of first-order verification conditions. This methodology is complete relative to the underlying first-order reasoning. However, the proofs can be difficult to construct and understand, particularly as the complexity of the system increases.We have developed diagram-based formalisms for the verification of general temporal properties of reactive, real-time and hybrid systems. A diagram is a visual abstraction of the system to be verified; it represents the aspects of the system relevant to the property to be proved. The diagram represents a schematic overview of a deductive proof, and therefore it is more intuitive and easier to construct and understand.These methods combine deductive and algorithmic verification, and are being extended to include modularity, abstraction and refinement to facilitate the verification of larger, more complex systems."
  },
  {
    "Title": "Deductive Model Checking",
    "URL": "https://dl.acm.org/doi/10.1023/A%3A1008791913551",
    "Full Abstract": "We present an extension of classical tableau-based model checking procedures to the case of infinite-state systems, using deductive methods in an incremental construction of the behavior graph. Logical formulas are used to represent infinite sets of states in an abstraction of this graph, which is repeatedly refined in the search for a counterexample computation, ruling out large portions of the graph before they are expanded to the state-level. This can lead to large savings, even in the case of finite-state systems. Only local conditions need to be checked at each step, and previously proven properties can be used to further constrain the search. Although the resulting method is not always automatic, it provides a flexible, general and complete framework that can integrate a diverse number of other verification tools."
  },
  {
    "Title": "Verification of Parameterized Systems by Dynamic Induction on Diagrams",
    "URL": "https://dl.acm.org/doi/10.5555/647768.733794",
    "Full Abstract": "In this paper we present a visual approach to proving progress properties of parameterized systems using induction on verification diagrams. The inductive hypothesis is represented by an automaton and is based on a state-dependent order on process indices, for increased flexibility. This approach yields more intuitive proofs for progress properties and simpler verification conditions that are more likely to be proved automatically."
  },
  {
    "Title": "Verifying Temporal Properties of Reactive Systems",
    "URL": "https://dl.acm.org/doi/10.1023/A%3A1008700623084",
    "Full Abstract": "We review a number of formal verification techniques supported by STeP, the Stanford Temporal Prover, describing how the tool can be used to verify properties of several versions of the Bakery Mutual exclusion algorithm for mutual exclusion. We verify the classic two-process algorithm and simple variants, as well as an atomic parameterized version. The methods used include deductive verification rules, verification diagrams, automatic invariant generation, and finite-state model checking and abstraction."
  },
  {
    "Title": "Alternating the Temporal Picture for Safety",
    "URL": "https://dl.acm.org/doi/10.5555/646253.686326",
    "Full Abstract": "We use alternating automata on infinite words to reduce the verification of linear temporal logic (LTL) safety properties over infinite-state systems to the proof of first-order verification conditions. Thus method generalizes the traditional deductive verification approach of providing verification rules for particular classes of formulas, such as invariances, nested precedence formulas, etc. It facilitates the deductive verification of arbitrary safety properties without the need for explicit temporal reasoning."
  },
  {
    "Title": "The ‘Cash-Point’ Service: A Verification Case Study Using STeP",
    "URL": "https://dl.acm.org/doi/10.1007/s001650070014",
    "Full Abstract": "STeP, the Stanford Temporal Prover, supports the computer-aided formal verification of concurrent and reactive systems based on temporal specifications [MBB99]. Automated"
  },
  {
    "Title": "Non-linear loop invariant generation using Gröbner bases",
    "URL": "https://dl.acm.org/doi/10.1145/964001.964028",
    "Full Abstract": "We present a new technique for the generation of non-linear (algebraic) invariants of a program. Our technique uses the theory of ideals over polynomial rings to reduce the non-linear invariant generation problem to a numerical constraint solving problem. So far, the literature on invariant generation has been focussed on the construction of linear invariants for linear programs. Consequently, there has been little progress toward non-linear invariant generation. In this paper, we demonstrate a technique that encodes the conditions for a given template assertion being an invariant into a set of constraints, such that all the solutions to these constraints correspond to non-linear (algebraic) loop invariants of the program. We discuss some trade-offs between the completeness of the technique and the tractability of the constraint-solving problem generated. The application of the technique is demonstrated on a few examples."
  },
  {
    "Title": "Deductive verification of real-time systems using STeP",
    "URL": "https://dl.acm.org/doi/10.1016/S0304-3975%2800%2900088-8",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Scalable analysis of linear systems using mathematical programming",
    "URL": "https://dl.acm.org/doi/10.1007/978-3-540-30579-8_2",
    "Full Abstract": "We present a method for generating linear invariants for large systems. The method performs forward propagation in an abstract domain consisting of arbitrary polyhedra of a predefined fixed shape. The basic operations on the domain like abstraction, intersection, join and inclusion tests are all posed as linear optimization queries, which can be solved efficiently by existing LP solvers. The number and dimensionality of the LP queries are polynomial in the program dimensionality, size and the number of target invariants. The method generalizes similar analyses in the interval, octagon, and octahedra domains, without resorting to polyhedral manipulations. We demonstrate the performance of our method on some benchmark programs."
  },
  {
    "Title": "Termination of polynomial programs",
    "URL": "https://dl.acm.org/doi/10.1007/978-3-540-30579-8_8",
    "Full Abstract": "We present a technique to prove termination of multipath polynomial programs, an expressive class of loops that enables practical code abstraction and analysis. The technique is based on finite differences of expressions over transition systems. Although no complete method exists for determining termination for this class of loops, we show that our technique is useful in practice. We demonstrate that our prototype implementation for C source code readily scales to large software projects, proving termination for a high percentage of targeted loops."
  },
  {
    "Title": "LOLA",
    "URL": "https://dl.acm.org/doi/10.1109/TIME.2005.26",
    "Full Abstract": "We present a specification language and algorithms for the online and offline monitoring of synchronous systems including circuits and embedded systems. Such monitoring is useful not only for testing, but also under actual deployment. The specification language is simple and expressive; it can describe both correctness/failure assertions along with interesting statistical measures that are useful for system profiling and coverage analysis. The algorithm for online monitoring of queries in this language follows a partial evaluation strategy: it incrementally constructs output streams from input streams, while maintaining a store of partially evaluated expressions for forward references. We identify a class of specifications, characterized syntactically, for which the algorithmýs memory requirement is independent of the length of the input streams. Being able to bound memory requirements is especially important in online monitoring of large input streams. We extend the concepts used in the online algorithm to construct an efficient offline monitoring algorithm for large traces. We have implemented our algorithm and applied it to two industrial systems, the PCI bus protocol and a memory controller. The results demonstrate that our algorithms are practical and that our specification language is sufficiently expressive to handle specifications of interest to industry."
  },
  {
    "Title": "Linear ranking with reachability",
    "URL": "https://dl.acm.org/doi/10.1007/11513988_48",
    "Full Abstract": "We present a complete method for synthesizing"
  },
  {
    "Title": "The polyranking principle",
    "URL": "https://dl.acm.org/doi/10.1007/11523468_109",
    "Full Abstract": "Although every terminating loop has a ranking function, not every loop has a ranking function of a restricted form, such as a lexicographic tuple of polynomials over program variables. The"
  },
  {
    "Title": "The decidability of the first-order theory of knuth-bendix order",
    "URL": "https://dl.acm.org/doi/10.1007/11532231_10",
    "Full Abstract": "Two kinds of orderings are widely used in term rewriting and theorem proving, namely"
  },
  {
    "Title": "Termination analysis of integer linear loops",
    "URL": "https://dl.acm.org/doi/10.1007/11539452_37",
    "Full Abstract": "Usually, ranking function synthesis and invariant generation over a loop with integer variables involves abstracting the loop to have real variables. Integer division and modulo arithmetic must be soundly abstracted away so that the analysis over the abstracted loop is sound for the original loop. Consequently, the analysis loses precision. In contrast, we introduce a technique for handling loops over integer variables directly. The resulting analysis is more precise than previous analyses."
  },
  {
    "Title": "Final semantics for event-pattern reactive programs",
    "URL": "https://dl.acm.org/doi/10.1007/11548133_23",
    "Full Abstract": "Event-pattern reactive programs are front-end programs for distributed reactive components that preprocess an incoming stream of event stimuli. Their purpose is to recognize temporal patterns of events that are relevant to the serviced program and ignore all other events, outsourcing some of the component's complexity and shielding it from event overload. Correctness of event-pattern reactive programs is essential, because bugs may result in loss of relevant events and hence failure to react appropriately."
  },
  {
    "Title": "Thread allocation protocols for distributed real-time and embedded systems",
    "URL": "https://dl.acm.org/doi/10.1007/11562436_13",
    "Full Abstract": "We study the problem of thread allocation in asynchronous distributed real-time and embedded systems. Each distributed node handles a limited set of resources, in particular a limited thread pool. Different methods can be invoked concurrently in each node, either by external agents or as a remote call during the execution of a method. In this pa- per we study thread allocation under a"
  },
  {
    "Title": "Expressive completeness of an event-pattern reactive programming language",
    "URL": "https://dl.acm.org/doi/10.1007/11562436_39",
    "Full Abstract": "Event-pattern reactive programs serve reactive components by pre-processing the input event stream and generating notifications according to temporal patterns. The declarative language PAR allows the expression of complex event-pattern reactions. Despite its simplicity and deterministic nature, PAR is expressively complete in the following sense:"
  },
  {
    "Title": "Termination and invariance analysis of loops",
    "URL": "https://dl.acm.org/doi/10.1007/11562948_2",
    "Full Abstract": "Deductive verification aims to prove deep properties about programs. The classic Floyd-Hoare-style approach to verifying sequential programs reduces program validity queries to first-order validity queries via verification conditions. Proving that a program is totally correct requires proving the safety aspect with invariants and the progress aspect with invariants and ranking functions. Where do the invariants and ranking functions come from?"
  },
  {
    "Title": "Optimal allocation of computational resources in VLSI",
    "URL": "https://dl.acm.org/doi/10.5555/1382436.1382776",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Locking Protocols",
    "URL": "https://dl.acm.org/doi/10.1145/2157.322406",
    "Full Abstract": "Copyright © 1983 ACM."
  },
  {
    "Title": "A Non-Two-Phase Locking Protocol for Concurrency Control in General Databases",
    "URL": "https://dl.acm.org/doi/10.5555/645911.673599",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Optimal Allocation of Area for Single-Chip Computations",
    "URL": "https://dl.acm.org/doi/10.1137/0214053",
    "Full Abstract": "This paper presents initial results on the problem of allocation of the available VLSI chip’s area among various functional components such as I/Q pads, memory cells, and internal wiring. First, a general lower bound for any chip computing a transitive function is derived; this bound is tight for certain functions. The arguments used in the various derivations are later used to specify which of the components are critical depending on the relative sizes of the chip and the number of variables of the function to be computed. The general lower bound is powerful enough that many of the previously proved lower bounds (which could account only for some of the functional requirements) are obtained as explicit special cases of the new result."
  },
  {
    "Title": "On high-speed computing with a programmable linear array",
    "URL": "https://dl.acm.org/doi/10.5555/62972.63026",
    "Full Abstract": "It has been observed by many researchers that systolic arrays are very suitable for certain high-speed computations. In this paper, using a formal methodology, a single simple programmable linear systolic array capable of solving large number of problems drawn from a variety of applications is designed. The methodology is applicable to problems solvable by sequential algorithms that can be specified as nested for loops of arbitrary depth. The algorithms of this form that can be computed on the array presented in this paper include 25 algorithms dealing with signal and image processing, algebraic computations, matrix arithmetic, pattern matching, database operations, sorting, and transitive closure. Assuming bounded I/O, for 18 of those algorithms the time and storage complexities are optimal, and therefore no improvement can be expected by utilizing dedicated special purpose linear systolic arrays designed for individual algorithms."
  },
  {
    "Title": "Synthesizing Linear Array Algorithms from Nested FOR Loop Algorithms",
    "URL": "https://dl.acm.org/doi/10.1109/12.9735",
    "Full Abstract": "The mapping of algorithms structured as depth-p nested FOR loops into special-purpose systolic VLSI linear arrays is addressed. The mappings are done by using linear functions to transform the original sequential algorithms into a form suitable for parallel execution on linear arrays. A feasible mapping is derived by identifying formal criteria to be satisfied by both the original sequential algorithm and the proposed transformation function. The methodology is illustrated by synthesizing algorithms for matrix multiplication and a version of the Warshall-Floyd transitive closure algorithm."
  },
  {
    "Title": "On visible surface generation by a priori tree structures",
    "URL": "https://dl.acm.org/doi/10.5555/95075.95084",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Querying and Controlling the Future Behaviour of Complex Objects",
    "URL": "https://dl.acm.org/doi/10.5555/645474.653854",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Optimal parallel suffix-prefix matching algorithm and applications",
    "URL": "https://dl.acm.org/doi/10.1145/72935.72977",
    "Full Abstract": "Copyright © 1989 ACM."
  },
  {
    "Title": "Relational database behavior: utilizing relational discrete event systems and models",
    "URL": "https://dl.acm.org/doi/10.1145/73721.73754",
    "Full Abstract": "Behavior of relational databases is studied within the framework of"
  },
  {
    "Title": "Mapping Nested Loop Algorithms into Multidimensional Systolic Arrays",
    "URL": "https://dl.acm.org/doi/10.1109/71.80125",
    "Full Abstract": "Consideration is given to transforming depth p-nested for loop algorithms into q-dimensional systolic VLSI arrays where 1>or=q>or=p-1. Previously, there existed complete characterizations of correct transformation only for the cases where q=p-1 orq=1. This gap is filled by giving formal necessary and sufficient conditions for correct transformation of a p-nested loop algorithm into a q-dimensional systolic array for any q,1>or=q>or=p-1. Practical methods are presented. The techniques developed are applied to the automatic design of special purpose and programmable systolic arrays. The results also contribute toward automatic compilation onto more general purpose programmable arrays. Synthesis of linear and planar systolic array implementations for a three-dimensional cube-graph algorithm and a reindexed Warshall-Floyd path-finding algorithm are used to illustrate the method."
  },
  {
    "Title": "Efficient robust parallel computations",
    "URL": "https://dl.acm.org/doi/10.1145/100216.100231",
    "Full Abstract": "Copyright © 1990 ACM."
  },
  {
    "Title": "The ",
    "URL": "https://dl.acm.org/doi/10.1145/78922.78927",
    "Full Abstract": "Concurrency control protocols based on two-phase locking are a popular family of locking protocols that preserve serializability in general (unstructured) database systems. A concurrency control algorithm (for databases with no inherent structure) is presented that is practical, non two-phase, and allows varieties of serializable logs not possible with any commonly known locking schemes. All transactions are required to predeclare the data they intend to read or write. Using this information, the protocol anticipates the existence (or absence) of possible conflicts and hence can allow non-two-phase locking."
  },
  {
    "Title": "On high-speed computing with a programmable linear array",
    "URL": "https://dl.acm.org/doi/10.1007/BF00127833",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Combining tentative and definite executions for dependable parallel computing",
    "URL": "https://dl.acm.org/doi/book/10.5555/99342",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Combining tentative and definite executions for very fast dependable parallel computing",
    "URL": "https://dl.acm.org/doi/10.1145/103418.103459",
    "Full Abstract": "Copyright © 1991 ACM."
  },
  {
    "Title": "Fast Parallel Algorithms for Coloring Random Graphs",
    "URL": "https://dl.acm.org/doi/10.5555/647672.757138",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Optimal parallel algorithms for forest and term matching",
    "URL": "https://dl.acm.org/doi/10.1016/0304-3975%2892%2990332-A",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "RAPID",
    "URL": "https://dl.acm.org/doi/10.1016/S0925-7721%2898%2900008-X",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Quantum Cryptography with Imperfect Apparatus",
    "URL": "https://dl.acm.org/doi/10.5555/795664.796390",
    "Full Abstract": "Quantum key distribution, first proposed by Bennett and Brassard, provides a possible key distribution scheme whose security depends only on the quantum laws of physics. So far the protocol has been proved secure even under channel noise and detector faults of the receiver, but is vulnerable if the photon source used is imperfect. In this paper we propose and give a concrete design for a new concept, \"self-checking source\", which requires the manufacturer of the photon source to provide certain tests; these tests are designed such that, if passed, the source is guaranteed to be adequate for the security of the quantum key distribution protocol, even though the testing devices may not be built to the original specification. The main mathematical result is a structural theorem which states that, for any state in a Hilbert space, if certain EPR-type equations are satisfied, the state must be essentially the orthogonal sum of EPR pairs."
  },
  {
    "Title": "An exponential lower bound on the size of algebraic decision trees for max",
    "URL": "https://dl.acm.org/doi/10.1007/s000370050010",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "NQP",
    "URL": "https://dl.acm.org/doi/10.1016/S0020-0190%2899%2900084-8",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Quantum bit escrow",
    "URL": "https://dl.acm.org/doi/10.1145/335305.335404",
    "Full Abstract": "Copyright © 2000 ACM."
  },
  {
    "Title": "Some perspectives on computational complexity",
    "URL": "https://dl.acm.org/doi/10.1145/380752.380856",
    "Full Abstract": "In past decades, the theory of computational complexity has flourished in terms of both the revelation of its internal structures and the unfolding of its numerous applications. In this paper we discuss several persistent and interwoven themes underlying many of these accomplishments. Chief among them are the interplay between communication and computation, the power of problem reduction, and the increasingly prominent role played by classical mathematics. We will also speculate on a few promising directions for future development of computational complexity."
  },
  {
    "Title": "Read-Once Branching Programs, Rectangular Proofs of the Pigeonhole Principle and the Transversal Calculus",
    "URL": "https://dl.acm.org/doi/10.1007/s00493-002-0007-7",
    "Full Abstract": "We investigate read-once branching programs for the following search problem: given a Boolean"
  },
  {
    "Title": "Classical physics and the Church--Turing Thesis",
    "URL": "https://dl.acm.org/doi/10.1145/602382.602411",
    "Full Abstract": "Would physical laws permit the construction of computing machines that are capable of solving some problems much faster than the standard computational model? Recent evidence suggests that this might be the case in the quantum world. But the question is of great interest even in the realm of classical physics. In this article, we observe that there is fundamental tension between the Extended Church--Turing Thesis and the existence of numerous seemingly intractable computational problems arising from classical physics. Efforts to resolve this incompatibility could both advance our knowledge of the theory of computation, as well as serve the needs of scientific computing."
  },
  {
    "Title": "On the power of quantum fingerprinting",
    "URL": "https://dl.acm.org/doi/10.1145/780542.780554",
    "Full Abstract": "In the simultaneous message model, two parties holding"
  },
  {
    "Title": "Graph entropy and quantum sorting problems",
    "URL": "https://dl.acm.org/doi/10.1145/1007352.1007377",
    "Full Abstract": "Let P = (X, <"
  },
  {
    "Title": "Graph Properties and Circular Functions",
    "URL": "https://dl.acm.org/doi/10.5555/1009378.1009564",
    "Full Abstract": "In decision tree models, considerable attention has beenpaid on the effect of symmetry on computational complexity.That is, for a permutation group, how low can thecomplexity be for any boolean function invariant under __ __In this paper we investigate this question for quantum decisiontrees for graph properties, directed graph properties,and circular functions. In particular, we prove that the n-vertexScorpion graph property has quantum query complexity\\widetilde\\Theta (n^{1/2}), which implies that the minimum quantumcomplexity for graph properties is strictly less than thatfor monotone graph properties (known to be \\widetilde\\Theta (n^{2/3})). Adirected graph property, SINK, is also shown to have the\\widetilde\\Theta (n^{1/2}) quantum query complexity. Furthermore, we givean N-ary circular function which has the quantum querycomplexity \\widetilde\\Theta (n^{1/4}). Finally, we show that for any permutationgroup, as long as is transitive, the quantumquery complexity of any function invariant to is at least\\widetilde\\Theta (n^{1/4}), which implies that our examples are (almost) thebest ones in the sense of pinning down the complexity forthe corresponding permutation group."
  },
  {
    "Title": "Self testing quantum apparatus",
    "URL": "https://dl.acm.org/doi/10.5555/2011827.2011830",
    "Full Abstract": "We study, in the context of quantum information and quantum communication, a configuration of devices that includes (1) a source of some unknown bipartite quantum state that is claimed to be the Bell state Φ"
  },
  {
    "Title": "Oblivious and Adaptive Strategies for the Majority and Plurality Problems",
    "URL": "https://dl.acm.org/doi/10.5555/2958119.2958222",
    "Full Abstract": "In the well-studied Majority problem, we are given a set of n balls colored with two or more colors, and the goal is to use the minimum number of color comparisons to find a ball of the majority color i.e., a color that occurs for more than ï ź n/2 ï ź times. The Plurality problem has exactly the same setting while the goal is to find a ball of the dominant color i.e., a color that occurs most often. Previous literature regarding this topic dealt mainly with adaptive strategies, whereas in this paper we focus more on the oblivious i.e., non-adaptive strategies. Given that our strategies are oblivious, we establish a linear upper bound for the Majority problem with arbitrarily many different colors. We then show that the Plurality problem is significantly more difficult by establishing quadratic lower and upper bounds. In the end, we also discuss some generalized upper bounds for adaptive strategies in the k-color Plurality problem."
  },
  {
    "Title": "On the communication complexity of co-linearity problems",
    "URL": "https://dl.acm.org/doi/10.1007/11549345_6",
    "Full Abstract": "In the"
  },
  {
    "Title": "On the security of public key protocols",
    "URL": "https://dl.acm.org/doi/10.1109/TIT.1983.1056650",
    "Full Abstract": "Recently the use of public key encryption to provide secure network communication has received considerable attention. Such public key systems are usually effective against passive eavesdroppers, who merely tap the lines and try to decipher the message. It has been pointed out, however, that an improperly designed protocol could be vulnerable to an active saboteur, one who may impersonate another user or alter the message being transmitted. Several models are formulated in which the security of protocols can be discussed precisely. Algorithms and characterizations that can be used to determine protocol security in these models are given."
  },
  {
    "Title": "On the Quantum Query Complexity of Local Search in Two and Three Dimensions",
    "URL": "https://dl.acm.org/doi/10.1109/FOCS.2006.57",
    "Full Abstract": "The quantum query complexity of searching for local optima has been a subject of much interest in the recent literature. For the d-dimensional grid graphs, the complexity has been determined asymptotically for all fixed d \\geqslant 5, but the lower dimensional cases present special difficulties, and considerable gaps exist in our knowledge. In the present paper we present near-optimal lower bounds, showing that the quantum query complexity for the 2-dimensional grid [n]^2 is \\Omega \\left( {n^{1/2 - \\delta } } \\right), and that for the 3-dimensional grid [n]^3 is \\Omega (n^{1- \\delta } ), for any fixed \\delta \\ge 0. A general lower bound approach for this problem, initiated by Aaronson [1](based on Ambainis' adversary method [3] for quantum lower bounds), uses random walks with low collision probabilities. This approach encounters obstacles in deriving tight lower bounds in low dimensions due to the lack of degrees of freedom in such spaces. We solve this problem by the novel construction and analysis of random walks with non-uniform step lengths. The proof employs in a nontrivial way sophisticated results of Sarkozy and Szemeredi [14], Bose and Chowla [5], and Halasz [9] from combinatorial number theory, as well as less familiar probability tools like Esseen's Inequality."
  },
  {
    "Title": "Oblivious and Adaptive Strategies for the Majority and Plurality Problems",
    "URL": "https://dl.acm.org/doi/10.1007/s00453-007-0060-0",
    "Full Abstract": "In the well-studied Majority problem, we are given a set of n balls colored with two or more colors, and the goal is to use the minimum number of color comparisons to find a ball of the majority color (i.e., a color that occurs for more than n/2 times). The Plurality problem has exactly the same setting while the goal is to find a ball of the dominant color (i.e., a color that occurs most often). Previous literature regarding this topic dealt mainly with adaptive strategies, whereas in this paper we focus more on the oblivious (i.e., non-adaptive) strategies. Given that our strategies are oblivious, we establish a linear upper bound for the Majority problem with arbitrarily many different colors assuming a majority label exists. We then show that the Plurality problem is significantly more difficult by establishing quadratic lower and upper bounds. In the end we also discuss some generalized upper bounds for adaptive strategies in the k-color Plurality problem."
  },
  {
    "Title": "A note on universal composable zero knowledge in common reference string model",
    "URL": "https://dl.acm.org/doi/10.5555/1767854.1767898",
    "Full Abstract": "Pass observed that universal composable zero-knowledge (UCZK) protocols in the common reference string (CRS) model, where a common reference string is selected trustily by a trusted third party and is known to all players, lose deniability that is a natural property of any ZK protocol in the plain model [33]. An open problem (or, natural query) raised in the literature is: are there any other essential security properties, other than the well-known deniability property, that could be lost by universal composable zero-knowledge in the common reference string model, in comparison with UC security in the plain model? In this work, we answer this open question (or, natural query), by showing that UCZK protocols in the CRS model could lose concurrent general composability (CGC) and proof of knowledge (POK) properties that are very important and essential security implications of UCZK in the plain model. This is demonstrated by concrete attacks."
  },
  {
    "Title": "A note on the feasibility of generalized universal composability",
    "URL": "https://dl.acm.org/doi/10.5555/1767854.1767899",
    "Full Abstract": "We clarify the potential limitation of the general feasibility for generalized universal composability (GUC) proposed in the recent work [8], and discuss a general principle for fully realizing universal composability. This in particular demonstrates the hardness of achieving generalized universal composability, and prevents potential misinterpretation in applications. We also propose some fixing approaches, which involve a source/session-authentic ID-based trapdoor commitment scheme via the hash-then-commit paradigm that could possibly be of independent interest."
  },
  {
    "Title": "Graph Design for Secure Multiparty Computation over Non-Abelian Groups",
    "URL": "https://dl.acm.org/doi/10.1007/978-3-540-89255-7_3",
    "Full Abstract": "Recently, Desmedt et al. studied the problem of achieving secure<em>n</em> -party computation over non-Abelian groups. Theyconsidered the passive adversary model and they assumed that theparties were only allowed to perform black-box operations over thefinite group <em>G</em> . They showed three results for the<em>n</em> -product function <em>f</em>"
  },
  {
    "Title": "An object-oriented framework for the integration of interactive animation techniques",
    "URL": "https://dl.acm.org/doi/10.1145/122718.122730",
    "Full Abstract": "We present an interactive modeling and animation system that facilitates the integration of a variety of simulation and animation paradigms. This system permits the modeling of diverse objects that change in shape, appearance, and behaviour over time. Our system thus extends modeling tools to include animation controls. Changes can be effected by various methods of control, including scripted, gestural, and behavioral specification. The system is an extensible testbed that supports research in the interaction of disparate control methods embodied in controller objects. This paper discusses some of the issues involved in modeling such interactions and the mechanisms implemented to provide solutions to some of these issues.The system's object-oriented architecture uses delegation hierarchies to let objects change all of their attributes dynamically. Objects include displayable objects, controllers, cameras, lights, renderers, and user interfaces. Techniques used to obtain interactive performance include the use of data-dependency networks, lazy evaluation, and extensive caching to exploit inter- and intra-frame coherency."
  },
  {
    "Title": "User-Interface Developments for the Nineties",
    "URL": "https://dl.acm.org/doi/10.1109/2.84899",
    "Full Abstract": "The purpose and history of user interfaces are briefly recounted. The language model and the implementation model of the user-computer dialogue are examined. User-centered design is discussed, and approaches to design tools are described. Key developments for the 1990s are considered. These include base technologies, 3-D user interfaces, virtual realities, multimedia and hypermedia, groupware, and intelligent agents, i.e., computer-based assistants or guides"
  },
  {
    "Title": "Three-dimensional widgets",
    "URL": "https://dl.acm.org/doi/10.1145/147156.147199",
    "Full Abstract": "Copyright © 1992 ACM."
  },
  {
    "Title": "Using deformations to explore 3D widget design",
    "URL": "https://dl.acm.org/doi/10.1145/133994.134091",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "From Discipline in Crisis to Mature Science",
    "URL": "https://dl.acm.org/doi/10.5555/618976.619846",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Interactive shadows",
    "URL": "https://dl.acm.org/doi/10.1145/142621.142622",
    "Full Abstract": "It is often difficult in computer graphics applications to understand spatial relationships between objects in a 3D scene or effect changes to those objects without specialized visualization and manipulation techniques. We present a set of three-dimensional tools (widgets) called “shadows” that not only provide valuable perceptual cues about the spatial relationships between objects, but also provide a direct manipulation interface to constrained transformation techniques. These shadow widgets provide two advances over previous techniques. First, they provide high correlation between their own geometric feedback and their effects on the objects they control. Second, unlike some other 3D widgets, they do not obscure the objects they control."
  },
  {
    "Title": "The challenges of 3D interaction",
    "URL": "https://dl.acm.org/doi/10.1145/259963.260500",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Implementing virtual reality",
    "URL": "https://dl.acm.org/doi/10.1145/259963.260525",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Introduction to Computer Graphics Macintosh Version Software of SRGP and SPHIGS Software",
    "URL": "https://dl.acm.org/doi/book/10.5555/1208920",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Introduction to Computer Graphics",
    "URL": "https://dl.acm.org/doi/book/10.5555/561541",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Research frontiers in virtual reality",
    "URL": "https://dl.acm.org/doi/10.1145/192161.192287",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Why is 3-D interaction so hard and what can we really do about it?",
    "URL": "https://dl.acm.org/doi/10.1145/192161.192299",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "The challenges of 3D interaction",
    "URL": "https://dl.acm.org/doi/10.1145/191642.191652",
    "Full Abstract": "3D computer graphics is becoming more and more popular due to the increased availability of 3D hardware and software on all classes of computers. However, despite this growing popularity and the existence of a number of successful 3D graphics applications, particularly in CAD, CAE, and medical and scientific visualization, the field is still very immature, There are no widely accepted standards for hardware or software platforms; learning to implement or use 3D graphics software is still extremely laborious; and the most effective ways for humans to interact with synthetic 3D environments are still not clear."
  },
  {
    "Title": "Interactive visualization via 3D user interfaces",
    "URL": "https://dl.acm.org/doi/10.5555/951087.951089",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Computer Graphics SRGP/SPHIGS for Macintosh",
    "URL": "https://dl.acm.org/doi/book/10.5555/1211196",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Computer graphics (2nd ed. in C)",
    "URL": "https://dl.acm.org/doi/book/10.5555/208249",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Standardisation—opportunity or constraint? (panel session)",
    "URL": "https://dl.acm.org/doi/10.1145/218380.218534",
    "Full Abstract": "Copyright © 1995 Copyright is held by the owner/author(s)."
  },
  {
    "Title": "50 years after “As we may think”",
    "URL": "https://dl.acm.org/doi/10.1145/227181.227187",
    "Full Abstract": "Copyright © 1996 ACM."
  },
  {
    "Title": "A case study in high-end communications technology in distance learning",
    "URL": "https://dl.acm.org/doi/10.5555/1253524.1253778",
    "Full Abstract": "The five principal investigators (PIs) of the graphics and visualization center, a distributed NSF science and technology center, report on the lessons learned from reaching an interactive graduate-level seminar involving their five sites over a high-end communications infrastructure. The experiences related will be of value to institutions presently conducting or considering distance learning. Although the experiences reported here are based an a high-end scenario available to this research center, the present trends in technology and distance education should make these observations applicable in the imminent future to a large number of educational institutions."
  },
  {
    "Title": "Reflections and observations",
    "URL": "https://dl.acm.org/doi/10.5555/1253524.1253826",
    "Full Abstract": "van Dam began teaching computer graphics just as the field was beginning, in the early 1960s. His first class was not of graduate students or post-docs, but was a group of forward thinking high school teachers and their best students. It was this experience that inspired van Dam to pursue a career in academia. For the past 30 years he has taught at Brown University where he co-founded the department of computer science and for 10 years served as its first chairman. The past five years have seen exceptionally strong demand for integration of computers into K-12 curricula driven both by the media hype surrounding computer technology and networks and the increasing pressure on educational institutions to improve scope and quality of education in a publicly demonstrable fashion. These forces have combined to produce a time of great potential for education but also one of great danger. Educators and administrators must consider how can this technology be used to promote rigorous and useful learning rather merely adding glitz to traditional types of assignments. Educators and administrators must also be aware that although computers can bring education to a more diverse and expanding audience, the same technology can serve to divide societies into groups of haves and have nots. van Dam analyzes several means of approaching these and other issues, drawing on current research findings and using real life examples from his experience as a researcher educator, and Director of the Graphics and Visualization Center."
  },
  {
    "Title": "Competitive generalized auctions",
    "URL": "https://dl.acm.org/doi/10.1145/509907.509921",
    "Full Abstract": "We describe mechanisms for auctions that are simultaneously truthful (alternately known as strategy-proof or incentive compatible) and guarantee high \"net\" profit. We make use of appropriate variants of competitive analysis of algorithms in designing and analyzing our mechanisms. Thus, we do not require any probabilistic assumptions on bids.We present two new concepts regarding auctions, that of a cancellable auction and that of a generalized auction. We use cancellable auctions in the design of generalized auctions, but they are of independent interest as well. Cancellable auctions have the property that if the revenue collected does not meet certain predetermined criteria, then the auction can be cancelled and the resulting auction is still truthful. The trivial approach (run a truthful auction and cancel if needed) yields an auction that is not necessarily truthfu.Generalized auctions can be used to model many problems previously considered in the literature, as well as numerous new problems. In particular, we give the first truthful profit-maximizing auctions for problems such as conditional financing and multicast."
  },
  {
    "Title": "Truthful and Competitive Double Auctions",
    "URL": "https://dl.acm.org/doi/10.5555/647912.740970",
    "Full Abstract": "In this paper we consider the problem of designing a mechanism for double auctions where bidders each bid to buy or sell one unit of a single commodity. We assume that each bidder's utility value for the item is private to them and we focus on truthful mechanisms, ones were the bidders' optimal strategy is to bid their true utility. The profit of the auctioneer is the difference between the total payments from buyers and total to the sellers. We aim to maximize this profit. We extend the competitive analysis framework of basic auctions [9] and give an upper bound on the profit of any truthful double auction. We then reduce the competitive double auction problem to basic auctions by showing that any competitive basic auction can be converted into a competitive double auction with a competitive ratio of twice that of the basic auction. In addition, we show that better competitive ratios can be obtained by directly adapting basic auction techniques to the double auction problem. This result provides insight into the design of profit maximizing mechanisms in general."
  },
  {
    "Title": "Mechanism Design for Fun and Profit",
    "URL": "https://dl.acm.org/doi/10.5555/647912.740971",
    "Full Abstract": "The emergence of the Internet as one of the most important arenas for resource sharing between parties with diverse and selfish interests has led to a number of fascinating and new algorithmic problems. In these problems, one must solicit the inputs to each computation from participants (or agents) whose goal is to manipulate the computation to their own advantage. Until fairly recently, failure models in computer science have not dealt the notion of selfish participants who \"play by the rules\" only when it fits them. To deal with this, algorithms must be designed so as to provide motivation to the participants to \"play along\". Recent work in this area, has drawn on ideas from game theory and microeconomics, and specifically from the field of mechanism design. The goal is to design protocols so that rational agents will be motivated to adhere to the protocol. A specific focus has been on truthful mechanisms in which selfish agents are motivated to reveal their true inputs.In the first part of the talk, we survey recent work in the area of algorithm mechanism design. In the second part of the talk, we focus on mechanism design specifically geared at maximizing the profit of the mechanism designer. In particular, we consider a class of dynamic pricing problems motivated by the same computational and economic trends. We describe a class of generalized auction problems as well as a competitive framework that can be used to evaluate solutions to these problems. We present a number of results on the design of profit-maximizing truthful generalized auctions. This is joint work with Amos Fiat, Andrew Goldberg and Jason Hartline."
  },
  {
    "Title": "On list update and work function algorithms",
    "URL": "https://dl.acm.org/doi/10.1016/S0304-3975%2801%2900253-5",
    "Full Abstract": "The"
  },
  {
    "Title": "On profit-maximizing envy-free pricing",
    "URL": "https://dl.acm.org/doi/10.5555/1070432.1070598",
    "Full Abstract": "We study the problem of pricing items for sale to consumers so as to maximize the seller's revenue. We assume that for each consumer, we know the maximum amount he would be willing to pay for each bundle of items, and want to find pricings of the items with corresponding allocations that maximize seller profit and at the same time are"
  },
  {
    "Title": "Beyond VCG",
    "URL": "https://dl.acm.org/doi/10.1109/SFCS.2005.25",
    "Full Abstract": "We study truthful mechanisms for auctions in which the auctioneer is trying to hire a team of agents to perform a complex task, and paying them for their work. As common in the field of mechanism design, we assume that the agents are selfish and will act in such a way as to maximize their profit, which in particular may include misrepresenting their true incurred cost. Our first contribution is a new and natural definition of the frugality ratio of a mechanism, measuring the amount by which a mechanism \"overpays\", and extending previous definitions to all monopoly-free set systems. After reexamining several known results in light of this new definition, we proceed to study in detail shortest path auctions and \"r-out-of-k sets\" auctions. We show that when individual set systems (e.g., graphs) are considered instead of worst cases over all instances, these problems exhibit a rich structure, and the performance of mechanisms may be vastly different. In particular, we show that the wellknown VCG mechanism may be far from optimal in these settings, and we propose and analyze a mechanism that is always within a constant factor of optimal."
  },
  {
    "Title": "Is the Open Way a Better Way? Digital Forensics Using Open Source Tools",
    "URL": "https://dl.acm.org/doi/10.1109/HICSS.2007.301",
    "Full Abstract": "The subject of digital forensics can be quite challenging. Digital forensics is in its infancy and teaching digital forensics includes the techniques as well as the tools that assist in the process. This article discusses the tools used in computer forensics, compares an open source tool to two commercial tools, and the advantages and disadvantages of all three tools in an academic environment. A team of four senior students sponsored by two faculty members established the project scope and requirements, presented three prototypes, and detailed the considerations of using open source tools. The same image was used to measure the performance of each software tool. The team found that the three tools provided the same results with different degrees of difficulty. The end results indicate that Open Source tools are a very good verification of evidence found using other products and should be included in the academic environment."
  },
  {
    "Title": "Cheap labor can be expensive",
    "URL": "https://dl.acm.org/doi/10.5555/1283383.1283459",
    "Full Abstract": "We study markets in which consumers are trying to hire a team of agents to perform a complex task. Each agent in the market prices their labor, and based on these prices, consumers hire the cheapest available team capable of doing the job they need done. We define the"
  },
  {
    "Title": "Ad Auctions --- Current and Future Research",
    "URL": "https://dl.acm.org/doi/10.1007/978-3-540-72870-2_41",
    "Full Abstract": "An exploding market has emerged during the last few years on the internet, the market of sponsored search slots. Advertisers are able to buy space on the webpages produced by popular search engines and place advertisements to promote their products alongside the regular algorithmic search results. The allocation of these advertising slots and their pricing is done via auctions. Since the introduction of this concept in 1998, sponsored search has evolved into a major source of revenue for internet giants such as Google, Yahoo!, MSN and others. Its success can be attributed partly to its effectiveness as a form of highly targeted advertising, and partly to the appealing framework that allows even small-scale advertisers to use it easily and effectively while only paying when their ad is clicked upon."
  },
  {
    "Title": "Balloon Popping With Applications to Ascending Auctions",
    "URL": "https://dl.acm.org/doi/10.1109/FOCS.2007.15",
    "Full Abstract": "We study the power of ascending auctions in a scenario in which a seller is selling a collection of identical items to anonymous unit-demand bidders. We show that even with full knowledge of the set of bidders' private valuations for the items, if the bidders are ex-ante identical, no ascending auction can extract more than a constant times the revenue of the best fixed price scheme. This problem is equivalent to the problem of coming up with an optimal strategy for blowing up indistinguishable balloons with known capacities in order to maximize the amount of contained air. We show that the algorithm which simply inflates all balloons to a fixed volume is close to optimal in this setting."
  },
  {
    "Title": "Auctions for structured procurement",
    "URL": "https://dl.acm.org/doi/10.5555/1347082.1347116",
    "Full Abstract": "This paper considers a general setting for structured procurement and the problem a buyer faces in designing a procurement mechanism to maximize profit. This brings together two agendas in algorithmic mechanism design, frugality in procurement mechanisms (e.g., for paths and spanning trees) and profit maximization in auctions (e.g., for digital goods). In the standard approach to frugality in procurement, a buyer attempts to purchase a set of elements that satisfy a feasibility requirement as cheaply as possible. For profit maximization in auctions, a seller wishes to sell some number of goods for as much as possible. We unify these objectives by endowing the buyer with a decreasing marginal benefit per feasible set purchased and then considering the problem of designing a mechanism to buy a number of sets which maximize the buyer's profit, i.e., the difference between their benefit for the sets and the cost of procurement. For the case where the feasible sets are bases of a matroid, we follow the approach of reducing the mechanism design optimization problem to a mechanism design decision problem. We give a"
  },
  {
    "Title": "Improved Approximation Algorithms for Budgeted Allocations",
    "URL": "https://dl.acm.org/doi/10.1007/978-3-540-70575-8_16",
    "Full Abstract": "We provide a 3/2-approximation algorithm for an offline budgetedallocations problem with applications to sponsored search auctions.This an improvement over the"
  },
  {
    "Title": "On the Equilibria and Efficiency of the GSP Mechanism in Keyword Auctions with Externalities",
    "URL": "https://dl.acm.org/doi/10.1007/978-3-540-92185-1_69",
    "Full Abstract": "In the increasingly important market of online search advertising, a multitude of parameters affect the performance of advertising campaigns and their ability to attract users' attention enough to produce clicks. Thus far, the majority of the relevant literature assumed an advertisement's probability of receiving a click to be dependent on the advertisement's quality and its position in the sponsored search list, but independent of the other advertisements shown on the same webpage."
  },
  {
    "Title": "Approximating Matches Made in Heaven",
    "URL": "https://dl.acm.org/doi/10.1007/978-3-642-02927-1_23",
    "Full Abstract": "Motivated by applications in online dating and kidney exchange, we study a stochastic matching problem in which we have a random graph"
  },
  {
    "Title": "Algorithms for Data Migration",
    "URL": "https://dl.acm.org/doi/10.5555/3118232.3118517",
    "Full Abstract": "The data migration problem is the problem of computing a plan for moving data objects stored on devices in a network from one configuration to another. Load balancing or changing usage patterns might necessitate such a rearrangement of data. In this paper, we consider the case where the objects are fixed-size and the network is complete. Our results are both theoretical and empirical. Our main theoretical results are (1) a polynomial time algorithm for finding a near-optimal migration plan in the presence of space constraints when a certain number of additional nodes is available as temporary storage, and (2) a 3/2-approximation algorithm for the case where data must be migrated directly to its destination. We also run extensive experiments on several algorithms for various data migration problems and show that empirically, many algorithms perform better in practice than their theoretical bounds suggest. We conclude that many of the algorithms we present are both practical and effective for data migration."
  },
  {
    "Title": "Integrality gaps of linear and semi-definite programming relaxations for Knapsack",
    "URL": "https://dl.acm.org/doi/10.5555/2018158.2018182",
    "Full Abstract": "In this paper, we study the integrality gap of the Knapsack linear program in the Sherali-Adams and Lasserre hierarchies. First, we show that an integrality gap of 2 - ε persists up to a linear number of rounds of Sherali-Adams, despite the fact that Knapsack admits a fully polynomial time approximation scheme [24, 30]. Second, we show that the Lasserre hierarchy closes the gap quickly. Specifically, after"
  },
  {
    "Title": "Prior-independent multi-parameter mechanism design",
    "URL": "https://dl.acm.org/doi/10.1007/978-3-642-25510-6_11",
    "Full Abstract": "In a unit-demand multi-unit multi-item auction, an auctioneer is selling a collection of different items to a set of agents each interested in buying at most unit. Each agent has a different private value for each of the items. We consider the problem of designing a truthful auction that maximizes the auctioneer's profit in this setting. Previously, there has been progress on this problem in the setting in which each value is drawn from a known prior distribution. Specifically, it has been shown how to design auctions tailored to these priors that achieve a constant factor approximation ratio [2, 5]. In this paper, we present a prior-independent auction for this setting. This auction is guaranteed to achieve a constant fraction of the optimal expected profit for a large class of, so called, \"regular\" distributions, without specific knowledge of the distributions."
  },
  {
    "Title": "Approximately revenue-maximizing auctions for deliberative agents",
    "URL": "https://dl.acm.org/doi/10.5555/2900728.2900914",
    "Full Abstract": "In many real-world auctions, a bidder does not know her exact value for an item, but can perform a costly deliberation to reduce her uncertainty. Relatively little is known about such deliberative environments, which are fundamentally different from classical auction environments. In this paper, we propose a new approach that allows us to leverage classical revenue-maximization results in deliberative environments. In particular, we use Myerson (1981) to construct the first nontrivial (i.e., dependent on deliberation costs) upper bound on revenue in deliberative auctions. This bound allows us to apply existing results in the classical environment to a deliberative environment. In addition, we show that in many deliberative environments the only optimal dominant-strategy mechanisms take the form of sequential posted-price auctions."
  },
  {
    "Title": "Evaluating competitive game balance with restricted play",
    "URL": "https://dl.acm.org/doi/10.5555/3014629.3014635",
    "Full Abstract": "Game balancing is the fine-tuning phase in which a functioning game is adjusted to be deep, fair, and interesting. Balancing is difficult and time-consuming, as designers must repeatedly tweak parameters, and run lengthy playtests to evaluate the effects of these changes. If designers could receive immediate feedback on their designs, they could explore a vast space of variations, and select only the most promising games for playtesting. Such automated design feedback has been difficult to achieve, as there is no mathematical formulation of game balance that unifies many of its forms. We argue for a formulation in which carefully restricted agents are played against standard agents. We develop this"
  },
  {
    "Title": "A Short Presentation of Coq",
    "URL": "https://dl.acm.org/doi/10.1007/978-3-540-71067-7_3",
    "Full Abstract": "The Coq proof assistant has been developed at INRIA, Ecole Normale Supérieure de Lyon, and University of Paris South for more than twenty years [6]. Its theoretical foundation is known as the \"Calculus of Inductive Constructions\" [4,5]. Versions of the system were distributed regularly from 1989 (version 4.10). The current revision is 8.1 and a revision 8.2 is about to come out. This 8th generation was started in 2004, at the time when a radical change in syntax was enforced and a textbook [2] was published. A more complete historical overview, provided by G. Huet and C. Paulin-Mohring, is available in the book foreword."
  },
  {
    "Title": "Using Structural Recursion for Corecursion",
    "URL": "https://dl.acm.org/doi/10.1007/978-3-642-02444-3_14",
    "Full Abstract": "We propose a (limited) solution to the problem of constructing stream values defined by recursive equations that do not respect the guardedness condition. The guardedness condition is imposed on definitions of corecursive functions in Coq, AGDA, and other higher-order proof assistants. In this paper, we concentrate in particular on those non-guarded equations where recursive calls appear under functions. We use a correspondence between streams and functions over natural numbers to show that some classes of non-guarded definitions can be modelled through the encoding as structural recursive functions. In practice, this work extends the class of stream values that can be defined in a constructive type theory-based theorem prover with inductive and coinductive types, structural recursion and guarded corecursion."
  },
  {
    "Title": "From Semantics to Computer Science",
    "URL": "https://dl.acm.org/doi/book/10.5555/1658177",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Formal study of plane delaunay triangulation",
    "URL": "https://dl.acm.org/doi/10.1007/978-3-642-14052-5_16",
    "Full Abstract": "This article presents the formal proof of correctness for a plane Delaunay triangulation algorithm. It consists in repeating a sequence of edge flippings from an initial triangulation until the Delaunay property is achieved. To describe triangulations, we rely on a combinatorial hypermap specification framework we have been developing for years. We embed hypermaps in the plane by attaching coordinates to elements in a consistent way. We then describe what are legal and illegal Delaunay edges and a flipping operation which we show preserves hypermap, triangulation, and embedding invariants. To prove the termination of the algorithm, we use a generic approach expressing that any non-cyclic relation is well-founded when working on a finite set."
  },
  {
    "Title": "Interactive Theorem Proving and Program Development",
    "URL": "https://dl.acm.org/doi/book/10.5555/1965123",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "A coq-based library for interactive and automated theorem proving in plane geometry",
    "URL": "https://dl.acm.org/doi/10.5555/2029365.2029401",
    "Full Abstract": "In this article, we present the development of a library of formal proofs for theorem proving in plane geometry in a pedagogical context. We use the Coq proof assistant. This library includes the basic geometric notions to state theorems and provides a database of theorems to construct interactive proofs more easily. It is an extension of the library of F. Guilhot for interactive theorem proving at the level of high-school geometry, where we eliminate redundant axioms and give formalizations for the geometric concepts using a vector approach. We also enrich this library by offering an automated deduction method which can be used as a complement to interactive proof. For that purpose, we integrate the formalization of the area method which was developed by J. Narboux in Coq."
  },
  {
    "Title": "A Combination of a Dynamic Geometry Software With a Proof Assistant for Interactive Formal Proofs",
    "URL": "https://dl.acm.org/doi/10.1016/j.entcs.2012.06.005",
    "Full Abstract": "This paper presents an interface for geometry proving. It is a combination of a dynamic geometry software, Geogebra Geogebra development team, Introduction to GeoGebra. http://www.geogebra.org/book/intro-en/ with a proof assistant, Coq Coq development team, The Coq proof assitant reference manual. http://coq.inria.fr/refman/. Thanks to the features of Geogebra, users can create and manipulate geometric constructions, they discover conjectures and interactively build formal proofs with the support of Coq. Our system allows users to construct fully traditional proofs in the same style as the ones in high school. For each step of proving, we provide a set of applicable rules verified in Coq for users, we also provide tactics in Coq by which minor steps of reasoning are solved automatically."
  },
  {
    "Title": "A machine-checked proof of the odd order theorem",
    "URL": "https://dl.acm.org/doi/10.1007/978-3-642-39634-2_14",
    "Full Abstract": "This paper reports on a six-year collaborative effort that culminated in a complete formalization of a proof of the Feit-Thompson Odd Order Theorem in the Coq proof assistant. The formalized proof is constructive, and relies on nothing but the axioms and rules of the foundational framework implemented by Coq. To support the formalization, we developed a comprehensive set of reusable libraries of formalized mathematics, including results in finite group theory, linear algebra, Galois theory, and the theories of the real and complex algebraic numbers."
  },
  {
    "Title": "Fixed Precision Patterns for the Formal Verification of Mathematical Constant Approximations",
    "URL": "https://dl.acm.org/doi/10.1145/2676724.2693172",
    "Full Abstract": "We describe two approaches for the computation of mathematical constant approximations inside interactive theorem provers. These two approaches share the same basis of fixed point computation and differ only in the way the proofs of correctness of the approximations are described. The first approach performs interval computations, while the second approach relies on bounding errors, for example with the help of derivatives. As an illustration, we show how to describe good approximations of the logarithm function and we compute -- to a precision of a million decimals inside the proof system, with a guarantee that all digits up to the millionth decimal are correct. All these experiments are performed with the Coq system, but most of the steps should apply to any interactive theorem prover."
  },
  {
    "Title": "Formal proofs of transcendence for e and pi as an application of multivariate and symmetric polynomials",
    "URL": "https://dl.acm.org/doi/10.1145/2854065.2854072",
    "Full Abstract": "We describe the formalisation in Coq of a proof that the numbers `e` and `pi` are transcendental. This proof lies at the interface of two domains of mathematics that are often considered separately: calculus (real and elementary complex analysis) and algebra. For the work on calculus, we rely on the Coquelicot library and for the work on algebra, we rely on the Mathematical Components library. Moreover, some of the elements of our formalized proof originate in the more ancient library for real numbers included in the Coq distribution. The case of `pi` relies extensively on properties of multivariate polynomials and this experiment was also an occasion to put to test a newly developed library for these multivariate polynomials."
  },
  {
    "Title": "Distant Decimals of $$\\pi $$ź",
    "URL": "https://dl.acm.org/doi/10.1007/s10817-017-9444-2",
    "Full Abstract": "We describe how to compute very far decimals of $$\\pi $$ź and how to provide formal guarantees that the decimals we compute are correct. In particular, we report on an experiment where 1 million decimals of $$\\pi $$ź and the billionth hexadecimal (without the preceding ones) have been computed in a formally verified way. Three methods have been studied, the first one relying on a spigot formula to obtain at a reasonable cost only one distant digit (more precisely a hexadecimal digit, because the numeration basis is 16) and the other two relying on arithmetic---geometric means. All proofs and computations can be made inside the Coq system. We detail the new formalized material that was necessary for this achievement and the techniques employed to guarantee the accuracy of the computed digits, in spite of the necessity to work with fixed precision numerical computation."
  },
  {
    "Title": "What's decidable about arrays?",
    "URL": "https://dl.acm.org/doi/10.1007/11609773_28",
    "Full Abstract": "Motivated by applications to program verification, we study a decision procedure for satisfiability in an expressive fragment of a theory of arrays, which is parameterized by the theories of the array elements. The decision procedure reduces satisfiability of a formula of the fragment to satisfiability of an equisatisfiable quantifier-free formula in the combined theory of equality with uninterpreted functions (EUF), Presburger arithmetic, and the element theories. This fragment allows a constrained use of universal quantification, so that one quantifier alternation is allowed, with some syntactic restrictions. It allows expressing, for example, that an assertion holds for all elements in a given index range, that two arrays are equal in a given range, or that an array is sorted. We demonstrate its expressiveness through applications to verification of sorting algorithms and parameterized systems. We also prove that satisfiability is undecidable for several natural extensions to the fragment. Finally, we describe our implementation in the"
  },
  {
    "Title": "Efficient strongly relational polyhedral analysis",
    "URL": "https://dl.acm.org/doi/10.1007/11609773_8",
    "Full Abstract": "Polyhedral analysis infers invariant linear equalities and inequalities of imperative programs. However, the exponential complexity of polyhedral operations such as image computation and convex hull limits the applicability of polyhedral analysis. Weakly relational domains such as intervals and octagons address the scalability issue by considering polyhedra whose constraints are drawn from a restricted, user-specified class. On the other hand, these domains rely solely on candidate expressions provided by the user. Therefore, they often fail to produce strong invariants."
  },
  {
    "Title": "Fixed point iteration for computing the time elapse operator",
    "URL": "https://dl.acm.org/doi/10.1007/11730637_40",
    "Full Abstract": "We investigate techniques for automatically generating symbolic approximations to the time solution of a system of differential equations. This is an important primitive operation for the safety analysis of continuous and hybrid systems. In this paper we design a"
  },
  {
    "Title": "On efficient distributed deadlock avoidance for real-time and embedded systems",
    "URL": "https://dl.acm.org/doi/10.5555/1898953.1899066",
    "Full Abstract": "Thread allocation is an important problem in distributed real-time and embedded (DRE) systems. A thread allocation policy that is too liberal may cause deadlock, while a policy that is too conservative limits potential parallelism, thus wasting resources. However, achieving (globally) optimal thread utilization, while avoiding deadlock, has been proven impractical in distributed systems: it requires too much communication between components."
  },
  {
    "Title": "Decision procedures for term algebras with integer constraints",
    "URL": "https://dl.acm.org/doi/10.5555/1196027.1196032",
    "Full Abstract": "Term algebras can model recursive data structures which are widely used in programming languages. To verify programs we must be able to reason about these structures. However, as programming languages often involve multiple data domains, in program verification decision procedures for a single theory are usually not applicable. An important class of mixed constraints consists of combinations of data structures with integer constraints on the size of data structures. Such constraints can express memory safety properties such as absence of memory overflow and out-of-bound array access, which are crucial for program correctness. In this paper we extend the theory of term algebras with the length function which maps a term to its size, resulting in a combined theory of term algebras and Presburger arithmetic. This arithmetic extension provides a natural but tight coupling between the two theories, and hence the general purpose combination methods like Nelson-Op-pen combination are not applicable. We present decision procedures for quantifier-free theories in structures with an infinite constant domain and with a finite constant domain. We also present a quantifier elimination procedure for the extended first-order theory that can remove a block of existential quantifiers in one step."
  },
  {
    "Title": "Efficient distributed deadlock avoidance with liveness guarantees",
    "URL": "https://dl.acm.org/doi/10.1145/1176887.1176891",
    "Full Abstract": "We present a deadlock avoidance algorithm for distributed systems that guarantees liveness. Deadlock avoidance in distributed systems is a hard problem and general solutions are considered impractical due to the high communication overhead. In previous work, however, we showed that practical solutions exist when all possible sequences of resource requests are known a priori in the form of call graphs; in this case protocols can be constructed that perform safe resource allocation based on local data only, that is, no communication between components is required. While avoiding deadlock, those protocols, however, did not avoid starvation: they guaranteed that some process could always make progress, but did not guarantee that every individual process would always eventually terminate.In this paper we present a resource allocation mechanism that avoids deadlock and guarantees absence of starvation, without undue loss of concurrency. The only assumption we make is that the local scheduler is fair. We prove the correctness of the algorithm and show how it can be implemented efficiently."
  },
  {
    "Title": "Proving ATL* properties of infinite-state systems",
    "URL": "https://dl.acm.org/doi/10.1007/11921240_17",
    "Full Abstract": "Alternating temporal logic (atl*) was introduced to prove properties of multi-agent systems in which the agents have different objectives and may collaborate to achieve them. Examples include (distributed) controlled systems, security protocols, and contract-signing protocols. Proving atl* properties over finite-state systems was shown decidable by Alur et al., and a model checker for the sublanguage atl implemented in mocha."
  },
  {
    "Title": "Verification constraint problems with strengthening",
    "URL": "https://dl.acm.org/doi/10.1007/11921240_3",
    "Full Abstract": "The deductive method reduces verification of safety properties of programs to, first, proposing inductive assertions and, second, proving the validity of the resulting set of first-order verification conditions. We discuss the transition from"
  },
  {
    "Title": "Distributed priority inheritance for real-time and embedded systems",
    "URL": "https://dl.acm.org/doi/10.1007/11945529_9",
    "Full Abstract": "We study the problem of priority inversion in distributed real-time and embedded systems and propose a solution based on a distributed version of the priority inheritance protocol (PIP). Previous approaches to priority inversions in distributed systems use variations of the priority ceiling protocol (PCP), originally designed for centralized systems as a modification of PIP that also prevents deadlock. PCP, however, requires maintaining a global view of the acquired resources, which in distributed systems leads to high communication overhead."
  },
  {
    "Title": "A family of distributed deadlock avoidance protocols and their reachable state spaces",
    "URL": "https://dl.acm.org/doi/10.5555/1759394.1759413",
    "Full Abstract": "We study resource management in distributed systems. Incorrect handling of resources may lead to deadlocks, missed deadlines, priority inversions, and other forms of incorrect behavior or degraded performance. While in centralized systems deadlock avoidance is commonly used to ensure correct and efficient resource allocation, distributed deadlock avoidance is harder, and general solutions are considered impractical due to the high communication overhead. However, solutions that use only operations on local data exist if some static information about the possible sequences of remote invocations is known."
  },
  {
    "Title": "Verifying Balanced Trees",
    "URL": "https://dl.acm.org/doi/10.1007/978-3-540-72734-7_26",
    "Full Abstract": "Balanced search trees provide guaranteed worst-case time performance and hence they form a very important class of data structures. However, the self-balancing ability comes at a price; balanced trees are more complex than their unbalanced counterparts both in terms of data structure themselves and related manipulation operations. In this paper we present a framework to model balanced trees in decidable first-order theories of term algebras with Presburger arithmetic. In this framework, a theory of term algebras (i.e., a theory of finite trees) is extended with Presburger arithmetic and with certain connecting functions that map terms (trees) to integers. Our framework is flexible in the sense that we can obtain a variety of decidable theories by tuning the connecting functions. By adding <em>maximal path</em>and <em>minimal path</em>functions, we obtain a theory of red-black trees in which the transition relation of tree self-balancing (rotation) operations is expressible. We then show how to reduce the verification problem of the red-black tree algorithm to constraint satisfiability problems in the extended theory."
  },
  {
    "Title": "The Calculus of Computation",
    "URL": "https://dl.acm.org/doi/book/10.5555/1324777",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "The reaction algebra",
    "URL": "https://dl.acm.org/doi/10.5555/1805839.1805872",
    "Full Abstract": "Event-pattern reactive programs are small programs that process an input stream of events to detect and act upon given temporal patterns. These programs are used in distributed systems to notify components when they must react."
  },
  {
    "Title": "Deductive verification of alternating systems",
    "URL": "https://dl.acm.org/doi/10.1007/s00165-008-0075-6",
    "Full Abstract": "Alternating systems are models of computer programs whose behavior is governed by the actions of multiple agents with, potentially, different goals. Examples include control systems, resource schedulers, security protocols, auctions and election mechanisms. Proving properties about such systems has emerged as an important new area of study in formal verification, with the development of logical frameworks such as the alternating temporal logic"
  },
  {
    "Title": "Constructing invariants for hybrid systems",
    "URL": "https://dl.acm.org/doi/10.1007/s10703-007-0046-1",
    "Full Abstract": "We present a new method for generating algebraic invariants of hybrid systems. The method reduces the invariant generation problem to a constraint solving problem using techniques from the theory of ideals over polynomial rings. Starting with a template invariant--a polynomial equality over the system variables with unknown coefficients--constraints are generated on the coefficients guaranteeing that the solutions are inductive invariants. To control the complexity of the constraint solving, several stronger conditions that imply inductiveness are proposed, thus allowing a trade-off between the complexity of the invariant generation process and the strength of the resulting invariants."
  },
  {
    "Title": "Property-directed incremental invariant generation",
    "URL": "https://dl.acm.org/doi/10.1007/s00165-008-0080-9",
    "Full Abstract": "A fundamental method of analyzing a system such as a program or a circuit is invariance analysis, in which one proves that an assertion holds on all reachable states. Typically, the proof is performed via induction; however, an assertion, while invariant, may not be inductive (provable via induction). Invariant generation procedures construct auxiliary inductive assertions for strengthening the assertion to be inductive. We describe a general method of generating invariants that is incremental and property-directed. Rather than generating one large auxiliary inductive assertion, our method generates many simple assertions, each of which is inductive relative to those generated before it. Incremental generation is amenable to parallelization. Our method is also property-directed in that it generates inductive assertions that are relevant for strengthening the given assertion. We describe two instances of our method: a procedure for generating clausal invariants of finite-state systems and a procedure for generating affine inequalities of numerical infinite-state systems. We provide evidence that our method scales to checking safety properties of some large finite-state systems."
  },
  {
    "Title": "The Logical Basis for Computer Programming",
    "URL": "https://dl.acm.org/doi/book/10.5555/1502271",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Temporal verification of reactive systems",
    "URL": "https://dl.acm.org/doi/10.5555/1880443.1880456",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "The Calculus of Computation",
    "URL": "https://dl.acm.org/doi/book/10.5555/1951719",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Advances in Knowledge Discovery and Data Mining",
    "URL": "https://dl.acm.org/doi/book/10.5555/2821229",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Advances in Knowledge Discovery and Data Mining",
    "URL": "https://dl.acm.org/doi/book/10.5555/2821283",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Trends and Applications in Knowledge Discovery and Data Mining",
    "URL": "https://dl.acm.org/doi/book/10.5555/3002432",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Resilient parallel computing on unreliable parallel machines",
    "URL": "https://dl.acm.org/doi/10.5555/165475.165497",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Parallel processing on networks of workstations",
    "URL": "https://dl.acm.org/doi/10.5555/876885.880024",
    "Full Abstract": "Abstract: One of the most sought after software innovation of this decade is the construction of systems using off-the-shelf-workstations that actually deliver and even surpass, the power and reliability of supercomputers. Using completely novel techniques: eager scheduling, evasive memory layouts and dispersed data management it is possible to build an execution environment for parallel programs on workstation networks. These techniques were originally developed in a theoretical framework for an abstract machine which models a shared memory asynchronous multiprocessor. The network of workstations platform presents an inherently asynchronous environment for the execution of our parallel program. This gives rise to substantial problems of correctness of the computation and of proper automatic load balancing of the work amongst the processors, so that a slow processor will not hold up the total computation. A limiting case of asynchrony is when a processor becomes infinitely slow, i.e. fails. Our methodology copes with all these problems, as well as with memory failures. An interesting feature of this system is that it is neither a fault-tolerant system extended for parallel processing nor is it parallel processing system extended for fault tolerance. The same novel mechanisms ensure both properties."
  },
  {
    "Title": "CALYPSO",
    "URL": "https://dl.acm.org/doi/10.5555/822081.823036",
    "Full Abstract": "The importance of adapting networks of workstations for use as parallel processing platforms is well established. However current solutions do not always address important issues that exist in real networks. External factors like the sharing of resources, unpredictable behavior of the network and failures, are present in multiuser networks and must be addressed. CALYPSO is a prototype software system for writing and executing parallel programs on non-dedicated platforms, based on COTS networked workstations operating systems, and compilers. Among notable properties of the system are: (1) simple programming paradigm incorporating shared memory constructs and separating the programming and the execution parallelism, (2) transparent utilization of unreliable shared resources by providing dynamic load balancing and fault tolerance, and (3) effective performance for large classes of coarse-grained computations. We present the system and report our initial experiments and performance results in settings that closely resemble the dynamic behavior of a \"real\" network. Under varying work-load conditions, resource availability and process failures, the efficiency of the test program we present ranged from 84% to 94% bench-marked against a sequential program."
  },
  {
    "Title": "Modeling data-intensive reactive systems with relational transition systems",
    "URL": "https://dl.acm.org/doi/10.1007/s002360050041",
    "Full Abstract": "In this paper, the formalism of"
  },
  {
    "Title": "Parallel Suffix--Prefix-Matching Algorithm and Applications",
    "URL": "https://dl.acm.org/doi/10.1137/S0097539792190157",
    "Full Abstract": "Our main result in this paper is a parallel algorithm for suffix--prefix- (s--p-) matching that has optimal speedup on a concurrent-read/concurrent-write parallel random-access machine (CRCW PRAM). Given a string of length $m$, the algorithm runs in time $O(\\log m)$ using $m/ \\log m$ processors. This algorithm is important because we utilize s--p matching as a fundamental building block to solve several pattern- and string-matching problems, such as the following: {1. string matching; 2. multitext/multipattern string matching; 3. multidimensional pattern matching; 4. pattern-occurrence detection; 5. on-line string matching.} In particular, our techniques and algorithms are the first to preserve optimal speedup in the context of pattern matching in higher dimensions and are the only known ones to do so for dimensions $d > 2$."
  },
  {
    "Title": "KnittingFactory: An Infrastructure for Distributed Web Applications",
    "URL": "https://dl.acm.org/doi/book/10.5555/890254",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Pincer Search",
    "URL": "https://dl.acm.org/doi/10.5555/645338.650396",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Exploiting Application Tunability for Efficient, Predictable, Parallel Resource Management",
    "URL": "https://dl.acm.org/doi/book/10.5555/890298",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Mechanisms for Just-in-Time Allocation of Resources to Adaptive Parallel Programs",
    "URL": "https://dl.acm.org/doi/10.5555/645608.661825",
    "Full Abstract": "Adaptive parallel computations-computations that can adapt to changes in resource availability and requirement- can effectively use networked machines because they dynamically expand as machines become available and dynamically acquire machines as needed. While most parallel programming systems provide the means to develop adaptive programs, they do not provide any functional interface to external resource management systems. Thus, no existing resource management system has the capability to manage resources on commodity system software, arbitrating the demands of multiple adaptive computations written using diverse programming environments.This paper presents a set of novel mechanisms that facilitate dynamic allocation of resources to adaptive parallel computations. The mechanisms are built on low-level features common to many programming systems, and unique in their ability to transparently manage multiple adaptive parallel programs that were not developed to have their resources managed by external systems. We also describe the design and the implementation of the initial prototype of ResourceBroker, a resource management system built to validate these mechanisms."
  },
  {
    "Title": "Exploiting Application Tunability for Efficient, Predictable Parallel Resource Management",
    "URL": "https://dl.acm.org/doi/10.5555/645608.661833",
    "Full Abstract": "Parallel computing is becoming increasing central and mainstream, driven both by the widespread availability of commodity SMP and high-performance cluster platforms, as well as the growing use of parallelism in general-purpose applications such as image recognition, virtual reality, and media processing. In addition to performance requirements, the latter computations impose soft real-time constraints, necessitating efficient, predictable parallel resource management. In this paper, we propose a novel approach for increasing parallel system utilization while meeting application soft real-time deadlines. Our approach exploits the application tunability found in several general-purpose computations. Tunability refers to an application's ability to trade off resource requirements over time, while maintaining a desired level of output quality. We first describe language extensions to support tunability in the Calypso system, then characterize the performance benefits of tunability, using a synthetic task system to systematically identify its benefits. Our results show that application tunability is convenient to express and can significantly improve parallel system utilization for computations with predictability requirements."
  },
  {
    "Title": "Metacomputing with MILAN",
    "URL": "https://dl.acm.org/doi/10.5555/795690.797900",
    "Full Abstract": "The MILAN project, a joint effort involving Arizona State University and New York University, has produced and validated fundamental techniques for the realization of efficient, reliable, predictable virtual machines, that is, metacomputers, on top of environments that consist of an unreliable and dynamically changing set of machines. In addition to the techniques, the principal outcomes of the project include three parallel programming systems- Calypso, Chime, and Charlotte-which enable applications be developed for ideal, shared memory, parallel machines to execute on distributed platforms that are subject to failures, slowdowns, and changing resource availability. The lessons learned from the MILAN project are being used to design Computing Communities, a metacomputing frame-work for general computations."
  },
  {
    "Title": "Charlotte",
    "URL": "https://dl.acm.org/doi/10.1016/S0167-739X%2899%2900009-6",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Exploiting Application Tunability for Efficient, Predictable Resource Management in Parallel and Distributed Systems",
    "URL": "https://dl.acm.org/doi/10.1006/jpdc.2000.1660",
    "Full Abstract": "Parallel and distributed computing is becoming increasingly mainstream, driven both by the widespread availability of commodity small-scale symmetric multiprocessors and high-performance cluster platforms, as well as the growing use of parallelism and distribution in networked applications such as image recognition, media processing, virtual reality, and telepresence. However, many of these applications impose soft timeliness and output quality constraints on top of the traditional performance requirements, necessitating efficient, predictable management of system resources. Existing techniques are inadequate to simultaneously support these twin requirements of efficiency and predictability. In this paper, we propose a novel approach for increasing system efficiency while meeting application timeliness and quality constraints. Our approach exploits the application tunability found in many general-purpose computations. Tunability refers to an application's ability to trade off resource requirements over several dimensions including time, quality, and resource type; the resulting flexibility enables the underlying resource management system to choose an application operating point best suited to available resource characteristics. We describe language and scheduler extensions to support tunability in the MILAN metacomputing environment and then systematically characterize performance benefits of tunability using a parameterizable task system. Our results show that application tunability is easily expressible and can significantly improve resource utilization."
  },
  {
    "Title": "Automatic data and computation decomposition on distributed memory parallel computers",
    "URL": "https://dl.acm.org/doi/10.1145/509705.509706",
    "Full Abstract": "To exploit parallelism on shared memory parallel computers (SMPCs), it is natural to focus on decomposing the computation (mainly by distributing the iterations of the nested Do-Loops). In contrast, on distributed memory parallel computers (DMPCs), the decomposition of computation and the distribution of data must both be handled---in order to balance the computation load and to minimize the migration of data. We propose and validate experimentally a method for handling computations and data synergistically to minimize the overall execution time on DMPCs. The method is based on a number of novel techniques, also presented in this article. The core idea is to rank the \"importance\" of data arrays in a program and specify some of the dominant. The intuition is that the dominant arrays are the ones whose migration would be the most expensive. Using the correspondence between iteration space mapping vectors and distributed dimensions of the dominant data array in each nested Do-loop, allows us to design algorithms for determining data and computation decompositions at the same time. Based on data distribution, computation decomposition for each nested Do-loop is determined based on either the \"owner computes\" rule or the \"owner stores\" rule with respect to the dominant data array. If all temporal dependence relations across iteration partitions are regular, we use tiling to allow pipelining and the overlapping of computation and communication. However, in order to use tiling on DMPCs, we needed to extend the existing techniques for determining tiling vectors and tile sizes, as they were originally suited for SMPCs only. The overall method is illustrated on programs for the 2D heat equation, for the Gaussian elimination with pivoting, and for the 2D fast Fourier transform on a linear processor array and on a 2D processor grid."
  },
  {
    "Title": "Pincer-Search",
    "URL": "https://dl.acm.org/doi/10.1109/TKDE.2002.1000342",
    "Full Abstract": "Discovering frequent itemsets is a key problem in important data mining applications, such as the discovery of association rules, strong rules, episodes, and minimal keys. Typical algorithms for solving this problem operate in a bottom-up, breadth-first search direction. The computation starts from frequent 1-itemsets (the minimum length frequent itemsets) and continues until all maximal (length) frequent itemsets are found. During the execution, every frequent itemset is explicitly considered. Such algorithms perform well when all maximal frequent itemsets are short. However, performance drastically deteriorates when some of the maximal frequent itemsets are long. We present a new algorithm which combines both the bottom-up and the top-down searches. The primary search direction is still bottom-up, but a restricted search is also conducted in the top-down direction. This search is used only for maintaining and updating a new data structure, the maximum frequent candidate set. It is used to prune early candidates that would be normally encountered in the bottom-up search. A very important characteristic of the algorithm is that it does not require explicit examination of every frequent itemset. Therefore, the algorithm performs well even when some maximal frequent itemsets are long. As its output, the algorithm produces the maximum frequent set, i.e., the set containing all maximal frequent itemsets, thus specifying immediately all frequent itemsets. We evaluate the performance of the algorithm using well-known synthetic benchmark databases, real-life census, and stock market databases. The improvement in performance can be up to several orders of magnitude, compared to the best previous algorithms."
  },
  {
    "Title": "Detecting malicious network traffic using inverse distributions of packet contents",
    "URL": "https://dl.acm.org/doi/10.1145/1080173.1080176",
    "Full Abstract": "We study the problem of detecting malicious IP traffic in the network early, by analyzing the contents of packets. Existing systems look at packet contents as a bag of substrings and study characteristics of its"
  },
  {
    "Title": "Sustaining moore's law in embedded computing through probabilistic and approximate design",
    "URL": "https://dl.acm.org/doi/10.1145/1629395.1629397",
    "Full Abstract": "The central theme of our work is the probabilistic and approximate design of embedded computing systems. This novel approach consists of two distinguishing aspects: (i) the design and implementation of embedded systems, using components which are susceptible to perturbations from various sources and (ii) a design methodology which consists of an exploration of a design space which characterizes the trade-off between quality of output and cost, to implement high performance and low energy embedded systems. In contrast with other work, our design methodology does not attempt to correct the errors introduced by components which are susceptible to perturbations, instead we design \"good enough\" systems. Our work has the potential to address challenges and impediments to Moore's law arising from material properties and manufacturing difficulties, which dictate that we shift from the current-day deterministic design paradigm to statistical and probabilistic designs of the future. In this paper, we provide a broad overview of our work on probabilistic and approximate design, present novel results in approximate arithmetic and its impact on digital signal processing algorithms, and sketch future directions for research."
  },
  {
    "Title": "Optimizing energy to minimize errors in dataflow graphs using approximate adders",
    "URL": "https://dl.acm.org/doi/10.1145/1878921.1878948",
    "Full Abstract": "Approximate arithmetic is a promising, new approach to low-energy designs while tackling reliability issues. We present a method to optimally distribute a given energy budget among adders in a dataflow graph so as to minimize expected errors. The method is based on new formal mathematical models and algorithms, which quantitatively characterize the relative importance of the adders in a circuit. We demonstrate this method on a"
  },
  {
    "Title": "An approach to energy-error tradeoffs in approximate ripple carry adders",
    "URL": "https://dl.acm.org/doi/10.5555/2016802.2016853",
    "Full Abstract": "Given a 16-bit or 32-bit overclocked ripple-carry adder, we minimize error by allocating multiple supply voltages to the gates. We solve the error minimization problem for a fixed energy budget using a binned geometric program solution (BGPS). A solution found via BGPS outperforms the two best prior approaches, uniform voltage scaling and biased voltage scaling, reducing error by as much as a factor of 2.58X and by a median of 1.58X in 90nm transistor technology."
  },
  {
    "Title": "Some Perspectives on Complexity-Based Cryptography",
    "URL": "https://dl.acm.org/doi/10.1007/978-3-540-89255-7_4",
    "Full Abstract": "In the 1940's, Shannon applied his information theory to build a mathematical foundation for classical cryptography which studies how information can be securely encrypted and communicated. In the internet age, Turing's theory of computation has been summoned to augment Shannon's model and create new frameworks, under which numerous cryptographic applications have blossomed. Fundamental concepts, such as ``information\" and ``knowledge transfer\", often need to be re-examined and reformulated. The amalgamation process is still on-going in view of the many unsolved security issues. In this talk we give a brief overview of the background, and discuss some of the recent developments in complexity-based cryptography. We also raise some open questions and explore directions for future work."
  },
  {
    "Title": "A note on the feasibility of generalised universal composability†",
    "URL": "https://dl.acm.org/doi/10.1017/S0960129508007330",
    "Full Abstract": "In this paper we study (interpret) the precise composability guarantee of the generalised universal composability (GUC) feasibility with global setups that was proposed in the recent paper Canetti"
  },
  {
    "Title": "A note on universal composable zero-knowledge in the common reference string model",
    "URL": "https://dl.acm.org/doi/10.1016/j.tcs.2008.10.027",
    "Full Abstract": "Pass observed that universal composable zero-knowledge (UCZK) protocols in the common reference string (CRS) model lose deniability that is a natural security property and implication of the ZK functionality in accordance with the UC framework. An open problem (or, natural query) raised in the literature is: are there any other essential security properties, other than the well-known deniability property, that could be lost by UCZK in the CRS model, in comparison with the ZK functionality in accordance with the UC framework? In this work, we answer this open question (or, natural query), by showing that when running concurrently with other protocols UCZK in the CRS model can lose proof of knowledge (POK) property that is very essential and core security implication of the ZK functionality. This is demonstrated by concrete attack against naturally existing UCZK protocols in the CRS model. Then, motivated by our attack, we make further clarifications of the underlying reasons beneath the concrete attack, and investigate the precise security guarantee of UC with CRS."
  },
  {
    "Title": "On the Quantum Query Complexity of Local Search in Two and Three Dimensions",
    "URL": "https://dl.acm.org/doi/10.1007/s00453-008-9170-6",
    "Full Abstract": "The quantum query complexity of searching for local optima has been a subject of much interest in the recent literature. For the"
  },
  {
    "Title": "Communication Complexity and Its Applications",
    "URL": "https://dl.acm.org/doi/10.1007/978-3-642-02270-8_2",
    "Full Abstract": "For any function f(x, y), its communication complexity is the minimum number of bits needed to be exchanged between two parties holding integers x and y respectively. Invented thirty years ago, communication complexity has been a central research area in theoretical computer science with rich applications to algorithmic problems. In this talk, we give an overview of computational complexity, high-lighting several notable recent results and the diverse mathematical techniques needed for deriving such results."
  },
  {
    "Title": "Deniable internet key exchange",
    "URL": "https://dl.acm.org/doi/10.5555/1894302.1894328",
    "Full Abstract": "In this work, we develop a family of non-malleable and deniable Diffie-Hellman key-exchange (DHKE) protocols, named deniable Internet keyexchange (DIKE). The newly developed DIKE protocols are of conceptual clarity, provide much remarkable privacy protection to protocol participants, and are of highly practical (online) efficiency."
  },
  {
    "Title": "Concurrent knowledge extraction in the public-key model",
    "URL": "https://dl.acm.org/doi/10.5555/1880918.1880994",
    "Full Abstract": "Knowledge extraction is a fundamental notion, modeling machine possession of values (witnesses) in a computational complexity sense and enabling one to argue about the internal state of a party in a protocol without probing its internal secret state. However, when transactions are concurrent (e.g., over the Internet) with players possessing public-keys (as is common in cryptography), assuring that entities \"know\" what they claim to know, where adversaries may be well coordinated across different transactions, turns out to be much more subtle and in need of re-examination. Here, we investigate how to formally treat knowledge possession by parties (with registered public-keys) interacting over the Internet. Stated more technically, we look into the relative power of the notion of \"concurrent knowledge-extraction\" (CKE) in the concurrent zero-knowledge (CZK) bare public-key (BPK) model where statements being proven can be dynamically and adaptively chosen by the prover."
  },
  {
    "Title": "Tight Approximation Ratio of a General Greedy Splitting Algorithm for the Minimum ",
    "URL": "https://dl.acm.org/doi/10.5555/1966796.1966799",
    "Full Abstract": "For an edge-weighted connected undirected graph, the minimum"
  },
  {
    "Title": "Tight Approximation Ratio of a General Greedy Splitting Algorithm for the Minimum k-Way Cut Problem",
    "URL": "https://dl.acm.org/doi/10.5555/3118745.3118910",
    "Full Abstract": "For an edge-weighted connected undirected graph, the minimum k-way cut problem is to find a subset of edges of minimum total weight whose removal separates the graph into k connected components. The problem is NP-hard when k is part of the input and W[1]-hard when k is taken as a parameter."
  },
  {
    "Title": "Computationally-Fair group and identity-based key-exchange",
    "URL": "https://dl.acm.org/doi/10.1007/978-3-642-29952-0_26",
    "Full Abstract": "In this work, we re-examine some fundamental group key-exchange and identity-based key-exchange protocols, specifically the Burmester-Desmedet group key-exchange protocol [7] (referred to as the BD-protocol) and the Chen-Kudla identity-based key-exchange protocol [9] (referred to as the CK-protocol). We identify some new attacks on these protocols, showing in particular that these protocols are not computationally fair. Specifically, with our attacks, an adversary can do the following damages:"
  },
  {
    "Title": "Quantum computing",
    "URL": "https://dl.acm.org/doi/10.1007/978-3-642-29952-0_7",
    "Full Abstract": "In recent years, the scientific world has seen much excitement over the development of quantum computing, and the ever increasing possibility of building real quantum computers. What's the advantage of quantum computing? What are the secrets in the atoms that could potentially unleash such enormous power, to be used for computing and information processing? In this talk, we will take a look at quantum computing, and make the case that we are witnessing a great science in the making."
  },
  {
    "Title": "Graph Coloring Applied to Secure Computation in Non-Abelian Groups",
    "URL": "https://dl.acm.org/doi/10.1007/s00145-011-9104-3",
    "Full Abstract": "We study the natural problem of secure"
  },
  {
    "Title": "Online/Offline Signatures for Low-Power Devices",
    "URL": "https://dl.acm.org/doi/10.1109/TIFS.2012.2232653",
    "Full Abstract": "When digital signature is applied on low-power devices, like smart cards, wireless sensors and RFID tags, some specific properties, e.g., better offline storage, more modular and flexible deployment, are desired. To meet these needs, a new variant of the Fiat–Shamir transformation for digital signatures, referred to as $\\Gamma$ -transformation, is introduced and formalized in this work. Following this new transformation approach, some new signature schemes (referred to as $\\Gamma$-signatures) are presented and discussed. In particular, it is shown that the $\\Gamma$-signatures for discrete logarithm problem (DLP) developed in this work combine, in essence, the advantages of both Schnorr's signature and the digital signature standard (DSS), while saving from the disadvantages of them both."
  },
  {
    "Title": "OAKE",
    "URL": "https://dl.acm.org/doi/10.1145/2508859.2516695",
    "Full Abstract": "Cryptographic algorithm standards play an important role both to the practice of information security and to cryptography theory research. Among them, the KEA and OPACITY (KEA/OPACITY, in short) protocols, and the MQV and HMQV ((H)MQV, in short) protocols, are a family of implicitly authenticated Diffie-Hellman key-exchange (IA-DHKE) protocols that are among the most efficient authenticated key-exchange protocols known and are widely standardized. In this work, from some new design insights, we develop a new family of practical IA-DHKE protocols, referred to as OAKE (standing for \"optimal authenticated key-exchange\" in brief). We show that the OAKE protocol family combines, in essence, the advantages of both (H)MQV and KEA/OPACITY, while saving from or alleviating the disadvantages of them both."
  },
  {
    "Title": "Privacy-Preserving Authenticated Key-Exchange Over Internet",
    "URL": "https://dl.acm.org/doi/10.1109/TIFS.2013.2293457",
    "Full Abstract": "Key-exchange, in particular Diffie–Hellman key-exchange (DHKE), is among the core cryptographic mechanisms for ensuring network security. For key-exchange over the Internet, both security and privacy are desired. In this paper, we develop a family of privacy-preserving authenticated DHKE protocols named deniable Internet key-exchange (DIKE), both in the traditional PKI setting and in the identity-based setting. The newly developed DIKE protocols are of conceptual clarity and practical (online) efficiency. They provide useful privacy protection to both protocol participants, and add novelty and new value to the IKE standard. To the best of our knowledge, our protocols are the first provably secure DHKE protocols that additionally enjoy all the following privacy protection advantages: 1) forward deniability, actually concurrent non-malleable statistical zero-knowledge, for both protocol participants simultaneously; 2) the session transcript and session-key can be generated merely from DH-exponents (together with some public values), which thus cannot be traced to the pair of protocol participants; and 3) exchanged messages do not bear peer's identity, and do not explicitly bear player role information."
  },
  {
    "Title": "An ",
    "URL": "https://dl.acm.org/doi/10.5555/2722129.2722137",
    "Full Abstract": "In this paper, we introduce a novel approach for reducing the"
  },
  {
    "Title": "Interdisciplinarity: A View from Theory of Computation",
    "URL": "https://dl.acm.org/doi/10.1145/2820468.2820472",
    "Full Abstract": "Increasingly, the concepts and methods of computer science are being recognized as a source of great intellectual interest, injecting fresh ideas into other scientific disciplines. Through discourses and collaborations, exciting multidisciplinary areas are blossoming. We illustrate this phenomenon from the viewpoint of Theory of Computation."
  },
  {
    "Title": "Concurrent Knowledge Extraction in Public-Key Models",
    "URL": "https://dl.acm.org/doi/10.1007/s00145-014-9191-z",
    "Full Abstract": "Knowledge extraction is a fundamental notion, modeling machine possession of values (witnesses) in a computational complexity sense and enabling one to argue about the internal state of a party in a protocol without probing its internal secret state. However, when transactions are concurrent, say over the Internet, with players possessing public keys (as is common in cryptography), assuring that entities \"know\" what they claim to know, where adversaries may be well coordinated across different transactions, turns out to be much more subtle and in need of re-examination. In such settings, mixing the public-key structure as part of the language and statements is a natural adversarial strategy. Here, we investigate how to formally treat knowledge possession by parties interacting concurrently in the public-key model. More technically, we look into the relative power of the notion of \"concurrent knowledge extraction\" (CKE) for concurrent zero knowledge (CZK) in the bare public-key (BPK) model, where the language and statements being proved can be dynamically and adaptively chosen by the prover and may be possibly based on verifiers' public keys. By concrete attacks against some existing natural protocols, we first show that concurrent soundness and normal arguments of knowledge do not guarantee concurrent verifier security in the public-key setting. Here, roughly speaking, concurrent verifier security says that the malicious concurrent prover should \"know\" all the witnesses to all the possibly public-key-related statements adaptively chosen and successfully proved in the concurrent sessions. These concrete attacks serve as a good motivation for understanding \"possession of knowledge\" for concurrent transactions with registered public keys, i.e., the subtleties of concurrent knowledge extraction in the public-key model. This motivates us to introduce and formalize the notion of CKE, along with clarifications of various subtleties. Two implementations are then presented for constant-round concurrently knowledge extractable concurrent zero-knowledge (CZK---CKE) argument for $$\\mathcal {NP}$$NP in the BPK model: One protocol is generic and based on standard polynomial-time assumptions, whereas the other protocol is computationally efficient and employs complexity leveraging in a novel way. Both protocols can be practically instantiated for some specific number-theoretic languages without going through general $$\\mathcal {NP}$$NP-reductions. Of independent interest are the discussions about the subtleties surrounding the fundamental structure of Feige---Shamir zero knowledge in the BPK model."
  },
  {
    "Title": "Dominant-Strategy versus Bayesian Multi-item Auctions",
    "URL": "https://dl.acm.org/doi/10.1145/3033274.3085120",
    "Full Abstract": "We address two related unanswered questions in maximum revenue multi-item auctions. Is dominant-strategy implementation equivalent to the semantically less stringent Bayesian one (as in the case of Myerson's 1-item auction)? Can one find explicit solutions for non-trivial families of multi-item auctions (as in the 1-item case)? In this paper, we present such natural families whose explicit solutions exhibit a revenue gap between the two implementations. More precisely, consider the"
  },
  {
    "Title": "Towards data-algorithm dependent generalization",
    "URL": "https://dl.acm.org/doi/10.5555/3666122.3669611",
    "Full Abstract": "One of the major open problems in machine learning is to characterize generalization in the overparameterized regime, where most traditional generalization bounds become inconsistent even for overparameterized linear regression [46]. In many scenarios, this failure can be attributed to obscuring the crucial interplay between the training algorithm and the underlying data distribution. This paper demonstrate that the generalization behavior of overparameterized model should be analyzed in a both data-relevant and algorithm-relevant manner. To make a formal characterization, We introduce a notion called data-algorithm compatibility, which considers the generalization behavior of the entire data-dependent training trajectory, instead of traditional last-iterate analysis. We validate our claim by studying the setting of solving overparameterized linear regression with gradient descent. Specifically, we perform a data-dependent trajectory analysis and derive a sufficient condition for compatibility in such a setting. Our theoretical results demonstrate that if we take early stopping iterates into consideration, generalization can hold with significantly weaker restrictions on the problem instance than the previous last-iterate analysis."
  },
  {
    "Title": "Post-WIMP user interfaces",
    "URL": "https://dl.acm.org/doi/10.1145/253671.253708",
    "Full Abstract": "Copyright © 1997 author."
  },
  {
    "Title": "The history of computer graphics standards development",
    "URL": "https://dl.acm.org/doi/10.1145/279389.279434",
    "Full Abstract": "In keeping with the retrospective theme of this issue of"
  },
  {
    "Title": "The shape of things to come",
    "URL": "https://dl.acm.org/doi/10.1145/279389.279446",
    "Full Abstract": "Copyright © 1998 Author."
  },
  {
    "Title": "Look Ma! four hands! new models for interacting with 3D environments",
    "URL": "https://dl.acm.org/doi/10.1145/280953.281554",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Granularity in the design of interactive illustrations",
    "URL": "https://dl.acm.org/doi/10.1145/299649.299794",
    "Full Abstract": "We describe some issues in designing and building educational Java applets for an introductory computer graphics course. The design problem involves balancing educational goals of building intuition about fundamental concepts in a domain against heterogeneity both in subject material and in student backgrounds. We present our design approach for resolving these forces --- fine-grained units addressing small concepts --- and discuss its effects on other areas including hypertext structure, interface design, and software engineering."
  },
  {
    "Title": "Scene graph APIs",
    "URL": "https://dl.acm.org/doi/10.1145/311625.311927",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Education",
    "URL": "https://dl.acm.org/doi/10.1145/345966.346038",
    "Full Abstract": "Copyright © 1999 ACM."
  },
  {
    "Title": "Immersive virtual reality for visualizing flow through an artery",
    "URL": "https://dl.acm.org/doi/10.5555/375213.375297",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Immersive Virtual Reality for Visualizing Flow Through an Artery",
    "URL": "https://dl.acm.org/doi/10.5555/832272.833917",
    "Full Abstract": "We present an immersive system for exploring numerically simulated flow data through a model of a coronary artery graft. This tightly-coupled interdisciplinary project is aimed at understanding how to reduce the failure rate of these grafts. The visualization system provides a mechanism for exploring the effect of changes to the geometry, to the flow, and for exploring potential sources of future lesions. The system uses gestural and voice interactions exclusively, moving away from more traditional windows/icons/menus/point-and-click (WIMP) interfaces.We present an example session using the system and discuss our experiences developing, testing, and using it. We describe some of the interaction and rendering techniques that we experimented with and describe their level of success. Our experience suggests that systems like this are exciting to clinical researchers, but conclusive evidence of their value is not yet available."
  },
  {
    "Title": "Immersive VR for Scientific Visualization",
    "URL": "https://dl.acm.org/doi/10.1109/38.888006",
    "Full Abstract": "Immersive virtual reality can provide powerful techniques for scientific visualization. The research agenda for the technology sketched here offers a progress report, a hope, and a call to action."
  },
  {
    "Title": "User interfaces",
    "URL": "https://dl.acm.org/doi/10.1145/365181.365192",
    "Full Abstract": "Copyright © 2001 ACM."
  },
  {
    "Title": "Immersive Electronic Books for Surgical Training",
    "URL": "https://dl.acm.org/doi/10.1109/MMUL.2005.48",
    "Full Abstract": "Immersive electronic books (IEBooks) for surgical training will let surgeons explore previous surgical procedures in 3D. The authors describe the techniques and tools for creating IEBook."
  },
  {
    "Title": "Visualization Research Problems in Next-Generation Educational Software",
    "URL": "https://dl.acm.org/doi/10.1109/MCG.2005.118",
    "Full Abstract": "The dream of universal access to high-quality, personalized educational content available both synchronously and asynchronously remains unrealized. For more than four decades, many have said that information technology (IT) would be a key technology in realizing this dream by helping to produce compelling and individualized educational content, the means for delivering it, and effective feedback and assessment mechanisms. Yet today the most visible impact of IT is simple uses of the Web as a delivery mechanism for text and images, as well as for some interactive Java applets, and as a communications medium through blogs and wikis."
  },
  {
    "Title": "Next-generation educational software",
    "URL": "https://dl.acm.org/doi/10.1145/1281500.1281543",
    "Full Abstract": "The dream of universal access to high-quality, personalized educational content that is available both synchronously and asynchronously remains unrealized. For more than four decades, it has been said that information technology would be a key enabling technology for making this dream a reality by providing the ability to produce compelling and individualized content, the means for delivering it, and effective feedback and assessment mechanisms. Although IT has certainly had some impact, it has become a cliché to note that education is the last field to take systematic advantage of IT. There have been some notable successes of innovative software (e.g., the graphing calculator, the Geometer's Sketchpad, and the World Wide Web as an information-storage and -delivery vehicle), but we continue to teach-and students continue to learn-in ways that are virtually unchanged since the invention of the blackboard."
  },
  {
    "Title": "Applications and Issues in Pen-Centric Computing",
    "URL": "https://dl.acm.org/doi/10.1109/MMUL.2008.82",
    "Full Abstract": "As part of the rapidly evolving field of designing more natural user interfaces for multimedia information, pen-centric computing refuses to disappear. As a quite natural and universal interface modality, it presents many challenges. In this article, the pen-centric computing group at Brown University, led by Andries Van Dam, surveys the many prototypes they have designed and implemented, and discuss the research issues in the field still to be explored."
  },
  {
    "Title": "NuSys",
    "URL": "https://dl.acm.org/doi/10.1145/3103010.3121045",
    "Full Abstract": "Knowledge workers consume and annotate digital documents such as PDF files, videos, images and text notes - in some cases collaboratively - to form mental models and gain insight. An abundance of software solutions and utilities that were designed to assist users in stages of this process but not in the process as a whole, which makes knowledge work with documents unnecessarily inefficient. In this paper, we introduce ideas on how to streamline common knowledge worker tasks, such as collaboratively searching, gathering and freely arranging fragments of various media documents to gain understanding and then transforming emergent insights into interactive structured visualizations. Furthermore, we present NuSys, an integrated development environment (IDE) specialized for document-centric workflows, that implements the core of these ideas."
  },
  {
    "Title": "Reflections on an introductory CS course, CS15, at Brown University",
    "URL": "https://dl.acm.org/doi/10.1145/3284639",
    "Full Abstract": "Copyright © 2018 ACM."
  },
  {
    "Title": "Reflections on a Half-Century of Hypertext",
    "URL": "https://dl.acm.org/doi/10.1145/3342220.3344782",
    "Full Abstract": "2019 marks not only the 30th anniversary of the falling of the Berlin Wall, but also the 50th anniversaries of equally momentous events of 1968-1969 in the US and elsewhere. Martin Luther King and Robert Kennedy were assassinated. Hippie \"flower power\" and the closely related anti-Vietnam war movement were socio-political revolutions. In Europe, 2019 marks the 100th anniversary of the end of the \"war to end all wars\" and the 75th anniversary of D-Day. Counterpointing this societal turmoil, technology gave us hope. Neil Armstrong and Buzz Aldrin walked on the moon. Doug Engelbart and his team presented the \"Mother of All Demos\" of NLS at the '68 Fall Joint Computer Conference. Ivan Sutherland's pioneering Sketchpad (that demo'd interactive graphics in 1963) and Engelbart's NLS demo were two landmark events that were early examples of interactive computing in an era of batch computation. Interactive computing on time-sharing systems, combined with microminiaturization, would lead more than a decade later to the birth of the personal computer. It caused a revolution in the dominant model of computing that was centered on large mainframes and minicomputers used for science and engineering, finance and commerce. Interactive computing based on computer graphics and its use in hypermedia systems characterizes most of my research career. In 2019, it is difficult to remember the impact that interaction-based information structuring and sharing had on society; it certainly shaped my research career. In this presentation, I will reflect on the development of five decades of hypermedia systems and will demo three systems that have been highlights of my journey in hyperland. First, I'll show our FRESS hypertext system (still running 50-year old assembly code!), with the database of poetry used by a class of English students in 1976 in what is arguably the first online scholarly community. Next, I will demo our TAG (Touch Art Gallery) used by the Nobel Foundation a few years ago for a traveling exhibition on Alfred Nobel and all the Nobel Laureates. Finally, I'll interweave the hypertext-centric parts of my talk with some source material stored in an unbounded 2D workspace, using our current hypermedia system Dash, which is still under development and in an early but already useful state. These systems will be presented in the context of the research trends that led, ultimately, to the interconnected society in which we live. All of us working on our first hypertext systems in the '60s understood the potential of this technology. What I did not predict is that 50 years later the revolution in human-centered computing would remain far too unfinished in terms of its positive societal impact. Indeed, that impact and utility are increasingly in jeopardy from a variety of forces, both economic and political. I will close with some thoughts on both deliberately designed and unanticipated societal issues of social media that I feel we technologists must urgently help address."
  },
  {
    "Title": "Dash",
    "URL": "https://dl.acm.org/doi/10.1145/3372923.3404807",
    "Full Abstract": "Popular application suites, as well as specialized apps, are designed for workflows in which users focus on a single task for extended periods of time. These application silos slow down the many other workflows that require users to move with agility between tasks in a single working session. This is particularly true for creative people who have personalized patterns of gathering, organizing, and presenting information from a variety of sources. Moreover, each application comes with its own learning curve and data model, restricting users seeking to extend their workflows and in some cases, losing data through poor data transferring mechanisms such as clipboard copy and paste."
  },
  {
    "Title": "50 Years of Changes–How to Brace Yourself!",
    "URL": "https://dl.acm.org/doi/10.1145/3587422.3597996",
    "Full Abstract": "Having lived through the 50 years of changes, the panelists attempt to put them in calibrated perspective, not merely for the sake of fond reminiscence–and fun!–but as a guide to those who face the looming future changes."
  },
  {
    "Title": "Approaching utopia",
    "URL": "https://dl.acm.org/doi/10.1145/2422436.2422463",
    "Full Abstract": "We introduce and study strongly truthful mechanisms and their applications. We use strongly truthful mechanisms as a tool for implementation in undominated strategies for several problems, including the design of externality resistant auctions and a variant of multi-dimensional scheduling."
  },
  {
    "Title": "Using behavioral data to identify interviewer fabrication in surveys",
    "URL": "https://dl.acm.org/doi/10.1145/2470654.2481404",
    "Full Abstract": "Surveys conducted by human interviewers are one of the principal means of gathering data from all over the world, but the quality of this data can be threatened by interviewer fabrication. In this paper, we investigate a new approach to detecting interviewer fabrication automatically. We instrument electronic data collection software to record logs of low-level behavioral data and show that supervised classification, when applied to features extracted from these logs, can identify interviewer fabrication with an accuracy of up to 96%. We show that even when interviewers know that our approach is being used, have some knowledge of how it works, and are incentivized to avoid detection, it can still achieve an accuracy of 86%. We also demonstrate the robustness of our approach to a moderate amount of label noise and provide practical recommendations, based on empirical evidence, on how much data is needed for our approach to be effective."
  },
  {
    "Title": "Selling in Exclusive Markets",
    "URL": "https://dl.acm.org/doi/10.1145/2465769.2465772",
    "Full Abstract": "We consider prior-free benchmarks in non-matroid settings. In particular, we show that a very desirable benchmark proposed by Hartline and Roughgarden is too strong, in the sense that no truthful mechanism can compete with it even in a very simple non-matroid setting where there are two exclusive markets and the seller can only sell to agents in one of them. On the other hand, we show that there is a mechanism that competes with a symmetrized version of this benchmark. We further investigate the more traditional best fixed price profit benchmark and show that there are mechanisms that compete with it in any downward-closed settings."
  },
  {
    "Title": "On revenue maximization for agents with costly information acquisition",
    "URL": "https://dl.acm.org/doi/10.1007/978-3-642-39212-2_43",
    "Full Abstract": "A prevalent assumption in traditional mechanism design is that buyers know their precise value for an item; however, this assumption is rarely true in practice. In most settings, buyers can \"deliberate\", i.e., spend money or time, in order improve their estimate of an item's value. It is known that the deliberative setting is fundamentally different than the classical one, and desirable properties of a mechanism such as equilibria, revenue maximization, or truthfulness, may no longer hold."
  },
  {
    "Title": "Approximate revenue maximization in interdependent value settings",
    "URL": "https://dl.acm.org/doi/10.1145/2600057.2602858",
    "Full Abstract": "We study revenue maximization in settings where agents' values are interdependent: each agent receives a signal drawn from a correlated distribution and agents' values are functions of all of the signals. We introduce a variant of the generalized VCG auction with reserve prices and random admission, and show that this auction gives a constant approximation to the optimal expected revenue in matroid environments. Our results do not require any assumptions on the signal distributions, however, they require the value functions to satisfy a standard single-crossing property and a concavity-type condition."
  },
  {
    "Title": "Convergence of Position Auctions under Myopic Best-Response Dynamics",
    "URL": "https://dl.acm.org/doi/10.1145/2632226",
    "Full Abstract": "We study the dynamics of multiround position auctions, considering both the case of exogenous click-through rates and the case in which click-through rates are determined by an endogenous consumer search process. In both contexts, we demonstrate that dynamic position auctions converge to their associated static, envy-free equilibria. Furthermore, convergence is efficient, and the entry of low-quality advertisers does not slow convergence. Because our approach predominantly relies on assumptions common in the sponsored search literature, our results suggest that dynamic position auctions converge more generally."
  },
  {
    "Title": "On a competitive secretary problem",
    "URL": "https://dl.acm.org/doi/10.5555/2887007.2887138",
    "Full Abstract": "Consider a scenario in which there are multiple employers competing to hire the best possible employee. How does the competition between the employers affect their hiring strategies or their ability to hire one of the best possible candidates? In this paper, we address this question by studying a generalization of the classical secretary problem from optimal stopping theory: a set of ranked employers compete to hire from the same random stream of employees, and each employer wishes to hire the best candidate in the bunch. We show how to derive subgame-perfect Nash equilibrium strategies in this game and analyze the impact the competition has on the quality of the hires as a function of the rank of the employer. We present numerical results from simulations of these strategies."
  },
  {
    "Title": "Simple pricing schemes for consumers with evolving values",
    "URL": "https://dl.acm.org/doi/10.5555/2884435.2884536",
    "Full Abstract": "We consider a pricing problem where a buyer is interested in purchasing/using a good, such as an app or music or software, repeatedly over time. The consumer discovers his value for the good only as he uses it, and the value evolves with each use. Optimizing for the seller's revenue in such dynamic settings is a complex problem and requires assumptions about how the buyer behaves before learning his future value(s), and in particular, how he reacts to risk. We explore the performance of a class of pricing mechanisms that are extremely simple for both the buyer and the seller to use: the buyer reacts to prices myopically without worrying about how his value evolves in the future; the seller needs to optimize for revenue over a space of only two parameters, and can do so without knowing the buyer's risk profile or fine details of the value evolution process. We present simple-versus-optimal type results, namely that under certain assumptions, simple pricing mechanisms of the above form are approximately optimal"
  },
  {
    "Title": "The FedEx Problem",
    "URL": "https://dl.acm.org/doi/10.1145/2940716.2940752",
    "Full Abstract": "Consider the pricing problem faced by FedEx. Each customer has a package to ship, a deadline $d$ by which he needs his package to arrive, and a value $v$ for a guarantee that the package will arrive by his deadline. FedEx can (and does) offer a number of different shipping options in order to extract more revenue from their customers. In this paper, we solve the optimal (revenue-maximizing) auction problem for the single-agent version of this problem. Our paper adds to the relatively short list of multi-parameter settings for which a closed-form solution is known."
  },
  {
    "Title": "A Prior-Independent Revenue-Maximizing Auction for Multiple Additive Bidders",
    "URL": "https://dl.acm.org/doi/10.1007/978-3-662-54110-4_12",
    "Full Abstract": "Recent work by Babaioff et al.ï ź[1], Yaoï ź[30], and Cai et al.ï ź[7] shows how to construct an approximately optimal auction for additive bidders, given access to the priors from which the bidders' values are drawn. In this paper, building on the single sample approach of Dhangwatnotai et al.ï ź[15], we show how the auctioneer can obtain approximately optimal expected revenue in this setting without knowing the priors, as long as the item distributions are regular."
  },
  {
    "Title": "Stability of service under time-of-use pricing",
    "URL": "https://dl.acm.org/doi/10.1145/3055399.3055455",
    "Full Abstract": "We consider time-of-use pricing as a technique for matching supply and demand of temporal resources with the goal of maximizing social welfare. Relevant examples include energy, computing resources on a cloud computing platform, and charging stations for electric vehicles, among many others. A client/job in this setting has a window of time during which he needs service, and a particular value for obtaining it. We assume a stochastic model for demand, where each job materializes with some probability via an independent Bernoulli trial. Given a per-time-unit pricing of resources, any realized job will first try to get served by the cheapest available resource in its window and, failing that, will try to find service at the next cheapest available resource, and so on. Thus, the natural stochastic fluctuations in demand have the potential to lead to cascading overload events. Our main result shows that setting prices so as to optimally handle the"
  },
  {
    "Title": "A simply exponential upper bound on the maximum number of stable matchings",
    "URL": "https://dl.acm.org/doi/10.1145/3188745.3188848",
    "Full Abstract": "Stable matching is a classical combinatorial problem that has been the subject of intense theoretical and empirical study since its introduction in 1962 in a seminal paper by Gale and Shapley. In this paper, we provide a new upper bound on"
  },
  {
    "Title": "Combinatorial Auctions with Interdependent Valuations",
    "URL": "https://dl.acm.org/doi/10.1145/3328526.3329759",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Energy Equilibria in Proof-of-Work Mining",
    "URL": "https://dl.acm.org/doi/10.1145/3328526.3329630",
    "Full Abstract": "The Bitcoin protocol induces miners, through monetary rewards, to expend energy in order to add blocks to the chain. We show that, when energy costs are substantial and taken into account, counterintuitive and unintended strategic behavior results: In a simple bounded-horizon setting with two identical miners there is a unique pure symmetric equilibrium in which both miners first \"slow down\" in order to decrease the crypto complexity and then take advantage of this decrease. If miners have different energy efficiencies and are restricted to choose the same hash rate for many epochs, there is a unique pure equilibrium in which miners either participate at low levels that depend in intricate ways on all the other miners' efficiencies, or choose to abstain from mining if their efficiency is too low. In the general setting in which miners can adapt their hash rates over time, we show that, unless the number of miners is very small, the only possible pure equilibria are rather chaotic, with miners quitting and starting again periodically --- or there is no pure equilibrium at all. We discuss the implications of these results for the stability of proof-of-work protocols."
  },
  {
    "Title": "An improved approximation algorithm for TSP in the half integral case",
    "URL": "https://dl.acm.org/doi/10.1145/3357713.3384273",
    "Full Abstract": "We design a 1.49993-approximation algorithm for the metric traveling salesperson problem (TSP) for instances in which an optimal solution to the subtour linear programming relaxation is half-integral. These instances received significant attention over the last decade due to a conjecture of Schalekamp, Williamson and van Zuylen stating that half-integral LP solutions have the largest integrality gap over all fractional solutions. So, if the conjecture of Schalekamp et al. holds true, our result shows that the integrality gap of the subtour polytope is bounded away from 3/2."
  },
  {
    "Title": "A (slightly) improved approximation algorithm for metric TSP",
    "URL": "https://dl.acm.org/doi/10.1145/3406325.3451009",
    "Full Abstract": "For some > 10"
  },
  {
    "Title": "An improved approximation algorithm for the minimum ",
    "URL": "https://dl.acm.org/doi/10.1145/3519935.3520062",
    "Full Abstract": "We give a randomized 1+5.06/√"
  },
  {
    "Title": "Combinatorial Auctions with Interdependent Valuations",
    "URL": "https://dl.acm.org/doi/10.1287/moor.2023.1371",
    "Full Abstract": "We study combinatorial auctions with interdependent valuations, where each agent"
  },
  {
    "Title": "A Deterministic Better-than-3/2 Approximation Algorithm for Metric TSP",
    "URL": "https://dl.acm.org/doi/10.1007/978-3-031-32726-1_19",
    "Full Abstract": "We show that the max entropy algorithm can be derandomized (with respect to a particular objective function) to give a deterministic"
  },
  {
    "Title": "Non-Adaptive Matroid Prophet Inequalities",
    "URL": "https://dl.acm.org/doi/10.1007/978-3-031-71033-9_22",
    "Full Abstract": "We investigate non-adaptive algorithms for matroid prophet inequalities. Matroid prophet inequalities have been considered resolved since 2012 when [KW12] introduced thresholds that guarantee a tight 2-approximation to the prophet; however, this algorithm is adaptive. Other approaches of [CHMS10] and [FSZ16] have used non-adaptive thresholds with a feasibility restriction on the items that can be taken; however, this translates to adaptively changing an item’s threshold to infinity when it cannot be taken with respect to the additional feasibility constraint, hence the algorithm is not truly non-adaptive. A major application of prophet inequalities is in auction design, where non-adaptive prices possess a significant advantage: they convert to order-oblivious posted pricings, and are essential for translating a prophet inequality into a truthful mechanism for multi-dimensional buyers. The existing matroid prophet inequalities do not suffice for this application. We present the first non-adaptive constant-factor prophet inequality for graphic matroids."
  },
  {
    "Title": "Greedy bidding strategies for keyword auctions",
    "URL": "https://dl.acm.org/doi/10.1145/1250910.1250949",
    "Full Abstract": "How should players bid in keyword auctions such as those used by Google, Yahoo! and MSN?allWe consider greedy bidding strategies for a repeated auction on a single keyword, where in each round, each player chooses some optimal bid for the next round, assuming that the other players merely repeat their previous bid. We study the revenue, convergence and robustness properties of such strategies. Most interesting among these is a strategy we call the"
  },
  {
    "Title": "Revenue monotonicity in combinatorial auctions",
    "URL": "https://dl.acm.org/doi/10.1145/1345037.1345048",
    "Full Abstract": "Copyright © 2007 Authors."
  },
  {
    "Title": "Bigraphical Reactive Systems",
    "URL": "https://dl.acm.org/doi/10.5555/646736.701773",
    "Full Abstract": "A notion of bigraph is introduced as a model of mobile interaction. A bigraph consists of two independent structures: a topograph representing locality and an edge net representing connectivity. Bigraphs are equipped with reaction rules to form bigraphical reactive systems (BRSs), which include versions of the π-calculus and the ambient calculus. A behavioural theory is established, using the categorical notion of relative pushout; it allows labelled transition systems to be derived uniformly for a wide variety of BRSs, in such a way that familiar behavioural preorders and equivalences, in particular bisimilarity, are congruential. An example of the derivation is discussed."
  },
  {
    "Title": "Shallow Linear Action Graphs and their Embeddings",
    "URL": "https://dl.acm.org/doi/10.1007/s001650200015",
    "Full Abstract": "Action calculi, which generalise process calculi such as Petri nets, π-calculusand ambient calculus, have been presented in terms of"
  },
  {
    "Title": "Techniques for efficient in-memory checkpointing",
    "URL": "https://dl.acm.org/doi/10.1145/2524224.2524236",
    "Full Abstract": "Checkpointing is a pivotal technique in system research, with applications ranging from crash recovery to replay debugging. In this paper, we evaluate a number of in-memory checkpointing techniques and compare their properties. We also present a new compiler-based checkpointing scheme which improves state-of-the-art performance and memory guarantees in the general case. Our solution relies on a"
  },
  {
    "Title": "Digest of ACM educational activities",
    "URL": "https://dl.acm.org/doi/10.1145/2465085.2465090",
    "Full Abstract": "Welcome to the latest installment of \"EduBits,\" your quarterly pipeline to new and exciting happenings in the world of ACM education. In this edition, the ACM Education Board kicks off a National Science Foundation (NSF)-funded effort to advance cybersecurity education. Also, Cameron Wilson, Director of ACM's Public Policy Office, offers his perspectives from Capitol Hill, and Cherri M. Pancake, Chair of the ACM Special Interest Group on High Performance Computing (SIGHPC), shares key programs for HPC students, academics, and practitioners. When it comes to computing education, there are as many interests as there are challenges---and the Education Council strives to represent them all. Although the Council typically meets only once a year, members of the Board are involved in ongoing initiatives throughout the year, undertaking many projects between Council meetings."
  },
  {
    "Title": "Digest of ACM educational activities",
    "URL": "https://dl.acm.org/doi/10.1145/2505990.2505992",
    "Full Abstract": "Copyright © 2013 Copryright held by authors."
  },
  {
    "Title": "Experience with grapevine: the growth of a distributed system",
    "URL": "https://dl.acm.org/doi/10.5555/59309.59340",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Network flow and generalized path compression",
    "URL": "https://dl.acm.org/doi/10.1145/800135.804394",
    "Full Abstract": "An O(EVlog"
  },
  {
    "Title": "On the Merits of Temporal Testers",
    "URL": "https://dl.acm.org/doi/10.1007/978-3-540-69850-0_11",
    "Full Abstract": "The paper discusses the merits of <em>temporal testers</em>, which can serve as a compositional basis for automata construction corresponding to temporal formulas in the context of <Emphasis Type=\"SmallCaps\">ltl</Emphasis>, <Emphasis Type=\"SmallCaps\">psl</Emphasis>, and <Emphasis Type=\"SmallCaps\">mitl</Emphasis>logics. Temporal testers can be viewed as (non-deterministic) transducers that, at any point, output a boolean value which is 1 iff the corresponding temporal formula holds starting at the current position."
  },
  {
    "Title": "An Action Structure for Synchronous pi-Calculus",
    "URL": "https://dl.acm.org/doi/10.5555/647896.757244",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Action Calculi, or Syntactic Action Structures",
    "URL": "https://dl.acm.org/doi/10.5555/645722.666408",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Higher-Order Action Calculi",
    "URL": "https://dl.acm.org/doi/10.5555/647843.736432",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Enhancing a dependable multiserver operating system with temporal protection via resource reservations",
    "URL": "https://dl.acm.org/doi/10.1007/s11241-009-9086-5",
    "Full Abstract": "Nowadays, microkernel-based systems are getting studied and adopted with a renewed interest in a wide number of IT scenarios. Their advantages over classical monolithic solutions mainly concern the dependability domain. By being capable of dynamically detect and solve non-expected behaviours within its core components, a microkernel-based OS would eventually run forever with no need to be restarted. Dependability in this context mainly aims at isolating components from a spatial point of view: a microkernel-based system may definitely not be adopted in the context of real-time environments, simply basing on this kind of protection only."
  },
  {
    "Title": "An initiative to attract students to computing",
    "URL": "https://dl.acm.org/doi/10.1145/1227310.1227360",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "The CAP filing system",
    "URL": "https://dl.acm.org/doi/10.1145/800214.806542",
    "Full Abstract": "The filing system for the CAP is based on the idea of preservation of capabilities: if a program has been able to obtain some capability then it has an absolute right to preserve it for subsequent use. The pursuit of this principle, using capability-oriented mechanisms in preference to access control lists, has led to a filing system in which a preserved capability may be retrieved from different directories to achieve different access statuses, in which the significance of a text name depends on the directory to which it is presented, and in which filing system 'privilege' is expressed by possession of directory capabilities."
  },
  {
    "Title": "An asynchronous garbage collector for the CAP filing system",
    "URL": "https://dl.acm.org/doi/10.1145/775332.775338",
    "Full Abstract": "Copyright © 1978 Authors."
  },
  {
    "Title": "Optimizing relevance and revenue in ad search",
    "URL": "https://dl.acm.org/doi/10.1145/1390334.1390404",
    "Full Abstract": "The primary business model behind Web search is based on textual advertising, where contextually relevant ads are displayed alongside search results. We address the problem of selecting these ads so that they are both relevant to the queries and profitable to the search engine, showing that optimizing ad relevance and revenue is not equivalent. Selecting the best ads that satisfy these constraints also naturally incurs high computational costs, and time constraints can lead to reduced relevance and profitability. We propose a novel two-stage approach, which conducts most of the analysis ahead of time. An offine preprocessing phase leverages additional knowledge that is impractical to use in real time, and rewrites frequent queries in a way that subsequently facilitates fast and accurate online matching. Empirical evaluation shows that our method optimized for relevance matches a state-of-the-art method while improving expected revenue. When optimizing for revenue, we see even more substantial improvements in expected revenue."
  },
  {
    "Title": "Validating More Loop Optimizations",
    "URL": "https://dl.acm.org/doi/10.1016/j.entcs.2005.02.044",
    "Full Abstract": "Translation validation is a technique for ensuring that a translator, such as a compiler, produces correct results. Because complete verification of the translator itself is often infeasible, translation validation advocates coupling the verification task with the translation task, so that each run of the translator produces verification conditions which, if valid, prove the correctness of the translation. In previous work, the translation validation approach was used to give a framework for proving the correctness of a variety of compiler optimizations, with a recent focus on loop transformations. However, some of these ideas were preliminary and had not been implemented. Additionally, there were examples of common loop transformations which could not be handled by our previous approaches. This paper addresses these issues. We introduce a new rule Reduce for loop reduction transformations, and we generalize our previous rule Validate so that it can handle more transformations involving loops. We then describe how all of this (including some previous theoretical work) is implemented in our compiler validation tool TVOC."
  },
  {
    "Title": "A theory of strict P-completeness",
    "URL": "https://dl.acm.org/doi/10.1007/BF01206637",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Functions as Processes",
    "URL": "https://dl.acm.org/doi/10.5555/646244.684376",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Interpreting one concurrent calculus in another",
    "URL": "https://dl.acm.org/doi/10.1016/0304-3975%2890%2990059-Q",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Is Your Cat Infected with a Computer Virus?",
    "URL": "https://dl.acm.org/doi/10.1109/PERCOM.2006.32",
    "Full Abstract": "RFID systems as a whole are often treated with suspicion, but the input data received from individual RFID tags is implicitly trusted. RFID attacks are currently conceived as properly formatted but fake RFID data; however no one expects an RFID tag to send a SQL injection attack or a buffer overflow. This paper is meant to serve as a warning that data from RFID tags can be used to exploit back-end software systems. RFID middleware writers must therefore build appropriate checks (bounds checking, special character filtering, etc.), to prevent RFID middleware from suffering all of the well-known vulnerabilities experienced by the Internet. Furthermore, as a proof of concept, this paper presents the first self-replicating RFID virus. This virus uses RFID tags as a vector to compromise backend RFID middleware systems, via a SQL injection attack."
  },
  {
    "Title": "Software Specification Techniques (International Computer Science Series)",
    "URL": "https://dl.acm.org/doi/book/10.5555/576977",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "The relation between programming and specification languages with particular reference to Anna",
    "URL": "https://dl.acm.org/doi/10.5555/60769.60776",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "A view of formal semantics",
    "URL": "https://dl.acm.org/doi/10.1016/0920-5489%2889%2990039-1",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Computing curricula 1991—a review",
    "URL": "https://dl.acm.org/doi/10.5555/116199.116207",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Parameterized verification by probabilistic abstraction",
    "URL": "https://dl.acm.org/doi/10.5555/1754809.1754817",
    "Full Abstract": "The paper studies automatic verification of liveness properties with probability 1 over parameterized programs that include probabilistic transitions, and proposes two novel approaches to the problem. The first approach is based on a Planner that occasionally determines the outcome of a finite sequence of \"random\" choices, while the other random choices are performed non-deterministically. Using a Planner, a probabilistic protocol can be treated just like a nonprobabilistic one and verified as such. The second approach is based on γ-fairness, a notion of fairness that is sound and complete for verifying simple temporal properties (whose only temporal operators are ⋄ and □) over finite-state systems. The paper presents a symbolic model checker based on γ-fairness.We then show how the network invariant approach can be adapted to accommodate probabilistic protocols. The utility of the Planner approach is demonstrated on a probabilistic mutual exclusion protocol. The utility of the approach of γ-fairness with network invariants is demonstrated on Lehman and Rabin's Courteous Philosophers algorithm."
  },
  {
    "Title": "Hybrid Systems",
    "URL": "https://dl.acm.org/doi/book/10.5555/861940",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Probabilistic Game Automata",
    "URL": "https://dl.acm.org/doi/10.5555/648296.754863",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Probabilistic game automata",
    "URL": "https://dl.acm.org/doi/10.5555/20284.20295",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Firing Squad",
    "URL": "https://dl.acm.org/doi/10.5555/647694.731341",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "A Security Architecture for Object-Based Distributed Systems",
    "URL": "https://dl.acm.org/doi/10.5555/784592.784804",
    "Full Abstract": "Large-scale distributed systems present numerous securityproblems not present in local systems. In this paperwe present a general security architecture for a large-scaleobject-based distributed system. Its main features includeways for servers to authenticate clients, clients to authenticateservers, new secure servers to be instantiated withoutmanual intervention, and ways to restrict which client canperform which operation on which object. All of these featuresare done in a platform- and application-independentway, so the results are quite general. The basic idea behindthe scheme is to have each object owner issue cryptographicallysealed certificates to users to prove which operationsthey may request and to servers to prove which operationsthey are authorized to execute. These certificates are usedto ensure secure binding and secure method invocation. Thepaper discusses the required certificates and security protocolsfor using them."
  },
  {
    "Title": "LL versus LR parsing with illustrations from ALGOL 68",
    "URL": "https://dl.acm.org/doi/10.1145/800238.807142",
    "Full Abstract": "The relative merits of LL and LR parsing methods are compared, particular reference being made to ALGOL 68. The fact that LR methods can be applied to a wider class of languages does not seem to give them a significant advantage in practice."
  },
  {
    "Title": "Some ALGOL 68 compilers",
    "URL": "https://dl.acm.org/doi/10.5555/1061688.1061697",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Aspects of the ALGOL 68 mode structure",
    "URL": "https://dl.acm.org/doi/10.1145/954245.954251",
    "Full Abstract": "Copyright © 1979 Author."
  },
  {
    "Title": "The  Definition of Programming Languages",
    "URL": "https://dl.acm.org/doi/book/10.5555/539787",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "The  Definition of Programming Languages",
    "URL": "https://dl.acm.org/doi/book/10.5555/539788",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Parameterized Verification with Automatically Computed Inductive Assertions",
    "URL": "https://dl.acm.org/doi/10.5555/647770.734120",
    "Full Abstract": "The paper presents a method, called the method of verification by invisible invariants, for the automatic verification of a large class of parameterized systems. The method is based on the automatic calculation of candidate inductive assertions and checking for their inductiveness, using symbolic model-checking techniques for both tasks. First, we show how to use model-checking techniques over finite (and small) instances of the parameterized system in order to derive candidates for invariant assertions. Next, we show that the premises of the standard deductive INV rule for proving invariance properties can be automatically resolved by finite-state (BDD-based) methods with no need for interactive theorem proving. Combining the automatic computation of invariants with the automatic resolution of the VCs (verification conditions) yields a (necessarily) incomplete but fully automatic sound method for verifying large classes of parameterized systems. The generated invariants can be transferred to the VC-validation phase without ever been examined by the user, which explains why we refer to them as \"invisible\". The efficacy of the method is demonstrated by automatic verification of diverse parameterized systems in a fully automatic and efficient manner."
  },
  {
    "Title": "Validating Software Pipelining Optimizations,",
    "URL": "https://dl.acm.org/doi/book/10.5555/903622",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Validation of Optimizing Compilers,",
    "URL": "https://dl.acm.org/doi/book/10.5555/903623",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Sticks and stones",
    "URL": "https://dl.acm.org/doi/10.1145/383962.383971",
    "Full Abstract": "We consider the problem of Uniform Algorithmic Verification of Parameterized Systems, which requires establishing in a single verification effort the correctness of a parameterized family of systems for any value of the parameter. As has been observed by several researchers, using regular expressions or equivalent formalisms (e.g. WS1S) as assertional language, we can perform symbolic model checking of systems of unbounded number of states."
  },
  {
    "Title": "From Falsification to Verification",
    "URL": "https://dl.acm.org/doi/10.5555/646839.708656",
    "Full Abstract": "This paper enhances the linear temporal logic model checking process with the ability to automatically generate a deductive proof that the system meets its temporal specification. Thus, we emphasize the point of view that model checking can also be used to justify why the system actually works. We show that, by exploiting the information in the graph that is generated during a failed search for counterexamples, we can generate a fully deductive proof that the system meets its specification."
  },
  {
    "Title": "An algebraic definition of simulation between programs",
    "URL": "https://dl.acm.org/doi/book/10.5555/891902",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "An algebraic definition of simulation between programs",
    "URL": "https://dl.acm.org/doi/10.5555/1622876.1622926",
    "Full Abstract": "A simulation relation between programs is defined which is a quasi-ordering. Mutual simulation is then an equivalence relation, and by dividing out by it we abstract from a program such details as how the sequencing is controlled and how data is represented. The equivalence classes are approximations to the algorithms which are realized, or expressed, by their member programs."
  },
  {
    "Title": "Report on the seventh ACM SIGOPS European workshop",
    "URL": "https://dl.acm.org/doi/10.1145/254784.254787",
    "Full Abstract": "Copyright © 1997 Author."
  },
  {
    "Title": "Operating systems (2nd ed.)",
    "URL": "https://dl.acm.org/doi/book/10.5555/249000",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Locating objects in wide-area systems",
    "URL": "https://dl.acm.org/doi/10.1109/35.649334",
    "Full Abstract": "Locating mobile objects in a worldwide system requires a scalable location service. An object can be a telephone or a notebook computer, but also a software or data object, such as a file or an electronic document. Our service strictly separates an object's name from the addresses where it can be contacted. This is done by introducing a location-independent object handle. An object's name is bound to its unique object handle, which, in turn, is mapped to the addresses where the object can be contacted. To locate an object, we need only its object handle. We present a scalable location service based on a worldwide distributed search tree that adapts dynamically to an object's migration pattern to optimize lookups and updates"
  },
  {
    "Title": "A Framework for Consistent, Replicated Web Objects",
    "URL": "https://dl.acm.org/doi/10.5555/850926.851703",
    "Full Abstract": "Despite the extensive use of caching techniques, the Web is overloaded. While the caching techniques currently used help some, it would be better to use different caching and replication strategies for different Web pages, depending on their characteristics. We propose a framework in which such strategies can be devised independently per Web document.A Web document is constructed as a worldwide, scalable distributed Web object. Depending on the coherence requirements for that document, the most appropriate caching or replication strategy can subsequently be implemented and encapsulated by the Web object. Coherence requirements are formulated from two different perspectives: that of the Web object, and that of clients using the Web object. We have developed a prototype in Java to demonstrate the feasibility of implementing different strategies for different Web objects."
  },
  {
    "Title": "Replicated invocations in wide-area systems",
    "URL": "https://dl.acm.org/doi/10.1145/319195.319215",
    "Full Abstract": "Copyright © 1998 ACM."
  },
  {
    "Title": "Abstracting probabilistic actions",
    "URL": "https://dl.acm.org/doi/10.5555/2074394.2074429",
    "Full Abstract": "This paper discusses the problem of abstracting conditional probabilistic actions. We identify two distinct types of abstraction: intra-action abstraction and inter-action abstraction. We define what it means for the abstraction of an action to be correct and then derive two methods of intra-action abstraction and two methods of inter-action abstraction which are correct according to this criterion. We illustrate the developed techniques by applying them to actions described with the temporal action representation used in the DRIPS decision-theoretic planner and we describe how the planner uses abstraction to reduce the complexity of planning."
  },
  {
    "Title": "Translation Validation",
    "URL": "https://dl.acm.org/doi/10.5555/646005.673739",
    "Full Abstract": "Translation validation is an alternative to the verification of translators (compilers, code generators). Rather than proving in advance that the compiler always produces a target code which correctly implements the source code (compiler verification), each individual translation (i.e. a run of the compiler) is followed by a validation phase which verifies that the target code produced on this run correctly implements the submitted source program. In order to be a practical alternative to compiler verification, a key feature of this validation is its full automation."
  },
  {
    "Title": "Verifying Tomasulo's Algoithm by Refinement",
    "URL": "https://dl.acm.org/doi/10.5555/520550.835050",
    "Full Abstract": "In this paper Tomasulo's algorithm for out-of-order execution is shown to be a refinement of the sequential instruction execution algorithm. Correctness of Tomasulo's algorithm is established by proving that the register files of Tomasulo's algorithm and the sequential algorithm agree once all instructions have been completed."
  },
  {
    "Title": "Orthogonal Polyhedra",
    "URL": "https://dl.acm.org/doi/10.5555/646879.710439",
    "Full Abstract": "In this paper we investigate orthogonal polyhedra, i.e. polyhedra which are finite unions of full-dimensional hyper-rectangles. We define representation schemes for these polyhedra based on their vertices, and show that these compact representation schemes are canonical for all (convex and non-convex) polyhedra in any dimension. We then develop efficient algorithms for membership, face-detection and Boolean operations for these representations."
  },
  {
    "Title": "Decidable integration graphs",
    "URL": "https://dl.acm.org/doi/10.1006/inco.1998.2774",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Proving refinement using transduction",
    "URL": "https://dl.acm.org/doi/10.1007/s004460050062",
    "Full Abstract": "When designing distributed systems, one is faced with the problem of verifying a refinement between two specifications, given at different levels of abstraction. Suggested verification techniques in the literature include refinement mappings and various forms of simulation. We present a verification method, in which refinement between two systems is proven by constructing a transducer that inputs a computation of a concrete system and outputs a matching computation of the abstract system. The transducer uses a FIFO queue that holds segments of the concrete computation that have not been matched yet. This allows a finite delay between the occurrence of a concrete event and the determination of the corresponding abstract event. This delay often makes the use of prophecy variables or backward simulation unnecessary.An important generalization of the method is to prove refinement modulo some transformation on the observed sequences of events. The method is adapted by replacing the FIFO queue by a component that allows the appropriate transformation on sequences of events. A particular case is partial-order refinement, i.e., refinement that preserves only a subset of the orderings between events of a system. Examples are sequential consistency and serializability. The case of sequential consistency is illustrated on a proof of sequential consistency of a cache protocol."
  },
  {
    "Title": "Deciding Equality Formulas by Small Domains Instantiations",
    "URL": "https://dl.acm.org/doi/10.5555/647768.733921",
    "Full Abstract": "We introduce an efficient decision procedure for the theory of equality based on finite instantiations. When using the finite instantiations method, it is a common practice to take a range of [1."
  },
  {
    "Title": "A Perfect Verification",
    "URL": "https://dl.acm.org/doi/10.5555/647544.730605",
    "Full Abstract": "The paper presents an approach to the formal verification of a complete software system intended to support the flagship product of Perfecto Technologies which enforces application security over an open communication net."
  },
  {
    "Title": "Verifying Liveness by Augmented Abstraction",
    "URL": "https://dl.acm.org/doi/10.5555/647849.737064",
    "Full Abstract": "The paper deals with the proof method of verification by augmented finitary abstraction (VAA), which presents an effective approach to the verification of the temporal properties of (potentially infinite-state) reactive systems. The method consists of a two-step process by which, in a first step, the system and its temporal specification are combined an then abstracted into a finite-state Büchi automaton. The second step uses model checking to establish emptiness of the abstracted automaton."
  },
  {
    "Title": "Distributed programming with shared data",
    "URL": "https://dl.acm.org/doi/10.1016/0096-0551%2891%2990003-R",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "The Amoeba distributed operating system—a status report",
    "URL": "https://dl.acm.org/doi/10.1016/0140-3664%2891%2990058-9",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "MINIX 1.5 for the Sun Sparcstation",
    "URL": "https://dl.acm.org/doi/book/10.5555/574007",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Transparent fault-tolerance in parallel Orca programs",
    "URL": "https://dl.acm.org/doi/10.5555/139156.139175",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Dynamic logic with non-rigid functions",
    "URL": "https://dl.acm.org/doi/10.1007/11814771_23",
    "Full Abstract": "We introduce a dynamic logic that is enriched by non-rigid functions, i.e., functions that may change their value from state to state (during program execution), and we present a (relatively) complete sequent calculus for this logic. In conjunction with dynamically typed object enumerators, non-rigid functions allow to embed notions of object-orientation in dynamic logic, thereby forming a basis for verification of object-oriented programs. A semantical generalisation of substitutions, called state update, which we add to the logic, constitutes the central technical device for dealing with object aliasing during function modification. With these few extensions, our dynamic logic captures the essential aspects of the complex verification system KeY and, hence, constitutes a foundation for object-oriented verification with the principles of reasoning that underly the successful KeY case studies."
  },
  {
    "Title": "Automating verification of cooperation, control, and design in traffic applications",
    "URL": "https://dl.acm.org/doi/10.5555/1793874.1793880",
    "Full Abstract": "We present a verification methodology for cooperating traffic agents covering analysis of cooperation strategies, realization of strategies through control, and implementation of control. For each layer, we provide dedicated approaches to formal verification of safety and stability properties of the design. The range of employed verification techniques invoked to span this verification space includes application of pre-verified design patterns, automatic synthesis of Lyapunov functions, constraint generation for parameterized designs, model-checking in rich theories, and abstraction refinement. We illustrate this approach with a variant of the European Train Control System (ETCS), employing layer specific verification techniques to layer specific views of an ETCS design."
  },
  {
    "Title": "Verifying Liveness Properties of Reactive Systems (Tutorial Abstract)",
    "URL": "https://dl.acm.org/doi/10.5555/646883.710937",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Data-Structures for the Verification of Timed Automata",
    "URL": "https://dl.acm.org/doi/10.5555/646883.756990",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Symbolic Model Checking with Rich ssertional Languages",
    "URL": "https://dl.acm.org/doi/10.5555/647766.733608",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Some Progress in the Symbolic Verification of Timed Automata",
    "URL": "https://dl.acm.org/doi/10.5555/647766.736016",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Verification engineering",
    "URL": "https://dl.acm.org/doi/10.1145/1283920.259407",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Verification engineering",
    "URL": "https://dl.acm.org/doi/10.1145/259380.259407",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "A Compositional Real-Time Semantics of STATEMATE Designs",
    "URL": "https://dl.acm.org/doi/10.5555/646738.702095",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Verifying out-of-order executions",
    "URL": "https://dl.acm.org/doi/10.5555/646703.701870",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Operating systems: design and implementation",
    "URL": "https://dl.acm.org/doi/book/10.5555/21853",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "A UNIX clone with source code for operating systems courses",
    "URL": "https://dl.acm.org/doi/10.1145/24592.24596",
    "Full Abstract": "Copyright © 1987 Author."
  },
  {
    "Title": "Operating systems: design and implementation",
    "URL": "https://dl.acm.org/doi/book/10.5555/22876",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Computer networks: 2nd edition",
    "URL": "https://dl.acm.org/doi/book/10.5555/59922",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "The r-Stirling numbers",
    "URL": "https://dl.acm.org/doi/book/10.5555/892285",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Efficient fault tolerant routings in networks",
    "URL": "https://dl.acm.org/doi/10.1145/800057.808724",
    "Full Abstract": "We analyze the problem of constructing a network which will have a fixed routing and which will be highly fault tolerant. A construction is presented which forms a “product route graph” from two or more constituent “route graphs.” The analysis involves the"
  },
  {
    "Title": "A provably secure polynomial approximation scheme for the distributed lottery problem (extended abstract)",
    "URL": "https://dl.acm.org/doi/10.1145/323596.323608",
    "Full Abstract": "Copyright © 1985 ACM."
  },
  {
    "Title": "Proving partial order properties",
    "URL": "https://dl.acm.org/doi/10.1016/0304-3975%2894%2990009-4",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Development of Hybrid Systems",
    "URL": "https://dl.acm.org/doi/10.5555/646843.759703",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Symbolic Controller Synthesis for Discrete and Timed Systems",
    "URL": "https://dl.acm.org/doi/10.5555/646875.709990",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Reachability analysis of dynamical systems having piecewise-constant derivatives",
    "URL": "https://dl.acm.org/doi/10.1016/0304-3975%2894%2900228-B",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "OBDD''s LTL MC Model Checking of Linear TL, Using OBDD''s",
    "URL": "https://dl.acm.org/doi/book/10.5555/903745",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "On the learnability of infinitary regular sets",
    "URL": "https://dl.acm.org/doi/10.1006/inco.1995.1070",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Once and For All",
    "URL": "https://dl.acm.org/doi/10.5555/788017.788753",
    "Full Abstract": "It has long been known that past-time operators add no expressive power to linear temporal logics. In this paper, we consider the extension of branching temporal logics with past-time operators. Two possible views regarding the nature of past in a branching- time model induce two different such extensions. In the first view, past is branching and each moment in time may have several possible futures and several possible pasts. In the second view, past is linear and each moment in time may have several possible futures and a unique past. Both views assume that past is finite. We discuss the practice of these extensions as specification languages, characterize their expressive power, and examine the complexity of their model-checking and satisfiability problems."
  },
  {
    "Title": "A Complete Proof Systems for QPTL",
    "URL": "https://dl.acm.org/doi/10.5555/788017.788779",
    "Full Abstract": "The paper presents an axiomatic system for \\emm{quantified propositional temporal logic} (\\qptl), which is propositional temporal logic equipped with quantification over propositions (boolean variables). The advantages of this extended temporal logic is that its expressive power is strictly higher than that of the un-quantified version (\\ptl) and is equal to that of S1S, as well as that of \\omega-automata. Another important application of \\qptl\\ is its use for formulating and verifying refinement relations between reactive systems. In fact, the completeness proof is based on the reduction of a \\qptl\\ formula into a \\buchi\\ automaton, and performing equivalence transformations on this automata, formally justifying these transformations."
  },
  {
    "Title": "Timing analysis of asynchronous circuits using timed automata",
    "URL": "https://dl.acm.org/doi/10.5555/646702.701843",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Using Ghost Variables to Prove Refinement",
    "URL": "https://dl.acm.org/doi/10.5555/646057.678341",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "A Platform for Combining Deductive with Algorithmic Verification",
    "URL": "https://dl.acm.org/doi/10.5555/647765.735986",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Ambiguous machine architecture and program efficiency",
    "URL": "https://dl.acm.org/doi/10.1145/859402.859404",
    "Full Abstract": "Copyright © 1977 Author."
  },
  {
    "Title": "Corrigenda: “A Tutorial on Algol 68”",
    "URL": "https://dl.acm.org/doi/10.1145/356698.356706",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Implications of structured programming for machine architecture",
    "URL": "https://dl.acm.org/doi/10.1145/359361.359454",
    "Full Abstract": "Based on an empirical study of more than 10,000 lines of program text written in a GOTO-less language, a machine architecture specifically designed for structured programs is proposed. Since assignment, CALL, RETURN, and IF statements together account for 93 percent of all executable statements, special care is given to ensure that these statements can be implemented efficiently. A highly compact instruction encoding scheme is presented, which can reduce program size by a factor of 3. Unlike a Huffman code, which utilizes variable length fields, this method uses only fixed length (1-byte) opcode and address fields. The most frequent instructions consist of a single 1-byte field. As a consequence, instruction decoding time is minimized, and the machine is efficient with respect to both space and time."
  },
  {
    "Title": "A method for implementing paged, segmented virtual memories on microprogrammable computers",
    "URL": "https://dl.acm.org/doi/10.1145/850657.850660",
    "Full Abstract": "Copyright © 1979 Author."
  },
  {
    "Title": "What is in a Step",
    "URL": "https://dl.acm.org/doi/10.5555/645867.670927",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "On the learnability of infinitary regular sets",
    "URL": "https://dl.acm.org/doi/10.5555/114836.114848",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Timed and Hybrid Statecharts and Their Textual Representation",
    "URL": "https://dl.acm.org/doi/10.5555/646842.706477",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "How Vital is Liveness? Verifying Timing Properties of Reactive and Hybrid Systems (Extended Abstract)",
    "URL": "https://dl.acm.org/doi/10.5555/646727.703341",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "System Specification and Refinement in Temporal Logic",
    "URL": "https://dl.acm.org/doi/10.5555/646830.759686",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Integration Graphs",
    "URL": "https://dl.acm.org/doi/10.5555/646874.709977",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Probabilistic verification",
    "URL": "https://dl.acm.org/doi/10.1006/inco.1993.1012",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Reachability Analysis of Planar Multi-limear Systems",
    "URL": "https://dl.acm.org/doi/10.5555/647762.735360",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Efficient encoding of machine instructions",
    "URL": "https://dl.acm.org/doi/10.1145/859470.859472",
    "Full Abstract": "Copyright © 1979 Authors."
  },
  {
    "Title": "An overview of the Amoeba distributed operating system",
    "URL": "https://dl.acm.org/doi/10.1145/1041500.1041502",
    "Full Abstract": "As hardware prices continue to drop rapidly, building large computer systems by interconnecting substantial numbers of microcomputers becomes increasingly attractive. Many techniques for interconnecting the hardware, such as Ethernet [Metcalfe and Boggs, 1976], ring nets [Farber and Larson, 1972], packet switching, and shared memory are well understood, but the corresponding software techniques are poorly understood. The design of general purpose distributed operating systems is one of the key research issues for the 1980s."
  },
  {
    "Title": "Network Protocols",
    "URL": "https://dl.acm.org/doi/10.1145/356859.356864",
    "Full Abstract": "Copyright © 1981 ACM."
  },
  {
    "Title": "The people's time sharing system",
    "URL": "https://dl.acm.org/doi/10.1002/spe.4380030204",
    "Full Abstract": "A set of programs running under a multiprogramming batch operating system on the CDC 6600 which provide remote users with a time sharing service is described. The basis for the system is the ability of a user program to create job control statements during execution, thereby tricking the operating system into treating it as an ordinary batch job. The text editor and the interactive debugging facilities are described. The performance of the system, known as the People's Time Sharing System (PTSS), and user reaction to it are also described."
  },
  {
    "Title": "Computer recreations",
    "URL": "https://dl.acm.org/doi/10.1002/spe.4380030412",
    "Full Abstract": "Jotto is a popular word game for two players. It is of interest here because it unquestionably requires some intellectual ability for people to play it well, and it is a game in which a simple program can beat most human players nearly all the time. © 1973 Wiley Periodicals, Inc."
  },
  {
    "Title": "A General-Purpose Macro Processor as a Poor Man's Compiler-Compiler",
    "URL": "https://dl.acm.org/doi/10.1109/TSE.1976.233539",
    "Full Abstract": "A method for quickly producing compilers for high level languages is described. The technique consists of feeding a description of the language to be translated to a general-purpose macro processor. Used in this way, the macro processor functions as a compiler-compiler, providing automatic parsing, lexical scanning, symbol table operations, and handling of syntactic errors. A complete syntactic and semantic description of a WHILE statement (except for Boolean expression processing) is given in only seven lines, as an example. A system programming language implemented by this method is discussed in order to illustrate the main ideas. The compiler produced for this language is compared to other compilers produced by conventional methods."
  },
  {
    "Title": "In defense of program testing or correctness proofs considered harmful",
    "URL": "https://dl.acm.org/doi/10.1145/956003.956011",
    "Full Abstract": "Copyright © 1976 Author."
  },
  {
    "Title": "A Tutorial on Algol 68",
    "URL": "https://dl.acm.org/doi/10.1145/356669.356671",
    "Full Abstract": "Copyright © 1976 ACM."
  },
  {
    "Title": "Using Peephole Optimization on Intermediate Code",
    "URL": "https://dl.acm.org/doi/10.1145/357153.357155",
    "Full Abstract": "Copyright © 1982 ACM."
  },
  {
    "Title": "A practical tool kit for making portable compilers",
    "URL": "https://dl.acm.org/doi/10.1145/358172.358182",
    "Full Abstract": "Copyright © 1983 ACM."
  },
  {
    "Title": "Structured Computer Organization",
    "URL": "https://dl.acm.org/doi/book/10.5555/538160",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "On the synthesis of a reactive module",
    "URL": "https://dl.acm.org/doi/10.1145/75277.75293",
    "Full Abstract": "We consider the synthesis of a reactive module with input"
  },
  {
    "Title": "In transition from global to modular temporal reasoning about programs",
    "URL": "https://dl.acm.org/doi/10.5555/101969.101977",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "On the development of reactive systems",
    "URL": "https://dl.acm.org/doi/10.5555/101969.101990",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Rooting UNITY",
    "URL": "https://dl.acm.org/doi/10.1145/75200.75202",
    "Full Abstract": "Copyright © 1989 Authors."
  },
  {
    "Title": "On the Synthesis of an Asynchronous Reactive Module",
    "URL": "https://dl.acm.org/doi/10.5555/646243.681607",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Learning omega-Regular Languages from Queries and Counter-Examples (A Preliminary Report)",
    "URL": "https://dl.acm.org/doi/10.5555/647702.734324",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Proving partial order liveness properties",
    "URL": "https://dl.acm.org/doi/10.5555/90397.92361",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Proving Partial Order Liveness Properties",
    "URL": "https://dl.acm.org/doi/10.5555/646244.684386",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Communication with directed logic variables",
    "URL": "https://dl.acm.org/doi/10.1145/99583.99615",
    "Full Abstract": "Copyright © 1991 ACM."
  },
  {
    "Title": "Immediate files",
    "URL": "https://dl.acm.org/doi/10.1002/spe.4380140407",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Does anybody out there want to write <u>HALF</u> of a compiler?",
    "URL": "https://dl.acm.org/doi/10.1145/988241.988252",
    "Full Abstract": "Copyright © 1984 Authors."
  },
  {
    "Title": "An overview of the Amoeba distributed operating system",
    "URL": "https://dl.acm.org/doi/10.5555/40489.40494",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Computer Networks",
    "URL": "https://dl.acm.org/doi/book/10.5555/536716",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "A distributed file service based on optimistic concurrency control",
    "URL": "https://dl.acm.org/doi/10.1145/323647.323634",
    "Full Abstract": "Copyright © 1985 ACM."
  },
  {
    "Title": "Distributed operating systems",
    "URL": "https://dl.acm.org/doi/10.1145/6041.6074",
    "Full Abstract": "Distributed operating systems have many aspects in common with centralized ones, but they also differ in certain ways. This paper is intended as an introduction to distributed operating systems, and especially to current university research about them. After a discussion of what constitutes a distributed operating system and how it is distinguished from a computer network, various key design issues are discussed. Then several examples of current research projects are examined in some detail, namely, the Cambridge Distributed Computing System, Amoeba, V, and Eden."
  },
  {
    "Title": "Research issues in distributed operating systems",
    "URL": "https://dl.acm.org/doi/10.5555/16918.16921",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "The Glory of the Past",
    "URL": "https://dl.acm.org/doi/10.5555/648065.747612",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Proving Termination of Prolog Programs",
    "URL": "https://dl.acm.org/doi/10.5555/648065.761168",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Linear and Branching Structures in the Semantics and Logics of Reactive Systems",
    "URL": "https://dl.acm.org/doi/10.5555/646239.683353",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Verification of multiprocess probabilistic protocols",
    "URL": "https://dl.acm.org/doi/10.1007/BF01843570",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "A really abstract concurrent model and its temporal logic",
    "URL": "https://dl.acm.org/doi/10.1145/512644.512660",
    "Full Abstract": "In this paper we advance the radical notion that a computational model based on the <i>reals</i> provides a more abstract description of concurrent and reactive systems, than the conventional <i>integers</i> based behavioral model of execution <i>sequences.</i> The real model is studied in the setting of temporal logic, and we illustrate its advantages by providing a <i>fully abstract</i> temporal semantics for a simple concurrent language, and an example of verification of a concurrent program within the real temporal logic defined here. It is shown that, by imposing the crucial condition of <i>finite variability,</i> we achieve a balanced formalism that is insensitive to <i>finite</i> stuttering, but can recognize <i>infinite</i> stuttering, a distinction which is essential for obtaining a fully abstract semantics of non-terminating processes. Among other advantages, going into real-based semantics obviates the need for the controversial representation of concurrency by interleaving, and most of the associated fairness constraints."
  },
  {
    "Title": "Applications of temporal logic to the specification and verification of reactive systems: a survey of current trends",
    "URL": "https://dl.acm.org/doi/10.5555/19518.19527",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Specification and implementation of concurrently accessed data structures: An abstract data type approach",
    "URL": "https://dl.acm.org/doi/10.5555/28220.28239",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Specification and Implementation of Concurrently Accessed Data Structures",
    "URL": "https://dl.acm.org/doi/10.5555/646503.696285",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Very High Level Concurrent Programming",
    "URL": "https://dl.acm.org/doi/10.1109/TSE.1987.233791",
    "Full Abstract": "Concurrent systems are typically large and complex, requiring long, development time and much labor. They are, therefore, prime candidates for simplification and automation of the design and programming process. Their major application areas include real time systems, operating systems and cooperative computation. New applications are emerging with the trends towards wide usage of personal computers connected in a network and towards use of parallel processing in supercomputer architectures."
  },
  {
    "Title": "Applications of temporal logic to the specification of real time systems (extended abstract)",
    "URL": "https://dl.acm.org/doi/10.5555/52808.52812",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Applications of Temporal Logic to the Specification of Real-time Systems",
    "URL": "https://dl.acm.org/doi/10.5555/646841.706461",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "A framework for the synthesis of reactive modules",
    "URL": "https://dl.acm.org/doi/10.5555/52824.52825",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "A Framework for the Synthesis of Reactive Modules",
    "URL": "https://dl.acm.org/doi/10.5555/646724.702877",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "The design of a real-time distributed system",
    "URL": "https://dl.acm.org/doi/10.5555/16918.16951",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Language and machine-independent global optimization on intermediate code",
    "URL": "https://dl.acm.org/doi/10.1016/0096-0551%2886%2990004-4",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Making distributed systems palatable",
    "URL": "https://dl.acm.org/doi/10.1145/503956.503999",
    "Full Abstract": "Designing and implementing a distributed system is easy compared to the task of convincing people to use it. In a university Computer Science Dept., people generally use UNIX and are not at all interested in moving to a different environment, no matter how wonderful it may be. In this paper we report on how we have implemented a UNIX environment for the Amoeba distributed operating system [1], in order to make the transition from UNIX to Amoeba as simple as possible."
  },
  {
    "Title": "Efficient fault-tolerant routings in networks",
    "URL": "https://dl.acm.org/doi/10.1016/0890-5401%2887%2990063-0",
    "Full Abstract": "We analyze the problem of constructing a network with a given number of nodes which has a fixed routing and which is highly fault tolerant. A construction is presented which forms a “product route graph” from two or more constituent “route graphs.” The analysis involves the"
  },
  {
    "Title": "Compilation of Nonprocedural Specifications into Computer Programs",
    "URL": "https://dl.acm.org/doi/10.1109/TSE.1983.236736",
    "Full Abstract": "The paper describes the compilation of a program specification, written in the very high level nonprocedural MODEL language, into an object, PL/1 or Cobol, procedural language program. Nonprocedural programming languages are descriptive and devoid of procedural controls. They are therefore easier to use and require less programming skills than procedural languages. The MODEL language is briefly presented and illustrated followed by a description of the compilation process. An important early phase in the compilation is the representation of the specification by a dependency graph, denoted as array graph, which expresses the data flow interdependencies between statements. Two classes of algorithms which utilize this graph are next described. The first class checks various completeness, nonambiguity, and consistency aspects of the specification. Upon detecting any problems, the system attempts some automatic correcting measures which are reported to the user, or alternately, when no corrections appear as reasonable, it reports the error and solicits a modification from the user. The second class of algorithms produces an intermediate design of an object program in a language independent form. Finally, PL/1 or Cobol code is generated."
  },
  {
    "Title": "There Exit Decidable Context Free Propositional Dynamic Logics",
    "URL": "https://dl.acm.org/doi/10.5555/648064.747595",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Termination of Probabilistic Concurrent Program",
    "URL": "https://dl.acm.org/doi/10.1145/2166.357214",
    "Full Abstract": "Copyright © 1983 ACM."
  },
  {
    "Title": "Symmetric and Economical Solutions to the Mutual Exclusion Problem in a Distributed System (Extended Abstract)",
    "URL": "https://dl.acm.org/doi/10.5555/646237.682887",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "On the extremely fair treatment of probabilistic algorithms",
    "URL": "https://dl.acm.org/doi/10.1145/800061.808757",
    "Full Abstract": "A proof system based on linear temporal logic for the qualitative verification of concurrent probabilistic programs is proposed. The concept of extreme fairness is introduced as an approximation to the notion of probabilistic executions. The proof system proposed is shown to be relatively complete with respect to validity over all extremely fair computations. The proof methodology is demonstrated by proving correctness of a new probabilistic algorithm for solving the mutual exclusion problem ([CLP])."
  },
  {
    "Title": "On the scope of static checking in definitional languages",
    "URL": "https://dl.acm.org/doi/10.1145/800171.809622",
    "Full Abstract": "The paper concerns the use in software development of a class of very high level languages characterized as"
  },
  {
    "Title": "Temporal verification of carrier-sense local area network protocols",
    "URL": "https://dl.acm.org/doi/10.1145/800017.800516",
    "Full Abstract": "We examine local area network protocols and verify the correctness of two representative algorithms using temporal logic. We introduce an interval temporal logic that allows us to make assertions of the form “in the next k units, X holds.” This logic encodes intuitive arguments about contention protocols quite directly. We present two proofs of an Ethernet-like contention protocol, one using the interval temporal logic and one using classical temporal logic. We also verify a contention-free protocol using an invariant that seems to have wide applicability for such protocols."
  },
  {
    "Title": "Verification of probabilistic programs",
    "URL": "https://dl.acm.org/doi/10.1137/0213021",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "A linear-history semantics for languages for distributed programming",
    "URL": "https://dl.acm.org/doi/10.1016/0304-3975%2884%2990022-7",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "A Hardware Implementation of the CSP Primitives and its Verification",
    "URL": "https://dl.acm.org/doi/10.5555/646238.683211",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Verification of multiprocess probabilistic protocols",
    "URL": "https://dl.acm.org/doi/10.1145/800222.806732",
    "Full Abstract": "A new probabilistic symmetric solution to the"
  },
  {
    "Title": "Is the interesting part of process logic uninteresting? A translation from PL to PDL",
    "URL": "https://dl.acm.org/doi/10.1137/0213051",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Now you may compose temporal logic specifications",
    "URL": "https://dl.acm.org/doi/10.1145/800057.808665",
    "Full Abstract": "A compositional temporal logic proof system for the specification and verification of concurrent programs is presented. Versions of the system are developed for shared variables and communication based programming languages that include procedures."
  },
  {
    "Title": "Checking that finite state concurrent programs satisfy their linear specification",
    "URL": "https://dl.acm.org/doi/10.1145/318593.318622",
    "Full Abstract": "We present an algorithm for checking satisfiability of a linear time temporal logic formula over a finite state concurrent program. The running time of the algorithm is exponential in the size of the formula but linear in the size of the checked program. The algorithm yields also a formal proof in case the formula is valid over the program. The algorithm has four versions that check satisfiability by unrestricted, impartial, just and fair computations of the given program."
  },
  {
    "Title": "On the second eigenvalue of random regular graphs",
    "URL": "https://dl.acm.org/doi/10.1109/SFCS.1987.45",
    "Full Abstract": "Expanders have many applications in Computer Science. It is known that random d-regular graphs are very efficient expanders, almost surely. However, checking whether a particular graph is a good expander is co-NP-complete. We show that the second eigenvalue of d-regular graphs, λ2, is concentrated in an interval of width O(√d) around its mean, and that its mean is O(d3/4). The result holds under various models for random d-regular graphs. As a consequence a random d-regular graph on n vertices, is, with high probability a certifiable efficient expander for n sufficiently large. The bound on the width of the interval is derived from martingale theory and the bound on E(λ2) is obtained by exploring the properties of random walks in random graphs."
  },
  {
    "Title": "On Generating Solved Instances of Computational Problems",
    "URL": "https://dl.acm.org/doi/10.5555/646753.704892",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Simple Programs and Their Decision Problems",
    "URL": "https://dl.acm.org/doi/10.5555/646231.682062",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "The temporal logic of programs",
    "URL": "https://dl.acm.org/doi/10.1109/SFCS.1977.32",
    "Full Abstract": "A unified approach to program verification is suggested, which applies to both sequential and parallel programs. The main proof method suggested is that of temporal reasoning in which the time dependence of events is the basic concept. Two formal systems are presented for providing a basis for temporal reasoning. One forms a formalization of the method of intermittent assertions, while the other is an adaptation of the tense logic system Kb, and is particularly suitable for reasoning about concurrent programs."
  },
  {
    "Title": "A proof method for cyclic programs",
    "URL": "https://dl.acm.org/doi/10.1007/BF00289074",
    "Full Abstract": "We consider the specification and verification of"
  },
  {
    "Title": "The Temporal Semantics of Concurrent Programs",
    "URL": "https://dl.acm.org/doi/10.5555/647172.716123",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "On the temporal analysis of fairness",
    "URL": "https://dl.acm.org/doi/10.1145/567446.567462",
    "Full Abstract": "The use of the temporal logic formalism for program reasoning is reviewed. Several aspects of responsiveness and fairness are analyzed, leading to the need for an additional temporal operator: the 'until' operator -U. Some general questions involving the 'until' operator are then discussed. It is shown that with the addition of this operator the temporal language becomes expressively complete. Then, two deductive systems DX and DUX are proved to be complete for the languages without and with the new operator respectively."
  },
  {
    "Title": "A linear history semantics for distributed languages extended abstract",
    "URL": "https://dl.acm.org/doi/10.1109/SFCS.1980.5",
    "Full Abstract": "A denotational semantics is given for a distributed language based on communication (CSP). The semantics uses linear sequences of communications to record computations; for any well formed program segment the semantics is a relation between attainable states and the communication sequences needed to attain these states. In binding two or more processes we match and merge the communication sequences assumed by each process to obtain a sequence and State of the combined process. The approach taken here is distinguished by relatively simple semantic domains and ordering."
  },
  {
    "Title": "Further Results on Propositional Dynamic Logic of Nonregular Programs",
    "URL": "https://dl.acm.org/doi/10.5555/648063.747451",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Finite Models for Deterministic Propositional Dynamic Logic",
    "URL": "https://dl.acm.org/doi/10.5555/646235.682560",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Impartiality, Justice and Fairness",
    "URL": "https://dl.acm.org/doi/10.5555/646235.682695",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Propositional dynamic logic of context-free programs",
    "URL": "https://dl.acm.org/doi/10.1109/SFCS.1981.38",
    "Full Abstract": "The borderline between decidable and undecidable Propositional Dynamic Logic (PDL) is sought when iterative programs represented by regular expressions are augmented with increasingly more complex recursive programs represented by context-free languages. The results in this paper and its companion [HPS] indicate that this line is extremely close to the original regular PDL. The main result of the present paper is: The validity problem for PDL with additional programs αΔ(β)γΔ for regular α, β and γ, defined as Uiαi; β; γi, is Π11-complete. One of the results of [HPS] shows that the single program AΔ(B) AΔ for atomic A and B is actually sufficient for obtaining Π11- completeness. However, the proofs of this paper use different techniques which seem to be worthwhile in their own right."
  },
  {
    "Title": "Termination of probabilistic concurrent programs",
    "URL": "https://dl.acm.org/doi/10.1145/582153.582154",
    "Full Abstract": "The asynchronous execution behavior of several concurrent processes, which may use randomization, is studied. Viewing each process as a discrete Markov chain over the set of common execution states, we give necessary and sufficient conditions for the processes to converge almost surely to a given set of goal states, under any fair, but otherwise arbitrary schedule, provided that the state space is finite. (These conditions can be checked mechanically.) An interesting feature of the proof method is that it depends only on the topology of the transitions and not on the actual values of the probabilities. We also show that in our model synchronization protocols that use randomization are in certain cases no more powerful than deterministic protocols. This is demonstrated by (a) Proving lower bounds on the size of a shared variable necessary to ensure mutual exlusion and lockout-free behavior of the protocol; and (b) Showing that no fully symmetric 'randomized' protocol can ensure mutual exclusion and freedom from lockout."
  },
  {
    "Title": "Rendezvous with ADA",
    "URL": "https://dl.acm.org/doi/10.1145/3304133.3304152",
    "Full Abstract": "A fragment of ADA abstracting the communication and synchronization part is studied. An operational semantics for this fragment is given, emphasizing the justice and fairness aspects of the selection mechanisms. An appropriate notion of fairness is shown to be equivalent to the explicit entry-queues proposed in the reference manual. Proof rules for invariance and liveness properties are given and illustrated on an example. The proof rules are based on temporal logic."
  },
  {
    "Title": "Is the interesting part of process logic uninteresting?",
    "URL": "https://dl.acm.org/doi/10.1145/582153.582189",
    "Full Abstract": "With the (necessary) condition that atomic programs in PL be binary, we present an algorithm for the translation of a PL formula X into a PDL program τ (X) such that a finite path satisfies X iff it belongs to τ (X). This reduction has two immediate corollaries: 1) validity in this PL can be tested by testing validity of formulas in PDL; 2) all finite-path program properties expressible in this PL are expressible in PDL.The translation, however, seems to be of non-elementary time complexity. The significance of the result to the search for natural and powerful logics of programs is discussed."
  },
  {
    "Title": "The cost distribution of clustering in random probing",
    "URL": "https://dl.acm.org/doi/10.1145/77600.77619",
    "Full Abstract": "A new approach to the analysis of random probing hashing algorithms is presented. The probability-generating function in closed form for the asymptotic cost of insertion via random probing with secondary clustering is derived. For higher-order clustering, it is shown that all the moments of the probability distribution of the insertion cost exist and are asymptotically equal to the corresponding moments of the cost distribution under uniform hashing. The method in this paper also leads to simple derivations for the expected cost of insertion for random probing with secondary and higher-order clustering."
  },
  {
    "Title": "Computer networks",
    "URL": "https://dl.acm.org/doi/book/10.5555/62795",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Computer networks: 2nd edition",
    "URL": "https://dl.acm.org/doi/book/10.5555/47313",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Permutation Graphs and Transitive Graphs",
    "URL": "https://dl.acm.org/doi/10.1145/321707.321710",
    "Full Abstract": "Copyright © 1972 ACM."
  },
  {
    "Title": "Axiomatic approach to total correctness of programs",
    "URL": "https://dl.acm.org/doi/10.1007/BF00288637",
    "Full Abstract": "We present here an axiomatic approach which enables one to prove by formal methods that his program is \"totally correct\" (i.e., it terminates and is logically correct--does what it is supposed to do). The approach is similar to Hoare's approach [3] for proving that a program is \"partially correct\" (i.e., that whenever it terminates it produces correct results). Our extension to Hoare's method lies in the possibility of proving both correctness and termination by one unified formalism. One can choose to prove total correctness by a single step, or by incremental proof steps, each step establishing more properties of the program."
  },
  {
    "Title": "A complete axiomatic system for proving deductions about recursive programs",
    "URL": "https://dl.acm.org/doi/10.1145/800105.803415",
    "Full Abstract": "Denoting a version of Hoare's system for proving partial correctness of recursive programs by"
  },
  {
    "Title": "Functional specialization in distributed operating systems",
    "URL": "https://dl.acm.org/doi/10.1145/504092.504120",
    "Full Abstract": "A distributed operating system provides the same functionality and interface as a monolithic operating system. That is, for both systems the goal is to make the computing and storage facilities as provided by the hardware available to the users of the system. In distributed operating system new hardware can be added to the system to increase the storage or computing power, or to increase the availability of the storage and computing services. During and after this addition, the interface to the system remains unchanged. Transparency of access is a key concept.The top-level interface consists of sophisticated command interpreters and editors, supported by a high-resolution graphical window system. This software is run by workstations. Workstations are powerful computer units, consisting of a CPU, memory, a bitmap display, keyboard, a pointing device such as a mouse, and a network interface. In addition, workstations are often equipped with a disk. The CPU is at least as powerful as those used in traditional computer systems, and the amount of memory is equivalent or even larger.A workstation is dedicated to one individual. Consequently, the workstation is idle most of the time. It is therefore tempting to use it as the main computing resource for the owner and perhaps others as well. It could also be used autonomously from the rest of the system in case of a failure. We are opposed to these uses of workstations, since we believe that workstations should only provide the top-level interface. In this paper we will outline our reasons for this, and show how this principle has been applied in the Amoeba distributed operating system."
  },
  {
    "Title": "Performance of the world's fastest distributed operating system",
    "URL": "https://dl.acm.org/doi/10.1145/54289.54291",
    "Full Abstract": "Distributed operating systems have been in the experimental stage for a number of years now, but few have progressed to the point of actually being used in a production environment. It is our belief that the reason lies primarily with the performance of these systems---they tend to be fairly slow compared to traditional single computer systems. The Amoeba system has been designed with high performance in mind. In this paper some performance measurements of Amoeba are presented and comparisons are made with UNIX on the SUN, as well as with some other interesting systems. In particular, short remote procedure calls take 1.4 msec and long data transfers achieve a user-to-user bandwidth of 677 kbytes/sec. Furthermore, the file server is so fast that it is limited by the communication bandwidth to 677 kbytes/sec. The real speed of the file server is too high to measure. To the best of our knowledge, these are the best figures yet reported in the literature for the class of hardware used."
  },
  {
    "Title": "The Evolution of a Distributed Operating System",
    "URL": "https://dl.acm.org/doi/10.5555/645793.668329",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Programming languages for distributed computing systems",
    "URL": "https://dl.acm.org/doi/10.1145/72551.72552",
    "Full Abstract": "When distributed systems first appeared, they were programmed in traditional sequential languages, usually with the addition of a few library procedures for sending and receiving messages. As distributed applications became more commonplace and more sophisticated, this ad hoc approach became less satisfactory. Researchers all over the world began designing new programming languages specifically for implementing distributed applications. These languages and their history, their underlying principles, their design, and their use are the subject of this paper."
  },
  {
    "Title": "An efficient reliable broadcast protocol",
    "URL": "https://dl.acm.org/doi/10.1145/70730.70732",
    "Full Abstract": "Many distributed and parallel applications can make good use of broadcast communication. In this paper we present a (software) protocol that simulates reliable broadcast, even on an unreliable network. Using this protocol, application programs need not worry about lost messages. Recovery of communication failures is handled automatically and transparently by the protocol. In normal operation, our protocol is more efficient than previously published reliable broadcast protocols. An initial implementation of the protocol on 10 MC68020 CPUs connected by a 10 Mbit/sec Ethernet performs a reliable broadcast in 1.5 msec."
  },
  {
    "Title": "On the design of the amoeba configuration manager",
    "URL": "https://dl.acm.org/doi/10.1145/72910.73340",
    "Full Abstract": "The program"
  },
  {
    "Title": "The design of very fast portable compilers",
    "URL": "https://dl.acm.org/doi/10.1145/71605.71616",
    "Full Abstract": "The Amsterdam Compiler Kit is a widely used compiler building system. Up until now, the emphasis has been on producing good object code. In this paper we describe recent work that has focused on reducing compile time. The techniques described in this paper have resulted in C compilers for the Sun-3 and VAX that are 3 to 4 times faster than the native compilers provided by the manufacturers."
  },
  {
    "Title": "Structured computer organization (3rd ed.)",
    "URL": "https://dl.acm.org/doi/book/10.5555/93745",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Amoeba",
    "URL": "https://dl.acm.org/doi/10.1109/2.53354",
    "Full Abstract": "A description is given of the Amoeba distributed operating system, which appears to users as a centralized system but has the speed, fault tolerance, security safeguards, and flexibility required for the 1990s. The Amoeba software is based on objects. Objects are managed by server processes and named using capabilities chosen randomly from a sparse name space. Amoeba has a unique, fast file system split into two parts: the bullet service stores immutable files contiguously on the disk; the directory service gives capabilities symbolic names and handles replication and atomicity, eliminating the need for a separate transaction management system. To bridge the gap with existing systems, Amoeba has a Unix emulation facility consisting of a library of Unix system call routines that make calls to the various Amoeba server processes."
  },
  {
    "Title": "Fault tolerance using group communication",
    "URL": "https://dl.acm.org/doi/10.1145/504136.504146",
    "Full Abstract": "We propose group communication as an efficient mechanism to support fault tolerance. Our approach is based on an efficient reliable broadcast protocol that requires on average only two messages per broadcast. To illustrate our approach we will describe how the task bag model can be made fault-tolerant using group communication."
  },
  {
    "Title": "Minix 1.5 for Macintosh Software and Reference Manual",
    "URL": "https://dl.acm.org/doi/book/10.5555/1202330",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Experiences with the Amoeba distributed operating system",
    "URL": "https://dl.acm.org/doi/10.1145/96267.96281",
    "Full Abstract": "The Amoeba project is a research effort aimed at understanding how to connect multiple computers in a seamless way [16, 17, 26, 27, 31]. The basic idea is to provide the users with the illusion of a single powerful timesharing system, when, in fact, the system is implemented on a collection of machines, potentially distributed among several countries. This research has led to the design and implementation of the Amoeba distributed operating system, which is being used as a prototype and vehicle for further research. In this article we will describe the current state of the system (Amoeba 4.0), and show some of the lessons we have learned designing and using it over the past eight years. We will also discuss how this experience has influenced our plans for the next version, Amoeba 5.0."
  },
  {
    "Title": "Network protocols",
    "URL": "https://dl.acm.org/doi/10.5555/128960.128961",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Fault tolerance using group communication",
    "URL": "https://dl.acm.org/doi/10.1145/122120.122126",
    "Full Abstract": "We propose group communication as an efficient mechanism to support fault tolerance. Our approach is based on an efficient reliable broadcast protocol that requires on average only two messages per broadcast. To illustrate our approach we will describe how the task bag model can be made fault-tolerant using group communication."
  },
  {
    "Title": "Two Decades of Temporal Logic",
    "URL": "https://dl.acm.org/doi/10.5555/795663.796320",
    "Full Abstract": "Abstract This year (1997) marks the 20th anniversary of the introduction of Temporal Logic (TL) into Computer Science as a language proposed for the specification and verification of reactive systems. The talk will present a personal view of the main contributions and achievements of TL over the last two decades emphasizing the recent, increase of acceptance and adoption of the temporal methodology by industry. We will then proceed to identify future challenges and directions that may extend the applicability of TL to wider classes of applications and the treatment of ever larger systems. We start by identifying the class of reactive systems for whose specification and verification TL has proved to be a most natural and effective language. These are systems whose role is to maintain an ongoing interaction with their environment, rather than produce a final result on termination. Most, embedded systems which control an external physical environment be-long to this important class. Such systems must be specified and analyzed in terms of their behavior."
  },
  {
    "Title": "Translation Validation",
    "URL": "https://dl.acm.org/doi/10.5555/646482.691453",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Deductive vs. Model-Theoretic Approaches to Formal Verification (Abstract of Invited Talk)",
    "URL": "https://dl.acm.org/doi/10.5555/648234.753475",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Translation Validation for Synchronous Languages",
    "URL": "https://dl.acm.org/doi/10.5555/646252.686146",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Algorithmic Verification of Linear Temporal Logic Specifications",
    "URL": "https://dl.acm.org/doi/10.5555/646252.756784",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Modularization and Abstraction",
    "URL": "https://dl.acm.org/doi/10.5555/645727.667507",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "On Discretization of Delays in Timed Automata and Digital Circuits",
    "URL": "https://dl.acm.org/doi/10.5555/646733.701304",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Herbrand Automata for Hardware Verification",
    "URL": "https://dl.acm.org/doi/10.5555/646733.701323",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Fair Synchronous Transition Systems and Their Liveness Proofs",
    "URL": "https://dl.acm.org/doi/10.5555/646845.706935",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Translation Validation",
    "URL": "https://dl.acm.org/doi/10.5555/647539.729871",
    "Full Abstract": "Translation validation is an alternative to the verification of translators (compilers, code generators). Rather than proving in advance that the compiler always produces a target code which correctly implements the source code (compiler verification), each individual translation (i.e. a run of the compiler) is followed by a validation phase which verifies that the target code produced on this run correctly implements the submitted source program. In order to be a practical alternative to compiler verification, a key feature of this validation is its full automation."
  },
  {
    "Title": "A Fast Algorithm for Scheduling Time-Constrained Instructions on Processors with ILP",
    "URL": "https://dl.acm.org/doi/10.5555/522344.825707",
    "Full Abstract": "Instruction scheduling is central to achieving performance in modern processors with instruction level parallelism (ILP). Classical work in this area has spanned the theoretical foundations of algorithms for instruction scheduling with provable optimality, as well as heuristic approaches with experimentally validated performance improvements. Typically, the theoretical foundations are developed in the context of basic-blocks of code. In this paper, we provide the theoretical foundations for scheduling basic-blocks of instructions with time-constraints, which can play an important role in compile-time ILP optimizations in embedded applications. We present an algorithm for scheduling unit-execution-time instructions on machines with multiple pipelines, in the presence of precedence constraints, release-times, deadlines, and latencies $l_{ij}$ between any pairs of instructions $i$ and $j$. Our algorithm runs in time $O(n^3\\alpha(n))$, where $\\alpha(n)$ is the functional inverse of the Ackermann function. It can be used construct feasible schedules for two classes of instances:one pipeline and the latencies between instructions are restricted to the values of 0 and 1, and arbitrary number of pipelines and monotone-interval order precedences. %The algorithm can also be used to construct minimal tardiness %schedules in polynomial time. Our result can be seen as a natural extension of previous work on instruction scheduling for pipelined machines in the presence of deadlines."
  },
  {
    "Title": "Verification of Data-Insensitive CIrcuits",
    "URL": "https://dl.acm.org/doi/10.5555/646185.683079",
    "Full Abstract": "There is a large class of circuits (including pipeline and out-of-order execution components) which can be formally verified while completely ignoring the precise characteristics (e.g. word-size) of the data manipulated by the circuits. In the literature, this is often described as the use of uninterpreted functions, implying that the concrete operations applied to the data are abstracted into unknown and featureless functions. In this paper, we briefly introduce an abstract unifying model for such data-insensitive circuits, and claim that the development of such models, perhaps even a theory of circuit schemas, can significantly contribute to the development of efficient and comprehensive verification algorithms combining deductive as well as enumerative methods.As a case study, we present in this paper an algorithm for out-of-order execution with in-order retirement and show it to be a refinement of the sequential instruction execution algorithm. Refinement is established by deductively proving (using pvs) that the register files of the out-of-order algorithm and the sequential algorithm agree at all times if the two systems are synchronized at instruction retirement time."
  },
  {
    "Title": "The image computation problem in hybrid systems model checking",
    "URL": "https://dl.acm.org/doi/10.5555/1760804.1760843",
    "Full Abstract": "In this paper, we analyze limits of approximation techniques for (non-linear) continuous image computation in model checking hybrid systems. In particular, we show that even a single step of continuous image computation is not semidecidable numerically even for a very restricted class of functions. Moreover, we show that symbolic insight about derivative bounds provides sufficient additional information for approximation refinement model checking. Finally, we prove that purely numerical algorithms can perform continuous image computation with arbitrarily high probability. Using these results, we analyze the prerequisites for a safe operation of the roundabout maneuver in air traffic collision avoidance."
  },
  {
    "Title": "Differential logic for reasoning about hybrid systems",
    "URL": "https://dl.acm.org/doi/10.5555/1760804.1760882",
    "Full Abstract": "We propose a first-order dynamic logic for reasoning about hybrid systems. As a uniform model for discrete and continuous evolutions in hybrid systems, we introduce hybrid programs with differential actions. Our logic can be used to specify and verify correctness statements about hybrid programs, which are suitable for symbolic processing by calculus rules. Using first-order variables, our logic supports systems with symbolic parameters. With dynamic modalities, it is prepared to handle multiple system components."
  },
  {
    "Title": "SAT-based Abstraction Refinement for Real-time Systems",
    "URL": "https://dl.acm.org/doi/10.1016/j.entcs.2006.09.034",
    "Full Abstract": "In this paper, we present an abstraction refinement approach for model checking safety properties of real-time systems using SAT-solving. We present a faithful embedding of bounded model checking for systems of timed automata into propositional logic with linear arithmetic and prove correctness. With this logical representation, we achieve a linear-size representation of parallel composition and introduce a quick abstraction technique that works uniformly for clocks, events, and states. When necessary, abstractions are refined by analysing spurious counterexamples using a promising extension of counterexample-guided abstraction refinement with syntactic information about Craig interpolants. To support generalisations, our overall approach identifies the algebraic and logical principles required for logic-based abstraction refinement."
  },
  {
    "Title": "Towards a Hybrid Dynamic Logic for Hybrid Dynamic Systems",
    "URL": "https://dl.acm.org/doi/10.1016/j.entcs.2006.11.026",
    "Full Abstract": "We introduce a hybrid variant of a dynamic logic with continuous state transitions along differential equations, and we present a sequent calculus for this extended hybrid dynamic logic. With the addition of satisfaction operators, this hybrid logic provides improved system introspection by referring to properties of states during system evolution. In addition to this, our calculus introduces state-based reasoning as a paradigm for delaying expansion of transitions using nominals as symbolic state labels. With these extensions, our hybrid dynamic logic advances the capabilities for compositional reasoning about (semialgebraic) hybrid dynamic systems. Moreover, the constructive reasoning support for goal-oriented analytic verification of hybrid dynamic systems carries over from the base calculus to our extended calculus."
  },
  {
    "Title": "A Temporal Dynamic Logic for Verifying Hybrid System Invariants",
    "URL": "https://dl.acm.org/doi/10.1007/978-3-540-72734-7_32",
    "Full Abstract": "We combine first-order dynamic logic for reasoning about possible behaviour of hybrid systems with temporal logic for reasoning about the temporal behaviour during their operation. Our logic supports verification of hybrid programs with first-order definable flows and provides a uniform treatment of discrete and continuous evolution. For our combined logic, we generalise the semantics of dynamic modalities to refer to hybrid traces instead of final states. Further, we prove that this gives a conservative extension of dynamic logic. On this basis, we provide a modular verification calculus that reduces correctness of temporal behaviour of hybrid systems to non-temporal reasoning. Using this calculus, we analyse safety invariants in a train control system and symbolically synthesise parametric safety constraints."
  },
  {
    "Title": "Finding hidden Hamiltonian cycles",
    "URL": "https://dl.acm.org/doi/10.1145/103418.103442",
    "Full Abstract": "Copyright © 1991 ACM."
  },
  {
    "Title": "Existence and construction of edge disjoint paths on expander graphs",
    "URL": "https://dl.acm.org/doi/10.1145/129712.129727",
    "Full Abstract": "Copyright © 1992 ACM."
  },
  {
    "Title": "Near-perfect Token Distribution",
    "URL": "https://dl.acm.org/doi/10.5555/646246.684721",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "On the satisfiability and maximum satisfiability of random 3-CNF formulas",
    "URL": "https://dl.acm.org/doi/10.5555/313559.313794",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "On-line choice of on-line algorithms",
    "URL": "https://dl.acm.org/doi/10.5555/313559.313847",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "On the problem of approximating the number of bases of a matroid",
    "URL": "https://dl.acm.org/doi/10.1016/0020-0190%2894%2990037-X",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Existence and Construction of Edge-Disjoint Pathson Expander Graphs",
    "URL": "https://dl.acm.org/doi/10.1137/S0097539792232021",
    "Full Abstract": "Given an expander graph $G=(V,E)$ and a set of $q$ disjoint pairs of vertices in $V$, the authors are interested in finding for each pair $(a_i, b_i)$ a path connecting $a_i$ to $b_i$ such that the set of $q$ paths so found is edge disjoint. (For general graphs the related decision problem is NP complete.)"
  },
  {
    "Title": "Balanced allocations for tree-like inputs",
    "URL": "https://dl.acm.org/doi/10.1016/0020-0190%2895%2900123-T",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "The worst-case running time of the random simplex algorithm is exponential in the height",
    "URL": "https://dl.acm.org/doi/10.1016/0020-0190%2895%2900101-H",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "An efficient algorithm for the vertex-disjoint paths problem in random graphs",
    "URL": "https://dl.acm.org/doi/10.5555/313852.314072",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Static and dynamic path selection on expander graphs (preliminary version)",
    "URL": "https://dl.acm.org/doi/10.1145/258533.258646",
    "Full Abstract": "Copyright © 1997 ACM."
  },
  {
    "Title": "Counting Minimum Weight Spanning Trees",
    "URL": "https://dl.acm.org/doi/10.1006/jagm.1996.0851",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Syntactic clustering of the Web",
    "URL": "https://dl.acm.org/doi/10.1016/S0169-7552%2897%2900031-7",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Syntactic clustering of the Web",
    "URL": "https://dl.acm.org/doi/10.5555/283554.283370",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Orca",
    "URL": "https://dl.acm.org/doi/10.1109/32.126768",
    "Full Abstract": "A detailed description is given of the Orca language design and the design choices are discussed. Orca is intended for applications programmers rather than systems programmers. This is reflected in its design goals to provide a simple, easy-to-use language that is type-secure and provides clean semantics. Three example parallel applications in Orca, one of which is described in detail, are discussed. One of the existing implementations, which is based on reliable broadcasting, is described. Performance measurements of this system are given for three parallel applications. The measurements show that significant speedups can be obtained for all three applications. The authors compare Orca with several related languages and systems."
  },
  {
    "Title": "FLIP; an Internetwork Protocol for Supporting Distributed Systems",
    "URL": "https://dl.acm.org/doi/10.1145/142111.993339",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Modern operating systems",
    "URL": "https://dl.acm.org/doi/book/10.5555/129206",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Replication techniques for speeding up parallel applications on distributed systems",
    "URL": "https://dl.acm.org/doi/10.1002/cpe.4330040502",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Parallel Programming Using Shared Objects and Broadcasting",
    "URL": "https://dl.acm.org/doi/10.1109/2.153276",
    "Full Abstract": "The two major design approaches taken to build distributed and parallel computer systems, multiprocessing and multicomputing, are discussed. A model that combines the best properties of both multiprocessor and multicomputer systems, easy-to-build hardware, and a conceptually simple programming model is presented. Using this model, a programmer defines and invokes operations on shared objects, the runtime system handles reads and writes on these objects, and the reliable broadcast layer implements indivisible updates to objects using the sequencing protocol. The resulting system is easy to program, easy to build, and has acceptable performance on problems with a moderate grain size in which reads are much more common than writes. Orca, a procedural language whose sequential constructs are roughly similar to languages like C or Modula 2 but which also supports parallel processes and shared objects and has been used to develop applications for the prototype system, is described."
  },
  {
    "Title": "An experimental comparison of remote procedure call and group communication",
    "URL": "https://dl.acm.org/doi/10.1145/506378.506405",
    "Full Abstract": "This paper suggests that a distributed system should support two communication paradigms: Remote Procedure Call (RPC) and group communication. The former is used for point-to-point communication; the latter is used for one-to-many communication. We demonstrate that group communication is an important paradigm by showing that a fault-tolerant directory service is much easier to implement with groups than with RPC and is also more efficient. The directory service exemplifies distributed services that provide high reliability and availability by replicating data."
  },
  {
    "Title": "A comparison of two paradigms for distributed shared memory",
    "URL": "https://dl.acm.org/doi/10.1002/spe.4380221105",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "FLIP: an internetwork protocol for supporting distributed systems",
    "URL": "https://dl.acm.org/doi/10.1145/151250.151253",
    "Full Abstract": "Most modern network protocols give adequate support for traditional applications such as file transfer and remote login. Distributed applications, however, have different requirements (e.g., efficient at-most-once remote procedure call even in the face of processor failures). Instead of using ad hoc protocols to meet each of the new requirements, we have designed a new protocol, called the Fast Local Internet Protocol (FLIP), that provides a clean and simple integrated approach to these new requirements. FLIP is an unreliable message protocol that provides both point-to-point communication and multicast communication, and requires almost no network management. Furthermore, by using FLIP we have simplified higher-level protocols such as remote procedure call and group communication, and enhanced support for process migration and security. A prototype implementation of FLIP has been built as part of the new kernel for the Amoeba distributed operating system, and is in daily use. Measurements of its performance are presented."
  },
  {
    "Title": "Using active messages to support shared objects",
    "URL": "https://dl.acm.org/doi/10.1145/504390.504421",
    "Full Abstract": "This paper discusses a reliable group communication system using active messages to update shared objects. We discuss the model, implementation techniques, and our preliminary performance results."
  },
  {
    "Title": "Distributed operating systems",
    "URL": "https://dl.acm.org/doi/book/10.5555/184674",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "A comparison of three microkernels",
    "URL": "https://dl.acm.org/doi/10.1007/BF01245395",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Orca",
    "URL": "https://dl.acm.org/doi/10.5555/201711.201713",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Paramecium",
    "URL": "https://dl.acm.org/doi/10.5555/822074.822401",
    "Full Abstract": "We describe the design of an extensible kernel, called Paramecium. This kernel uses an object-based software architecture which together with instance naming, late binding and explicit overrides enables easy reconfiguration. Determining which components reside in the kernel protection domain is up to the user. A certification authority or one of its delegates certifies which components are trustworthy and therefore permitted to run in the kernel protection domain. These delegates may include validation programs, correctness provers, and system administrators. The main advantage of certifications is that it can handle trust and sharing in a non-cooperative environment."
  },
  {
    "Title": "Computer networks (3rd ed.)",
    "URL": "https://dl.acm.org/doi/book/10.5555/248731",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "An architecture for a wide area distributed system",
    "URL": "https://dl.acm.org/doi/10.1145/504450.504465",
    "Full Abstract": "Distributed systems provide sharing of resources and information over a computer network. A key design issue that makes these systems attractive is that all aspects related to distribution are transparent to users. Unfortunately, general-purpose wide area distributed systems that allow users to share and manage arbitrary resources in a transparent way hardly exist. In particular, they generally do not take into account the most important properties that characterize wide area systems: 1) A very large number of users and resources, 2) an inherent latency problem caused by the distance between nodes, 3) heterogeneity due to a variety of underlying operating systems and networks, and 4) involvement of multiple administrative organizations.The research described in this paper is part of the Globe Project (Globe stands for GLobal Object Based Environment). The goal of this project is the design and implementation of a wide area distributed system that provides a convenient programming abstraction and full transparency. The main contribution of this paper is the description of a new system for distributed shared objects. In contrast to other systems, the implementation of distribution, consistency, and replication of state is completely encapsulated in a distributed shared object. This allows for object-specific solutions, and provides the right mechanism for building efficient and truly scalable systems."
  },
  {
    "Title": "Communication in GLOBE",
    "URL": "https://dl.acm.org/doi/10.5555/851041.856924",
    "Full Abstract": "Current paradigms for interprocess communication are not sufficient to describe the exchange of information at an adequate level of abstraction. They are either too low-level, or their implementations cannot meet performance requirements. As an alternative, we propose distributed shared objects as a unifying concept. These objects offer user-defined operations on shared state, but allow for efficient implementations through replication and distribution of state. In contrast to other object-based models, these implementation aspects are completely hidden from applications."
  },
  {
    "Title": "A Framework for Scheduler Synthesis",
    "URL": "https://dl.acm.org/doi/10.5555/827271.829109",
    "Full Abstract": "In this paper we present a framework integrating specification and scheduler generation for real-time systems. In a first step, the system, which can include arbitrarily designed tasks (cyclic or sporadic, with or without precedence constraints, any number of resources and CPUs) is specified as a timed Petri-net. In a second step, our tool generates the most general non-preemptive online scheduler for the specification, using a controller synthesis technique."
  },
  {
    "Title": "A Comparison of Two Verification Methods for Speculative Instruction Execution",
    "URL": "https://dl.acm.org/doi/10.5555/646484.691761",
    "Full Abstract": "In this paper we describe and compare two methodologies for verifying the correctness of a speculative out-of-order execution system with interrupts. Both methods are deductive (we use PVS) and are based on refinement. The first proof is by direct refinement to a sequential system; the second proof combines refinement with induction over the number of retirement buffer slots."
  },
  {
    "Title": "Liveness and Acceleration in Parameterized Verification",
    "URL": "https://dl.acm.org/doi/10.5555/647769.734100",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Rigorous development of embedded systems",
    "URL": "https://dl.acm.org/doi/10.1145/354880.354881",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Verification by Augmented Finitary Abstraction",
    "URL": "https://dl.acm.org/doi/10.1006/inco.2000.3000",
    "Full Abstract": "The paper deals with the proof method of verification by finitary abstraction (VFA), which presents a feasible approach to the verification of the temporal properties of (potentially infinite-state) reactive systems. The method consists of a two-step process by which, in a first step, the system and its temporal specification are jointly abstracted into a finite-state system and a finite-state specification. The second step uses model checking to establish the validity of the abstracted property over the abstracted system. The VFA method can be considered a viable alternative to verification by temporal deduction which, up to now, has been the main method generally applicable for verification of infinite-state systems. The paper presents a general recipe for the joint abstraction, which is shown to be sound, where soundness means that validity over the abstract system implies validity over the concrete (original) system. To make the method applicable for the verification of liveness properties, pure abstraction is sometimes no longer adequate. We show that by augmenting the system by an appropriate (and standardly constructible) progress monitor, we obtain an augmented system, whose computations are essentially the same as the original system, and which may now be abstracted while preserving the desired liveness properties. We refer to the extended method as verification by augmented abstraction (VAA). We then proceed to show that the VAA method is sound and complete for proving all properties expressible by temporal logic (including both safety and liveness). Completeness establishes that whenever the property is valid, there exists a finitary abstraction which abstracts the system, augmented by an appropriate progress monitor, into a finite-state system which validated the abstracted property."
  },
  {
    "Title": "Formal Verification of the Ricart-Agrawala Algorithm",
    "URL": "https://dl.acm.org/doi/10.5555/646838.708648",
    "Full Abstract": "This paper presents the first formal verification of the Ricart-Agrawala algorithm RA81. for distributed mutual exclusion of an arbitrary number of nodes. It uses the Temporal Methodology of [MP95a]. We establish both the safety property of mutual exclusion and the liveness property of accessibility. To establish these properties for an arbitrary number of nodes, parameterized proof rules are used as presented in [MP95a] (for safety) and [MP94] (for liveness). A new and efficient notation is introduced to facilitate the presentation of liveness proofs by verification diagrams."
  },
  {
    "Title": "Scheduling time-constrained instructions on pipelined processors",
    "URL": "https://dl.acm.org/doi/10.1145/383721.383733",
    "Full Abstract": "In this work we investigate the problem of scheduling instructions on idealized microprocessors with multiple pipelines, in the presence of precedence constraints, release-times, deadlines, and latency constraints. A latency of"
  },
  {
    "Title": "Model Checking with Strong Fairness,",
    "URL": "https://dl.acm.org/doi/book/10.5555/903616",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Automatic Deductive Verification with Invisible Invariants",
    "URL": "https://dl.acm.org/doi/10.5555/646485.694452",
    "Full Abstract": "The paper presents a method for the automatic verification of a certain class of parameterized systems. These are bounded-data systems consisting of"
  },
  {
    "Title": "Symbolic model checking with rich assertional languages",
    "URL": "https://dl.acm.org/doi/10.1016/S0304-3975%2800%2900103-1",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Verification by Augmented Abstraction",
    "URL": "https://dl.acm.org/doi/10.1006/jcss.2000.1744",
    "Full Abstract": "This paper deals with the proof method of verification by finitary abstraction (vfa), which presents an alternative approach to the verification of (potentially infinite-state) reactive systems. We assume that the negation of the property to be verified is given by the user in the form of an infinite-state nondeterministic B chi discrete system (bds). The method consists of a two-step process by which, in a first step, the system and its (negated) specification are combined into a single infinite-state fair discrete system (fds, which is similar to a bds but with Streett acceptance conditions), which is abstracted into a finite-state automaton. The second step uses model checking to establish that the abstracted automaton is infeasible, i.e., has no computations. The vfa method can be considered as a viable alternative to verification by temporal deduction, which, up to now, has been the main method generally applicable for verification of infinite-state systems. The paper presents a general recipe for an fds abstraction, which is shown to be sound, where soundness means that infeasibility of the abstracted fds implies infeasibility of the unabstracted one, implying in turn the validity of the property over the concrete (infinite-state) system. To make the method applicable for the verification of liveness properties, pure abstraction is sometimes no longer adequate. We show that by augmenting the system with an appropriate (and standardly constructible) progress monitor, we obtain an augmented system, whose computations are essentially the same as those of the original system and which may now be abstracted while preserving the desired liveness properties. We refer to the extended method as verification by augmented abstraction (vaa). We then proceed to show that the vaa method is sound and complete for proving all properties whose negations are expressible by a bds. Given that every linear temporal logic (ltl) property can be translated to a bds, this establishes that the vaa method is sound and complete for proving the validity of all ltl properties, including both safety and liveness."
  },
  {
    "Title": "Efficient decision-theoretic planning",
    "URL": "https://dl.acm.org/doi/10.5555/2074158.2074184",
    "Full Abstract": "This paper discusses techniques for performing efficient decision-theoretic planning. We give an overview of the DRIPS decision-theoretic refinement planning system, which uses abstraction to efficiently identify optimal plans. We present techniques for automatically generating search control information, which can significantly improve the planner's performance. We evaluate the efficiency of DRIPS both with and without the search control rules on a complex medical planning problem and compare its performance to that of a branch-and-bound decision tree algorithm."
  },
  {
    "Title": "Modeling probabilistic actions for practical decision-theoretic planning",
    "URL": "https://dl.acm.org/doi/10.5555/3036846.3036855",
    "Full Abstract": "Most existing decision-theoretic planners represent uncertainty about the state of the world with a precisely specified probability distribution over world states. This representation is not expressive enough to model many interesting classes of practical planning problems, and renders inapplicable some abstraction-based planning approaches. In this paper we propose as a remedy a more general world and action model with a well-founded semantics based on probability intervals. We introduce the concept of"
  },
  {
    "Title": "Sound abstraction of probabilistic actions in the constraint mass assignment framework",
    "URL": "https://dl.acm.org/doi/10.5555/2074284.2074311",
    "Full Abstract": "This paper provides a formal and practical framework for sound abstraction of probabilistic actions. We start by precisely defining the concept of sound abstraction within the context of finite-horizon planning (where each plan is a finite sequence of actions). Next we show that such abstraction cannot be performed within the traditional probabilistic action representation, which models a world with a single probability distribution over the state space. We then present the constraint mass assignment representation, which models the world with a set of probability distributions and is a generalization of mass assignment representations. Within this framework, we present sound abstraction procedures for three types of action abstraction. We end the paper with discussions and related work on sound and approximate abstraction. We give pointers to papers in which we discuss other sound abstraction-related issues, including applications, estimating loss due to abstraction, and automatically generating abstraction hierarchies."
  },
  {
    "Title": "Geometric foundations for interval-based probabilities",
    "URL": "https://dl.acm.org/doi/10.1023/A%3A1018936829318",
    "Full Abstract": "The need to reason with imprecise probabilities arises in a wealth of situations ranging from pooling of knowledge from multiple experts to abstractionýbased probabilistic planning. Researchers have typically represented imprecise probabilities using intervals and have developed a wide array of different techniques to suit their particular requirements. In this paper we provide an analysis of some of the central issues in representing and reasoning with interval probabilities. At the focus of our analysis is the probability crossýproduct operator and its interval generalization, the ccýoperator. We perform an extensive study of these operators relative to manipulation of sets of probability distributions. This study provides insight into the sources of the strengths and weaknesses of various approaches to handling probability intervals. We demonstrate the application of our results to the problems of inference in interval Bayesian networks and projection and evaluation of abstract probabilistic plans."
  },
  {
    "Title": "Efficiently ordering query plans for data integration",
    "URL": "https://dl.acm.org/doi/10.5555/3068476.3068482",
    "Full Abstract": "We describe Streamer, the query-reformulation component of a data integration system. Given a utility measure and a user query, Streamer uses abstraction-based refinement planning and exploits information on plan independence to produce, in decreasing order of utility, a set of plans that access data sources to obtain answers to the query. We then focus on plan coverage as an important utility measure. We show how to use statistic information about the domain and data sources to estimate plan coverage, and how to incorporate the plan-coverage framework into Streamer. In doing so, we provide the first method for effectively integrating the use of quantitative information into the query optimizer of a data-integration system. We present preliminary experimental results suggesting that Streamer runs an order of magnitude faster than brute-force plan-ordering methods, which are the only currently available methods to compute"
  },
  {
    "Title": "Reconciling schemas of disparate data sources",
    "URL": "https://dl.acm.org/doi/10.1145/375663.375731",
    "Full Abstract": "A data-integration system provides access to a multitude of data sources through a single mediated schema. A key bottleneck in building such systems has been the laborious manual construction of semantic mappings between the source schemas and the mediated schema. We describe LSD, a system that employs and extends current machine-learning techniques to semi-automatically find such mappings. LSD first asks the user to provide the semantic mappings for a small set of data sources, then uses these mappings together with the sources to train a set of learners. Each learner exploits a different type of information either in the source schemas or in their data. Once the learners have been trained, LSD finds semantic mappings for a new data source by applying the learners, then combining their predictions using a meta-learner. To further improve matching accuracy, we extend machine learning techniques so that LSD can incorporate domain constraints as an additional source of knowledge, and develop a novel learner that utilizes the structural information in XML documents. Our approach thus is distinguished in that it incorporates multiple types of knowledge. Importantly, its architecture is extensible to additional learners that may exploit new kinds of information. We describe a set of experiments on several real-world domains, and show that LSD proposes semantic mappings with a high degree of accuracy."
  },
  {
    "Title": "Learning to map between structured representations of data",
    "URL": "https://dl.acm.org/doi/book/10.5555/936674",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Learning to map between ontologies on the semantic web",
    "URL": "https://dl.acm.org/doi/10.1145/511446.511532",
    "Full Abstract": "Ontologies play a prominent role on the Semantic Web. They make possible the widespread publication of machine understandable data, opening myriad opportunities for automated information processing. However, because of the Semantic Web's distributed nature, data on it will inevitably come from many different ontologies. Information processing across ontologies is not possible without knowing the semantic mappings between their elements. Manually finding such mappings is tedious, error-prone, and clearly not possible at the Web scale. Hence, the development of tools to assist in the ontology mapping process is crucial to the success of the Semantic Web.We describe"
  },
  {
    "Title": "Database research at the University of Illinois at Urbana-Champaign",
    "URL": "https://dl.acm.org/doi/10.1145/601858.601881",
    "Full Abstract": "Copyright © 2002 Authors."
  },
  {
    "Title": "Learning to Match the Schemas of Data Sources",
    "URL": "https://dl.acm.org/doi/10.1023/A%3A1021765902788",
    "Full Abstract": "The problem of integrating data from multiple data sources—either on the Internet or within enterprises—has received much attention in the database and AI communities. The focus has been on building data integration systems that provide a"
  },
  {
    "Title": "Object matching for information integration",
    "URL": "https://dl.acm.org/doi/10.5555/3104278.3104289",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Differential Dynamic Logic for Verifying Parametric Hybrid Systems",
    "URL": "https://dl.acm.org/doi/10.1007/978-3-540-73099-6_17",
    "Full Abstract": "We introduce a first-order dynamic logic for reasoning about systems with discrete and continuous state transitions, and we present a sequent calculus for this logic. As a uniform model, our logic supports hybrid programs with discrete and differential actions. For handling real arithmetic during proofs, we lift quantifier elimination to dynamic logic. To obtain a modular combination, we use side deductions for verifying interacting dynamics. With this, our logic supports deductive verification of hybrid systems with symbolic parameters and first-order definable flows. Using our calculus, we prove a parametric inductive safety constraint for speed supervision in a train control system."
  },
  {
    "Title": "Logical Verification and Systematic Parametric Analysis in Train Control",
    "URL": "https://dl.acm.org/doi/10.1007/978-3-540-78929-1_55",
    "Full Abstract": "We formally verify hybrid safety properties of cooperation protocols in a fully parametric version of the"
  },
  {
    "Title": "Computing Differential Invariants of Hybrid Systems as Fixedpoints",
    "URL": "https://dl.acm.org/doi/10.1007/978-3-540-70545-1_17",
    "Full Abstract": "We introduce a fixedpoint algorithm for verifying safety properties of hybrid systems with differential equations whose right-hand sides are polynomials in the state variables. In order to verify nontrivial systems without solving their differential equations and without numerical errors, we use a continuous generalization of induction, for which our algorithm computes the required <em>differential invariants</em>. As a means for combining local differential invariants into global system invariants in a sound way, our fixedpoint algorithm works with a compositional verification logic for hybrid systems. To improve the verification power, we further introduce a <em>saturation procedure</em>that refines the system dynamics successively with differential invariants until safety becomes provable. By complementing our symbolic verification algorithm with a robust version of numerical falsification, we obtain a fast and sound verification procedure. We verify roundabout maneuvers in air traffic management and collision avoidance in train control."
  },
  {
    "Title": "Differential Dynamic Logic for Hybrid Systems",
    "URL": "https://dl.acm.org/doi/10.1007/s10817-008-9103-8",
    "Full Abstract": "Hybrid systems are models for complex physical systems and are defined as dynamical systems with interacting discrete transitions and continuous evolutions along differential equations. With the goal of developing a theoretical and practical foundation for deductive verification of hybrid systems, we introduce a dynamic logic for hybrid programs, which is a program notation for hybrid systems. As a verification technique that is suitable for automation, we introduce a free variable proof calculus with a novel combination of real-valued free variables and Skolemisation for lifting quantifier elimination for real arithmetic to dynamic logic. The calculus is compositional, i.e., it reduces properties of hybrid programs to properties of their parts. Our main result proves that this calculus axiomatises the transition behaviour of hybrid systems completely relative to differential equations. In a case study with cooperating traffic agents of the European Train Control System, we further show that our calculus is well-suited for verifying realistic hybrid systems with parametric system dynamics."
  },
  {
    "Title": "KeYmaera",
    "URL": "https://dl.acm.org/doi/10.1007/978-3-540-71070-7_15",
    "Full Abstract": "KeYmaera is a hybrid verification tool for hybrid systems that combines deductive, real algebraic, and computer algebraic prover technologies. It is an automated and interactive theorem prover for a natural specification and verification logic for hybrid systems. KeYmaera supports <em>differential dynamic logic</em>, which is a real-valued first-order dynamic logic for hybrid programs, a program notation for hybrid automata. For automating the verification process, KeYmaera implements a generalized free-variable sequent calculus and automatic proof strategies that decompose the hybrid system specification symbolically. To overcome the complexity of real arithmetic, we integrate real quantifier elimination following an iterative background closure strategy. Our tool is particularly suitable for verifying parametric hybrid systems and has been used successfully for verifying collision avoidance in case studies from train control and air traffic management."
  },
  {
    "Title": "Differential dynamic logics",
    "URL": "https://dl.acm.org/doi/book/10.5555/2073238",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Verification of Cyberphysical Transportation Systems",
    "URL": "https://dl.acm.org/doi/10.1109/MIS.2009.81",
    "Full Abstract": "Cyberphysical system technology has an important share in modern intelligent transportation systems, including next generation flight, rail, and car control. This control technology is intended to help improve performance objectives like throughput and improve overall system safety. To ensure that these transportation systems operate correctly, new analysis techniques are needed that consider physical movement combined with computational control to establish properties like collision freedom. Logic-based analysis can verify the correct functioning of these cyberphysical systems."
  },
  {
    "Title": "Real World Verification",
    "URL": "https://dl.acm.org/doi/10.1007/978-3-642-02959-2_35",
    "Full Abstract": "Scalable handling of real arithmetic is a crucial part of the verification of hybrid systems, mathematical algorithms, and mixed analog/digital circuits. Despite substantial advances in verification technology, complexity issues with classical decision procedures are still a major obstacle for formal verification of real-world applications, e.g., in automotive and avionic industries. To identify strengths and weaknesses, we examine state of the art symbolic techniques and implementations for the universal fragment of real-closed fields: approaches based on quantifier elimination, Gröbner Bases, and semidefinite programming for the Positivstellensatz. Within a uniform context of the verification tool KeYmaera, we compare these approaches qualitatively and quantitatively on verification benchmarks from hybrid systems, textbook algorithms, and on geometric problems. Finally, we introduce a new decision procedure combining Gröbner Bases and semidefinite programming for the real Nullstellensatz that outperforms the individual approaches on an interesting set of problems."
  },
  {
    "Title": "Computing differential invariants of hybrid systems as fixedpoints",
    "URL": "https://dl.acm.org/doi/10.1007/s10703-009-0079-8",
    "Full Abstract": "We introduce a fixedpoint algorithm for verifying safety properties of hybrid systems with differential equations whose right-hand sides are polynomials in the state variables. In order to verify nontrivial systems without solving their differential equations and without numerical errors, we use a continuous generalization of induction, for which our algorithm computes the required"
  },
  {
    "Title": "A Bayesian Approach to Model Checking Biological Systems",
    "URL": "https://dl.acm.org/doi/10.1007/978-3-642-03845-7_15",
    "Full Abstract": "Recently, there has been considerable interest in the use of Model Checking for Systems Biology. Unfortunately, the state space of stochastic biological models is often too large for classical Model Checking techniques. For these models, a statistical approach to Model Checking has been shown to be an effective alternative. Extending our earlier work, we present the first algorithm for performing statistical Model Checking using Bayesian Sequential Hypothesis Testing. We show that our Bayesian approach outperforms current statistical Model Checking techniques, which rely on tests from Classical (aka Frequentist) statistics, by requiring fewer system simulations. Another advantage of our approach is the ability to incorporate prior Biological knowledge about the model being verified. We demonstrate our algorithm on a variety of models from the Systems Biology literature and show that it enables faster verification than state-of-the-art techniques, even when no prior knowledge is available."
  },
  {
    "Title": "Formal Verification of Curved Flight Collision Avoidance Maneuvers",
    "URL": "https://dl.acm.org/doi/10.1007/978-3-642-05089-3_35",
    "Full Abstract": "Aircraft collision avoidance maneuvers are important and complex applications. Curved flight exhibits nontrivial continuous behavior. In combination with the control choices during air traffic maneuvers, this yields hybrid systems with challenging interactions of discrete and continuous dynamics. As a case study illustrating the use of a new proof assistant for a logic for nonlinear hybrid systems, we analyze collision freedom of roundabout maneuvers in air traffic control, where appropriate curved flight, good timing, and compatible maneuvering are crucial for guaranteeing safe spatial separation of aircraft throughout their flight. We show that formal verification of hybrid systems can scale to curved flight maneuvers required in aircraft control applications. We introduce a fully flyable variant of the roundabout collision avoidance maneuver and verify safety properties by compositional verification."
  },
  {
    "Title": "European Train Control System",
    "URL": "https://dl.acm.org/doi/10.1007/978-3-642-10373-5_13",
    "Full Abstract": "Complex physical systems have several degrees of freedom. They only work correctly when their control parameters obey corresponding constraints. Based on the informal specification of the <em>European Train Control System</em> (ETCS), we design a controller for its cooperation protocol. For its free parameters, we successively identify constraints that are required to ensure collision freedom. We formally prove the parameter constraints to be sharp by characterizing them equivalently in terms of reachability properties of the hybrid system dynamics. Using our deductive verification tool KeYmaera, we formally verify controllability, safety, liveness, and reactivity properties of the ETCS protocol that entail collision freedom. We prove that the ETCS protocol remains correct even in the presence of perturbation by disturbances in the dynamics. We verify that safety is preserved when a PI controlled speed supervision is used."
  },
  {
    "Title": "Differential-algebraic Dynamic Logic for Differential-algebraic Programs",
    "URL": "https://dl.acm.org/doi/10.1093/logcom/exn070",
    "Full Abstract": "We generalize dynamic logic to a logic for differential-algebraic (DA) programs, i.e. discrete programs augmented with first-order differential-algebraic formulas as continuous evolution constraints in addition to first-order discrete jump formulas. These programs characterize interacting discrete and continuous dynamics of hybrid systems elegantly and uniformly. For our logic, we introduce a calculus over real arithmetic with discrete induction and a new"
  },
  {
    "Title": "Bayesian statistical model checking with application to Simulink/Stateflow verification",
    "URL": "https://dl.acm.org/doi/10.1145/1755952.1755987",
    "Full Abstract": "We address the problem of model checking stochastic systems, i.e.~checking whether a stochastic system satisfies a certain temporal property with a probability greater (or smaller) than a fixed threshold. In particular, we present a novel Statistical Model Checking (SMC) approach based on Bayesian statistics. We show that our approach is feasible for hybrid systems with stochastic transitions, a generalization of Simulink/Stateflow models. Standard approaches to stochastic (discrete) systems require numerical solutions for large optimization problems and quickly become infeasible with larger state spaces. Generalizations of these techniques to hybrid systems with stochastic effects are even more challenging. The SMC approach was pioneered by Younes and Simmons in the discrete and non-Bayesian case. It solves the verification problem by combining randomized sampling of system traces (which is very efficient for Simulink/Stateflow) with hypothesis testing or estimation. We believe SMC is essential for scaling up to large Stateflow/Simulink models. While the answer to the verification problem is not guaranteed to be correct, we prove that Bayesian SMC can make the probability of giving a wrong answer arbitrarily small. The advantage is that answers can usually be obtained much faster than with standard, exhaustive model checking techniques. We apply our Bayesian SMC approach to a representative example of stochastic discrete-time hybrid system models in Stateflow/Simulink: a fuel control system featuring hybrid behavior and fault tolerance. We show that our technique enables faster verification than state-of-the-art statistical techniques, while retaining the same error bounds. We emphasize that Bayesian SMC is by no means restricted to Stateflow/Simulink models: we have in fact successfully applied it to very large stochastic models from Systems Biology."
  },
  {
    "Title": "Quantified differential dynamic logic for distributed hybrid systems",
    "URL": "https://dl.acm.org/doi/10.5555/1887459.1887497",
    "Full Abstract": "We address a fundamental mismatch between the combinations of dynamics that occur in complex physical systems and the limited kinds of dynamics supported in analysis. Modern applications combine communication, computation, and control. They may even form dynamic networks, where neither structure nor dimension stay the same while the system follows mixed discrete and continuous dynamics."
  },
  {
    "Title": "Logical Analysis of Hybrid Systems",
    "URL": "https://dl.acm.org/doi/book/10.5555/1869900",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Quantified differential invariants",
    "URL": "https://dl.acm.org/doi/10.1145/1967701.1967713",
    "Full Abstract": "We address the verification problem for distributed hybrid systems with nontrivial dynamics. Consider air traffic collision avoidance maneuvers, for example. Verifying dynamic appearance of aircraft during an ongoing collision avoidance maneuver is a longstanding and essentially unsolved problem. The resulting systems are not hybrid systems and their state space is not of the form <bf>R</bf>"
  },
  {
    "Title": "Adaptive cruise control",
    "URL": "https://dl.acm.org/doi/10.5555/2021296.2021304",
    "Full Abstract": "Car safety measures can be most effective when the cars on a street coordinate their control actions using distributed cooperative control. While each car optimizes its navigation planning locally to ensure the driver reaches his destination, all cars coordinate their actions in a distributed way in order to minimize the risk of safety hazards and collisions. These systems control the physical aspects of car movement using cyber technologies like local and remote sensor data and distributed V2V and V2I communication. They are thus cyber-physical systems. In this paper, we consider a distributed car control system that is inspired by the ambitions of the California PATH project, the CICAS system, SAFESPOT and PReVENT initiatives.We develop a formal model of a distributed car control system in which every car is controlled by adaptive cruise control. One of the major technical difficulties is that faithful models of distributed car control have both distributed systems and hybrid systems dynamics. They form distributed hybrid systems, which makes them very challenging for verification. In a formal proof system, we verify that the control model satisfies its main safety objective and guarantees collision freedom for arbitrarily many cars driving on a street, even if new cars enter the lane from on-ramps or multi-lane streets. The system we present is in many ways one of the most complicated cyber-physical systems that has ever been fully verified formally."
  },
  {
    "Title": "Quantifier elimination over finite fields using Gröbner bases",
    "URL": "https://dl.acm.org/doi/10.5555/2022278.2022289",
    "Full Abstract": "We give an algebraic quantifier elimination algorithm for the first-order theory over any given finite field using Gröbner basis methods. The algorithm relies on the strong Nullstellensatz and properties of elimination ideals over finite fields. We analyze the theoretical complexity of the algorithm and show its application in the formal analysis of a biological controller model."
  },
  {
    "Title": "Logic and compositional verification of hybrid systems",
    "URL": "https://dl.acm.org/doi/10.5555/2032305.2032309",
    "Full Abstract": "Hybrid systems are models for complex physical systems and have become a widely used concept for understanding their behavior. Many applications are safety-critical, including car, railway, and air traffic control, robotics, physical-chemical process control, and biomedical devices. Hybrid systems analysis studies how we can build computerised controllers for physical systems which are guaranteed to meet their design goals. The continuous dynamics of hybrid systems can be modeled by differential equations, the discrete dynamics by a combination of discrete state-transitions and conditional execution. The discrete and continuous dynamics interact to form hybrid systems, which makes them quite challenging for verification."
  },
  {
    "Title": "Optimal Construction of Edge-Disjoint Paths in Random Graphs",
    "URL": "https://dl.acm.org/doi/10.1137/S0097539795290805",
    "Full Abstract": "Given a graph G=(V,E) with n vertices, m edges, and a family of $\\kappa$ pairs of vertices in"
  },
  {
    "Title": "A technique for measuring the relative size and overlap of public Web search engines",
    "URL": "https://dl.acm.org/doi/10.1016/S0169-7552%2898%2900127-5",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "The connectivity server",
    "URL": "https://dl.acm.org/doi/10.1016/S0169-7552%2898%2980047-0",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "A technique for measuring the relative size and overlap of public Web search engines",
    "URL": "https://dl.acm.org/doi/10.5555/297805.297863",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "The connectivity server",
    "URL": "https://dl.acm.org/doi/10.5555/297805.297941",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Dynamic Packet Routing on Arrays with Bounded Buffers",
    "URL": "https://dl.acm.org/doi/10.5555/646387.690185",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Min-wise independent permutations (extended abstract)",
    "URL": "https://dl.acm.org/doi/10.1145/276698.276781",
    "Full Abstract": "Copyright © 1998 ACM."
  },
  {
    "Title": "Summary cache",
    "URL": "https://dl.acm.org/doi/10.1145/285237.285287",
    "Full Abstract": "The sharing of caches among Web proxies is an important technique to reduce Web traffic and alleviate network bottlenecks. Nevertheless it is not widely deployed due to the overhead of existing protocols. In this paper we propose a new protocol called \"Summary Cache\"; each proxy keeps a summary of the URLs of cached documents of each participating proxy and checks these summaries for potential hits before sending any queries. Two factors contribute to the low overhead: the summaries are updated only periodically, and the summary representations are economical --- as low as 8 bits per entry. Using trace-driven simulations and a prototype implementation, we show that compared to the existing Internet Cache Protocol (ICP), Summary Cache reduces the number of inter-cache messages by a factor of 25 to 60, reduces the bandwidth consumption by over 50%, and eliminates between 30% to 95% of the CPU overhead, while at the same time maintaining almost the same hit ratio as ICP. Hence Summary Cache enables cache sharing among a large number of proxies."
  },
  {
    "Title": "A Derandomization Using Min-Wise Independent Permutations",
    "URL": "https://dl.acm.org/doi/10.5555/646975.711400",
    "Full Abstract": "Min-wise independence is a recently introduced notion of limited independence, similar in spirit to pairwise independence. The later has proven essential for the derandomization of many algorithms. Here we show that approximate min-wise independence allows similar uses, by presenting a derandomization of the RNC algorithm for approximate set cover due to S. Rajagopalan and V. Vazirani. We also discuss how to derandomize their set multi-cover and multi-set multi-cover algorithms in restricted cases. The multi-cover case leads us to discuss the concept of"
  },
  {
    "Title": "Information Retrieval on the Web",
    "URL": "https://dl.acm.org/doi/10.5555/795664.796468",
    "Full Abstract": "The Web explosion offers a bonanza of algorithmic problems. In particular, information retrieval in the web context requires methods and ideas that have not been addressed in the classic IR literature. This tutorial will survey emerging techniques for IR in the web context and discuss some of the pertinent open problems.The list of topics includes search engine technology, ranking and classification methods, web measurements (usage, size, connectivity), and new graph and data structure problems arising in the web IR context."
  },
  {
    "Title": "Static and dynamic path selection on expander graphs",
    "URL": "https://dl.acm.org/doi/10.5555/308215.308231",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Unscrambling address lines",
    "URL": "https://dl.acm.org/doi/10.5555/314500.315057",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Mirror, mirror on the Web",
    "URL": "https://dl.acm.org/doi/10.1016/S1389-1286%2899%2900021-3",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Finding anything in the billion page Web",
    "URL": "https://dl.acm.org/doi/10.5555/313009.313138",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Completeness and Robustness Properties of Min-Wise Independent Permutations",
    "URL": "https://dl.acm.org/doi/10.5555/646976.711541",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Improved classification via connectivity information",
    "URL": "https://dl.acm.org/doi/10.5555/338219.338610",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Min-Wise versus linear independence (extended abstract)",
    "URL": "https://dl.acm.org/doi/10.5555/338219.338246",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Min-Wise Independent Permutations",
    "URL": "https://dl.acm.org/doi/10.1006/jcss.1999.1690",
    "Full Abstract": "We define and study the notion of min-wise independent families of permutations. We say that F Sn (the symmetric group) is min-wise independent if for any set X n and any x X, when is chosen at random in F we havePr(min{ (X)}= (x))=1|X| . In other words we require that all the elements of any fixed set X have an equal chance to become the minimum element of the image of X under . Our research was motivated by the fact that such a family (under some relaxations) is essential to the algorithm used in practice by the AltaVista web index software to detect and filter near-duplicate documents. However, in the course of our investigation we have discovered interesting and challenging theoretical questions related to this concept we present the solutions to some of them and we list the rest as open problems."
  },
  {
    "Title": "Graph structure in the Web",
    "URL": "https://dl.acm.org/doi/10.1016/S1389-1286%2800%2900083-9",
    "Full Abstract": "The study of the Web as a graph is not only fascinating in its own right, but also yields valuable insight into Web algorithms for crawling, searching and community discovery, and the sociological phenomena which characterize its evolution. We report on experiments on local and global properties of the Web graph using two AltaVista crawls each with over 200 million pages and 1.5 billion links. Our study indicates that the macroscopic structure of the Web is considerably more intricate than suggested by earlier experiments on a smaller scale."
  },
  {
    "Title": "Structured Computer Organization",
    "URL": "https://dl.acm.org/doi/book/10.5555/552473",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Globe",
    "URL": "https://dl.acm.org/doi/10.1109/4434.749137",
    "Full Abstract": "Developing large-scale wide-area applications requires an infrastructure that is presently lacking. Currently, most Internet applications have to be built on top of raw communication services, such as TCP connections. All additional services, including those for naming, replication, migration, persistence, fault tolerance, and security, have to be implemented for each application anew. Not only is this a waste of effort, it also makes interoperability between different applications difficult or even impossible. The authors present a novel, object-based framework for developing wide-area distributed applications. The framework is based on the concept of a distributed shared object, which has the characteristic feature that its state can be physically distributed across multiple machines at the same time. All implementation aspects, including communication protocols, replication strategies, and distribution and migration of state, are part of each object and are hidden behind its interface. The current performance problems of the World-Wide Web are taken as an example to illustrate the benefit of encapsulating state, operations, and implementation strategies on a per-object basis. The authors describe how distributed objects can be used to implement worldwide scalable Web documents."
  },
  {
    "Title": "A Security Design for a Wide-Area Distributed System",
    "URL": "https://dl.acm.org/doi/10.5555/646281.687819",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "From Remote Objects to Physically Distributed Objects",
    "URL": "https://dl.acm.org/doi/10.5555/795674.797051",
    "Full Abstract": "Present-day object-oriented middleware provides little support for the distribution, replication and caching of the state of a distributed object. This makes these platforms unsuitable for the development of large-scale distributed applications. We argue that the model of distributed objects on which these middleware platforms are based hinders the addition of comprehensive distribution and replication support to these platforms. We present an alternative view of distributed objects, in which objects are not only in control of the functional aspects of their implementation but also in control of their nonfunctional aspects, in particular, the distribution and replication of their state. We claim that a middleware platform based on this view of distributed objects is better suited for developing the large-scale applications of the future."
  },
  {
    "Title": "The globe distribution network",
    "URL": "https://dl.acm.org/doi/10.5555/1267724.1267765",
    "Full Abstract": "The goal of the Globe project is to design and build a middleware platform that facilitates the development of large-scale distributed applications, such as those found on the Internet. To demonstrate the feasibility of our design and to test our ideas, we are currently building a new Internet application: The Globe Distribution Network. The Globe Distribution Network, or GDN, is an application for the efficient, worldwide distribution of free software and other free data. The GDN can be seen as an improvement to anonymous FTP and the World Wide Web due to its flexibility and extensive support for replication. This paper describes the design of the GDN. We start by explaining how the replication facilities of the Globe middleware are used to make the GDN efficient, and how these facilities are implemented. Next, we present the architecture of the GDN and discuss how the Domain Name System can be used as a first approach towards a worldwide service for naming software packages and other entities. This is followed by an analysis of the security requirements for the GDN and measures taken to satisfy these requirements. We hope to make Globe and GDN itself available for free under the BSD license by 2001."
  },
  {
    "Title": "Disallowing Unauthorized State Changes of Distributed Shared Objects",
    "URL": "https://dl.acm.org/doi/10.5555/647183.719499",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "The distributed ASCI Supercomputer project",
    "URL": "https://dl.acm.org/doi/10.1145/506106.506115",
    "Full Abstract": "The Distributed ASCI Supercomputer (DAS) is a homogeneous wide-area distributed system consisting of four cluster computers at different locations. DAS has been used for research on communication software, parallel languages and programming systems, schedulers, parallel applications, and distributed applications. The paper gives a preview of the most interesting research results obtained so far in the DAS project."
  },
  {
    "Title": "Modern Operating Systems",
    "URL": "https://dl.acm.org/doi/book/10.5555/516975",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Differentiated strategies for replicating Web documents",
    "URL": "https://dl.acm.org/doi/10.1016/S0140-3664%2800%2900319-4",
    "Full Abstract": "Replicating Web documents reduces user-perceived delays and wide-area network traffic. Numerous caching and replication protocols have been proposed to manage such replication while keeping the document copies consistent. We claim, however, that no single caching or replication policy can efficiently manage all documents. Instead, we propose that each document be replicated with a policy specifically tailored to it. We have collected traces on our university's Web server and conducted simulations to determine the performance such tailored policies would produce, as opposed to using the same policy for all documents. The results show a significant performance improvement with respect to end-user delays, wide-area network traffic and document consistency. We also present how these results can be used to build adaptive replicated Web documents, capable of automatically selecting the policy that best suits them."
  },
  {
    "Title": "Scalable Human-Friendly Resource Names",
    "URL": "https://dl.acm.org/doi/10.1109/4236.957891",
    "Full Abstract": "Currently, Uniform Resource Locators (URLs) are used to name and access Web-based resources. However, URLs pose a significant scalability problem because they cannot be used to refer to replicated Web pages. The authors propose a new URI scheme called Human-Friendly Names (HFNs) to solve this scalability problem. HFNs are high-level names that are easy-to-use by humans and name Web resources in a location-independent way. This article describes a scalable HFN-to-URL resolution mechanism that is based on URNs and makes use of the Domain Name System (DNS) and the Globe Location Service."
  },
  {
    "Title": "Distributed Systems",
    "URL": "https://dl.acm.org/doi/book/10.5555/559404",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "A Law-Abiding Peer-to-Peer Network for Free-Software Distribution",
    "URL": "https://dl.acm.org/doi/10.5555/580585.883129",
    "Full Abstract": "The Globe Distribution Network (GDN) is an application for worldwide distribution of freely redistributable software packages. The GDN takes a novel, optimistic approach to stop the illegal distribution of copyrighted and illicit material via the network. Instead of having moderators check the software archives at upload time, illegal content is removed and its uploader's access to the network permanently revoked only when the content is discovered. An important feature of the GDN is that the objects containing the software can run on untrustworthy servers. A first version of the GDN has been implemented and has been running since October 2000 across four European sites."
  },
  {
    "Title": "Experiences with the amoeba distributed operating system",
    "URL": "https://dl.acm.org/doi/10.5555/360596.360643",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Dynamically Selecting Optimal Distribution Strategies for Web Documents",
    "URL": "https://dl.acm.org/doi/10.1109/TC.2002.1009149",
    "Full Abstract": "To improve the scalability of the Web, it is common practice to apply caching and replication techniques. Numerous strategies for placing and maintaining multiple copies of Web documents at several sites have been proposed. These approaches essentially apply a global strategy by which a single family of protocols is used to choose replication sites and keep copies mutually consistent. We propose a more flexible approach by allowing each distributed document to have its own associated strategy. We propose a method for assigning an optimal strategy to each document separately and prove that it generates a family of optimal results. Using trace-based simulations, we show that optimal assignments clearly outperform any global strategy. We have designed an architecture for supporting documents that can dynamically select their optimal strategy and evaluate its feasibility."
  },
  {
    "Title": "Access control, reverse access control and replication control in a world wide distributed system",
    "URL": "https://dl.acm.org/doi/10.5555/647802.737168",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Implementation and applications of Scott's logic for computable functions",
    "URL": "https://dl.acm.org/doi/10.1145/800235.807067",
    "Full Abstract": "The basis for this paper is a logic designed by Dana Scott [1] in 1969 for formalizing arguments about computable functions of higher type. This logic uses typed combinators, and we give a more or less direct translation into typed λ-calculus, which is an easier formalism to use, though not so easy for the metatheory because of the presence of bound variables. We then describe, by example only, a proof-checker program which has been implemented for this logic; the program is fully described in [2]. We relate the induction rule which is central to the logic to two more familiar rules - Recursion Induction and Structural Induction - showing that the former is a theorem of the logic, and that for recursively defined structures the latter is a derived rule of the logic. Finally we show how the syntax and semantics of a simple programming language may be described completely in the logic, and we give an example of a theorem which relates syntactic and semantic properties of programs and which can be stated and proved within the logic."
  },
  {
    "Title": "Logic for Computable Functions: description of a machine implementation.",
    "URL": "https://dl.acm.org/doi/book/10.5555/891954",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "A calculus for the mathematical theory of computation",
    "URL": "https://dl.acm.org/doi/10.5555/646795.704997",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Models of LCF.",
    "URL": "https://dl.acm.org/doi/book/10.5555/891977",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "A Metalanguage for interactive proof in LCF",
    "URL": "https://dl.acm.org/doi/10.1145/512760.512773",
    "Full Abstract": "Copyright © 1978 ACM."
  },
  {
    "Title": "An Algebraic Theory for Synchronization",
    "URL": "https://dl.acm.org/doi/10.5555/647209.719878",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Concurrent Processes and Their Syntax",
    "URL": "https://dl.acm.org/doi/10.1145/322123.322134",
    "Full Abstract": "Copyright © 1979 ACM."
  },
  {
    "Title": "Flowgraphs and Flow Algebras",
    "URL": "https://dl.acm.org/doi/10.1145/322154.322167",
    "Full Abstract": "Copyright © 1979 ACM."
  },
  {
    "Title": "On Observing Nondeterminism and Concurrency",
    "URL": "https://dl.acm.org/doi/10.5555/646234.758793",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "A Modal Characterisation of Observable Machine-Behaviour",
    "URL": "https://dl.acm.org/doi/10.5555/648216.750906",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Principal type-schemes for functional programs",
    "URL": "https://dl.acm.org/doi/10.1145/582153.582176",
    "Full Abstract": "Copyright © 1982 ACM."
  },
  {
    "Title": "Four combinators for concurrency",
    "URL": "https://dl.acm.org/doi/10.1145/800220.806687",
    "Full Abstract": "An algebraic calculus of asynchronous parallel computation, called CCS (Calculus of Communicating Systems), was developed in [HM,Mil 1]. CCS can express both the semantics of parallel programming languages and the behaviour of data structures (mailbox, random access memory, buffer) which serve as interfaces between independent agents. The primitive notion is 'handshake' communication. The emphasis is upon (i) synthesis from components and (ii) extensionality (meaning = observable behaviour), in contrast with Petri's Net theory which emphasizes causal independence."
  },
  {
    "Title": "A  Calculus of Communicating Systems",
    "URL": "https://dl.acm.org/doi/book/10.5555/539036",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Using Algebra for Concurrency",
    "URL": "https://dl.acm.org/doi/10.5555/647694.731201",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Parallel Combinator Reduction Machine",
    "URL": "https://dl.acm.org/doi/10.5555/647694.731340",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Beyond Regular Model Checking",
    "URL": "https://dl.acm.org/doi/10.5555/646839.708790",
    "Full Abstract": "In recent years, it has been established that regular model checking can be successfully applied to several parameterized verification problems. However, there are many parameterized verification problems that cannot be described by regular languages, and thus cannot be verified using regular model checking. In this study we try to practice symbolic model checking using classes of languages more expressive than the regular languages. We provide three methods for the uniform verification of non-regular parameterized systems."
  },
  {
    "Title": "Range Allocation for Equivalence Logic",
    "URL": "https://dl.acm.org/doi/10.5555/646839.759698",
    "Full Abstract": "The range allocation problem was recently introduced as part of an efficient decision procedure for deciding satisfiability of equivalence logic formulas with or without uninterpreted functions. These type of formulas are mainly used when proving equivalence or refinement between systems (hardware designs, compiler's translation, etc). The problem is to find in polynomial time a small finite domain for each of the variables in an equality formula ϕ, such that ϕ is valid if and only if it is valid over this small domain. The heuristic that was presented for finding small domains was static, i.e. it finds a small set of integer constants for each variable. In this paper we show new, more flexible range allocation methods. We also show the limitations of these and other related approaches by proving a lower bound on the size of the state space generated by such procedures. To prove this lower bound we reduce the question to a graph theoretic counting question, which we believe to be of independent interest."
  },
  {
    "Title": "Model-Checking and Abstraction to the Aid of Parameterized Systems",
    "URL": "https://dl.acm.org/doi/10.5555/646542.696212",
    "Full Abstract": "Parameterized systems are systems that involve numerous instantiations of the same finite-state module. Examples of parameterized systems include tele-communication protocols, bus protocols, cache coherence protocols, and many other protocols that underly current state-of-the-art systems. Formal verification of parameterized systems is known to be undecidable [AK86] and thus cannot be automated. Recent research has shown that in many cases it is possible to use abstraction methods to generate a finite-state systems from a parameterized systems. The finite-state system can then be model-checked. If successful, it is possible to conclude that the original parameterized system satisfies its requirements. Otherwise, it is often the case that the counterexample produced by the model checker can indicate an error in the original parameterized system. This combined technique allows for automatic verification of parameterized systems.This presentation describes our recent approaches that combine abstraction and model-checking to verify safety as well we liveness properties of parameterized systems. We start with the method of invisible invariants [APR+01] that combines a small-model theorem with an heuristics to generate proofs of correctness of parameterized systems. We also describe the method of network invariants [ZPK02, KPSZ02] which allows to explicitly describe a finite-system that, in a precise sense, has the same external behavior as an infinite-state one, and can be used for model-checking properties."
  },
  {
    "Title": "Automatic Verification of Probabilistic Free Choice",
    "URL": "https://dl.acm.org/doi/10.5555/646541.696191",
    "Full Abstract": "We study automatic methods for establishing P-validity (validity with probability 1) of simple temporal properties over finite-state probabilistic systems. The proposed approach replaces P-validity with validity over a non-probabilistic version of the system, in which probabilistic choices are replaced by non-deterministic choices constrained by compassion (strong fairness) requirements. \"Simple\" properties are temporal properties whose only temporal operators are l (eventually) and its dual (always). In general, the appropriate compassion requirements are \"global,\" since they involve global states of the system. Yet, in many cases they can be transformed into \"local\" requirements, which enables their verification by model checkers. We demonstrate our methodology of translating the problem of P-validity into that of verification of a system with local compassion requirement on the \"courteous philosophers\" algorithm of [LR81], a parameterized probabilistic system that is notoriously difficult to verify, and outline a verification of the algorithm that was obtained by the tlv model checker."
  },
  {
    "Title": "Erratum to \"Verification by augmented finitary abstraction,\" vol. 163, no. 1 (2000) pp. 203-243, doi:10.1006/inco.2000.3000",
    "URL": "https://dl.acm.org/doi/10.5555/512520.512524",
    "Full Abstract": "The paper deals with the proof method of verification by finitary abstraction (VFA), which presents a feasible approach to the verification of the temporal properties of (potentially infinite-state) reactive systems. The method consists of a two-step process by which, in a first step, the system and its temporal specification are jointly abstracted into a finite-state system and a finite-state specification. The second step uses model checking to establish the validity of the abstracted property over the abstracted system. The VFA method can be considered a viable alternative to verification by temporal deduction which, up to now, has been the main method generally applicable for verification of infinite-state systems. The paper presents a general recipe for the joint abstraction, which is shown to be sound, where soundness means that validity over the abstract system implies validity over the concrete (original) system. To make the method applicable for the verification of liveness properties, pure abstraction is sometimes no longer adequate. We show that by augmenting the system by an appropriate (and standardly constructible) progress monitor, we obtain an augmented system, whose computations are essentially the same as the original system, and which may now be abstracted while preserving the desired liveness properties. We refer to the extended method as verification by augmented abstraction (VAA). We then proceed to show that the VAA method is sound and complete for proving all properties expressible by temporal logic (including both safety and liveness). Completeness establishes that whenever the property is valid, there exists a finitary abstraction which abstracts the system, augmented by an appropriate progress monitor, into a finite-state system which validated the abstracted property. Copyright 2000 Academic Press."
  },
  {
    "Title": "TimeC",
    "URL": "https://dl.acm.org/doi/10.1023/A%3A1015131814255",
    "Full Abstract": "Enabled by RISC technologies, low-cost commodity microprocessors are performing at ever increasing levels, significantly via instruction level parallelism (ILP). This in turn increases the opportunities for their use in a variety of day-to-day applications ranging from the simple control of appliances such as microwave ovens, to sophisticated systems for cabin control in modern aircraft. Indeed, embedded applications such as these represent segments in the computer industry with great potential for growth. However, this growth is currently impeded by the lack of robust optimizing compiler technologies that support the assured, rapid and inexpensive prototyping of real-time software in the context of microprocessors with ILP. In this paper we describe a novel notation, TimeC, for specifying timing constraints in programs, i&gt;independent of the base language being used to develop the embedded application; TimeC specifications are language independent and can be instrumented into imperative and object-oriented languages non-intrusively. As we will show, the program synthesis problem that arise out of Time_tract specifications, a subset of TimeC, are always tractable. In contrast, a range of specification mechanisms proposed earlier yield substantially intractable synthesis questions, thereby limiting their potential utility. We will compare the tractability and related expressive power issues between TimeC and some of the extant mechanisms for specifying properties of timed programs."
  },
  {
    "Title": "Liveness with (0, 1, infty)-Counter Abstraction",
    "URL": "https://dl.acm.org/doi/10.5555/647771.734286",
    "Full Abstract": "We introduce the (0, 1, )-counter abstraction method by which a parameterized system of unbounded size is abstracted into a finite-state system. Assuming that each process in the parameterized system is finite-state, the abstract variables are limited counters which count, for each local state s of a process, the number of processes which currently are in local state s. The counters are saturated at 2, which means that ("
  },
  {
    "Title": "Network Invariants in Action",
    "URL": "https://dl.acm.org/doi/10.5555/646737.701938",
    "Full Abstract": "The paper presents the method of network invariants for verifying a wide spectrum of LTL properties, including liveness, of parameterized systems. This method can be applied to establish the validity of the property over a system"
  },
  {
    "Title": "A Deductive Proof System for CTL",
    "URL": "https://dl.acm.org/doi/10.5555/646737.756915",
    "Full Abstract": "The paper presents a sound and (relatively) complete deductive proof system for the verification of CTL* properties over possibly infinite-state reactive systems.T he proof system is based on a set of proof rules for the verification of basic CTL* formulas, namely CTL* formulas with no embedded path quantifiers.W e first show how to decompose the proof of a general (non-basic) CTL* formula into proofs of basic CTL* formulas.W e then present proof rules for some of the most useful basic CTL* formulas, then present a methodology for transforming an arbitrary basic formula into one of these special cases."
  },
  {
    "Title": "Applications of Formal Methods in Biology",
    "URL": "https://dl.acm.org/doi/10.5555/646847.707119",
    "Full Abstract": "From the first introduction of the notion of \"Reactive Systems\" and development of specification languages (such as Temporal Logic and Statecharts) and verification methods for this class of systems, it has been stated that this notion encompasses a wider class of systems than just programs or hardware designs, and should be applicable to other complex systems unrelated to computers. In a similar vein, the acronym UML talks about \"modeling language\" rather than \"programming language\", implying that the approach should be applicable to a more general class of systems than just computer-related.While this claim of wider applicability has been always implied, it was never before seriously substantiated. In this talk, I will describe some recent attempts to apply the discipline of formal methods to the modeling, analysis, and prediction of biological systems. This corresponds to an emerging trend in Biology, according to which Biology in the 21st century will have to direct its attention towards understanding how component parts collaborate to create a whole system or organism. The transition from identifying building blocks (analysis) to integrating the parts into a whole (synthesis) will have to use mathematics and algorithmics. We need a language that is legible both to biologists and computers, and that is faithful to the logic of the biological system of interest.In search for an appropriate rigorous approach to modeling biological systems, we examined formal modeling methods in computer science that were originally developed for specification, design, and analysis of reactive systems. We found that the visual formalism of statecharts can address this challenge, within the general framework of object-oriented modeling. This conclusion followed an initial study we carried out, in which we constructed a detailed executable model for T cell activation, and were able, using verification techniques to find and correct a flaw in the original model.Following this preliminary study, we have now undertaken the more challenging project of applying and extending this methodology for constructing a detailed model of the developmental processes that lead to the formation of the egg-laying system in the nematode C. elegans. The model is built to capture in a natural yet rigorous and analyzable way the aspects of concurrency, multi scalar data, and hierarchical organization. This project involves a close collaboration with Naaman Kam, David Harel, and Irun Cohen from the department of Immunology at the Weizmann Institute."
  },
  {
    "Title": "Embedded Systems",
    "URL": "https://dl.acm.org/doi/10.5555/646788.704045",
    "Full Abstract": "In this position paper, we mention some of the challenges in specification and verification which are raised by the emerging discipline of embedded systems. The main proposition of the paper is that a feasible solution to the problem of effective, reliable, and dependable construction of embedded systems can be provided by a seamless development process based on a formal specification of the required system, which proceeds by the activities of verification and analysis of the specification at very early stages of the design, and then followed by automatic code generation, preceded if necessary by code distribution and allocation.As a prototype example of such a development process, we quote some experiences from the Sacres project and its follow-up Safeair. Necessary extensions to these preliminary experiments are discussed and evaluated."
  },
  {
    "Title": "Validating software pipelining optimizations",
    "URL": "https://dl.acm.org/doi/10.1145/581630.581676",
    "Full Abstract": "The paper presents a method for translation validation of a specific optimization, software pipelining optimization, used to increase the instruction level parallelism in EPIC type of architectures. Using a methodology as in [15] to establish simulation relation between source and target based on computational induction, we describe an algorithm that automatically produces a set of decidable proof obligations. The paper also describes"
  },
  {
    "Title": "The small model property",
    "URL": "https://dl.acm.org/doi/10.1016/S0890-5401%2802%2993175-5",
    "Full Abstract": "Efficient decision procedures for equality logic (quantifier-free predicate calculus + the equality sign) are of major importance when proving logical equivalence between systems. We introduce an efficient decision procedure for the theory of equality based on finite instantiations. The main idea is to analyze the structure of the formula and compute accordingly a small domain to each variable such that the formula is satisfiable iff it can be satisfied over these domains. We show how the problem of finding these small domains can be reduced to an interesting graph theoretic problem. This method enabled us to verify formulas containing hundreds of integer and floating point variables that could not be efficiently handled with previously known techniques."
  },
  {
    "Title": "Smart Play-out of Behavioral Requirements",
    "URL": "https://dl.acm.org/doi/10.5555/646187.683385",
    "Full Abstract": "We describe a methodology for executing scenario-based requirements of reactive systems, focusing on \"playing-out\" the behavior using formal verification techniques for driving the execution. The methodology is implemented in full in our play-engine tool. The approach appears to be useful in many stages in the development of reactive systems, and might also pave the way to systems that are constructed directly from their requirements, without the need for intra-object or intra-component modeling or coding."
  },
  {
    "Title": "Formal Modeling of C. elegans Development",
    "URL": "https://dl.acm.org/doi/10.5555/648295.754699",
    "Full Abstract": "We present preliminary results of a new approach to the formal modeling of biological phenomena. The approach stems from the conceptual compatibility of the methods and logic of data collection and analysis in the field of developmental genetics with the languages, methods and tools of scenario-based reactive system design. In particular, we use the recently developed methodology consisting of the language of live sequence charts with the play-in/play-out process, to model the well-characterized process of cell fate acquisition during C. elegans vulval development."
  },
  {
    "Title": "Building data integration systems",
    "URL": "https://dl.acm.org/doi/10.5555/3104278.3104314",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Profile-Based Object Matching for Information Integration",
    "URL": "https://dl.acm.org/doi/10.1109/MIS.2003.1234770",
    "Full Abstract": "Object matching is a fundamental problem that arises in numerous information integration scenarios. Virtually all existing solutions assume that the objects to be matched share the same attribute set and that systems can match them by comparing attribute similarities. Our work addresses the more general problem in which objects also have disjoint attributes-for example, matching tuples from relational tables that have different schemas, such as (age, name) and (name, salary). Profile-Based Object Matching, which applies this idea, exploits disjoint attributes to improve matching accuracy. PROM first matches any two tuples based on a shared attribute, such as name. It then applies a set of profilers, each of which contains some knowledge about what constitutes a typical person. The profilers examine the tuple pair to see if it plausibly describes a person. A profiler might state, for example, that if the pair produces a person with an age of 6 and a salary of $100,000, the pair doesn't describe a real person, so the tuples don't match. Profilers can be manually specified by domain experts, trained on training data, transferred from other matching tasks, or built from external data. PROM is thus distinct in that it not only exploits disjoint attributes to improve matching accuracy but also facilitates knowledge reuse from previous object-matching tasks."
  },
  {
    "Title": "Learning to match ontologies on the Semantic Web",
    "URL": "https://dl.acm.org/doi/10.1007/s00778-003-0104-2",
    "Full Abstract": "On the Semantic Web, data will inevitably come from many different ontologies, and information processing across ontologies is not possible without knowing the semantic mappings between them. Manually finding such mappings is tedious, error-prone, and clearly not possible on the Web scale. Hence the development of tools to assist in the ontology mapping process is crucial to the success of the Semantic Web. We describe"
  },
  {
    "Title": "Semantic Integration Workshop at the Second International Semantic Web Conference (ISWC‐2003)",
    "URL": "https://dl.acm.org/doi/10.1609/aimag.v25i1.1753",
    "Full Abstract": "In numerous distributed environments, including today's World Wide Web, enterprise data management systems, large science projects, and the emerging semantic web, applications will inevitably use the information described by multiple ontologies and schemas. We organized the Workshop on Semantic Integration at the Second International Semantic Web Conference to bring together different communities working on the issues of enabling integration among different resources. The workshop generated a lot of interest and attracted more than 70 participants."
  },
  {
    "Title": "Semantic integration workshop at the second international semantic web conference (ISWC-2003)",
    "URL": "https://dl.acm.org/doi/10.5555/996917.996930",
    "Full Abstract": "In numerous distributed environments, including today's World Wide Web, enterprise data management systems, large science projects, and the emerging semantic web, applications will inevitably use the information described by multiple ontologies and schemas. We organized the Workshop on Semantic Integration at the Second International Semantic Web Conference to bring together different communities working on the issues of enabling integration among different resources. The workshop generated a lot of interest and attracted more than 70 participants."
  },
  {
    "Title": "An interactive clustering-based approach to integrating source query interfaces on the deep Web",
    "URL": "https://dl.acm.org/doi/10.1145/1007568.1007582",
    "Full Abstract": "An increasing number of data sources now become available on the Web, but often their contents are only accessible through query interfaces. For a domain of interest, there often exist many such sources with varied coverage or querying capabilities. As an important step to the integration of these sources, we consider the integration of their query interfaces. More specifically, we focus on the crucial step of the integration: accurately matching the interfaces. While the integration of query interfaces has received more attentions recently, current approaches are not sufficiently general: (a) they all model interfaces with flat schemas; (b) most of them only consider 1:1 mappings of fields over the interfaces; (c) they all perform the integration in a blackbox-like fashion and the whole process has to be restarted from scratch if anything goes wrong; and (d) they often require laborious parameter tuning. In this paper, we propose an interactive, clustering-based approach to matching query interfaces. The hierarchical nature of interfaces is captured with ordered trees. Varied types of complex mappings of fields are examined and several approaches are proposed to effectively identify these mappings. We put the human integrator back in the loop and propose several novel approaches to the interactive learning of parameters and the resolution of uncertain mappings. Extensive experiments are conducted and results show that our approach is highly effective."
  },
  {
    "Title": "iMAP",
    "URL": "https://dl.acm.org/doi/10.1145/1007568.1007612",
    "Full Abstract": "Creating semantic matches between disparate data sources is fundamental to numerous data sharing efforts. Manually creating matches is extremely tedious and error-prone. Hence many recent works have focused on automating the matching process. To date, however, virtually all of these works deal only with one-to-one (1-1) matches, such as"
  },
  {
    "Title": "Privacy-preserving data integration and sharing",
    "URL": "https://dl.acm.org/doi/10.1145/1008694.1008698",
    "Full Abstract": "Integrating data from multiple sources has been a longstanding challenge in the database community. Techniques such as privacy-preserving data mining promises privacy, but assume data has integration has been accomplished. Data integration methods are seriously hampered by inability to share the data to be integrated. This paper lays out a privacy framework for data integration. Challenges for data integration in the context of this framework are discussed, in the context of existing accomplishments in data integration. Many of these challenges are opportunities for the data mining community."
  },
  {
    "Title": "Introduction to the special issue on semantic integration",
    "URL": "https://dl.acm.org/doi/10.1145/1041410.1041412",
    "Full Abstract": "Semantic heterogeneity is one of the key challenges in integrating and sharing data across disparate sources, data exchange and migration, data warehousing, model management, the Semantic Web and peer-to-peer databases. Semantic heterogeneity can arise at the schema level and at the data level. At the schema level, sources can differ in relations, attribute and tag names, data normalization, levels of detail, and the coverage of a particular domain. The problem of reconciling schema-level heterogeneity is often referred to as"
  },
  {
    "Title": "Semantic Integration",
    "URL": "https://dl.acm.org/doi/10.1609/aimag.v26i1.1794",
    "Full Abstract": "Sharing data across disparate sources requires solving many problems of semantic integration, such as matching ontologies or schemas, detecting duplicate tuples, reconciling inconsistent data values, modeling complex relations between concepts in different sources, and reasoning with semantic mappings. This issue of"
  },
  {
    "Title": "Semantic‐Integration Research in the Database Community",
    "URL": "https://dl.acm.org/doi/10.1609/aimag.v26i1.1801",
    "Full Abstract": "Semantic integration has been a long‐standing challenge for the database community. It has received steady attention over the past two decades, and has now become a prominent area of database research. In this article, we first review database applications that require semantic integration and discuss the difficulties underlying the integration process. We then describe recent progress and identify open research issues. We focus in particular on schema matching, a topic that has received much attention in the database community, but also discuss data matching (for example, tuple deduplication) and open issues beyond the match discovery context (for example, reasoning with matches, match verification and repair, and reconciling inconsistent data values). For previous surveys of database research on semantic integration, see Rahm and Bernstein (2001); Ouksel and Seth (1999); and Batini, Lenzerini, and Navathe (1986)."
  },
  {
    "Title": "Semantic integration",
    "URL": "https://dl.acm.org/doi/10.5555/1090488.1090490",
    "Full Abstract": "Sharing data across disparate sources requires solving many problems of semantic integration, such as matching ontologies or schemas, detecting duplicate tuples, reconciling inconsistent data values, modeling complex relations between concepts in different sources, and reasoning with semantic mappings. This issue of AI Magazine includes papers that discuss various methods on establishing mappings between ontology elements or data fragments. The collection includes papers that discuss semantic-integration issues in such contexts as data integration and web services. The issue also includes a brief survey of semantic-integration research in the database community."
  },
  {
    "Title": "Semantic-integration research in the database community",
    "URL": "https://dl.acm.org/doi/10.5555/1090488.1090497",
    "Full Abstract": "Semantic integration has been a long-standing challenge for the database community. It has received steady attention over the past two decades, and has now become a prominent area of database research. In this article, we first review database applications that require semantic integration and discuss the difficulties underlying the integration process. We then describe recent progress and identify open research issues. We focus in particular on schema matching, a topic that has received much attention in the database community, but also discuss data matching (for example, tuple deduplication) and open issues beyond the match discovery context (for example, reasoning with matches, match verification and repair, and reconciling inconsistent data values). For previous surveys of database research on semantic integration, see Rahm and Bernstein (2001); Ouksel and Seth (1999); and Batini, Lenzerini, and Navathe (1986)."
  },
  {
    "Title": "Corpus-Based Schema Matching",
    "URL": "https://dl.acm.org/doi/10.1109/ICDE.2005.39",
    "Full Abstract": "Schema Matching is the problem of identifying corresponding elements in different schemas. Discovering these correspondences or matches is inherently difficult to automate. Past solutions have proposed a principled combination of multiple algorithms. However, these solutions sometimes perform rather poorly due to the lack ofsufficient evidence in the schemas being matched. In this paper we show how a corpus of schemas and mappings can be used to augment the evidence about the schemas being matched, so they can be matched better. Such a corpus typically contains multiple schemas that model similar concepts and hence enables us to learn variations in the elements and their properties. We exploit such a corpus in two ways. First, we increase the evidence about each element being matched by including evidence from similar elements in the corpus. Second, we learn statistics about elements and their relationships and use them to infer constraints that we use to prune candidate mappings. We also describe how to use known mappings to learn the importance of domain and generic constraints. We present experimental results that demonstrate corpus-based matching outperforms direct matching (without the benefit of a corpus) in multiple domains."
  },
  {
    "Title": "Integrating Data from Disparate Sources",
    "URL": "https://dl.acm.org/doi/10.1109/ICDE.2005.81",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Constraint-based entity matching",
    "URL": "https://dl.acm.org/doi/10.5555/1619410.1619471",
    "Full Abstract": "Entity matching is the problem of deciding if two given mentions in the data, such as \"Helen Hunt\" and \"H. M. Hunt\", refer to the same real-world entity. Numerous solutions have been developed, but they have not considered in depth the problem of exploiting integrity constraints that frequently exist in the domains. Examples of such constraints include \"a mention with age two cannot match a mention with salary 200K\" and \"if two paper citations match, then their authors are likely to match in the same order\". In this paper we describe a probabilistic solution to entity matching that exploits such constraints to improve matching accuracy. At the heart of the solution is a generative model that takes into account the constraints during the generation process, and provides well-defined interpretations of the constraints. We describe a novel combination of EM and relaxation labeling algorithms that efficiently learns the model, thereby matching mentions in an unsupervised way, without the need for annotated training data. Experiments on several real-world domains show that our solution can exploit constraints to significantly improve matching accuracy, by 3-12% F-1, and that the solution scales up to large data sets."
  },
  {
    "Title": "Tuning schema matching software using synthetic scenarios",
    "URL": "https://dl.acm.org/doi/10.5555/1083592.1083707",
    "Full Abstract": "Most recent schema matching systems assemble"
  },
  {
    "Title": "Mapping maintenance for data integration systems",
    "URL": "https://dl.acm.org/doi/10.5555/1083592.1083709",
    "Full Abstract": "To answer user queries, a data integration system employs a set of semantic mappings between the mediated schema and the schemas of data sources. In dynamic environments sources often undergo changes that invalidate the mappings. Hence, once the system is deployed, the administrator must monitor it over time, to detect and repair broken mappings. Today such continuous monitoring is extremely labor intensive, and poses a key bottleneck to the widespread deployment of data integration systems in practice.We describe MAVERIC, an automatic solution to detecting broken mappings. At the heart of MAVERIC is a set of computationally inexpensive modules called"
  },
  {
    "Title": "Bootstrapping domain ontology for semantic web services from source web sites",
    "URL": "https://dl.acm.org/doi/10.1007/11607380_2",
    "Full Abstract": "The vision of Semantic Web services promises a network of interoperable Web services over different sources. A major challenge to the realization of this vision is the lack of automated means of acquiring domain ontologies necessary for marking up the Web services. In this paper, we propose the DeepMiner system which learns domain ontologies from the source Web sites. Given a set of sources in a domain of interest, DeepMiner first learns a base ontology from their query interfaces. It then grows the current ontology by probing the sources and discovering additional concepts and instances from the data pages retrieved from the sources. We have evaluated DeepMiner in several real-world domains. Preliminary results indicate that DeepMiner discovers concepts and instances with high accuracy."
  },
  {
    "Title": "Merging Interface Schemas on the Deep Web via Clustering Aggregation",
    "URL": "https://dl.acm.org/doi/10.1109/ICDM.2005.92",
    "Full Abstract": "We consider the problem of integrating a large number of interface schemas over the Deep Web, The scale of the problem and the diversity of the sources present serious challenges to the conventional manual or rule-based approaches to schema integration. To address these challenges, we propose a novel formulation of schema integration as an optimization problem, with the objective of maximally satisfying the constraints given by individual schemas. Since the optimization problem can be shown to be NP-complete, we develop a novel approximation algorithm LMax, which builds the unified schema via recursive applications of clustering aggregation. We further extend LMax to handle the irregularities frequently occurring among the interface schemas. Extensive evaluation on real-world data sets shows the effectiveness of our approach."
  },
  {
    "Title": "Stochastic differential dynamic logic for stochastic hybrid programs",
    "URL": "https://dl.acm.org/doi/10.5555/2032266.2032300",
    "Full Abstract": "Logic is a powerful tool for analyzing and verifying systems, including programs, discrete systems, real-time systems, hybrid systems, and distributed systems. Some applications also have a stochastic behavior, however, either because of fundamental properties of nature, uncertain environments, or simplifications to overcome complexity. Discrete probabilistic systems have been studied using logic. But logic has been chronically underdeveloped in the context of stochastic hybrid systems, i.e., systems with interacting discrete, continuous, and stochastic dynamics. We aim at overcoming this deficiency and introduce a dynamic logic for stochastic hybrid systems. Our results indicate that logic is a promising tool for understanding stochastic hybrid systems and can help taming some of their complexity. We introduce a compositional model for stochastic hybrid systems. We prove adaptivity, càdlàg, and Markov time properties, and prove that the semantics of our logic is measurable. We present compositional proof rules, including rules for stochastic differential equations, and prove soundness."
  },
  {
    "Title": "Statistical model checking for distributed probabilistic-control hybrid automata with smart grid applications",
    "URL": "https://dl.acm.org/doi/10.5555/2075089.2075103",
    "Full Abstract": "The power industry is currently moving towards a more dynamical, intelligent power grid. This Smart Grid is still in its infancy and a formal evaluation of the expensive technologies and ideas on the table is necessary before committing to a full investment. In this paper, we argue that a good model for the Smart Grid must match its basic properties: it must be hybrid (both evolve over time, and perform control/computation), distributed (multiple concurrently executing entities), and allow for asynchronous communication and stochastic behaviour (to accurately model real-world power consumption). We propose Distributed Probabilistic-Control Hybrid Automata (DPCHA) as a model for this purpose, and extend Bounded LTL to Quantified Bounded LTL in order to adapt and apply existing statistical model-checking techniques. We provide an implementation of a framework for developing and verifying DPCHAs. Finally, we conduct a case study for Smart Grid communications analysis."
  },
  {
    "Title": "Distributed theorem proving for distributed hybrid systems",
    "URL": "https://dl.acm.org/doi/10.5555/2075089.2075121",
    "Full Abstract": "Distributed hybrid systems present extraordinarily challenging problems for verification. On top of the notorious difficulties associated with distributed systems, they also exhibit continuous dynamics described by quantified differential equations. All serious proofs rely on decision procedures for real arithmetic, which can be extremely expensive. Quantified Differential Dynamic Logic (QdL) has been identified as a promising approach for getting a handle in this domain. QdL has been proved to be complete relative to quantified differential equations. But important questions remain as to how best to translate this theoretical result into practice: how do we succinctly specify a proof search strategy, and how do we control the computational cost? We address the problem of automated theorem proving for distributed hybrid systems. We identify a simple mode of use of QdL that cuts down on the enormous number of choices that it otherwise allows during proof search. We have designed a powerful strategy and tactics language for directing proof search. With these techniques, we have implemented a new automated theorem prover called KeYmaeraD. To overcome the high computational complexity of distributed hybrid systems verification, KeYmaeraD uses a distributed proving backend. We have experimentally observed that calls to the real arithmetic decision procedure can effectively be made in parallel. In this paper, we demonstrate these findings through an extended case study where we prove absence of collisions in a distributed car control system with a varying number of arbitrarily many cars."
  },
  {
    "Title": "Logical analysis of hybrid systems",
    "URL": "https://dl.acm.org/doi/10.5555/3173440.3173452",
    "Full Abstract": "Hybrid systems are systems with interacting discrete and continuous dynamics. They are models for understanding, e.g., computer systems interfacing with the physical environment. Hybrid systems have a complete axiomatization in differential dynamic logic relative to continuous systems. They also have a complete axiomatization relative to discrete systems. Moreover, there is a constructive reduction of properties of hybrid systems to corresponding properties of continuous systems or to corresponding properties of discrete systems. We briefly summarize and discuss some of the implications of these results."
  },
  {
    "Title": "Towards Formal Verification of Freeway Traffic Control",
    "URL": "https://dl.acm.org/doi/10.1109/ICCPS.2012.25",
    "Full Abstract": "We study how CPS technology can help improve freeway traffic by combining local car GPS positioning, traffic center control decisions, and communication to achieve more tightly coupled feedback control in intelligent speed adaptation. We develop models for an intelligent speed adaptation that respects variable speed limit control and incident management. We identify safe ranges for crucial design parameters in these systems and, using the theorem prover KeYmaera, formally verify safety of the resulting CPS models. Finally, we show how those parameter ranges can be used to decide trade-offs for practical system implementations even for design parameters that are not modeled formally."
  },
  {
    "Title": "Logics of Dynamical Systems",
    "URL": "https://dl.acm.org/doi/10.1109/LICS.2012.13",
    "Full Abstract": "We study the logic of dynamical systems, that is, logics and proof principles for properties of dynamical systems. Dynamical systems are mathematical models describing how the state of a system evolves over time. They are important in modeling and understanding many applications, including embedded systems and cyber-physical systems. In discrete dynamical systems, the state evolves in discrete steps, one step at a time, as described by a difference equation or discrete state transition relation. In continuous dynamical systems, the state evolves continuously along a function, typically described by a differential equation. Hybrid dynamical systems or hybrid systems combine both discrete and continuous dynamics. This is a brief survey of differential dynamic logic for specifying and verifying properties of hybrid systems. We explain hybrid system models, differential dynamic logic, its semantics, and its axiomatization for proving logical formulas about hybrid systems. We study differential invariants, i.e., induction principles for differential equations. We briefly survey theoretical results, including soundness and completeness and deductive power. Differential dynamic logic has been implemented in automatic and interactive theorem provers and has been used successfully to verify safety-critical applications in automotive, aviation, railway, robotics, and analogue electrical circuits."
  },
  {
    "Title": "The Complete Proof Theory of Hybrid Systems",
    "URL": "https://dl.acm.org/doi/10.1109/LICS.2012.64",
    "Full Abstract": "Hybrid systems are a fusion of continuous dynamical systems and discrete dynamical systems. They freely combine dynamical features from both worlds. For that reason, it has often been claimed that hybrid systems are more challenging than continuous dynamical systems and than discrete systems. We now show that, proof-theoretically, this is not the case. We present a complete proof-theoretical alignment that interreduces the discrete dynamics and the continuous dynamics of hybrid systems. We give a sound and complete axiomatization of hybrid systems relative to continuous dynamical systems and a sound and complete axiomatization of hybrid systems relative to discrete dynamical systems. Thanks to our axiomatization, proving properties of hybrid systems is exactly the same as proving properties of continuous dynamical systems and again, exactly the same as proving properties of discrete dynamical systems. This fundamental cornerstone sheds light on the nature of hybridness and enables flexible and provably perfect combinations of discrete reasoning with continuous reasoning that lift to all aspects of hybrid systems and their fragments."
  },
  {
    "Title": "Playing hybrid games with keymaera",
    "URL": "https://dl.acm.org/doi/10.1007/978-3-642-31365-3_34",
    "Full Abstract": "We propose a new logic, called"
  },
  {
    "Title": "Logical analysis of hybrid systems",
    "URL": "https://dl.acm.org/doi/10.1007/978-3-642-31623-4_3",
    "Full Abstract": "Hybrid systems have a complete axiomatization in differential dynamic logic relative to continuous systems. They also have a complete axiomatization relative to discrete systems. Moreover, there is a constructive reduction of properties of hybrid systems to corresponding properties of continuous systems or to corresponding properties of discrete systems. We briefly summarize and discuss some of the implications of these results."
  },
  {
    "Title": "Statistical Model Checking for Markov Decision Processes",
    "URL": "https://dl.acm.org/doi/10.1109/QEST.2012.19",
    "Full Abstract": "Statistical Model Checking (SMC) is a computationally very efficient verification technique based on selective system sampling. One well identified shortcoming of SMC is that, unlike probabilistic model checking, it cannot be applied to systems featuring nondeterminism, such as Markov Decision Processes (MDP). We address this limitation by developing an algorithm that resolves nondeterminism probabilistically, and then uses multiple rounds of sampling and Reinforcement Learning to provably improve resolutions of nondeterminism with respect to satisfying a Bounded Linear Temporal Logic (BLTL) property. Our algorithm thus reduces an MDP to a fully probabilistic Markov chain on which SMC may be applied to give an approximate solution to the problem of checking the probabilistic BLTL property. We integrate our algorithm in a parallelised modification of the PRISM simulation framework. Extensive validation with both new and PRISM benchmarks demonstrates that the approach scales very well in scenarios where symbolic algorithms fail to do so."
  },
  {
    "Title": "Formal verification of distributed aircraft controllers",
    "URL": "https://dl.acm.org/doi/10.1145/2461328.2461350",
    "Full Abstract": "As airspace becomes ever more crowded, air traffic management must reduce both space and time between aircraft to increase throughput, making on-board collision avoidance systems ever more important. These safety-critical systems must be extremely reliable, and as such, many resources are invested into ensuring that the protocols they implement are accurate. Still, it is challenging to guarantee that such a controller works properly under every circumstance. In tough scenarios where a large number of aircraft must execute a collision avoidance maneuver, a human pilot under stress is not necessarily able to understand the complexity of the distributed system and may not take the right course, especially if actions must be taken quickly. We consider a class of distributed collision avoidance controllers designed to work even in environments with arbitrarily many aircraft or UAVs. We prove that the controllers never allow the aircraft to get too close to one another, even when new planes approach an in-progress avoidance maneuver that the new plane may not be aware of. Because these safety guarantees always hold, the aircraft are protected against unexpected emergent behavior which simulation and testing may miss. This is an important step in formally verified, flyable, and distributed air traffic control."
  },
  {
    "Title": "A generalization of SAT and #SAT for robust policy evaluation",
    "URL": "https://dl.acm.org/doi/10.5555/2540128.2540500",
    "Full Abstract": "Both SAT and #SAT can represent difficult problems in seemingly dissimilar areas such as planning, verification, and probabilistic inference. Here, we examine an expressive new language, #∃SAT, that generalizes both of these languages. #∃SAT problems require counting the number of satisfiable formulas in a concisely-describable set of existentially-quantified, propositional formulas. We characterize the expressiveness and worst-case difficulty of #∃SAT by proving it is complete for the complexity class #"
  },
  {
    "Title": "Bayesian statistical model checking with application to Stateflow/Simulink verification",
    "URL": "https://dl.acm.org/doi/10.1007/s10703-013-0195-3",
    "Full Abstract": "We address the problem of model checking stochastic systems, i.e., checking whether a stochastic system satisfies a certain temporal property with a probability greater (or smaller) than a fixed threshold. In particular, we present a Statistical Model Checking (SMC) approach based on Bayesian statistics. We show that our approach is feasible for a certain class of hybrid systems with stochastic transitions, a generalization of Simulink/Stateflow models. Standard approaches to stochastic discrete systems require numerical solutions for large optimization problems and quickly become infeasible with larger state spaces. Generalizations of these techniques to hybrid systems with stochastic effects are even more challenging. The SMC approach was pioneered by Younes and Simmons in the discrete and non-Bayesian case. It solves the verification problem by combining randomized sampling of system traces (which is very efficient for Simulink/Stateflow) with hypothesis testing (i.e., testing against a probability threshold) or estimation (i.e., computing with high probability a value close to the true probability). We believe SMC is essential for scaling up to large Stateflow/Simulink models. While the answer to the verification problem is not guaranteed to be correct, we prove that Bayesian SMC can make the probability of giving a wrong answer arbitrarily small. The advantage is that answers can usually be obtained much faster than with standard, exhaustive model checking techniques. We apply our Bayesian SMC approach to a representative example of stochastic discrete-time hybrid system models in Stateflow/Simulink: a fuel control system featuring hybrid behavior and fault tolerance. We show that our technique enables faster verification than state-of-the-art statistical techniques. We emphasize that Bayesian SMC is by no means restricted to Stateflow/Simulink models. It is in principle applicable to a variety of stochastic models from other domains, e.g., systems biology."
  },
  {
    "Title": "Refactoring, Refinement, and Reasoning",
    "URL": "https://dl.acm.org/doi/10.1007/978-3-319-06410-9_33",
    "Full Abstract": "Refactoring of code is a common device in software engineering. As cyber-physical systems CPS become ever more complex, similar engineering practices become more common in CPS development. Proper safe developments of CPS designs are accompanied by a proof of correctness. Since the inherent complexities of CPS practically mandate iterative development, frequent changes of models are standard practice, but require reverification of the resulting models after every change."
  },
  {
    "Title": "A Hierarchy of Proof Rules for Checking Differential Invariance of Algebraic Sets",
    "URL": "https://dl.acm.org/doi/10.1007/978-3-662-46081-8_24",
    "Full Abstract": "This paper presents a theoretical and experimental comparison of sound proof rules for proving invariance of algebraic sets, that is, sets satisfying polynomial equalities, under the flow of polynomial ordinary differential equations. Problems of this nature arise in formal verification of continuous and hybrid dynamical systems, where there is an increasing need for methods to expedite formal proofs. We study the trade-off between proof rule generality and practical performance and evaluate our theoretical observations on a set of heterogeneous benchmarks. The relationship between increased deductive power and running time performance of the proof rules is far from obvious; we discuss and illustrate certain classes of problems where this relationship is interesting."
  },
  {
    "Title": "A Formally Verified Hybrid System for the Next-Generation Airborne Collision Avoidance System",
    "URL": "https://dl.acm.org/doi/10.1007/978-3-662-46681-0_2",
    "Full Abstract": "The"
  },
  {
    "Title": "Proving hybrid systems",
    "URL": "https://dl.acm.org/doi/10.5555/2893529.2893530",
    "Full Abstract": "Cyber-physical systems (CPS) combine cyber aspects such as communication and computer control with physical aspects such as movement in space, which arise frequently in many safety-critical application domains, including aviation, automotive, railway, and robotics. But how can we ensure that these systems are guaranteed to meet their design goals, e.g., that an aircraft will not crash into another one?"
  },
  {
    "Title": "Verified Traffic Networks",
    "URL": "https://dl.acm.org/doi/10.1109/ITSC.2015.128",
    "Full Abstract": "We address the problem how high-fidelity verification results about the hybrid systems dynamics of cyber-physical flow systems can be provided at the scale of large (traffic) networks without prohibitive analytic cost. We propose the use of contracts for traffic flow components concisely capturing the conditions for a safe operation in the context of a traffic network. This reduces the analysis of flows in the full traffic network to simple arithmetic checks of the local compatibility of the traffic component contracts, while retaining higher-fidelity correctness guarantees of the global hybrid systems models that inherits from correct contracts of the hybrid system components. We evaluate our approach in a case study of a modular traffic network and a prototypical implementation in a model-based analysis and design tool for traffic flow networks."
  },
  {
    "Title": "Summary cache",
    "URL": "https://dl.acm.org/doi/10.1109/90.851975",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Logic-Based Modeling Approaches for Qualitative and Hybrid Reasoning in Dynamic Spatial Systems",
    "URL": "https://dl.acm.org/doi/10.1145/2764901",
    "Full Abstract": "Autonomous agents that operate as components of dynamic spatial systems are becoming increasingly popular and mainstream. Applications can be found in consumer robotics, in road, rail, and air transportation, manufacturing, and military operations. Unfortunately, the approaches to modeling and analyzing the behavior of dynamic spatial systems are just as diverse as these application domains. In this article, we discuss reasoning approaches for the medium-term control of autonomous agents in dynamic spatial systems, which requires a sufficiently detailed description of the agent’s behavior and environment but may still be conducted in a qualitative manner. We survey logic-based qualitative and hybrid modeling and commonsense reasoning approaches with respect to their features for describing and analyzing dynamic spatial systems in general, and the actions of autonomous agents operating therein in particular. We introduce a conceptual reference model, which summarizes the current understanding of the characteristics of dynamic spatial systems based on a catalog of evaluation criteria derived from the model. We assess the modeling features provided by logic-based qualitative commonsense and hybrid approaches for projection, planning, simulation, and verification of dynamic spatial systems. We provide a comparative summary of the modeling features, discuss lessons learned, and introduce a research roadmap for integrating different approaches of dynamic spatial system analysis to achieve coverage of all required features."
  },
  {
    "Title": "Graph structure in the Web",
    "URL": "https://dl.acm.org/doi/10.5555/347319.346290",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Identifying and Filtering Near-Duplicate Documents",
    "URL": "https://dl.acm.org/doi/10.5555/647819.736184",
    "Full Abstract": "The mathematical concept of document resemblance captures well the informal notion of syntactic similarity. The resemblance can be estimated using a fixed size \"sketch\" for each document. For a large collection of documents (say hundreds of millions) the size of this sketch is of the order of a few hundred bytes per document."
  },
  {
    "Title": "Min-wise Independent Permutations",
    "URL": "https://dl.acm.org/doi/10.5555/646253.686321",
    "Full Abstract": "A family of permutations F ⊆"
  },
  {
    "Title": "A comparison of techniques to find mirrored hosts on the WWW",
    "URL": "https://dl.acm.org/doi/10.5555/359203.359211",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Completeness and robustness properties of min-wise independent permutations",
    "URL": "https://dl.acm.org/doi/10.5555/370982.370985",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "A general approach to dynamic packet routing with bounded buffers",
    "URL": "https://dl.acm.org/doi/10.1145/375827.375849",
    "Full Abstract": "We prove a sufficient condition for the stability of dynamic packet routing algorithms. Our approach reduces the problem of steady state analysis to the easier and better understood question of static routing. We show that certain high probability and worst case bounds on the quasi-static (finite past) performance of a routing algorithm imply bounds on the performance of the dynamic version of that algorithm. Our technique is particularly useful in analyzing routing on networks with bounded buffers where complicated dependices make standard queuing techniques inapplicable."
  },
  {
    "Title": "Algorithmic aspects of information retrieval on the web",
    "URL": "https://dl.acm.org/doi/10.5555/779232.779234",
    "Full Abstract": "The Web explosion offers a bonanza of novel problems. In particular, information retrieval in the Web context requires methods and ideas that have not been addressed in the classic information retrieval literature. This chapter will survey emerging techniques for information retrieval in the Web context and discuss some of the pertinent open problems."
  },
  {
    "Title": "Optimal plans for aggregation",
    "URL": "https://dl.acm.org/doi/10.1145/571825.571852",
    "Full Abstract": "We consider the following problem, which arises in the context of distributed Web computations. An"
  },
  {
    "Title": "A taxonomy of web search",
    "URL": "https://dl.acm.org/doi/10.1145/792550.792552",
    "Full Abstract": "Classic IR (information retrieval) is inherently predicated on users searching for information, the so-called \"information need\". But the need behind a web search is often not informational -- it might be navigational (give me the url of the site I want to reach) or transactional (show me sites where I can perform a certain transaction, e.g. shop, download a file, or find a map). We explore this taxonomy of web searches and discuss how global search engines evolved to deal with web-specific needs."
  },
  {
    "Title": "A derandomization using min-wise independent permutations",
    "URL": "https://dl.acm.org/doi/10.1016/S1570-8667%2803%2900003-0",
    "Full Abstract": "Min-wise independence is a recently introduced notion of limited independence, similar in spirit to pairwise independence. The latter has proven essential for the derandomization of many algorithms. Here we show that approximate min-wise independence allows similar uses, by presenting a derandomization of the RNC algorithm for approximate set cover due to S. Rajagopalan and V. Vazirani. We also discuss how to derandomize their set multi-cover and multi-set multi-cover algorithms in restricted cases. The multi-cover case leads us to discuss the concept of"
  },
  {
    "Title": "Efficient URL caching for world wide web crawling",
    "URL": "https://dl.acm.org/doi/10.1145/775152.775247",
    "Full Abstract": "Crawling the web is deceptively simple: the basic algorithm is (a) Fetch a page (b) Parse it to extract all linked URLs (c) For all the URLs not seen before, repeat (a)-(c). However, the size of the web (estimated at over 4 billion pages) and its rate of change (estimated at 7% per week) move this plan from a trivial programming exercise to a serious algorithmic and system design challenge. Indeed, these two factors alone imply that for a reasonably fresh and complete crawl of the web, step (a) must be executed about a thousand times per second, and thus the membership test (c) must be done well over ten thousand times per second against a set too large to store in main memory. This requires a distributed architecture, which further complicates the membership test.A crucial way to speed up the test is to cache, that is, to store in main memory a (dynamic) subset of the \"seen\" URLs. The main goal of this paper is to carefully investigate several URL caching techniques for web crawling. We consider both practical algorithms: random replacement, static cache, LRU, and CLOCK, and theoretical limits: clairvoyant caching and infinite cache. We performed about 1,800 simulations using these algorithms with various cache sizes, using actual log data extracted from a massive 33 day web crawl that issued over one billion HTTP requests.Our main conclusion is that caching is very effective - in our setup, a cache of roughly 50,000 entries can achieve a hit rate of almost 80%. Interestingly, this cache size falls at a critical point: a substantially smaller cache is much less effective while a substantially larger cache brings little additional benefit. We conjecture that such critical points are inherent to our problem and venture an explanation for this phenomenon."
  },
  {
    "Title": "Keynote Address - exploring, modeling, and using the web graph",
    "URL": "https://dl.acm.org/doi/10.1145/860435.860436",
    "Full Abstract": "The Web graph, meaning the graph induced by Web pages as nodes and their hyperlinks as directed edges, has become a fascinating object of study for many people: physicists, sociologists, mathematicians, computer scientists, and information retrieval specialists.Recent results range from theoretical (e.g.: models for the graph, semi-external algorithms), to experimental (e.g.: new insights regarding the rate of change of pages, new data on the distribution of degrees), to practical (e.g.: improvements in crawling technology).Recent results range from theoretical (e.g.: models for the graph, semi-external algorithms), to experimental (e.g.: new insights regarding the rate of change of pages, new data on the distribution of degrees), to practical (e.g.: improvements in crawling technology).The goal of this talk is to convey an introduction to the state of the art in this area and to sketch the current issues in collecting, representing, analyzing, and modeling this graph. Although graph analytic methods are essential tools in the Web IR arsenal, they are well known to the SIGIR community and will not be discussed here in any detail; instead, we will explore some challenges and opportunities for using IR methods and techniques in the exploration of the Web graph, in particular in dealing with legitimate and \"spam\" perturbations of the \"natural\" process of birth and death of nodes and links, and conversely, the challenges and opportunities of using graph methods in support of IR on the Web and in the enterprise."
  },
  {
    "Title": "Using XML to query XML",
    "URL": "https://dl.acm.org/doi/10.5555/2816272.2816325",
    "Full Abstract": "A cornerstone concept in classical Information Retrieval is the vector space model, whereby both documents and queries are viewed as vectors in a multidimensional space. Relevance of a given document to a given query is determined by evaluating the similarity between these vectors, using a measure like the cosine measure of similarity, for instance. The vector space model has been highly successful for dealing with plain text collections, in both theoretical and practical terms. In prior work, we extended this classic approach to the search of XML collections by requiring queries to be presented as XML Fragments, which allows for a very simple extension of the cosine similarity measure to the XML framework."
  },
  {
    "Title": "Efficient query evaluation using a two-level retrieval process",
    "URL": "https://dl.acm.org/doi/10.1145/956863.956944",
    "Full Abstract": "We present an efficient query evaluation method based on a two level approach: at the first level, our method iterates in parallel over query term postings and identifies candidate documents using an"
  },
  {
    "Title": "Sic transit gloria telae",
    "URL": "https://dl.acm.org/doi/10.1145/988672.988716",
    "Full Abstract": "The rapid growth of the web has been noted and tracked extensively. Recent studies have however documented the dual phenomenon: web pages have small half lives, and thus the web exhibits rapid death as well. Consequently, page creators are faced with an increasingly burdensome task of keeping links up-to-date, and many are falling behind. In addition to just individual pages, collections of pages or even entire neighborhoods of the web exhibit significant"
  },
  {
    "Title": "Program Verification Using ADA",
    "URL": "https://dl.acm.org/doi/book/10.5555/539111",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Secure data replication over untrusted hosts",
    "URL": "https://dl.acm.org/doi/10.5555/1251054.1251075",
    "Full Abstract": "Data replication is a widely used technique for achieving fault tolerance and improved performance. With the advent of content delivery networks, it is becoming more and more frequent that data content is placed on hosts that are not directly controlled by the content owner, and because of this, security mechanisms to protect data integrity are necessary. In this paper we present a system architecture that allows arbitrary queries to be supported on data content replicated on untrusted servers. To prevent these servers from returning erroneous answers to client queries, we make use of a small number of trusted hosts that randomly check these answers and take corrective action whenever necessary. Additionally, our system employs an audit mechanism that guarantees that any untrusted server acting maliciously will eventually be detected and excluded from the system."
  },
  {
    "Title": "A Certificate Revocation Scheme for a Large-Scale Highly Replicated Distributed System",
    "URL": "https://dl.acm.org/doi/10.5555/839294.843438",
    "Full Abstract": "A common way to protect objects in distributed systemsis to issue authorization certificates to users, which theypresent to gain access. In some situations a way is needed torevoke existing certificates. Current methods, such as havinga master revocation list, have been designed to workefficiently with identity certificates, and do not take into accountthe delegation of certificate-issuing rights requiredwhen implementing complex administrative hierarchies forlarge distributed applications. In this paper we presenta novel mechanism for revoking authorization certificatesbased on clustering users and servers, and present argumentsshowing that it is more efficient than other methods.We also discuss a way for probabilistically auditingthe use of the revocation mechanism proposed to reduce thechances of any component behaving maliciously."
  },
  {
    "Title": "Redes de Computadoras",
    "URL": "https://dl.acm.org/doi/book/10.5555/996192",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Safe and private data sharing with turtle",
    "URL": "https://dl.acm.org/doi/10.1007/11861386_24",
    "Full Abstract": "In this paper we describe Turtle, a peer-to-peer architecture for safe sharing of sensitive data. The truly revolutionary aspect of Turtle rests in its novel way of dealing with trust issues: while existing peer-to-peer architectures with similar aims attempt to build trust relationships on top of the basic, trust-agnostic, peer-to-peer overlay, Turtle takes the opposite approach, and builds its overlay on top of pre-existent trust relationships among its users. This allows both data sender and receiver anonymity, while also protecting"
  },
  {
    "Title": "Sistemas Operativos Modernos",
    "URL": "https://dl.acm.org/doi/book/10.5555/1205752",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Support for multi-level security policies in DRM architectures",
    "URL": "https://dl.acm.org/doi/10.1145/1065907.1065909",
    "Full Abstract": "Digital rights management systems allow copyrighted content to be commercialized in digital format without the risk of revenue loss due to piracy. Making such systems secure is no easy task, given that content needs to be protected while accessed through electronic devices in the hands of potentially malicious end-users; in this context, intrusion tolerance becomes a very useful system property. In this paper we point out a limitation shared by all current DRM architectures, namely their weakness in reacting to possible device compromise and confining the damage caused by such a compromise. As a solution, we propose a paradigm shift - moving from the original DRM system model where all devices are equally trustworthy and have discretionary control over all protected content, to a new model where information flow is controlled through a multi-level security policy that differentiates between devices based on their tamper-resistance properties. We show that besides improved intrusion-tolerance, supporting such policies has other advantages, such as the ability to define more flexible business models for supplying content. We also show that for a given DRM architecture, the type authentication protocol used when accepting new devices in the system has a big impact on how well multi-level security policies can be supported, and that a number of protocols currently being considered are not very well suited for this job."
  },
  {
    "Title": "Keep on blockin' in the free world",
    "URL": "https://dl.acm.org/doi/10.5555/1802438.1802444",
    "Full Abstract": "This paper introduces an off-tag RFID access control mechanism called \"Selective RFID Jamming\". Selective RFID Jamming protects low-cost RFID tags by enforcing access control on their behalf, in a similar manner to the RFID Blocker Tag. However, Selective RFID Jamming is novel because it uses an active mobile device to enforce centralized ACL-based access control policies. Selective RFID Jamming also solves a Differential Signal Analysis attack to which the RFID Blocker Tag is susceptible."
  },
  {
    "Title": "Structured Computer Organization (5th Edition)",
    "URL": "https://dl.acm.org/doi/book/10.5555/1215402",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "How to incorporate revocation status information into the trust metrics for public-key certification",
    "URL": "https://dl.acm.org/doi/10.1145/1066677.1067037",
    "Full Abstract": "In a traditional PKI, the trust associated with a public key is expressed in binary either by 0 or 1. Alternatively, several authors have proposed trust metrics to evaluate the confidence afforded by a public key. However their work has a static point of view and does not take into account the issue of public key revocation. In this paper, we make the first attempt to incorporate the revocation status information into the trust metrics for public key certification. To achieve our goal, we use a tailored form of a vector of trust model recently proposed. This would allow us to reason formally about when there is a need to check revocation status and how reliable the revocation mechanism should be in a given security application."
  },
  {
    "Title": "RFID guardian",
    "URL": "https://dl.acm.org/doi/10.1007/11506157_16",
    "Full Abstract": "RFID tags are tiny, inexpensive, inductively powered computers that are going to replace bar codes on many products, but which have many other uses as well. For example, they will allow smart washing machines to check for incompatible clothes (e.g., white shirts and red socks) and smart refrigerators to check for milk that is too old to be consumed. Subdermal tags with medical information are already being implanted in animals and people. However, a world in which practically everything is tagged and can be read at a modest distance by anyone who wants to buy an RFID reader introduces serious security and privacy issues. For example, women walking down the street may be effectively broadcasting the sizes of their RFID-tagged bras and medical data without realizing it. To protect people in this environment, we propose developing a compact, portable, electronic device called an RFID Guardian, which people can carry with them. In the future, it could be integrated into PDAs or cell phones. The RFID Guardian looks for, records, and displays all RFID tags and scans in the vicinity, manages RFID keys, authenticates nearby RFID readers, and blocks attempted accesses to the user’s RFID tags from unauthorized readers. In this way, people can find out what RFID activity is occuring around them and take corrective action if need be."
  },
  {
    "Title": "Counting abuses using flexible off-line credentials",
    "URL": "https://dl.acm.org/doi/10.1007/11506157_46",
    "Full Abstract": "Mobile and ad-hoc networks allow businesses to provide a new range of applications and services and at the same time they introduce new constraints that have important effects on the way in which security primitives must be designed. This is challenging because it translates to a demand of richer and more flexible security primitives that often need to satisfy stricter requirements than traditional wired network scenarios. In this paper we focus on one of this primitive, namely security credentials. We present a solution that extends the existing protocols used to implement off-line credentials such that, not only abuses can be detected but they can also be counted. Our solution addresses the problem of 1-time and 2-times credentials and we will conclude by discussing the challenges that need to be solved to generalize the primitive to"
  },
  {
    "Title": "One-Time sensors",
    "URL": "https://dl.acm.org/doi/10.1007/11601494_7",
    "Full Abstract": "Dealing with captured nodes is generally accepted as the most difficult challenge to wireless sensor network security. By utilizing the low-cost property of sensor nodes, we introduce the novel concept of one-time sensors to mitigate node-capture attacks. The basic idea is to load each sensor with only one cryptographic token so that the captured node can inject only a single malicious message into the network. In addition, sybil attacks are avoided and explicit revocation is not necessary using one-time sensors. By using public key techniques, one-way hash functions and Merkle’s hash tree, we also show efficient implementations and interesting tradeoffs for one-time sensors."
  },
  {
    "Title": "Operating Systems Design and Implementation (3rd Edition)",
    "URL": "https://dl.acm.org/doi/book/10.5555/1076555",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Lectures on a Calculus for Communicating Systems",
    "URL": "https://dl.acm.org/doi/10.5555/646723.702732",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "A proposal for standard ML",
    "URL": "https://dl.acm.org/doi/10.1145/800055.802035",
    "Full Abstract": "Copyright © 1984 ACM."
  },
  {
    "Title": "Algebraic laws for nondeterminism and concurrency",
    "URL": "https://dl.acm.org/doi/10.1145/2455.2460",
    "Full Abstract": "Since a nondeterministic and concurrent program may, in general, communicate repeatedly with its environment, its meaning cannot be presented naturally as an input/output function (as is often done in the denotational approach to semantics). In this paper, an alternative is put forth. First, a definition is given of what it is for two programs or program parts to be equivalent for all observers; then two program parts are said to be"
  },
  {
    "Title": "The use of machines to assist in rigorous proof",
    "URL": "https://dl.acm.org/doi/10.5555/3721.3725",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Using algebra for concurrency: some approaches",
    "URL": "https://dl.acm.org/doi/10.5555/5010.5011",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Lectures on a calculus for communicating systems",
    "URL": "https://dl.acm.org/doi/10.5555/22086.22090",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Dialogue with a proof system",
    "URL": "https://dl.acm.org/doi/10.5555/29580.29599",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Enabling DRM-Preserving Digital Content Redistribution",
    "URL": "https://dl.acm.org/doi/10.1109/ICECT.2005.43",
    "Full Abstract": "Traditionally, the process of online digital content distribution has involved a limited number of centralised distributors selling protected contents and licenses authorising the use of these contents, to consumers. In this paper, we extend this model by introducing a security scheme that enables DRM preserving digital content redistribution. Essentially consumers can not only buy the rights to use digital content but also the rights to redistribute it to other consumers in a DRM controlled fashion. We examine the threats associated with such a redistribution model and explain how our scheme addresses them."
  },
  {
    "Title": "Lectures on a calculus for communicating systems",
    "URL": "https://dl.acm.org/doi/10.5555/58776.58781",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "A type discipline for Program modules",
    "URL": "https://dl.acm.org/doi/10.5555/67683.67703",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Dialogue with a Proof System",
    "URL": "https://dl.acm.org/doi/10.5555/646622.759379",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Verifying a Protocol Using Relativized Bisimulation",
    "URL": "https://dl.acm.org/doi/10.5555/646241.681247",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Verifying a protocol using relativized bisimulation",
    "URL": "https://dl.acm.org/doi/10.5555/29601.29612",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "A Type Discipline for Program Modules",
    "URL": "https://dl.acm.org/doi/10.5555/646623.698042",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Communication and Concurrency",
    "URL": "https://dl.acm.org/doi/book/10.5555/534666",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Communication and concurrency",
    "URL": "https://dl.acm.org/doi/book/10.5555/63446",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "A complete axiomatisation for observational congruence of finite-state behaviours",
    "URL": "https://dl.acm.org/doi/10.1016/0890-5401%2889%2990070-9",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "The complexity of stochastic games",
    "URL": "https://dl.acm.org/doi/10.1016/0890-5401%2892%2990048-K",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "A Theory of Strict P-completeness",
    "URL": "https://dl.acm.org/doi/10.5555/646508.694496",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "On games of incomplete information",
    "URL": "https://dl.acm.org/doi/10.1016/0304-3975%2892%2990085-T",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Functions as processes",
    "URL": "https://dl.acm.org/doi/10.5555/90397.90426",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Random walks on colored graphs",
    "URL": "https://dl.acm.org/doi/10.1002/rsa.3240050204",
    "Full Abstract": "We initiate a study of random walks on undirected graphs with colored edges. In our model, a sequence of colors is specified before the walk begins, and it dictates the color of edge to be followed at each step. We give tight upper and lower bounds on the expected cover time of a random walk on an undirected graph with colored edges. We show that, in general, graphs with two colors have exponential expected cover time, and graphs with three or more colors have doubly‐exponential expected cover time. We also give polynomial bounds on the expected cover time in a number of interesting special cases. We described applications of our results to understanding the dominant eigenvectors of products and weighted averages of stochastic matrices, and to problems on time‐inhomogeneous Markov chains. © 1994 John Wiley & Sons, Inc."
  },
  {
    "Title": "Probabilistically checkable debate systems and approximation algorithms for PSPACE-hard functions",
    "URL": "https://dl.acm.org/doi/10.1145/167088.167190",
    "Full Abstract": "Copyright © 1993 ACM."
  },
  {
    "Title": "Asynchronous analysis of parallel dynamic programming",
    "URL": "https://dl.acm.org/doi/10.1145/166955.167035",
    "Full Abstract": "We examine a very simple asynchronous model of parallel computation that assumes the time to compute a task is random, following some probability distribution. The goal of this model is to capture the effects of unexpected delays on processors."
  },
  {
    "Title": "On the power of finite automata with both nondeterministic and probabilistic states (preliminary version)",
    "URL": "https://dl.acm.org/doi/10.1145/195058.195431",
    "Full Abstract": "Copyright © 1994 ACM."
  },
  {
    "Title": "erratum to \"The small model property: How small can it be?\" [Inform. comput. 178(2002)279-293]",
    "URL": "https://dl.acm.org/doi/10.1016/S0890-5401%2803%2900117-2",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Synthesis revisited",
    "URL": "https://dl.acm.org/doi/10.5555/2137662.2137683",
    "Full Abstract": "Constructing a program from a specification is a long-known general and fundamental problem. Besides its theoretical interest, this question also has practical implications, since finding good synthesis algorithms could bring about a major improvement in the reliable development of complex systems. In this paper we describe a methodology for synthesizing statechart models from scenario-based requirements. The requirements are given in the language of live sequence charts (LSCs), and may be played in directly from the GUI, and the resulting statecharts are of the object-oriented variant, as adopted in the UML. We have implemented our algorithms as part of the Play-Engine tool and the generated statechart model can then be executed using existing UML case tools."
  },
  {
    "Title": "Abstraction for liveness",
    "URL": "https://dl.acm.org/doi/10.1007/978-3-540-30579-8_10",
    "Full Abstract": "Unlike model checking which is restricted to finite-state systems, there are two methods which can be applied for the verification of arbitrary infinite-state systems. These are the methods of"
  },
  {
    "Title": "Model checking and abstraction to the aid of parameterized systems (a survey)",
    "URL": "https://dl.acm.org/doi/10.1016/j.cl.2004.02.006",
    "Full Abstract": "Parameterized systems are systems that involve numerous instantiations of the same finite-state module, and depend on a parameter which defines their size. Examples of parameterized systems include sensor systems, telecommunication protocols, bus protocols, cache coherence protocols, and many other protocols that underly current state-of-the-art systems. Formal verification of parameterized systems is known to be undecidable (Inform. Process. Lett. 22 (6)) and thus cannot be automated. Recent research has shown that it is often the case that a combination of methodologies allows to reduce the problem of verification of a parameterized system into the problem of verification of a finite-state system, that can be automatically verified. This paper describes several recent methodologies, based on model checking and abstraction. We start with the method of invisible auxiliary assertions that combines a small-model theorem with heuristics to automatically generate auxiliary constructs used in proofs of correctness of parameterized systems. We also describe the method of counter abstraction that offers simple liveness proofs for many parameterized systems, and discuss novel methodologies of using counter abstraction to automatically verify that probabilistic parameterized system satisfy their temporal specifications with probability 1."
  },
  {
    "Title": "Shape analysis by predicate abstraction",
    "URL": "https://dl.acm.org/doi/10.1007/978-3-540-30579-8_12",
    "Full Abstract": "The paper presents an approach for shape analysis based on predicate abstraction. Using a predicate base that involves reachability relations between program variables pointing into the heap, we are able to analyze functional properties of programs with destructive heap updates, such as list reversal and various in-place list sorts. The approach allows verification of both safety and liveness properties. The abstraction we use does not require any abstract representation of the heap nodes (e.g. abstract shapes), only reachability relations between the program variables."
  },
  {
    "Title": "A compositional approach to CTL",
    "URL": "https://dl.acm.org/doi/10.1016/j.tcs.2004.09.023",
    "Full Abstract": "The paper presents a compositional approach to the verification of CTL"
  },
  {
    "Title": "Smart Play-Out Extended",
    "URL": "https://dl.acm.org/doi/10.5555/1018442.1022049",
    "Full Abstract": "Smart play-out is a powerful technique for executing live sequence charts (LSCs). It uses verification techniques to help run a program, rather than to prove properties thereof. In this paper we extend smart play-out to cover a larger set of the LSC language features and to deal more efficiently with larger models. The extensions cover two key features of the rich version of LSCs, namely, time and forbidden elements. The former is crucial for systems with time constraints and/or time-driven behavior, and the latter allows specifying invariants and contracts on behavior. Forbidden elements can also help reduce the state space considered, thus enabling smart play-out to handle larger models."
  },
  {
    "Title": "A discrete-time UML semantics for concurrency and communication in safety-critical applications",
    "URL": "https://dl.acm.org/doi/10.1016/j.scico.2004.05.012",
    "Full Abstract": "We define a subset krtUML of UML which is rich enough to express such modelling entities of UML, used in real-time applications, as active objects, dynamic object creation and destruction, dynamically changing communication topologies, combinations of synchronous and asynchronous communication, and shared memory usage through object attributes. We define a formal interleaving semantics for this kernel language by associating with each model"
  },
  {
    "Title": "Temporal logic for scenario-based specifications",
    "URL": "https://dl.acm.org/doi/10.1007/978-3-540-31980-1_29",
    "Full Abstract": "We provide semantics for the powerful scenario-based language of live sequence charts (LSCs). We show how the semantics of live sequence charts can be captured using temporal logic. This is done by studying various subsets of the LSC language and providing an explicit translation into temporal logic. We show how a kernel subset of the LSC language (which omits variables, for example) can be embedded within the temporal logic CTL"
  },
  {
    "Title": "Matching Schemas in Online Communities",
    "URL": "https://dl.acm.org/doi/10.1109/ICDE.2008.4497419",
    "Full Abstract": "When integrating data from multiple sources, a key task that online communities often face is to match the schemas of the data sources. Today, such matching often incurs a huge workload that overwhelms the relatively small set of volunteer integrators. In such cases, community members may not even volunteer to be integrators, due to the high workload, and consequently no integration systems can be built. To address this problem, we propose to enlist the multitude of users in the community to help match the schemas, in a Web 2.0 fashion. We discuss the challenges of this approach and provide initial solutions. Finally, we describe an extensive set of experiments on both real-world and synthetic data that demonstrate the utility of the approach."
  },
  {
    "Title": "Optimizing SQL Queries over Text Databases",
    "URL": "https://dl.acm.org/doi/10.1109/ICDE.2008.4497472",
    "Full Abstract": "Text documents often embed data that is structured in nature, and we can expose this structured data using information extraction technology. By processing a text database with information extraction systems, we can materialize a variety of structured \"relations,\" over which we can then issue regular SQL queries. A key challenge to process SQL queries in this text-based scenario is efficiency: information extraction is time-consuming, so query processing strategies should minimize the number of documents that they process. Another key challenge is result quality: in the traditional relational world, all correct execution strategies for a SQL query produce the same (correct) result; in contrast, a SQL query execution over a text database might produce answers that are not fully accurate or complete, for a number of reasons. To address these challenges, we study a family of select-project-join SQL queries over text databases, and characterize query processing strategies on their efficiency and - critically - on their result quality as well. We optimize the execution of SQL queries over text databases in a principled, cost-based manner, incorporating this tradeoff between efficiency and result quality in a user-specific fashion. Our large-scale experiments- over real data sets and multiple information extraction systems - show that our SQL query processing approach consistently picks appropriate execution strategies for the desired balance between efficiency and result quality."
  },
  {
    "Title": "Building Community Wikipedias",
    "URL": "https://dl.acm.org/doi/10.1109/ICDE.2008.4497473",
    "Full Abstract": "The rapid growth of Web communities has motivated many solutions for building community data portals. These solutions follow roughly two approaches. The first approach (e.g., Libra, Citeseer, Cimple) employs semi-automatic methods to extract and integrate data from a multitude of data sources. The second approach (e.g., Wikipedia, Intellipedia) deploys an initial portal in wiki format, then invites community members to revise and add material. In this paper we consider combining the above two approaches to building community portals. The new hybrid machine-human approach brings significant benefits. It can achieve broader and deeper coverage, provide more incentives for users to contribute, and keep the portal more up-to-date with less user effort. In a sense, it enables building \"community wikipedias\", backed by an underlying structured database that is continuously updated using automatic techniques. We outline our ideas for the new approach, describe its challenges and opportunities, and provide initial solutions. Finally, we describe a real-world implementation and preliminary experiments that demonstrate the utility of the new approach."
  }
]
