[
  {
    "Title": "Computing 2002",
    "URL": "https://dl.acm.org/doi/10.1145/543812.543816",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Approaching utopia",
    "URL": "https://dl.acm.org/doi/10.1145/2422436.2422463",
    "Full Abstract": "We introduce and study strongly truthful mechanisms and their applications. We use strongly truthful mechanisms as a tool for implementation in undominated strategies for several problems, including the design of externality resistant auctions and a variant of multi-dimensional scheduling."
  },
  {
    "Title": "Advances in Knowledge Discovery and Data Mining",
    "URL": "https://dl.acm.org/doi/book/10.5555/2821229",
    "Full Abstract": "This two-volume set, LNAI 9077 + 9078, constitutes the refereed proceedings of the 19th Pacific-Asia Conference on Advances in Knowledge Discovery and Data Mining, PAKDD 2015, held in Ho Chi Minh City, Vietnam, in May 2015.The proceedings contain 117 paper carefully reviewed and selected from 405 submissions. They have been organized in topical sections named: social networks and social media; classification; machine learning; applications; novel methods and algorithms; opinion mining and sentiment analysis; clustering; outlier and anomaly detection; mining uncertain and imprecise data; mining temporal and spatial data; feature extraction and selection; mining heterogeneous, high-dimensional and sequential data; entity resolution and topic-modeling; itemset and high-performance data mining; and recommendations."
  },
  {
    "Title": "The Beckman report on database research",
    "URL": "https://dl.acm.org/doi/10.1145/2845915",
    "Full Abstract": "Database researchers paint big data as a defining challenge. To make the most of the enormous opportunities at hand will require focusing on five research areas."
  },
  {
    "Title": "Competitive generalized auctions",
    "URL": "https://dl.acm.org/doi/10.1145/509907.509921",
    "Full Abstract": "We describe mechanisms for auctions that are simultaneously truthful (alternately known as strategy-proof or incentive compatible) and guarantee high \"net\" profit. We make use of appropriate variants of competitive analysis of algorithms in designing and analyzing our mechanisms. Thus, we do not require any probabilistic assumptions on bids.We present two new concepts regarding auctions, that of a cancellable auction and that of a generalized auction. We use cancellable auctions in the design of generalized auctions, but they are of independent interest as well. Cancellable auctions have the property that if the revenue collected does not meet certain predetermined criteria, then the auction can be cancelled and the resulting auction is still truthful. The trivial approach (run a truthful auction and cancel if needed) yields an auction that is not necessarily truthfu.Generalized auctions can be used to model many problems previously considered in the literature, as well as numerous new problems. In particular, we give the first truthful profit-maximizing auctions for problems such as conditional financing and multicast."
  },
  {
    "Title": "RAPID",
    "URL": "https://dl.acm.org/doi/10.1016/S0925-7721%2898%2900008-X",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Implementation of an interpreter for a parallel language in Centaur",
    "URL": "https://dl.acm.org/doi/10.5555/92011.92016",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "The CAP filing system",
    "URL": "https://dl.acm.org/doi/10.1145/800214.806542",
    "Full Abstract": "The filing system for the CAP is based on the idea of preservation of capabilities: if a program has been able to obtain some capability then it has an absolute right to preserve it for subsequent use. The pursuit of this principle, using capability-oriented mechanisms in preference to access control lists, has led to a filing system in which a preserved capability may be retrieved from different directories to achieve different access statuses, in which the significance of a text name depends on the directory to which it is presented, and in which filing system 'privilege' is expressed by possession of directory capabilities."
  },
  {
    "Title": "An asynchronous garbage collector for the CAP filing system",
    "URL": "https://dl.acm.org/doi/10.1145/775332.775338",
    "Full Abstract": "Copyright © 1978 Authors."
  },
  {
    "Title": "VeriPhy: verified controller executables from verified cyber-physical system models",
    "URL": "https://dl.acm.org/doi/10.1145/3192366.3192406",
    "Full Abstract": "We present VeriPhy, a verified pipeline which automatically transforms verified high-level models of safety-critical cyber-physical systems (CPSs) in differential dynamic logic (dL) to verified controller executables. VeriPhy proves that all safety results are preserved end-to-end as it bridges abstraction gaps, including: i) the gap between mathematical reals in physical models and machine arithmetic in the implementation, ii) the gap between real physics and its differential-equation models, and iii) the gap between nondeterministic controller models and machine code. VeriPhy reduces CPS safety to the faithfulness of the physical environment, which is checked at runtime by synthesized, verified monitors. We use three provers in this effort: KeYmaera X, HOL4, and Isabelle/HOL. To minimize the trusted base, we cross-verify KeYmaeraX in Isabelle/HOL. We evaluate the resulting controller and monitors on commodity robotics hardware."
  },
  {
    "Title": "The Claremont report on database research",
    "URL": "https://dl.acm.org/doi/10.1145/1516046.1516062",
    "Full Abstract": "Database research is expanding, with major efforts in system architecture, new languages, cloud services, mobile and virtual worlds, and interplay between structure and text."
  },
  {
    "Title": "Program Checkers for Probability Generation",
    "URL": "https://dl.acm.org/doi/10.5555/646245.684535",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Combining dimensionality and rate of growth arguments for establishing lower bounds on the number of multiplications",
    "URL": "https://dl.acm.org/doi/10.1145/800119.803912",
    "Full Abstract": "In this paper we describe a new method for establishing lower bounds for the number of multiplications and divisions required to compute rational functions. We shall start by reminding the reader of some standard notations."
  },
  {
    "Title": "COMBINING DIMENSIONALITY AND RATE OF GROWTH ARGUMENTS FOR ESTABLISHING LOWER BOUNDS ON THE NUMBER OF MULTIPLICATIONS",
    "URL": "https://dl.acm.org/doi/book/10.5555/889589",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Functions as Processes",
    "URL": "https://dl.acm.org/doi/10.5555/646244.684376",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Interpreting one concurrent calculus in another",
    "URL": "https://dl.acm.org/doi/10.1016/0304-3975%2890%2990059-Q",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Is Your Cat Infected with a Computer Virus?",
    "URL": "https://dl.acm.org/doi/10.1109/PERCOM.2006.32",
    "Full Abstract": "RFID systems as a whole are often treated with suspicion, but the input data received from individual RFID tags is implicitly trusted. RFID attacks are currently conceived as properly formatted but fake RFID data; however no one expects an RFID tag to send a SQL injection attack or a buffer overflow. This paper is meant to serve as a warning that data from RFID tags can be used to exploit back-end software systems. RFID middleware writers must therefore build appropriate checks (bounds checking, special character filtering, etc.), to prevent RFID middleware from suffering all of the well-known vulnerabilities experienced by the Internet. Furthermore, as a proof of concept, this paper presents the first self-replicating RFID virus. This virus uses RFID tags as a vector to compromise backend RFID middleware systems, via a SQL injection attack."
  },
  {
    "Title": "Can We Make Operating Systems Reliable and Secure?",
    "URL": "https://dl.acm.org/doi/10.1109/MC.2006.156",
    "Full Abstract": "Microkernels--long discarded as unacceptable because of their lower performance compared with monolithic kernels--might be making a comeback in operating systems due to their potentially higher reliability, which many researchers now regard as more important than performance."
  },
  {
    "Title": "WebIQ",
    "URL": "https://dl.acm.org/doi/10.1109/ICDE.2006.172",
    "Full Abstract": "Integrating Deep Web sources requires highly accurate semantic matches between the attributes of the source query interfaces. These matches are usually established by comparing the similarities of the attributes' labels and instances. However, attributes on query interfaces often have no or very few data instances. The pervasive lack of instances seriously reduces the accuracy of current matching techniques. To address this problem, we describe WebIQ, a solution that learns from both the Surface Web and the Deep Web to automatically discover instances for interface attributes. WebIQ extends question answering techniques commonly used in the AI community for this purpose. We describe how to incorporate WebIQ into current interface matching systems. Extensive experiments over five realworld domains show the utility ofWebIQ. In particular, the results show that acquired instances help improve matching accuracy from 89.5% F-1 to 97.5%, at only a modest runtime overhead."
  },
  {
    "Title": "On Parallel Computation for the Knapsack Problem",
    "URL": "https://dl.acm.org/doi/10.1145/322326.322342",
    "Full Abstract": "Copyright © 1982 ACM."
  },
  {
    "Title": "On the Average-Case Complexity of Selecting the ",
    "URL": "https://dl.acm.org/doi/10.1137/0211034",
    "Full Abstract": "Let $\\bar V_k (n)$ be the minimum average number of pairwise comparisons needed to find the"
  },
  {
    "Title": "Protocols for secure computations",
    "URL": "https://dl.acm.org/doi/10.5555/1382436.1382751",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Probabilistic Game Automata",
    "URL": "https://dl.acm.org/doi/10.5555/648296.754863",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Probabilistic game automata",
    "URL": "https://dl.acm.org/doi/10.5555/20284.20295",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Firing Squad",
    "URL": "https://dl.acm.org/doi/10.5555/647694.731341",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "A Security Architecture for Object-Based Distributed Systems",
    "URL": "https://dl.acm.org/doi/10.5555/784592.784804",
    "Full Abstract": "Large-scale distributed systems present numerous securityproblems not present in local systems. In this paperwe present a general security architecture for a large-scaleobject-based distributed system. Its main features includeways for servers to authenticate clients, clients to authenticateservers, new secure servers to be instantiated withoutmanual intervention, and ways to restrict which client canperform which operation on which object. All of these featuresare done in a platform- and application-independentway, so the results are quite general. The basic idea behindthe scheme is to have each object owner issue cryptographicallysealed certificates to users to prove which operationsthey may request and to servers to prove which operationsthey are authorized to execute. These certificates are usedto ensure secure binding and secure method invocation. Thepaper discusses the required certificates and security protocolsfor using them."
  },
  {
    "Title": "Enforcing security policies for distributed objects applications",
    "URL": "https://dl.acm.org/doi/10.1007/11542322_16",
    "Full Abstract": "In this paper we present the design and the implementation of a policy engine for enforcing security policies for distributed applications. Such policies, represented by using the RBAC model, include both how the distributed, shared and replicated objects are used, by mean of"
  },
  {
    "Title": "Building data integration systems",
    "URL": "https://dl.acm.org/doi/10.5555/3104278.3104314",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "A compact data structure for storing, retrieving and manipulating line drawings",
    "URL": "https://dl.acm.org/doi/10.1145/1465482.1465580",
    "Full Abstract": "The field of graphical man/machine interaction is customarily split into hardware and software areas. The former can be considered to have come of age: there are over twenty-five brands of off-the-shelf consoles with all the requisite input devices, and new techniques and improvements are constantly being developed. Many consoles are also provided with primitive supporting software which allow one to draw points, lines, arcs, etc., in a symbolic language of some sort. Less well understood and developed, however, is that aspect of display software concerned with representing and manipulating the problem model from which these primitive point/line/arc pictures are derived. The \"data structure\" is the machine representation of the often complex and hierarchical problem model. It must be judiciously derived from the model on the one hand and, on the other, lead readily to the reduced console display file of points, lines and arcs which cause the actual visual display. Furthermore, the data structure must be efficiently stored and processed (usually contradictory requirements)."
  },
  {
    "Title": "On the average-case complexity of selecting the k-th best",
    "URL": "https://dl.acm.org/doi/book/10.5555/892214",
    "Full Abstract": "Let ${\\bar{V_k$(n) be the minimum average number of pairwise comparisons needed to find the k-th largest of n numbers (k $\\leq$ 2), assuming that all n! orderings are equally likely. D. W. Matula proved that, for some absolute constant c, ${\\bar{V_k$(n)-n $\\leq$ c k log log n as n $\\rightarrow \\infty$. In the present paper, we show that there exists an absolute constant c' < 0 such that ${\\bar{V_k$(n)-n $\\leq$ c' k log log n as n $\\rightarrow \\infty$, proving a conjecture of Matula."
  },
  {
    "Title": "Some complexity questions related to distributive computing(Preliminary Report)",
    "URL": "https://dl.acm.org/doi/10.1145/800135.804414",
    "Full Abstract": "Let"
  },
  {
    "Title": "Should tables by sorted?",
    "URL": "https://dl.acm.org/doi/book/10.5555/892229",
    "Full Abstract": "We examine optimality questions in the following information retrieval problem: Given a set S of n keys, store them so that queries of the form \"Is x $\\in$ S?\" can be answered quickly. It is shown that, in a rather general model including al1 the commonly-used schemes, $\\lceil$ lg(n+l) $\\rceil$ probes to the table are needed in the worst case, provided the key space is sufficiently large. The effects of smaller key space and arbitrary encoding are also explored."
  },
  {
    "Title": "Completing the temporal picture",
    "URL": "https://dl.acm.org/doi/book/10.5555/892484",
    "Full Abstract": "The paper presents a relatively complete proof system for proving the validity of temporal properties of reactive programs. The presented proof system improves oll previous temporal systems, such as [MP83a] and [MP83b], in that it reduces the validity of program properties into pure assertional reasoning, not involving additional temporal reasoning. The proof system is based on the classification of temporal properties according to the Borel hierarchy, providing an appropriate proof rule for each of the main classes, such as safety, response, and progress properties."
  },
  {
    "Title": "The logical basis for computer programming: vol. 2, deductive systems",
    "URL": "https://dl.acm.org/doi/book/10.5555/78091",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "An algebraic definition of simulation between programs",
    "URL": "https://dl.acm.org/doi/book/10.5555/891902",
    "Full Abstract": "A simulation relation between programs is defined which is quasi-ordering. Mutual simulation is then an equivalence relation, and by dividing out by it we abstract from a program such details as how the sequencing is controlled and how data is represented. The equivalence classes are approxiamtions to the algorithms which are realized, or expressed, by their member programs. A technique is given and illustrated for proving simulation and equivalence of programs; there is an analogy with Floyd's technique for proving correctness of programs. Finally, necessary and sufficient conditions for simulation are given."
  },
  {
    "Title": "An algebraic definition of simulation between programs",
    "URL": "https://dl.acm.org/doi/10.5555/1622876.1622926",
    "Full Abstract": "A simulation relation between programs is defined which is a quasi-ordering. Mutual simulation is then an equivalence relation, and by dividing out by it we abstract from a program such details as how the sequencing is controlled and how data is represented. The equivalence classes are approximations to the algorithms which are realized, or expressed, by their member programs."
  },
  {
    "Title": "Implementation and applications of Scott's logic for computable functions",
    "URL": "https://dl.acm.org/doi/10.1145/800235.807067",
    "Full Abstract": "The basis for this paper is a logic designed by Dana Scott [1] in 1969 for formalizing arguments about computable functions of higher type. This logic uses typed combinators, and we give a more or less direct translation into typed λ-calculus, which is an easier formalism to use, though not so easy for the metatheory because of the presence of bound variables. We then describe, by example only, a proof-checker program which has been implemented for this logic; the program is fully described in [2]. We relate the induction rule which is central to the logic to two more familiar rules - Recursion Induction and Structural Induction - showing that the former is a theorem of the logic, and that for recursively defined structures the latter is a derived rule of the logic. Finally we show how the syntax and semantics of a simple programming language may be described completely in the logic, and we give an example of a theorem which relates syntactic and semantic properties of programs and which can be stated and proved within the logic."
  },
  {
    "Title": "Report on the seventh ACM SIGOPS European workshop",
    "URL": "https://dl.acm.org/doi/10.1145/254784.254787",
    "Full Abstract": "Copyright © 1997 Author."
  },
  {
    "Title": "Abstracting probabilistic actions",
    "URL": "https://dl.acm.org/doi/10.5555/2074394.2074429",
    "Full Abstract": "This paper discusses the problem of abstracting conditional probabilistic actions. We identify two distinct types of abstraction: intra-action abstraction and inter-action abstraction. We define what it means for the abstraction of an action to be correct and then derive two methods of intra-action abstraction and two methods of inter-action abstraction which are correct according to this criterion. We illustrate the developed techniques by applying them to actions described with the temporal action representation used in the DRIPS decision-theoretic planner and we describe how the planner uses abstraction to reduce the complexity of planning."
  },
  {
    "Title": "Efficient decision-theoretic planning",
    "URL": "https://dl.acm.org/doi/10.5555/2074158.2074184",
    "Full Abstract": "This paper discusses techniques for performing efficient decision-theoretic planning. We give an overview of the DRIPS decision-theoretic refinement planning system, which uses abstraction to efficiently identify optimal plans. We present techniques for automatically generating search control information, which can significantly improve the planner's performance. We evaluate the efficiency of DRIPS both with and without the search control rules on a complex medical planning problem and compare its performance to that of a branch-and-bound decision tree algorithm."
  },
  {
    "Title": "Experience with a regular expression compiler",
    "URL": "https://dl.acm.org/doi/book/10.5555/892299",
    "Full Abstract": "The language of regular expressions is a useful one for specifying certain sequebtial processes at a very high level. They allow easy modification of designs for circuits, like controllers, that are described by patterns of events they must recognize and the responses they must make to those patterns. This paper discusses the compilation of such expressions into reasonably compact layouts. The translation of regular expressions into nondeterministic automata by two different methods is discussed, along with the advantages of each method. A major part of the compilation problem is selection of good state codes for the nondeterministic automata; one successful strategy is explained in the paper."
  },
  {
    "Title": "Competitive snoopy caching",
    "URL": "https://dl.acm.org/doi/10.1109/SFCS.1986.14",
    "Full Abstract": "In a snoopy cache multiprocessor system, each processor has a cache in which it stores blocks of data. Each cache is connected to a bus used to communicate with the other caches and with main memory. For several of the proposed models of snoopy caching, we present new on-line algorithms which decide, for each cache, which blocks to retain and which to drop in order to minimize communication over the bus. We prove that, for any sequence of operations, our algorithms' communication costs are within a constant factor of the minimum required for that sequence; for some of our algorithms we prove that no on-line algorithm has this property with a smaller constant."
  },
  {
    "Title": "A study of concrete computational complexity.",
    "URL": "https://dl.acm.org/doi/book/10.5555/907570",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "On computing the minima of quadratic forms (Preliminary Report)",
    "URL": "https://dl.acm.org/doi/10.1145/800116.803749",
    "Full Abstract": "The following problem was recently raised by C. William Gear [1]: Let F(x"
  },
  {
    "Title": "Addition chains with multiplicative cost",
    "URL": "https://dl.acm.org/doi/book/10.5555/892092",
    "Full Abstract": "If each step in an addition chain is assigned a cost equal to the product of the numbers added at that step, \"binary\" addition chains are shown to minimize total cost."
  },
  {
    "Title": "Special relations in automated deduction",
    "URL": "https://dl.acm.org/doi/10.1145/4904.4905",
    "Full Abstract": "Two deduction rules are introduced to give streamlined treatment to relations of special importance in an automated theorem-proving system. These rules, the"
  },
  {
    "Title": "A timely resolution",
    "URL": "https://dl.acm.org/doi/book/10.5555/892378",
    "Full Abstract": "We present a novel proof system R for First-order (Linear) Temporal Logic. This system extends our Propositional Temporal Logic proof system ([AM]). The system R is based on nonclausal resolution; proofs are natural and generally short. Special quantifier rules, unification techniques, and a resolution rule are introduced. We relate R to other proof systems for First-order Temporal Logic and discuss completeness issues. The system R should be useful as a tool for such tasks as verification of concurrent programs and reasoning about hardware devices."
  },
  {
    "Title": "Model theorem proving",
    "URL": "https://dl.acm.org/doi/book/10.5555/892375",
    "Full Abstract": "We describe resolution proof systems for several modal logics. First we present the propositional versions of the systems and prove their completeness. The first-order resolution rule for classical logic is then modified to handle quantifiers directly. This new resolution rule enables us to extend our propositional systems to complete first-order systems. The systems for the different modal logics are closely related."
  },
  {
    "Title": "How to Clear a Block",
    "URL": "https://dl.acm.org/doi/10.5555/648227.749317",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Modal Theorem Proving",
    "URL": "https://dl.acm.org/doi/10.5555/648227.751971",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "A deductive approach to program synthesis",
    "URL": "https://dl.acm.org/doi/10.5555/31870.31871",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Finding hidden Hamiltonian cycles",
    "URL": "https://dl.acm.org/doi/10.1145/103418.103442",
    "Full Abstract": "Copyright © 1991 ACM."
  },
  {
    "Title": "Existence and construction of edge disjoint paths on expander graphs",
    "URL": "https://dl.acm.org/doi/10.1145/129712.129727",
    "Full Abstract": "Copyright © 1992 ACM."
  },
  {
    "Title": "Near-perfect Token Distribution",
    "URL": "https://dl.acm.org/doi/10.5555/646246.684721",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "On the satisfiability and maximum satisfiability of random 3-CNF formulas",
    "URL": "https://dl.acm.org/doi/10.5555/313559.313794",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Scheduling Unit-Time Tasks with Limited Resources",
    "URL": "https://dl.acm.org/doi/10.5555/647406.724133",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "On-line choice of on-line algorithms",
    "URL": "https://dl.acm.org/doi/10.5555/313559.313847",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "On the problem of approximating the number of bases of a matroid",
    "URL": "https://dl.acm.org/doi/10.1016/0020-0190%2894%2990037-X",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Existence and Construction of Edge-Disjoint Pathson Expander Graphs",
    "URL": "https://dl.acm.org/doi/10.1137/S0097539792232021",
    "Full Abstract": "Given an expander graph $G=(V,E)$ and a set of $q$ disjoint pairs of vertices in $V$, the authors are interested in finding for each pair $(a_i, b_i)$ a path connecting $a_i$ to $b_i$ such that the set of $q$ paths so found is edge disjoint. (For general graphs the related decision problem is NP complete.)"
  },
  {
    "Title": "A hardware semantics based on temporal intervals",
    "URL": "https://dl.acm.org/doi/book/10.5555/892293",
    "Full Abstract": "We present an interval-based temporal logic that permits the rigorous specification of a variety of hardware components and facilitates describing properties such as correctness of implementation. Conceptual levels of circuit operation ranging from detailed quantitative timing and signal propagation up to functional behavior are integrated in a unified way. After giving some motivation for reasoning about hardware, we present the propositional and first-order syntax and semantics of the temporal logic. In addition we illustrate techniques for describing signal transitions as well as for formally specifying and comparing a number of delay models. Throughout the discussion, the formalism provides a means for examining such concepts as device equivalence and internal states."
  },
  {
    "Title": "Proving precedence properties: the temporal way",
    "URL": "https://dl.acm.org/doi/book/10.5555/892294",
    "Full Abstract": "This paper explores the three important classes of temporal properties of concurrent programs: invariance, liveness and precedence. It presents the first methodological approach to the precedence properties, while providing a review of the invariance and liveness properties. The approach is based on the 'unless' operator, which is a weak version of the 'until' operator. For each class of properties, we present a single complete proof principle. Finally, we show that the properties of each class are decidable over finite state programs."
  },
  {
    "Title": "Verification of concurrent programs: a temporal proof system",
    "URL": "https://dl.acm.org/doi/book/10.5555/892296",
    "Full Abstract": "A proof system based on temporal logic is presented for proving properties of concurrent programs based on the shared-variables computation model. The system consists of three parts: the general uninterpreted part, the domain dependent part and the program dependent part. In the general part we give a complete proof system for first-order temporal logic with detailed proofs of useful theorems. This logic enables reasoning about general time sequences. The domain dependent part characterizes the special properties of the domain over which the program operates. The program dependent part introduces program axioms which restrict the time sequences considered to be execution sequences of a given program. The utility of the full system is demonstrated by proving invariance, liveness and precedence properties of several concurrent programs. Derived proof principles for these classes of properties are obtained and lead to a compact representation of proofs."
  },
  {
    "Title": "Reasoning in Interval Temporal Logic",
    "URL": "https://dl.acm.org/doi/10.5555/648064.747582",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Reasoning in interval temporal logic",
    "URL": "https://dl.acm.org/doi/book/10.5555/892297",
    "Full Abstract": "Predicate logic is a powerful and general descriptive formalism with a long history of development. However, since the logic's underlying semantics have no notion of time, statements such as \"I increases by 2\" cannot be directly expressed. We discuss interval temporal logic (ITL), a formalism that augments standard predicate logic with operators for time-dependent concepts. Our earlier work used ITL to specify and reason about hardware. In this paper we show how ITL can also directly capture various control structures found in conventional programming languages. Constructs are given for treating assignment, iteration, sequential and parallel computations and scoping. The techniques used permit specification and reasoning about such algorithms as concurrent Quicksort. We compare ITL with the logic-based programming languages Lucid and Prolog."
  },
  {
    "Title": "A Hardware Semantics Based on Temporal Intervals",
    "URL": "https://dl.acm.org/doi/10.5555/646237.683015",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Proving Precedence Properties",
    "URL": "https://dl.acm.org/doi/10.5555/646237.683020",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "The r-Stirling numbers",
    "URL": "https://dl.acm.org/doi/book/10.5555/892285",
    "Full Abstract": "The r-Stirling numbers of the first and second kind count restricted permutations and respectively restricted partitions, the restriction being that the first r elements must be in distinct cycles and respectively distinct subsets. The combinatorial and algebraic properties of these numbers, which is most cases generalize similar properties of the regular Stirling numbers, are explored starting from the above definition."
  },
  {
    "Title": "Efficient fault tolerant routings in networks",
    "URL": "https://dl.acm.org/doi/10.1145/800057.808724",
    "Full Abstract": "We analyze the problem of constructing a network which will have a fixed routing and which will be highly fault tolerant. A construction is presented which forms a “product route graph” from two or more constituent “route graphs.” The analysis involves the"
  },
  {
    "Title": "A provably secure polynomial approximation scheme for the distributed lottery problem (extended abstract)",
    "URL": "https://dl.acm.org/doi/10.1145/323596.323608",
    "Full Abstract": "Copyright © 1985 ACM."
  },
  {
    "Title": "Efficient fault-tolerant routings in networks",
    "URL": "https://dl.acm.org/doi/10.1016/0890-5401%2887%2990063-0",
    "Full Abstract": "We analyze the problem of constructing a network with a given number of nodes which has a fixed routing and which is highly fault tolerant. A construction is presented which forms a “product route graph” from two or more constituent “route graphs.” The analysis involves the"
  },
  {
    "Title": "On the second eigenvalue of random regular graphs",
    "URL": "https://dl.acm.org/doi/10.1109/SFCS.1987.45",
    "Full Abstract": "Expanders have many applications in Computer Science. It is known that random d-regular graphs are very efficient expanders, almost surely. However, checking whether a particular graph is a good expander is co-NP-complete. We show that the second eigenvalue of d-regular graphs, λ2, is concentrated in an interval of width O(√d) around its mean, and that its mean is O(d3/4). The result holds under various models for random d-regular graphs. As a consequence a random d-regular graph on n vertices, is, with high probability a certifiable efficient expander for n sufficiently large. The bound on the width of the interval is derived from martingale theory and the bound on E(λ2) is obtained by exploring the properties of random walks in random graphs."
  },
  {
    "Title": "On Generating Solved Instances of Computational Problems",
    "URL": "https://dl.acm.org/doi/10.5555/646753.704892",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "The cost distribution of clustering in random probing",
    "URL": "https://dl.acm.org/doi/10.1145/77600.77619",
    "Full Abstract": "A new approach to the analysis of random probing hashing algorithms is presented. The probability-generating function in closed form for the asymptotic cost of insertion via random probing with secondary clustering is derived. For higher-order clustering, it is shown that all the moments of the probability distribution of the insertion cost exist and are asymptotically equal to the corresponding moments of the cost distribution under uniform hashing. The method in this paper also leads to simple derivations for the expected cost of insertion for random probing with secondary and higher-order clustering."
  },
  {
    "Title": "A UNIX clone with source code for operating systems courses",
    "URL": "https://dl.acm.org/doi/10.1145/24592.24596",
    "Full Abstract": "Copyright © 1987 Author."
  },
  {
    "Title": "Structured programming with recursion",
    "URL": "https://dl.acm.org/doi/book/10.5555/892162",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Is “sometime” sometimes better than “always”?",
    "URL": "https://dl.acm.org/doi/10.1145/359340.359353",
    "Full Abstract": "This paper explores a technique for proving the correctness and termination of programs simultaneously. This approach, the"
  },
  {
    "Title": "Proving termination and multiset orderings",
    "URL": "https://dl.acm.org/doi/book/10.5555/892168",
    "Full Abstract": "A common tool for proving the termination of programs is the well-founded set, a set ordered in such a way as to admit no infinite descending sequences. The basic approach is to find a termination function that maps the elements of the program into some well-founded set, such that the value of the termination function is continually reduced throughout the computation. All too often, the termination functions required are difficult to find and are of a complexity out of proportion to the program under consideration. However, by providing more sophisticated well-founded sets, the corresponding termination functions can be simplified. Given a well-founded set S, we consider multisets over S, \"sets\" that admit multiple occurrences of elements taken from S. We define an ordering on all finite multisets over S that is induced by the given ordering on S. This multiset ordering is shown to be well-founded. The value of the multiset ordering is that it permits the use of relatively simple and intuitive termination functions in otherwise difficult termination proofs. In particular, we apply the multiset ordering to provide simple proofs of the termination of production systems, programs defined in terms of sets of rewriting rules."
  },
  {
    "Title": "Inference rules for program annotation",
    "URL": "https://dl.acm.org/doi/10.5555/800099.803206",
    "Full Abstract": "Methods are presented whereby an Algol-like program, given together with its specifications, can be documented automatically. The program is incrementally annotated with invariant relationships that hold between program variables at intermediate points in the program and explain the actual workings of the program regardless of whether the program is correct. Thus this documentation can be used for proving the correctness of the program or may serve as an aid in the debugging of an incorrect program."
  },
  {
    "Title": "The synthesis of structure-changing programs",
    "URL": "https://dl.acm.org/doi/10.5555/800099.803208",
    "Full Abstract": "Deductive techniques are presented for deriving programs systematically from given specifications. The specifications express the purpose of the desired program without giving any hint of the algorithm to be employed. The desired program is intended to achieve this purpose by means of such low-level primitives as assignment statements, the conditional statements, and recursion. The basic approach is to transform the specifications repeatedly according to certain rules, until a satisfactory program is produced. The rules are guided by a number of strategic controls."
  },
  {
    "Title": "A deductive approach to program synthesis",
    "URL": "https://dl.acm.org/doi/book/10.5555/892190",
    "Full Abstract": "Program synthesis is the systematic derivation of a program from a given specification. A deductive approach to program synthesis is presented for the construction of recursive programs. This approach regards program synthesis as a theorem-proving task and relies on a theorem-proving method that combines the features of transformation rules, unification, and mathematical induction within a single framework."
  },
  {
    "Title": "The translation of 'go to' programs to 'while' programs",
    "URL": "https://dl.acm.org/doi/10.5555/1241515.1241521",
    "Full Abstract": "Some of the papers presented in this book already have been widely circulated; others were published in well-known journals, like IBM Systems Journal but largely were ignored when they first appeared; and then there are the obscure papers like this one by Ashcroft and Manna, which was presented at the 1971 IFIP Conference in Ljubljana, Yugoslavia. It's not that the ideas in the paper are obscure -- it's just that very few people in the mainstream EDP community attended the Conference, and precious few copies of the conference proceedings ever found their way into American libraries. It is, however, a paper that many people over the years have wanted to read, particularly since it deals with a subject also mentioned by Knuth (\"Structured Programming with go to State, ments\" [see Paper 20]), Wulf (\"A Case Against the GOTO\" [Paper 8]), and Böm and Jacopini (\"Flow Diagrams, Turing Machines and Languages with Only Two Formation Rules\" [Paper 2])."
  },
  {
    "Title": "The Modal Logic of Programs",
    "URL": "https://dl.acm.org/doi/10.5555/646233.682234",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Proving termination with Multiset Orderings",
    "URL": "https://dl.acm.org/doi/10.5555/646233.682248",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Proving termination with multiset orderings",
    "URL": "https://dl.acm.org/doi/10.1145/359138.359142",
    "Full Abstract": "A common tool for proving the termination of programs is the"
  },
  {
    "Title": "A deductive approach to program synthesis",
    "URL": "https://dl.acm.org/doi/10.5555/1624861.1624985",
    "Full Abstract": "Program synthesis is the systematic derivation of a program from a given specification. A deductive approach to program synthesis is presented for the construction of recursive programs. This approach regards program synthesis as a theorem-proving task and relies on a theorem-proving method that combines the features of transformation rules, unification, and mathematical induction within a single framework."
  },
  {
    "Title": "A Deductive Approach to Program Synthesis",
    "URL": "https://dl.acm.org/doi/10.1145/357084.357090",
    "Full Abstract": "Program synthesis is the systematic derivation of a program from a given specification. A deductive approach to program synthesis is presented for the construction of recursive programs. This approach regards program synthesis as a theorem-proving task and relies on a theorem-proving method that combines the features of transformation rules, unification, and mathematical induction within a single framework."
  },
  {
    "Title": "Synchronous schemes and their decision problems",
    "URL": "https://dl.acm.org/doi/10.1145/567446.567453",
    "Full Abstract": "A class of schemes called synchronous schemes is defined. A synchronous scheme can have several variables, but all the active ones are required to keep a synchronized rate of computation as measured by the height of their respective Herbrand values. A \"reset\" statement, which causes all the variables to restart a new computation, is admitted. It is shown that equivalence, convergence, and other properties are decidable for schemes in this class. The class of synchronous schemes contains, as special cases, the known decidable classes of Ianov schemes, one-variable schemes with resets, and progressive schemes."
  },
  {
    "Title": "Problematic features of programming languages: a situational-calculus approach",
    "URL": "https://dl.acm.org/doi/book/10.5555/892247",
    "Full Abstract": "Certain features of programming languages, such as data structure operations and procedure call mechanisms, have been found to resist formalization by classical techniques. An alternate approach is presented, based on a \"situational calculus,\" which makes explicit reference to the states of a computation. For each state, a distinction is drawn between an expression, its value, and the location of the value. Within this conceptual framework, the features of a programming language can be described axiomatically. Programs in the language can then be synthesized, executed, verified, or transformed by performing deductions in this axiomatic system. Properties of entire classes of programs, and of programming languages, can also be expressed and proved in this way. The approach is amenable to machine implementation. In a situational-calculus formalism it is possible to model precisely many \"problematic\" features of programming langauges, including operations on such data structures as arrays, pointers, lists, and records, and such procedure call mechanisms as call-by-reference, call-by-value, and call-by-name. No particular obstacle is presented by aliasing between variables, by declarations, or by recursive procedures. The paper is divided into three parts, focusing respectively on the assignment statement, on data structure operations, and on procedure call mechanisms. In this first part, we introduce the conceptual framework to be applied throughout and present the axiomatic definition of the assignment statement. If suitable restrictions on the programming language are imposed, the well-known Hoare assignment axiom can then be proved as a theorem. However, our definition can also describe the assignment statement of unrestricted programming languages, for which the Hoare axiom does not hold."
  },
  {
    "Title": "The temporal logic of branching time",
    "URL": "https://dl.acm.org/doi/10.1145/567532.567551",
    "Full Abstract": "A temporal language and system are presented which are based on branching time structure. By the introduction of symmetrically dual sets of temporal operators, it is possible to discuss properties which hold either along one path or along all paths. Consequently it is possible to express in this system all the properties that were previously expressible in linear time or branching time systems. We present an exponential decision procedure for satisfiability in the language based on tableaux methods, and a complete deduction system. As associated temporal semantics is illustrated for both structured and graph representation of programs."
  },
  {
    "Title": "Towards automatic debugging of programs",
    "URL": "https://dl.acm.org/doi/10.1145/390016.808434",
    "Full Abstract": "We present the germ of an idea for automatically correcting logical errors in programs by manipulating the invariants of the program. An invariant tree is defined, and we show how it can be used to change the program in order to guarantee correctness."
  },
  {
    "Title": "The optimal fixedpoint of recursive programs",
    "URL": "https://dl.acm.org/doi/10.1145/800116.803769",
    "Full Abstract": "In this paper a new fixedpoint approach towards the semantics of recursive programs is presented. The fixedpoint defined by a recursive program under this semantics contains, in some sense, the maximal amount of “interesting” information which can be extracted from the program. This optimal fixedpoint (which always uniquely exists) may be strictly more defined than the program's least fixedpoint. We consider both the theoretical and the computational aspects of the approach, as well as some techniques for proving properties of the optimal fixedpoint of a given recursive program."
  },
  {
    "Title": "Translating Program Schemas to While-Schemas",
    "URL": "https://dl.acm.org/doi/10.1137/0204011",
    "Full Abstract": "While-schemas are defined as program schemas without goto statements, in which iteration is achieved using while statements. We present two translations of program schemas into equivalent while-schemas, the first one by adding extra program variables, and the second one by adding extra logical variables. In both cases we aim to preserve as much of the structure of the original program schemas as possible."
  },
  {
    "Title": "Knowledge and reasoning in program synthesis",
    "URL": "https://dl.acm.org/doi/10.5555/1624626.1624670",
    "Full Abstract": "Prograin synthesis is the construction of a computer program from given specifications. An automatic program synthesis system must combine reasoning and programming ability with a good deal of knowledge about the subject matter of the program. This ability and knowledge must be manifested both procedurally (by programs) and structurally (by choice of representation)."
  },
  {
    "Title": "A new approach to recursive programs.",
    "URL": "https://dl.acm.org/doi/book/10.5555/892089",
    "Full Abstract": "In this paper we critically evaluate the classical least-fixedpoint approach towards recursive programs. We suggest a new approach which extracts the maximal amount of valuable information embedded in the programs. The presentation is informal, with emphasis on examples."
  },
  {
    "Title": "The theoretical aspects of the optimal fixedpoint",
    "URL": "https://dl.acm.org/doi/book/10.5555/892093",
    "Full Abstract": "In thls paper we define a new type of fixedpoint of recursive definitions and investigate some of its properties. This optimal fixedpoint (which always uniquely exists) contains, in some sense, the maximal amount of \"interesting\" information which can be extracted from the recursive definition, and it may be strictly more defined than the program's least fixedpoint. This fixedpoint can be the basis for assigning a new semantics to recursive programs. This is a modified and extended version of part 1 of a paper presented at the Symposium on Theory of Computing, Albuquerque, New Mexico (May 1975)."
  },
  {
    "Title": "Logical analysis of programs",
    "URL": "https://dl.acm.org/doi/10.1145/360032.360048",
    "Full Abstract": "Most present systems for verification of computer programs are incomplete in that intermediate inductive assertions must be provided manually by the user, termination is not proven, and incorrect programs are not treated. As a unified solution to these problems, this paper suggests conducting a logical analysis of programs by using invariants which express what is actually occurring in the program."
  },
  {
    "Title": "The Theoretical Aspects of the Optimal Fixedpoint",
    "URL": "https://dl.acm.org/doi/10.1137/0205033",
    "Full Abstract": "In this paper we define a new type of fixedpoint of recursive definitions and investigate some of its properties. This optimal fixedpoint (which always uniquely exists) contains, in some sense, the maximal amount of “interesting” information which can be extracted from the recursive definition, and it may be strictly more defined than the program’s least fixedpoint. This fixedpoint can be the basis for assigning a new semantics to recursive programs."
  },
  {
    "Title": "Is “sometime” sometimes better than “always”?",
    "URL": "https://dl.acm.org/doi/10.5555/800253.807645",
    "Full Abstract": "This paper explores a technique for proving the correctness and termination of programs simultaneously. This approach, which we call the"
  },
  {
    "Title": "The evolution of programs: a system for automatic program modification",
    "URL": "https://dl.acm.org/doi/book/10.5555/892128",
    "Full Abstract": "An attempt is made to formulate techniques of program modification, whereby a program that achieves one result can be transformed into a new program that uses the same principles to achieve a different goal. For example, a program that uses the binary search paradigm to calculate the square-root of a number may be modified to divide two numbers in a similar manner, or vice versa. Program debugging is considered as a special case of modification: if a program computes wrong results, it must be modified to achieve the intended results. The application of abstract program schemata to concrete problems is also viewed from the perspective of modification techniques. We have embedded this approach in a running implementation; our methods are illustrated with several examples that have been performed by it."
  },
  {
    "Title": "Studies in Automatic Programming Logic",
    "URL": "https://dl.acm.org/doi/book/10.5555/578683",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Studies in Automatic Programming Logic",
    "URL": "https://dl.acm.org/doi/book/10.5555/578684",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "The evolution of programs",
    "URL": "https://dl.acm.org/doi/10.1145/512950.512964",
    "Full Abstract": "A programmer spends more time modifying already existing programs than constructing original ones. An attempt is made to formulate techniques of program modification, whereby a program that achieves one result can be transformed into a new program that uses the same principles to achieve a different goal. For example, a program that uses the binary search paradigm to divide two numbers may be modified to calculate the square-root of a number in a similar manner.Program debugging is considered as a special case of modification if a program computers wrong results, it must be modified to achieve the intended results The application of abstract program schemata to concrete problems is also viewed from the perspective of modification techniques.We, have embedded this approach in a running implementation; our methods are illustrated with several examples that have been performed by it."
  },
  {
    "Title": "Is \"sometime\" sometimes better than \"always\"? Intermittent assertions in proving program correctness",
    "URL": "https://dl.acm.org/doi/book/10.5555/892103",
    "Full Abstract": "This paper explores a technique for proving the correctness and termination of programs simultaneously. This approach, which we call the intermittent-assertion method, involves documenting the program with assertions that must be true at some time when control passes through the corresponding point, but that need not be true every time. The method, introduced by Burstall, promises to provide a valuable complement to the more conventional methods. We first introduce the intermittent-assertion method with a number of examples of correctness and termination proofs. Some of these proofs are markedly simpler than their conventional counterparts. On the other hand, we show that a proof of correctness or termination by any of the conventional techniques can be rephrased directly as a proof using intermittent assertions. Finally, we show how the intermittent assertion method can be applied to prove the validity of program transformations and the correctness of continuously operating programs. This is a revised and simplified version of a previous paper with the same title (AIM-281, June 1976)."
  },
  {
    "Title": "The convergence of functions to fixedpoints of recursive definitions",
    "URL": "https://dl.acm.org/doi/book/10.5555/892143",
    "Full Abstract": "The classical method for constructing the least fixedpoint of a recursive definition is to generate a sequence of functions whose initial element is the totally undefined function and which converges to the desired least fixedpoint. This method, due to Kleene, cannot be generalized to allow the construction of other fixedpoints. In this paper we present an alternate definition of convergence and a new fixedpoint access method of generating sequences of functions for a given recursive definition. The initial function of the sequence can be an arbitrary function, and the sequence will always converge to a fixedpoint that is \"close\" to the initial function. This defines a monotonic mapping from the set of partial functions onto the set of all fixedpoints of the given recursive definition."
  },
  {
    "Title": "The people's time sharing system",
    "URL": "https://dl.acm.org/doi/10.1002/spe.4380030204",
    "Full Abstract": "A set of programs running under a multiprogramming batch operating system on the CDC 6600 which provide remote users with a time sharing service is described. The basis for the system is the ability of a user program to create job control statements during execution, thereby tricking the operating system into treating it as an ordinary batch job. The text editor and the interactive debugging facilities are described. The performance of the system, known as the People's Time Sharing System (PTSS), and user reaction to it are also described."
  },
  {
    "Title": "Formalization of Properties of Functional Programs",
    "URL": "https://dl.acm.org/doi/10.1145/321592.321606",
    "Full Abstract": "The problems of convergence, correctness, and equivalence of computer programs can be formulated by means of the satisfiability or validity of certain first-order formulas. An algorithm is presented for constructing such formulas for functional programs, i.e. programs defined by LISP-like conditional recursive expressions."
  },
  {
    "Title": "Towards automatic program synthesis",
    "URL": "https://dl.acm.org/doi/book/10.5555/891872",
    "Full Abstract": "An elementary outline of the theorem-proving approach to automatic program synthesis is given, without dwelling on technical details. The method is illustrated by the automatic construction of both recursive and iterative programs operating on natural numbers, lists, and trees. In order to construct a program satisfying certain specifications, a theorem induced by those specifications is proved, and the desired program is extracted from the proof. The same technique is applied to transform recursively defined functions into iterative programs, frequently with a major gain in efficiency. It is emphasized that in order to construct a program with loops or with recursion, the principle of mathematical induction must be applied. The relation between the version of the induction rule used and the form of the program constructed is explored in some detail."
  },
  {
    "Title": "The translation of ''go to'' programs to ''while'' programs",
    "URL": "https://dl.acm.org/doi/book/10.5555/891881",
    "Full Abstract": "In this paper we show that every flowchart program can be written without go to$ statements by using while$ statements. The main idea is to introduce new variables to preserve the values of certain variables at particular points in the program; or alternatively, to introduce special boolean variables to keep information about the course of the computation. The 'while' programs produced yield the same final results as the original flowchart program but need not perform computations in exactly the same way. However, the new programs do preserve the 'topology' of the original flowchart program, and are of the same order of efficiency. We also show that this cannot be done in general without adding variables."
  },
  {
    "Title": "Toward automatic program synthesis",
    "URL": "https://dl.acm.org/doi/10.1145/362566.362568",
    "Full Abstract": "An elementary outline of the theorem-proving approach to automatic program synthesis is given, without dwelling on technical details. The method is illustrated by the automatic construction of both recursive and iterative programs operating on natural numbers, lists, and trees."
  },
  {
    "Title": "Decidable properties of monadic functional schemas",
    "URL": "https://dl.acm.org/doi/book/10.5555/891910",
    "Full Abstract": "We define a class of (monadic) functional schemas which properly includes 'Ianov' flowchart schemas. We show that the termination, divergence and freedom problems for functional schemas are decidable. Although it is possible to translate a large class of non-free functional schemas into equivalent free functional schemas, we show that this cannot be done in general. We show also that the equivalence problem for free functional schemas is decidable. Most of the results are obtained from well-known results in Formal Languages and Automata Theory."
  },
  {
    "Title": "Computation of recursive programs",
    "URL": "https://dl.acm.org/doi/10.1145/1478873.1478902",
    "Full Abstract": "This note is actually an informal exposition of a part of a recent paper by Manna, Ness and Vuillemin. We have two main purposes in this note. First, we present some known results about computation of recursive programs, emphasizing some differences between the theoretical and practical approaches. Second, we introduce the computational induction method for proving properties of recursive programs. It turns out that most known methods for proving properties of programs are very closely related to the computational induction method. We illustrate this point by showing how Floyd's inductive assertions method for proving properties of \"flowchart programs\" can be expressed in terms of computational induction on recursive programs."
  },
  {
    "Title": "Program schemas with equality",
    "URL": "https://dl.acm.org/doi/book/10.5555/891927",
    "Full Abstract": "We discuss the class of program schemas augmented with equality tests, that is, tests of equality between terms. In the first part of the paper we discuss and illustrate the \"power\" of equality tests. It turns out that the class of program schemas with equality is more powerful than the \"maximal\" classes of schemas suggested by other investigators. In the second part of the paper we discuss the decision problems of program schemas with equality. It is shown for example that while the decision problems normally considered for schemas (such as halting, divergence, equivalence, isomorphism and freedom) are solvable for Ianov schemas, they all become unsolvable if general equality tests are added. We suggest, however, limited equality tests which can be added to certain subclasses of program schemas while preserving their solvable properties."
  },
  {
    "Title": "Recursive definitions of partial functions and their computations",
    "URL": "https://dl.acm.org/doi/10.1145/942578.807072",
    "Full Abstract": "The object of this paper is to present a syntactic and semantic model for recursive definitions, and to study the relation between their computed functions and their fixpoints. The recursive definitions that we consider are syntactic generalizations of those introduced in [2] by Kleene and in [5] by McCarthy."
  },
  {
    "Title": "Inductive methods for proving properties of programs",
    "URL": "https://dl.acm.org/doi/10.1145/942580.807070",
    "Full Abstract": "We have two main purposes in this paper. First, we clarify and extend known results about computation of recursive programs, emphasizing the difference between the theoretical and practical approaches. Secondly, we present and examine various known methods for proving properties of recursive programs. We discuss in detail two powerful inductive methods, computational induction and structural induction, illustrating their applications by various examples. We also briefly discuss some other related methods."
  },
  {
    "Title": "Fixpoint approach to the theory of computation.",
    "URL": "https://dl.acm.org/doi/book/10.5555/891944",
    "Full Abstract": "Following the fixpoint theory of Scott, we propose to define the semantics of computer programs in terms of the least fixpoints of recursive programs. This allows one not only to justify all existing verification techniques, but also to extend them to handle various properties of computer programs, including correctness, termination and equivalence, in a uniform manner."
  },
  {
    "Title": "Program schemas with equality",
    "URL": "https://dl.acm.org/doi/10.1145/800152.804896",
    "Full Abstract": "We discuss the class of program schemas augmented with equality tests, that is, tests of equality between terms."
  },
  {
    "Title": "Fixpoint approach to the theory of computation",
    "URL": "https://dl.acm.org/doi/10.1145/361454.361460",
    "Full Abstract": "Following the fixpoint theory of Scott, the semantics of computer programs are defined in terms of the least fixpoints of recursive programs. This allows not only the justification of all existing verification techniques, but also their extension to the handling, in a uniform manner of various properties of computer programs, including correctness, termination, and equivalence."
  },
  {
    "Title": "On the power of programming features.",
    "URL": "https://dl.acm.org/doi/book/10.5555/891979",
    "Full Abstract": "We consider the power of several programming features such as counters, pushdown stacks, queues, arrays, recursion and equality. In this study program schemas are used as the model for computation. The relations between the powers of these features is completely described by a comparison diagram."
  },
  {
    "Title": "A heuristic approach to program verification.",
    "URL": "https://dl.acm.org/doi/book/10.5555/891986",
    "Full Abstract": "We present various heuristic techniques for use in proving the correctness of computer programs. The techniques are designed to obtain automatically the \"inductive assertions\" attached to the loops of the program which previously required human \"understanding\" of the program's performance. We distinguish between two general approaches: one in which we obtain the inductive assertion by analyzing predicates which are known to be true at the entrances and exits of the loop (top-down$ approach), and another in which we generate the inductive assertion directly from the statements of the loop (bottom-up$ approach)."
  },
  {
    "Title": "Decidable Properties of Monadic Functional Schemas",
    "URL": "https://dl.acm.org/doi/10.1145/321765.321780",
    "Full Abstract": "A class of (monadic) functional schemas which properly includes “Ianov” flowchart schemas is defined. It is shown that the termination, divergence, and freedom problems for functional schemas are decidable. Although it is possible to translate a large class of non-free functional schemas into equivalent free functional schemas, it is shown that in general this cannot be done. It is also shown that the equivalence problem for free functional schemas is decidable. Most of the results are obtained from well-known results in formal languages and automata theory."
  },
  {
    "Title": "Axiomatic approach to total correctness of programs.",
    "URL": "https://dl.acm.org/doi/book/10.5555/891989",
    "Full Abstract": "We present here an axiomatic approach which enables one to prove by formal methods that his program is \"totally correct\" (i.e., it terminates and is logically correct -- does what it is supposed to do). The approach is similar to Hoare's approach for proving that a program is \"partially correct\" (i.e., that whenever it terminates it produces correct results). Our extension to Hoare's method lies in the possibility of proving correctness and$ termination at once, and in the enlarged scope of properties that can be proved by it."
  },
  {
    "Title": "Termination of algorithms",
    "URL": "https://dl.acm.org/doi/book/10.5555/904866",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Properties of Programs and the First-Order Predicate Calculus",
    "URL": "https://dl.acm.org/doi/10.1145/321510.321516",
    "Full Abstract": "This paper is concerned with the relationship of the termination problem for programs and abstract programs to the validity of certain formulas in the first-order predicate calculus. By exploiting this relationship, subclasses of abstract programs for which the termination problem is decidable can be isolated. Moreover, known proof procedures for the first-order predicate calculus (e.g. resolution) can be applied to prove the termination of both programs and abstract programs. The correctness and equivalence problems of abstract programs are shown to be reducible to the termination problem."
  },
  {
    "Title": "Formalization of properties of recursively defined functions",
    "URL": "https://dl.acm.org/doi/10.1145/800169.805434",
    "Full Abstract": "This paper is concerned with the relationship between the convergence, correctness and equivalence of recursively defined functions and the satisfiability (or unsatisfiability) of certain first-order formulas."
  },
  {
    "Title": "Second-order mathematical theory of computation",
    "URL": "https://dl.acm.org/doi/10.1145/800161.805161",
    "Full Abstract": "In this work we show that it is possible to formalize all properties regularly observed in (deterministic and non-deterministic) algorithms in second-order predicate calculus."
  },
  {
    "Title": "Inductive methods for proving properties of programs",
    "URL": "https://dl.acm.org/doi/10.1145/355609.362336",
    "Full Abstract": "There are two main purposes in this paper: first, clarification and extension of known results about computation of recursive programs, with emphasis on the difference between the theoretical and practical approaches; second, presentation and examination of various known methods for proving properties of recursive programs. Discussed in detail are two powerful inductive methods, computational induction and structural induction, including examples of their applications."
  },
  {
    "Title": "A heuristic approach to program verification",
    "URL": "https://dl.acm.org/doi/10.5555/1624775.1624837",
    "Full Abstract": "We present various heuristic techniques for use in proving the correctness of computer programs. The techniques are designed to obtain automatically the \"inductive assertions\" attached to the loops of the program which previously required human \"understanding\" of the program's performance. We distinguish between two general approaches: one in which we obtain the inductive assertion by analyzing predicates which are known to be true at the entrances and exits of the loop (top-down approach), and another in which we generate the inductive assertion directly from the statements of the loop (bottom-up approach)."
  },
  {
    "Title": "Knowledge and Reasoning in Program Synthesis",
    "URL": "https://dl.acm.org/doi/10.5555/647950.742874",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Introduction to Mathematical Theory of Computation",
    "URL": "https://dl.acm.org/doi/book/10.5555/542899",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Computer recreations",
    "URL": "https://dl.acm.org/doi/10.1002/spe.4380030412",
    "Full Abstract": "Jotto is a popular word game for two players. It is of interest here because it unquestionably requires some intellectual ability for people to play it well, and it is a game in which a simple program can beat most human players nearly all the time. © 1973 Wiley Periodicals, Inc."
  },
  {
    "Title": "A General-Purpose Macro Processor as a Poor Man's Compiler-Compiler",
    "URL": "https://dl.acm.org/doi/10.1109/TSE.1976.233539",
    "Full Abstract": "A method for quickly producing compilers for high level languages is described. The technique consists of feeding a description of the language to be translated to a general-purpose macro processor. Used in this way, the macro processor functions as a compiler-compiler, providing automatic parsing, lexical scanning, symbol table operations, and handling of syntactic errors. A complete syntactic and semantic description of a WHILE statement (except for Boolean expression processing) is given in only seven lines, as an example. A system programming language implemented by this method is discussed in order to illustrate the main ideas. The compiler produced for this language is compared to other compilers produced by conventional methods."
  },
  {
    "Title": "In defense of program testing or correctness proofs considered harmful",
    "URL": "https://dl.acm.org/doi/10.1145/956003.956011",
    "Full Abstract": "Copyright © 1976 Author."
  },
  {
    "Title": "A Tutorial on Algol 68",
    "URL": "https://dl.acm.org/doi/10.1145/356669.356671",
    "Full Abstract": "Copyright © 1976 ACM."
  },
  {
    "Title": "The automatic synthesis of recursive programs",
    "URL": "https://dl.acm.org/doi/10.1145/872734.806929",
    "Full Abstract": "We describe a deductive technique for the automatic construction of recursive programs to meet given input-output specifications. These specifications express what conditions the output of the desired program is expected to satisfy. The deductive technique involves transforming the specifications by a collection of rules, summoned by pattern-directed function invocation. Some of these transformation rules express the semantics of the subject domain; others represent more general programming techniques. The rules that introduce conditional expressions and recursive calls into the program are discussed in some detail."
  },
  {
    "Title": "The logic of computer programming",
    "URL": "https://dl.acm.org/doi/book/10.5555/892142",
    "Full Abstract": "Techniques derived from mathematical logic promise to provide an alternative to the conventional methodology for constructing, debugging, and optimizing computer programs. Ultimately, these techniques are intended to lead to the automation of many of the facets of the programming process. This paper provides a unified tutorial exposition of the logical techniques, illustrating each with examples. The strengths and limitations of each technique as a practical programming aid are assessed and attempts to implement these methods in experimental systems are discussed."
  },
  {
    "Title": "The automatic synthesis of systems of recursive programs",
    "URL": "https://dl.acm.org/doi/10.5555/1624435.1624526",
    "Full Abstract": "A technique is presented for constructing, a program from given specifications. The basic approach is to transform the specifications repeatedly, according to certain rules, until the desired program is produced. Two important transformation rules are those responsible for introducing conditional expressions and recursion into the target program. These transformations have been introduced in previous publications, and are discussed here briefly."
  },
  {
    "Title": "Inference rules for program annotation",
    "URL": "https://dl.acm.org/doi/book/10.5555/892155",
    "Full Abstract": "Methods are presented whereby an Algol-like program, given together with its specifications, can be documented automatically. The program is incrementally annotated with invariant relationships that hold between program variables at intermediate points in the program and explain the acutal workings of the program regardless of whether the program is correct. Thus this documentation can be used for proving the correctness of the program or may serve as an aid in the debugging of an incorrect program. The annotation techniques are formulated as Hoare-llike inference rules which derive invariants from the assignment statements, from the control structure of the program, or, heuristically, from suggested invariants. The application of these rules is demonstrated by two examples which have run on an experimental implementation."
  },
  {
    "Title": "The optimal approach to recursive programs",
    "URL": "https://dl.acm.org/doi/10.1145/359863.359885",
    "Full Abstract": "The classical fixedpoint approach toward recursive programs suggests choosing the “least defined fixedpoint” as the most appropriate solution to a recursive program. A new approach is described which introduces an “optimal fixedpoint,” which, in contrast to the least defined fixedpoint, embodies the maximal amount of valuable information embedded in the program. The practical implications of this approach are discussed and techniques for proving properties of optimal fixedpoints are given. The presentation is informal, with emphasis on examples."
  },
  {
    "Title": "Ambiguous machine architecture and program efficiency",
    "URL": "https://dl.acm.org/doi/10.1145/859402.859404",
    "Full Abstract": "Copyright © 1977 Author."
  },
  {
    "Title": "Corrigenda: “A Tutorial on Algol 68”",
    "URL": "https://dl.acm.org/doi/10.1145/356698.356706",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Implications of structured programming for machine architecture",
    "URL": "https://dl.acm.org/doi/10.1145/359361.359454",
    "Full Abstract": "Based on an empirical study of more than 10,000 lines of program text written in a GOTO-less language, a machine architecture specifically designed for structured programs is proposed. Since assignment, CALL, RETURN, and IF statements together account for 93 percent of all executable statements, special care is given to ensure that these statements can be implemented efficiently. A highly compact instruction encoding scheme is presented, which can reduce program size by a factor of 3. Unlike a Huffman code, which utilizes variable length fields, this method uses only fixed length (1-byte) opcode and address fields. The most frequent instructions consist of a single 1-byte field. As a consequence, instruction decoding time is minimized, and the machine is efficient with respect to both space and time."
  },
  {
    "Title": "A method for implementing paged, segmented virtual memories on microprogrammable computers",
    "URL": "https://dl.acm.org/doi/10.1145/850657.850660",
    "Full Abstract": "Copyright © 1979 Author."
  },
  {
    "Title": "Efficient encoding of machine instructions",
    "URL": "https://dl.acm.org/doi/10.1145/859470.859472",
    "Full Abstract": "Copyright © 1979 Authors."
  },
  {
    "Title": "An overview of the Amoeba distributed operating system",
    "URL": "https://dl.acm.org/doi/10.1145/1041500.1041502",
    "Full Abstract": "As hardware prices continue to drop rapidly, building large computer systems by interconnecting substantial numbers of microcomputers becomes increasingly attractive. Many techniques for interconnecting the hardware, such as Ethernet [Metcalfe and Boggs, 1976], ring nets [Farber and Larson, 1972], packet switching, and shared memory are well understood, but the corresponding software techniques are poorly understood. The design of general purpose distributed operating systems is one of the key research issues for the 1980s."
  },
  {
    "Title": "Network Protocols",
    "URL": "https://dl.acm.org/doi/10.1145/356859.356864",
    "Full Abstract": "Copyright © 1981 ACM."
  },
  {
    "Title": "Using Peephole Optimization on Intermediate Code",
    "URL": "https://dl.acm.org/doi/10.1145/357153.357155",
    "Full Abstract": "Copyright © 1982 ACM."
  },
  {
    "Title": "A practical tool kit for making portable compilers",
    "URL": "https://dl.acm.org/doi/10.1145/358172.358182",
    "Full Abstract": "Copyright © 1983 ACM."
  },
  {
    "Title": "Structured Computer Organization",
    "URL": "https://dl.acm.org/doi/book/10.5555/538160",
    "Full Abstract": "From the Publisher:"
  },
  {
    "Title": "Immediate files",
    "URL": "https://dl.acm.org/doi/10.1002/spe.4380140407",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Does anybody out there want to write <u>HALF</u> of a compiler?",
    "URL": "https://dl.acm.org/doi/10.1145/988241.988252",
    "Full Abstract": "Copyright © 1984 Authors."
  },
  {
    "Title": "An overview of the Amoeba distributed operating system",
    "URL": "https://dl.acm.org/doi/10.5555/40489.40494",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Computer Networks",
    "URL": "https://dl.acm.org/doi/book/10.5555/536716",
    "Full Abstract": "From the Book: This book is now in its third edition. Each edition has corresponded to a different phase in the way computer networks were used. When the first edition appeared in 1980, networks were an academic curiosity. When the second edition appeared in 1988, networks were used by universities and large businesses. When the third edition appeared in 1996, computer networks, especially the worldwide Internet, had become a daily reality for millions of people. Furthermore, the networking hardware and software have completely changed since the second edition appeared In 1988, nearly all networks were based on copper wire. Now, many are based on fiber optics or wireless communication. Proprietary networks, such as SNA have become far less important than public networks, especially the Internet. The OSI protocols have quietly vanished,, and the TCP/IP protocol suite has become dominant. In fact, so much has changed, the book has almost been rewritten from scratch. Although Chap. 1 has the same introductory function as it did in the second edition, the contents have been completely revised and brought up to date. For example, instead of basing the hook on the seven-layer OSI model. a five-layer hybrid model (shown in Fig. 1-21) is now used and introduced in Chap. 1. While not exactly identical to the TCP/IP model, it is much closer to the TCP/IP model in spirit than it is to the OSI model used in the second edition. Also, the new running examples used throughout the book - the Internet and Al M networks are introduced here, along with some gigabit networks and other popular networks. In Chap. 2, the focus has moved from copper wire to fiber optics and wireless communication,since these arc the technologies of the future. The telephone system has become almost entirely digital in the past decade, so the material on it has been largely rewritten, with new material on broadband ISDN added. The material on cellular radio has been greatly expanded, and new material on low-orbit satellites has been added to the chapter. The order of discussion of the data link layer and the MAC sublayer has been reversed, since experience with students shows that they understand the MAC sublayer better after they have studied the data link layer. The example protocols there have been kept, as they have proven very popular, but they have been rewritten in C. New material on the Internet and ATM data link layers has been added. The MAC sublayer principles of Chap. 4. have been revised to reflect new protocols, including wavelength division multiplexing, wireless LANs, and digital radio. The discussion of bridges has been revised, and new material has been added on high-speed LANs. Most of the routing algorithms of Chap. 5 have been replaced by more modern ones, including distance vector and link state routing. The sections on congestion control have been completely redone, and material on the running examples, the Internet and ATM is all new. Chap. 6 is still about the transport layer, but here, too, major changes have occurred, primarily, the addition of a large amount of new material about the Internet, ATM, and network performance. Chap. 7, on the application layer, is now the longest chapter in the book. The material on network security has been doubled in length, and new material has been added on DNS, SNMP, email, USENET, the World Wide Web, HTML, Java, multimedia, video on demand, and the MBone. Of the 395 figures in the third edition, 276 (70 percent) are completely new and some of the others have been revised. Of the 371 references to the literature, 282 (76 percent) are to books and papers that have appeared since the second edition was published. Of these, over 100 are to works published in 1995 and 1996 alone. All in all, probably 75 percent of the entire book is brand new, and parts of the remaining 25 percent have been heavily revised. Since this is effectively a new book, the cover was redesigned to avoid confusion with the second edition. Computer books are full of acronyms. This one is no exception. By the time you are finished reading this one, all of the following should ring a bell: AAL, AMPS, ARP, ASN, ATM, BGP, CDMA, CDPD, CSMA, DQDB, DNS, FAQ, FDM, FTP, FTTC, FTTH, GSM, HDLC, HEC, HlPPl, TAB, lCMP, IDEA, IETF, 1Pv6, ISO, ITU, LATA, MAC, MACA, MAN, MIB, MIME, NAP, NNTP, NSA, NSAP, OSI, OSPF, PCM, PCN, PCS, PEM, PGP, PPP, PSTN, PTT, PVC, QAM, RARP, RFC, RSA, SABME, SAP, SAR, SDH, SDLC, SHA, SMI, SNA, SNMP, SNRME, SPX, TCP, UDP, VHF, VLF, VSAT, WARC, WDM, WWV, and WWW. But don't worry. Each one will be carefully defined before it is used. To help instructors using this book as a text for course, the author has prepared three teaching aids: A problem solutions manual. PostScript files containing all the figures (for making overhead sheets). A simulator (written in C) for the example protocols of Chap. 3. The solutions manual is available from Prentice Hall (but only to instructors). The file with the figures and the simulator are available via the World Wide Web. To get them, please see the author's home page: http://www.cs.vu.nl/~ast/. The book was typeset in Times Roman using Troff, which, after all these years, is still the only way to go. While Troff is not as trendy as WYSIWYG systems, the reader is invited to compare the typesetting quality of this book with books produced by WYSIWYG systems. My only concession to PCs and desktop publishing is that for the first time, the art was produced using Adobe Illustrator, instead of being drawn on paper. Also for the first time, the book was produced entirely electronically. The PostScript output from Troff was sent over the Internet to the printer, where the film for making the offset plates was produced. No intermediate paper copy was printed and photographed, as is normally done. Andrew S. Tanenbaum"
  },
  {
    "Title": "A distributed file service based on optimistic concurrency control",
    "URL": "https://dl.acm.org/doi/10.1145/323647.323634",
    "Full Abstract": "Copyright © 1985 ACM."
  },
  {
    "Title": "Distributed operating systems",
    "URL": "https://dl.acm.org/doi/10.1145/6041.6074",
    "Full Abstract": "Distributed operating systems have many aspects in common with centralized ones, but they also differ in certain ways. This paper is intended as an introduction to distributed operating systems, and especially to current university research about them. After a discussion of what constitutes a distributed operating system and how it is distinguished from a computer network, various key design issues are discussed. Then several examples of current research projects are examined in some detail, namely, the Cambridge Distributed Computing System, Amoeba, V, and Eden."
  },
  {
    "Title": "Research issues in distributed operating systems",
    "URL": "https://dl.acm.org/doi/10.5555/16918.16921",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "The design of a real-time distributed system",
    "URL": "https://dl.acm.org/doi/10.5555/16918.16951",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Language and machine-independent global optimization on intermediate code",
    "URL": "https://dl.acm.org/doi/10.1016/0096-0551%2886%2990004-4",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Making distributed systems palatable",
    "URL": "https://dl.acm.org/doi/10.1145/503956.503999",
    "Full Abstract": "Designing and implementing a distributed system is easy compared to the task of convincing people to use it. In a university Computer Science Dept., people generally use UNIX and are not at all interested in moving to a different environment, no matter how wonderful it may be. In this paper we report on how we have implemented a UNIX environment for the Amoeba distributed operating system [1], in order to make the transition from UNIX to Amoeba as simple as possible."
  },
  {
    "Title": "Verification of Concurrent Programs",
    "URL": "https://dl.acm.org/doi/10.5555/648063.747433",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Synthesis of Communicating Processes from Temporal Logic Specifications",
    "URL": "https://dl.acm.org/doi/10.5555/648063.747434",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Verification of concurrent programs, Part I: The temporal framework",
    "URL": "https://dl.acm.org/doi/book/10.5555/892270",
    "Full Abstract": "This is the first in a series of reports describing the application of temporal logic to the specification and verification of concurrent programs. We first introduce temporal logic as a tool for reasoning about sequences of states. Models of concurrent programs based both on transition graphs and on linear-text representations are presented and the notions of concurrent and fair executions are defined. The general temporal language is then specialized to reason aboaut those execution sequences that are fair computations of a concurrent program. Subsequently, the language is used to describe properties of concurrent programs. The set of interesting properties is classified into invariance (safety), eventuality (liveness), and precedence (until) properties. Among the properties studied are: partial correctness, global invariance, clean behavior, mutual exclusion, absence of deadlock, termination, total correctness, intermittent assertions, accessibility, responsiveness, safe liveness, absence of unsolicited response, fair responsiveness, and precedence. In the following reports of this series, we will use the temporal formalism to develop proof methodologies for proving the properties discussed here."
  },
  {
    "Title": "Verification of concurrent programs: proving eventualities by well-founded ranking",
    "URL": "https://dl.acm.org/doi/book/10.5555/892275",
    "Full Abstract": "In this paper, one of a series on verification of concurrent programs, we present proof methods for establishing eventuality and until properties. The methods are based on well-founded ranking and are applicable to both \"just\" and \"fair\" computations. These methods do not assume a decrcase of the rank at each computation step. It is sufficient that there exists one process which decreases the rank when activated. Fairness then ensures that the program will eventually attain its goal."
  },
  {
    "Title": "How to cook a temporal proof system for your pet language",
    "URL": "https://dl.acm.org/doi/10.1145/567067.567082",
    "Full Abstract": "An abstract temporal proof system is presented whose program-dependent part has a high-level interface with the programming language actually studied. Given a new language, it is sufficient to deline the interface notions of atomic transitions, justice, and fairness in order to obtain a full temporal proof system for this language. This construction is particularly useful for the analysis of concurrent systems. We illustrate the construction on the shared-variable model and on CSP. The generic proof system is shown to be relatively complete with respect to pure first-order temporal logic."
  },
  {
    "Title": "Operating systems: design and implementation",
    "URL": "https://dl.acm.org/doi/book/10.5555/21853",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Operating systems: design and implementation",
    "URL": "https://dl.acm.org/doi/book/10.5555/22876",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Computer networks: 2nd edition",
    "URL": "https://dl.acm.org/doi/book/10.5555/59922",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Computer networks",
    "URL": "https://dl.acm.org/doi/book/10.5555/62795",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Computer networks: 2nd edition",
    "URL": "https://dl.acm.org/doi/book/10.5555/47313",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Functional specialization in distributed operating systems",
    "URL": "https://dl.acm.org/doi/10.1145/504092.504120",
    "Full Abstract": "A distributed operating system provides the same functionality and interface as a monolithic operating system. That is, for both systems the goal is to make the computing and storage facilities as provided by the hardware available to the users of the system. In distributed operating system new hardware can be added to the system to increase the storage or computing power, or to increase the availability of the storage and computing services. During and after this addition, the interface to the system remains unchanged. Transparency of access is a key concept.The top-level interface consists of sophisticated command interpreters and editors, supported by a high-resolution graphical window system. This software is run by workstations. Workstations are powerful computer units, consisting of a CPU, memory, a bitmap display, keyboard, a pointing device such as a mouse, and a network interface. In addition, workstations are often equipped with a disk. The CPU is at least as powerful as those used in traditional computer systems, and the amount of memory is equivalent or even larger.A workstation is dedicated to one individual. Consequently, the workstation is idle most of the time. It is therefore tempting to use it as the main computing resource for the owner and perhaps others as well. It could also be used autonomously from the rest of the system in case of a failure. We are opposed to these uses of workstations, since we believe that workstations should only provide the top-level interface. In this paper we will outline our reasons for this, and show how this principle has been applied in the Amoeba distributed operating system."
  },
  {
    "Title": "Performance of the world's fastest distributed operating system",
    "URL": "https://dl.acm.org/doi/10.1145/54289.54291",
    "Full Abstract": "Distributed operating systems have been in the experimental stage for a number of years now, but few have progressed to the point of actually being used in a production environment. It is our belief that the reason lies primarily with the performance of these systems---they tend to be fairly slow compared to traditional single computer systems. The Amoeba system has been designed with high performance in mind. In this paper some performance measurements of Amoeba are presented and comparisons are made with UNIX on the SUN, as well as with some other interesting systems. In particular, short remote procedure calls take 1.4 msec and long data transfers achieve a user-to-user bandwidth of 677 kbytes/sec. Furthermore, the file server is so fast that it is limited by the communication bandwidth to 677 kbytes/sec. The real speed of the file server is too high to measure. To the best of our knowledge, these are the best figures yet reported in the literature for the class of hardware used."
  },
  {
    "Title": "The Evolution of a Distributed Operating System",
    "URL": "https://dl.acm.org/doi/10.5555/645793.668329",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Programming languages for distributed computing systems",
    "URL": "https://dl.acm.org/doi/10.1145/72551.72552",
    "Full Abstract": "When distributed systems first appeared, they were programmed in traditional sequential languages, usually with the addition of a few library procedures for sending and receiving messages. As distributed applications became more commonplace and more sophisticated, this ad hoc approach became less satisfactory. Researchers all over the world began designing new programming languages specifically for implementing distributed applications. These languages and their history, their underlying principles, their design, and their use are the subject of this paper."
  },
  {
    "Title": "An efficient reliable broadcast protocol",
    "URL": "https://dl.acm.org/doi/10.1145/70730.70732",
    "Full Abstract": "Many distributed and parallel applications can make good use of broadcast communication. In this paper we present a (software) protocol that simulates reliable broadcast, even on an unreliable network. Using this protocol, application programs need not worry about lost messages. Recovery of communication failures is handled automatically and transparently by the protocol. In normal operation, our protocol is more efficient than previously published reliable broadcast protocols. An initial implementation of the protocol on 10 MC68020 CPUs connected by a 10 Mbit/sec Ethernet performs a reliable broadcast in 1.5 msec."
  },
  {
    "Title": "On the design of the amoeba configuration manager",
    "URL": "https://dl.acm.org/doi/10.1145/72910.73340",
    "Full Abstract": "The program"
  },
  {
    "Title": "The design of very fast portable compilers",
    "URL": "https://dl.acm.org/doi/10.1145/71605.71616",
    "Full Abstract": "The Amsterdam Compiler Kit is a widely used compiler building system. Up until now, the emphasis has been on producing good object code. In this paper we describe recent work that has focused on reducing compile time. The techniques described in this paper have resulted in C compilers for the Sun-3 and VAX that are 3 to 4 times faster than the native compilers provided by the manufacturers."
  },
  {
    "Title": "Structured computer organization (3rd ed.)",
    "URL": "https://dl.acm.org/doi/book/10.5555/93745",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Amoeba",
    "URL": "https://dl.acm.org/doi/10.1109/2.53354",
    "Full Abstract": "A description is given of the Amoeba distributed operating system, which appears to users as a centralized system but has the speed, fault tolerance, security safeguards, and flexibility required for the 1990s. The Amoeba software is based on objects. Objects are managed by server processes and named using capabilities chosen randomly from a sparse name space. Amoeba has a unique, fast file system split into two parts: the bullet service stores immutable files contiguously on the disk; the directory service gives capabilities symbolic names and handles replication and atomicity, eliminating the need for a separate transaction management system. To bridge the gap with existing systems, Amoeba has a Unix emulation facility consisting of a library of Unix system call routines that make calls to the various Amoeba server processes."
  },
  {
    "Title": "Fault tolerance using group communication",
    "URL": "https://dl.acm.org/doi/10.1145/504136.504146",
    "Full Abstract": "We propose group communication as an efficient mechanism to support fault tolerance. Our approach is based on an efficient reliable broadcast protocol that requires on average only two messages per broadcast. To illustrate our approach we will describe how the task bag model can be made fault-tolerant using group communication."
  },
  {
    "Title": "Minix 1.5 for Macintosh Software and Reference Manual",
    "URL": "https://dl.acm.org/doi/book/10.5555/1202330",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Experiences with the Amoeba distributed operating system",
    "URL": "https://dl.acm.org/doi/10.1145/96267.96281",
    "Full Abstract": "The Amoeba project is a research effort aimed at understanding how to connect multiple computers in a seamless way [16, 17, 26, 27, 31]. The basic idea is to provide the users with the illusion of a single powerful timesharing system, when, in fact, the system is implemented on a collection of machines, potentially distributed among several countries. This research has led to the design and implementation of the Amoeba distributed operating system, which is being used as a prototype and vehicle for further research. In this article we will describe the current state of the system (Amoeba 4.0), and show some of the lessons we have learned designing and using it over the past eight years. We will also discuss how this experience has influenced our plans for the next version, Amoeba 5.0."
  },
  {
    "Title": "Network protocols",
    "URL": "https://dl.acm.org/doi/10.5555/128960.128961",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Fault tolerance using group communication",
    "URL": "https://dl.acm.org/doi/10.1145/122120.122126",
    "Full Abstract": "We propose group communication as an efficient mechanism to support fault tolerance. Our approach is based on an efficient reliable broadcast protocol that requires on average only two messages per broadcast. To illustrate our approach we will describe how the task bag model can be made fault-tolerant using group communication."
  },
  {
    "Title": "The temporal logic of branching time",
    "URL": "https://dl.acm.org/doi/10.1007/BF01257083",
    "Full Abstract": "A temporal logic is defined which contains both linear and branching operators. The underlying model is the tree of all possible computations. The following metatheoretical results are proven: 1) an exponential decision procedure for satisfiability; 2) a finite model property; 3) the completeness of an axiomatization."
  },
  {
    "Title": "Synthesis of Communicating Processes from Temporal Logic Specifications",
    "URL": "https://dl.acm.org/doi/10.1145/357233.357237",
    "Full Abstract": "Copyright © 1984 ACM."
  },
  {
    "Title": "Adequate proof principles for invariance and liveness properties of concurrent programs",
    "URL": "https://dl.acm.org/doi/book/10.5555/892313",
    "Full Abstract": "This paper presents proof principles for establishing invariance and liveness properties of concurrent programs. Invariance properties are established by systematically checking that they are preserved by every atomic instruction in the program. The methods for establishing liveness properties are based on 'well-founded asserations' and are applicable to both \"just\" and \"fair\" computations. These methods do not assume a decrease of the rank at each computation step. It is sufficient that there exists one process which decreases the rank when activated. Fairness then ensures that the program will eventually attain its goal. In the finite state case such proofs can be represented by diagrams. Several examples are given."
  },
  {
    "Title": "TABLOG: the deductive-tableau programming language",
    "URL": "https://dl.acm.org/doi/book/10.5555/892317",
    "Full Abstract": "TABLOG (Tableau Logic Programming Language) is a language based on first-order predicate logic with equality that combines functional and logic programming. TABLOG incorporates advantages of LISP and PROLOG. A program in TABLOG is a list of formulas in a first-order logic (including equality, negation, and equivalence) that is more general and more expressive than PROLOG's Horn clauses. Whereas PROLOG programs must be relational, TABLOG programs may define either relations or functions. While LISP programs yield results of a computation by returning a single output value, TABLOG programs can be relations and can produce several results simultaneously through their arguments. TABLOG employs the Manna-Waldinger deductive-tableau proof system as an interpreter in the same way that PROLOG uses a resolution-based proof system. Unification is used by TABLOG to match a call with a line in the program and to bind arguments. The basic rules of deduction used for computing are nonclausal resolution and rewriting by means of equality and equivalence. A pilot interpreter for the language has been implemented."
  },
  {
    "Title": "TABLOG",
    "URL": "https://dl.acm.org/doi/10.1145/800055.802049",
    "Full Abstract": "TABLOG (Tableau Logic Programming Language) is a language combining functional and logic programming using first-order (quantifier-free) predicate logic with equality. TABLOG incorporates advantages of LISP and PROLOG."
  },
  {
    "Title": "Adequate proof principles for invariance and liveness properties of concurrent programs",
    "URL": "https://dl.acm.org/doi/10.1016/0167-6423%2884%2990003-0",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "The logical basis for computer programming. Volume 1:  deductive reasoning",
    "URL": "https://dl.acm.org/doi/book/10.5555/3510",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Special relations in automated deduction",
    "URL": "https://dl.acm.org/doi/book/10.5555/892351",
    "Full Abstract": "Two deduction rules are introduced to give streamlined treatment to relations of special importance in an automated theorem-proving system. These rules, the relation replacement and relation matching rules, generalize to an arbitrary binary relation the paramodulation and E-resolution rules, respectively, for equality, and may operate within a nonclausal or clausal system. The new rules depend on an extension of the notion of polarity to apply to subterms as well as to subsentences, with respect to a given binary relation. The rules allow us to eliminate troublesome axioms, such as transitivity and monotonicity, from the system; proofs are shorter and more comprehensible, and the search space is correspondingly deflated."
  },
  {
    "Title": "Nonclausal temporal deduction",
    "URL": "https://dl.acm.org/doi/book/10.5555/892354",
    "Full Abstract": "We present a proof system for propositional temporal logic. This system is based on nonclausal resolution; proofs are natural and generally short. Its extension to first-order temporal logic is considered. Two variants of the system are described. The first one is for a logic with $\\Box$ (\"always\"), $\\Diamond$ (\"sometime\"), and $\\bigcirc$ (\"next\"). The second variant is an extension of the first one to a logic with the additional operators U (\"until\") and P (\"precedes\"). Each of these variants is proved complete."
  },
  {
    "Title": "Nonclausal Temporal Deduction",
    "URL": "https://dl.acm.org/doi/10.5555/648065.747731",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Special Relations in Automated Deduction",
    "URL": "https://dl.acm.org/doi/10.5555/646239.683367",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "The origin of the binary-search paradigm",
    "URL": "https://dl.acm.org/doi/10.5555/1625135.1625176",
    "Full Abstract": "In a binary-search algorithm for the computation of a numerical function, the interval in which the desired output is sought is divided in half at each iteration. The paper considers how such algorithms might be derived from their specifications by an automatic program-synthesis system. The derivation of the binary-search concept has been found to be surprisingly straightforward. The programs obtained, though reasonably simple and efficient, are quite different from those that would have been constructed by informal means."
  },
  {
    "Title": "Deduction with Relation Matching",
    "URL": "https://dl.acm.org/doi/10.5555/646823.706894",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Balanced allocations for tree-like inputs",
    "URL": "https://dl.acm.org/doi/10.1016/0020-0190%2895%2900123-T",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "The worst-case running time of the random simplex algorithm is exponential in the height",
    "URL": "https://dl.acm.org/doi/10.1016/0020-0190%2895%2900101-H",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "An efficient algorithm for the vertex-disjoint paths problem in random graphs",
    "URL": "https://dl.acm.org/doi/10.5555/313852.314072",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Static and dynamic path selection on expander graphs (preliminary version)",
    "URL": "https://dl.acm.org/doi/10.1145/258533.258646",
    "Full Abstract": "Copyright © 1997 ACM."
  },
  {
    "Title": "Counting Minimum Weight Spanning Trees",
    "URL": "https://dl.acm.org/doi/10.1006/jagm.1996.0851",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Syntactic clustering of the Web",
    "URL": "https://dl.acm.org/doi/10.1016/S0169-7552%2897%2900031-7",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Syntactic clustering of the Web",
    "URL": "https://dl.acm.org/doi/10.5555/283554.283370",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Distributed programming with shared data",
    "URL": "https://dl.acm.org/doi/10.1016/0096-0551%2891%2990003-R",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "The Amoeba distributed operating system—a status report",
    "URL": "https://dl.acm.org/doi/10.1016/0140-3664%2891%2990058-9",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "MINIX 1.5 for the Sun Sparcstation",
    "URL": "https://dl.acm.org/doi/book/10.5555/574007",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Transparent fault-tolerance in parallel Orca programs",
    "URL": "https://dl.acm.org/doi/10.5555/139156.139175",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Orca",
    "URL": "https://dl.acm.org/doi/10.1109/32.126768",
    "Full Abstract": "A detailed description is given of the Orca language design and the design choices are discussed. Orca is intended for applications programmers rather than systems programmers. This is reflected in its design goals to provide a simple, easy-to-use language that is type-secure and provides clean semantics. Three example parallel applications in Orca, one of which is described in detail, are discussed. One of the existing implementations, which is based on reliable broadcasting, is described. Performance measurements of this system are given for three parallel applications. The measurements show that significant speedups can be obtained for all three applications. The authors compare Orca with several related languages and systems."
  },
  {
    "Title": "FLIP; an Internetwork Protocol for Supporting Distributed Systems",
    "URL": "https://dl.acm.org/doi/10.1145/142111.993339",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Modern operating systems",
    "URL": "https://dl.acm.org/doi/book/10.5555/129206",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Replication techniques for speeding up parallel applications on distributed systems",
    "URL": "https://dl.acm.org/doi/10.1002/cpe.4330040502",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Parallel Programming Using Shared Objects and Broadcasting",
    "URL": "https://dl.acm.org/doi/10.1109/2.153276",
    "Full Abstract": "The two major design approaches taken to build distributed and parallel computer systems, multiprocessing and multicomputing, are discussed. A model that combines the best properties of both multiprocessor and multicomputer systems, easy-to-build hardware, and a conceptually simple programming model is presented. Using this model, a programmer defines and invokes operations on shared objects, the runtime system handles reads and writes on these objects, and the reliable broadcast layer implements indivisible updates to objects using the sequencing protocol. The resulting system is easy to program, easy to build, and has acceptable performance on problems with a moderate grain size in which reads are much more common than writes. Orca, a procedural language whose sequential constructs are roughly similar to languages like C or Modula 2 but which also supports parallel processes and shared objects and has been used to develop applications for the prototype system, is described."
  },
  {
    "Title": "An experimental comparison of remote procedure call and group communication",
    "URL": "https://dl.acm.org/doi/10.1145/506378.506405",
    "Full Abstract": "This paper suggests that a distributed system should support two communication paradigms: Remote Procedure Call (RPC) and group communication. The former is used for point-to-point communication; the latter is used for one-to-many communication. We demonstrate that group communication is an important paradigm by showing that a fault-tolerant directory service is much easier to implement with groups than with RPC and is also more efficient. The directory service exemplifies distributed services that provide high reliability and availability by replicating data."
  },
  {
    "Title": "A comparison of two paradigms for distributed shared memory",
    "URL": "https://dl.acm.org/doi/10.1002/spe.4380221105",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "FLIP: an internetwork protocol for supporting distributed systems",
    "URL": "https://dl.acm.org/doi/10.1145/151250.151253",
    "Full Abstract": "Most modern network protocols give adequate support for traditional applications such as file transfer and remote login. Distributed applications, however, have different requirements (e.g., efficient at-most-once remote procedure call even in the face of processor failures). Instead of using ad hoc protocols to meet each of the new requirements, we have designed a new protocol, called the Fast Local Internet Protocol (FLIP), that provides a clean and simple integrated approach to these new requirements. FLIP is an unreliable message protocol that provides both point-to-point communication and multicast communication, and requires almost no network management. Furthermore, by using FLIP we have simplified higher-level protocols such as remote procedure call and group communication, and enhanced support for process migration and security. A prototype implementation of FLIP has been built as part of the new kernel for the Amoeba distributed operating system, and is in daily use. Measurements of its performance are presented."
  },
  {
    "Title": "Using active messages to support shared objects",
    "URL": "https://dl.acm.org/doi/10.1145/504390.504421",
    "Full Abstract": "This paper discusses a reliable group communication system using active messages to update shared objects. We discuss the model, implementation techniques, and our preliminary performance results."
  },
  {
    "Title": "Distributed operating systems",
    "URL": "https://dl.acm.org/doi/book/10.5555/184674",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Paramecium",
    "URL": "https://dl.acm.org/doi/10.5555/822074.822401",
    "Full Abstract": "We describe the design of an extensible kernel, called Paramecium. This kernel uses an object-based software architecture which together with instance naming, late binding and explicit overrides enables easy reconfiguration. Determining which components reside in the kernel protection domain is up to the user. A certification authority or one of its delegates certifies which components are trustworthy and therefore permitted to run in the kernel protection domain. These delegates may include validation programs, correctness provers, and system administrators. The main advantage of certifications is that it can handle trust and sharing in a non-cooperative environment."
  },
  {
    "Title": "A comparison of three microkernels",
    "URL": "https://dl.acm.org/doi/10.1007/BF01245395",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Orca",
    "URL": "https://dl.acm.org/doi/10.5555/201711.201713",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Computer networks (3rd ed.)",
    "URL": "https://dl.acm.org/doi/book/10.5555/248731",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "An architecture for a wide area distributed system",
    "URL": "https://dl.acm.org/doi/10.1145/504450.504465",
    "Full Abstract": "Distributed systems provide sharing of resources and information over a computer network. A key design issue that makes these systems attractive is that all aspects related to distribution are transparent to users. Unfortunately, general-purpose wide area distributed systems that allow users to share and manage arbitrary resources in a transparent way hardly exist. In particular, they generally do not take into account the most important properties that characterize wide area systems: 1) A very large number of users and resources, 2) an inherent latency problem caused by the distance between nodes, 3) heterogeneity due to a variety of underlying operating systems and networks, and 4) involvement of multiple administrative organizations.The research described in this paper is part of the Globe Project (Globe stands for GLobal Object Based Environment). The goal of this project is the design and implementation of a wide area distributed system that provides a convenient programming abstraction and full transparency. The main contribution of this paper is the description of a new system for distributed shared objects. In contrast to other systems, the implementation of distribution, consistency, and replication of state is completely encapsulated in a distributed shared object. This allows for object-specific solutions, and provides the right mechanism for building efficient and truly scalable systems."
  },
  {
    "Title": "Communication in GLOBE",
    "URL": "https://dl.acm.org/doi/10.5555/851041.856924",
    "Full Abstract": "Current paradigms for interprocess communication are not sufficient to describe the exchange of information at an adequate level of abstraction. They are either too low-level, or their implementations cannot meet performance requirements. As an alternative, we propose distributed shared objects as a unifying concept. These objects offer user-defined operations on shared state, but allow for efficient implementations through replication and distribution of state. In contrast to other object-based models, these implementation aspects are completely hidden from applications."
  },
  {
    "Title": "Modal theorem proving",
    "URL": "https://dl.acm.org/doi/10.5555/22289.22302",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "How to clear a block: plan formation in situational logic",
    "URL": "https://dl.acm.org/doi/10.5555/22289.22337",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Specification and Verification of Concurrent Programs by forall-Automata",
    "URL": "https://dl.acm.org/doi/10.5555/647236.720395",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "The deductive synthesis of imperative LISP programs",
    "URL": "https://dl.acm.org/doi/10.5555/1856670.1856698",
    "Full Abstract": "A framework is described for the automatic synthesis of imperative programs, which may alter data structures and produce destructive side effects as part of their intended behavior. A program meeting a given specification is extracted from the proof of a theorem in a variant of situational logic, in which the states of a computation are explicit objects. As an example, an in-place reverse program has been derived in an imperative LISP, which includes assignment and destructive list operations (rplaca and rplacd)."
  },
  {
    "Title": "The deductive synthesis of imperative LISP programs",
    "URL": "https://dl.acm.org/doi/10.5555/1863696.1863724",
    "Full Abstract": "A framework is described for the automatic synthesis of imperative programs, which may alter data structures and produce destructive side effects as part of their intended behavior. A program meeting a given specification is extracted from the proof of a theorem in a variant of situational logic, in which the states of a computation are explicit objects. As an example, an in-place reverse program has been derived in an imperative LISP, which includes assignment and destructive list operations (rplaca and rplacd)."
  },
  {
    "Title": "The origin of a binary-search paradigm",
    "URL": "https://dl.acm.org/doi/10.1016/0167-6423%2887%2990025-6",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "A Hierarchy of Temporal Properties",
    "URL": "https://dl.acm.org/doi/book/10.5555/892426",
    "Full Abstract": "We propose a classification of temporal properties into a hierarchy which refines the known safety-liveness classification of properties. The new classification recognizes the classes of safety, guarantee, persistence, fairness, and hyper-fairness. The classification suggested here is based on the different ways a property of finite computations can be extended into a property of infinite computations. For properties that are expressible by temporal logic and predicate automata, we provide a syntactic characterization of the formulae and automata that specify properties in the different classes. We consider the verification of properties over a given program, and provide a unique proof principle for each class."
  },
  {
    "Title": "Specification and verification of concurrent programs by A ∀ automata",
    "URL": "https://dl.acm.org/doi/10.1145/41625.41626",
    "Full Abstract": "∀-automata are non-deterministic finite-state automata over infinite sequences. They differ from conventional automata in that a sequence is accepted if"
  },
  {
    "Title": "How to clear a block: A theory of plans",
    "URL": "https://dl.acm.org/doi/10.5555/41391.41392",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "A hierarchy of temporal properties",
    "URL": "https://dl.acm.org/doi/10.1145/41840.41857",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "The anchored version of the temporal framework",
    "URL": "https://dl.acm.org/doi/10.5555/648140.749663",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Specification and Verification of Concurrent Programs by For-All Automata",
    "URL": "https://dl.acm.org/doi/book/10.5555/892457",
    "Full Abstract": "For-all automata are non-deterministic finite-state automata over infinite sequences. They differ from conventional automata in that a sequence is accepted if all runs of the automaton over the sequence are accepting. These automata are suggested as a formalism for the specification and verification of temporal properties of concurrent programs. It is shown that they are as expressive as extended temporal logic (ETL), and, in some cases, provide a more compact representation of properties than temporal logic. A structured diagram notation is suggested for the graphical representation of these automata. A single sound and complete proof rule is presented for proving that all computations of a program have the property specified by a for-all automaton."
  },
  {
    "Title": "Completing the Temporal Picture",
    "URL": "https://dl.acm.org/doi/10.5555/646243.681453",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Temporal logic programming",
    "URL": "https://dl.acm.org/doi/10.1016/S0747-7171%2889%2980070-7",
    "Full Abstract": "Temporal logic, often used as a specification language for programs, can serve directly as a programming language. We propose a specific programming language TEMPLOG, which extends the classical PROLOG-like languages to include temporal operators. PROLOG progams are collections of classical Horn clauses and they are efficiently interpreted by SLD-resolution. Similarly, TEMPLOG programs are collections of temporal Horn clauses and we interpret them with temporal SLD-resolution, a restricted form of a general temporal resolution method."
  },
  {
    "Title": "On the average behavior of set merging algorithms (Extended Abstract)",
    "URL": "https://dl.acm.org/doi/10.1145/800113.803648",
    "Full Abstract": "In this paper we study the expected running time of a variety of algorithms that perform set merging. The set merging problem (for example, see AHU [1]) is concerned with using suitable data structures to represent partition of a set S = { 1,2, ....,n so that a sequence of instructions of the form “x Ξ y”, meaning"
  },
  {
    "Title": "Lower Bounds on Merging Networks",
    "URL": "https://dl.acm.org/doi/10.1145/321958.321976",
    "Full Abstract": "Let"
  },
  {
    "Title": "K + 1 heads are better than K",
    "URL": "https://dl.acm.org/doi/10.1109/SFCS.1976.18",
    "Full Abstract": "There are languages which can be recognized by a deterministic (k + 1)-headed oneway finite automaton but which cannot be recognized by a k-headed one-way (deterministic or non-deterministic) finite automaton. Furthermore, there is a language accepted by a 2-headed nondeterministic finite automaton which is accepted by no k-headed deterministic finite automaton."
  },
  {
    "Title": "The complexity of searching an ordered random table",
    "URL": "https://dl.acm.org/doi/10.1109/SFCS.1976.32",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "An Ω(n",
    "URL": "https://dl.acm.org/doi/10.1145/800105.803391",
    "Full Abstract": "Let P be a polyhedron with f"
  },
  {
    "Title": "On the loop switching addressing problem",
    "URL": "https://dl.acm.org/doi/book/10.5555/892151",
    "Full Abstract": "The following graph addressing problem was studied by Graham and Pollak in devising a routing scheme for Pierce's Loop Switching Network. Let G be a graph with n vertices. It is desired to assign to each vertex $v_i$ an address in ${{0,1,*^\\ell$, such that the Hamming distance between the addresses of any two vertices agrees with their distance in G. Let N(G) be the minimum length $\\ell$ for which an assignment is possible. It was shown by Graham and Pollak that N(G) $\\leq m_G$(n-1), where $m_G$ is the diameter of G. In the present paper, we shall prove that N(G) $\\leq 1.09(lg m_G$)n + 8n by an explicit construction. This shows in particular that any graph has an addressing scheme of length O(n log n)."
  },
  {
    "Title": "The complexity of pattern matching for a random string",
    "URL": "https://dl.acm.org/doi/book/10.5555/892154",
    "Full Abstract": "We study the average-case complexity of finding all occurrences of a given pattern $\\alpha$ in an input text string. Over an alphabet of q symbols, let c($\\alpha$,n) be the minimum average number of characters that need to be examined in a random text string of length n. We prove that, for large m, almost all patterns $\\alpha$ of length m satisfy c($\\alpha$,n) = $\\Theta (\\lceil \\log_q (${n-m/{ln m + 2)\\rceil )$ if $m \\leq n \\leq 2m$, and c($\\alpha$,n) = $\\Theta ({\\lceil \\log_q m\\rceil/m n)$ if n < 2m. This in particular confirms a conjecture raised in a recent paper by Knuth, Morris, and Pratt [1977]."
  },
  {
    "Title": "A lower bound to palindrome recognition by probabilistic Turing machines",
    "URL": "https://dl.acm.org/doi/book/10.5555/892157",
    "Full Abstract": "We call attention to the problem of proving lower bounds on probabilistic Turing machine computations. It is shown that any probabilisitc Turing machine recognizing the language L = {w $\\phi$ w | w $\\epsilon$ ${{0,1^*$ with error $\\lambda$ > 1/2 must take $\\Omega$(n log n) time."
  },
  {
    "Title": "On constructing minimum spanning trees in k-dimensional spaces and related problems",
    "URL": "https://dl.acm.org/doi/book/10.5555/892163",
    "Full Abstract": "The problem of finding a minimum spanning tree connecting n points in a k-dimensional space is discussed under three common distance metrics -- Euclidean, rectilinear, and $L_\\infty$. By employing a subroutine that solves the post office problem, we show that, for fixed k $\\geq$ 3, such a minimum spanning tree can be found in time O($n^{2-a(k) {(log n)^{1-a(k)$), where a(k) = $2^{-(k+1)$. The bound can be improved to O(${(n log n)^{1.8$) for points in the 3-dimensional Euclidean space. We also obtain o($n^2$) algorithms for finding a farthest pair in a set of n points and for other related problems."
  },
  {
    "Title": "k",
    "URL": "https://dl.acm.org/doi/10.1145/322063.322076",
    "Full Abstract": "Copyright © 1978 ACM."
  },
  {
    "Title": "New algorithms in bin packing",
    "URL": "https://dl.acm.org/doi/book/10.5555/892175",
    "Full Abstract": "In the bin-packing problem a list L of n numbers are to be packed into unit-capacity bins. For any algorithm S, let r(S) be the maximum ratio S(L)/$L^*$ for large $L^*$, where S(L) denotes the number of bins used by S and $L^*$ denotes the minimum number needed. In this paper we give an on-line O(n log n)-time algorithm RFF with r(RFF) = 5/3, and an off-line polynomial-time algorithm RFFD with r(RFFD) = (11/9)-$\\epsilon$ for some fixed $\\epsilon$ < 0. These are strictly better respectively than two prominent algorithms -- the First-Fit (FF) which is on-line with r(FF) = 17/10, and the First-Fit-Decreasing (FFD) with r(FFD) = 11/9. Furthermore, it is shown that any on-line algorithm S must have r(S) $\\geq$ 3/2. We also discuss the question \"how well can an O(n)-time algorithm perform?\", showing that, in the generalized d-dimensional bin-packing, any O(n)-time algorithm S must have r(S) $\\geq$ d."
  },
  {
    "Title": "Information bounds are weak in the shortest distance problem",
    "URL": "https://dl.acm.org/doi/book/10.5555/892180",
    "Full Abstract": "In the all-pair shortest distance problem, one computes the matrix D = ($d_{ij$) where $d_{ij$ is the minimum weighted length of any path from vertex i to vertex j in a directed complete graph with a weight on each edge. In all the known algorithms, a shortest path $p_{ij$ achieving $d_{ij$ is also implicitly computed. In fact, $\\log_3$ f(n) is an information-theoretic lower bound where f(n) is the total number of distinct patterns ($p_{ij$) for n-vertex graphs. As f(n) potentially can be as large as $2^{n^3$, it is hopeful that a non-trivial lower bound can be derived this way in the decision tree model. We study the characterization and enumeration of realizable patterns, and show that f(n) $\\leq C^{n^2$. Thus no lower bound greater than C$n^2$ can be derived from this approach. We prove as a corollary that the Triangular polyhedron $T^{(n)$, defined in $E^{(n\\choose 2)$ by $d_{ij \\geq 0$ and the triangle inequalities $d_{ij + d_{jk \\geq d_{ik$, has at most $C^{n^2$ faces of all dimensions, thus resolving an open question in a similar information bound approach to the shortest distance problem."
  },
  {
    "Title": "On the average-case complexity of selecting k-th best",
    "URL": "https://dl.acm.org/doi/10.1109/SFCS.1978.29",
    "Full Abstract": "Let Vk (n) be the minimum average number of pairwise comparisons needed to find the k-th largest of n numbers (k≥2), assuming that all n! orderings are equally likely. D. W. Matula proved that, for some absolute constant c, Vk(n)- n ≤ ck log log n as n → ∞. In the present paper, we show that there exists an absolute constant c′ > 0 such that Vk(n) - n ≥ c′k log log n as n → ∞, proving a conjecture by Matula."
  },
  {
    "Title": "An analysis of a memory allocation scheme for implementing stacks",
    "URL": "https://dl.acm.org/doi/book/10.5555/892201",
    "Full Abstract": "Consider the implementation of two stacks by letting them grow towards each other in a table of size m . Suppose a random sequence of insertions and deletions are executed, with each instruction having a fixed probability p (0 > p > 1/2) to be a deletion. Let $A_p (m) denote the expected value of max{x,y, where x and y are the stack heights when the table first becomes full. We shall prove that, as $m \\rightarrow \\infty$, $A_p (m) = \\sqrt{m/(2 \\pi (1-2p)) + O((log m)/ \\sqrt{m)$. This gives a solution to an open problem in Knuth [\"The Art of Computer Programming, Vol. 1, Exercise 2.2.2-13]."
  },
  {
    "Title": "On fault-tolerant networks for sorting",
    "URL": "https://dl.acm.org/doi/book/10.5555/892209",
    "Full Abstract": "The study of constructing reliable systems from unreliable components goes back to the work of von Neumann, and of Moore and Shannon. The present paper studies the use of redundancy to enhance reliability for sorting and related networks built from unreliable comparators. Two models of fault-tolerant networks are discussed. The first model patterns after the concept of error-correcting codes in information theory, and the other follows the stochastic criterion used by von Neumann and Moore-Shannon. It is shown, for example, that an additional k(2n-3) comparators are sufficient to render a sorting network reliable, provided that no more than k of its comparators may be faulty."
  },
  {
    "Title": "An analysis of (h,k,l)-shellsort",
    "URL": "https://dl.acm.org/doi/book/10.5555/892211",
    "Full Abstract": "One classical sorting algorithm, whose performance in many cases remains unanalyzed, is Shellsort. Let $\\vec{h be a t-component vector of positive integers. An $\\vec{h$-Shellsort will sort any given n elements in t passes, by means of comparisons and exchanges of elements. Let $S_j$($\\vec{h$;n) denote the average number of element exchanges in the j-th pass, assuming that all the n! initial orderings are equally likely. In this paper we derive asymptotic formulas of $S_j$($\\vec{h$;n) for any fixed $\\vec{h$ = (h,k,l), making use of a new combinatorial interpretation of $S_3$. For the special case $\\vec{h$ = (3,2,1), the analysis if further sharpened to yield exact expressions."
  },
  {
    "Title": "A lower bound to finding convex hulls",
    "URL": "https://dl.acm.org/doi/book/10.5555/891707",
    "Full Abstract": "Given a set S of n distinct points {($x_i$,$y_i$) | 0 $\\leq$ i > n, the convex hull problem is to determine the vertices of the convex hull H(S). All the known algorithms for solving this problem have a worst-case running time of cn log n or higher, and employ only quadratic tests, i.e., tests of the form f($x_0$, $y_0$, $x_1$, $y_1$,...,$x_{n-1$, $y_{n-1$): 0 with f being any polynomial of degree not exceeding 2. In this paper, we show that any algorithm in the quadratic decision-tree model must make cn log n tests for some input."
  },
  {
    "Title": "Modeling probabilistic actions for practical decision-theoretic planning",
    "URL": "https://dl.acm.org/doi/10.5555/3036846.3036855",
    "Full Abstract": "Most existing decision-theoretic planners represent uncertainty about the state of the world with a precisely specified probability distribution over world states. This representation is not expressive enough to model many interesting classes of practical planning problems, and renders inapplicable some abstraction-based planning approaches. In this paper we propose as a remedy a more general world and action model with a well-founded semantics based on probability intervals. We introduce the concept of"
  },
  {
    "Title": "Sound abstraction of probabilistic actions in the constraint mass assignment framework",
    "URL": "https://dl.acm.org/doi/10.5555/2074284.2074311",
    "Full Abstract": "This paper provides a formal and practical framework for sound abstraction of probabilistic actions. We start by precisely defining the concept of sound abstraction within the context of finite-horizon planning (where each plan is a finite sequence of actions). Next we show that such abstraction cannot be performed within the traditional probabilistic action representation, which models a world with a single probability distribution over the state space. We then present the constraint mass assignment representation, which models the world with a set of probability distributions and is a generalization of mass assignment representations. Within this framework, we present sound abstraction procedures for three types of action abstraction. We end the paper with discussions and related work on sound and approximate abstraction. We give pointers to papers in which we discuss other sound abstraction-related issues, including applications, estimating loss due to abstraction, and automatically generating abstraction hierarchies."
  },
  {
    "Title": "Geometric foundations for interval-based probabilities",
    "URL": "https://dl.acm.org/doi/10.1023/A%3A1018936829318",
    "Full Abstract": "The need to reason with imprecise probabilities arises in a wealth of situations ranging from pooling of knowledge from multiple experts to abstractionýbased probabilistic planning. Researchers have typically represented imprecise probabilities using intervals and have developed a wide array of different techniques to suit their particular requirements. In this paper we provide an analysis of some of the central issues in representing and reasoning with interval probabilities. At the focus of our analysis is the probability crossýproduct operator and its interval generalization, the ccýoperator. We perform an extensive study of these operators relative to manipulation of sets of probability distributions. This study provides insight into the sources of the strengths and weaknesses of various approaches to handling probability intervals. We demonstrate the application of our results to the problems of inference in interval Bayesian networks and projection and evaluation of abstract probabilistic plans."
  },
  {
    "Title": "Efficiently ordering query plans for data integration",
    "URL": "https://dl.acm.org/doi/10.5555/3068476.3068482",
    "Full Abstract": "We describe Streamer, the query-reformulation component of a data integration system. Given a utility measure and a user query, Streamer uses abstraction-based refinement planning and exploits information on plan independence to produce, in decreasing order of utility, a set of plans that access data sources to obtain answers to the query. We then focus on plan coverage as an important utility measure. We show how to use statistic information about the domain and data sources to estimate plan coverage, and how to incorporate the plan-coverage framework into Streamer. In doing so, we provide the first method for effectively integrating the use of quantitative information into the query optimizer of a data-integration system. We present preliminary experimental results suggesting that Streamer runs an order of magnitude faster than brute-force plan-ordering methods, which are the only currently available methods to compute"
  },
  {
    "Title": "Reconciling schemas of disparate data sources",
    "URL": "https://dl.acm.org/doi/10.1145/375663.375731",
    "Full Abstract": "A data-integration system provides access to a multitude of data sources through a single mediated schema. A key bottleneck in building such systems has been the laborious manual construction of semantic mappings between the source schemas and the mediated schema. We describe LSD, a system that employs and extends current machine-learning techniques to semi-automatically find such mappings. LSD first asks the user to provide the semantic mappings for a small set of data sources, then uses these mappings together with the sources to train a set of learners. Each learner exploits a different type of information either in the source schemas or in their data. Once the learners have been trained, LSD finds semantic mappings for a new data source by applying the learners, then combining their predictions using a meta-learner. To further improve matching accuracy, we extend machine learning techniques so that LSD can incorporate domain constraints as an additional source of knowledge, and develop a novel learner that utilizes the structural information in XML documents. Our approach thus is distinguished in that it incorporates multiple types of knowledge. Importantly, its architecture is extensible to additional learners that may exploit new kinds of information. We describe a set of experiments on several real-world domains, and show that LSD proposes semantic mappings with a high degree of accuracy."
  },
  {
    "Title": "Learning to map between structured representations of data",
    "URL": "https://dl.acm.org/doi/book/10.5555/936674",
    "Full Abstract": "This dissertation studies"
  },
  {
    "Title": "Learning to map between ontologies on the semantic web",
    "URL": "https://dl.acm.org/doi/10.1145/511446.511532",
    "Full Abstract": "Ontologies play a prominent role on the Semantic Web. They make possible the widespread publication of machine understandable data, opening myriad opportunities for automated information processing. However, because of the Semantic Web's distributed nature, data on it will inevitably come from many different ontologies. Information processing across ontologies is not possible without knowing the semantic mappings between their elements. Manually finding such mappings is tedious, error-prone, and clearly not possible at the Web scale. Hence, the development of tools to assist in the ontology mapping process is crucial to the success of the Semantic Web.We describe"
  },
  {
    "Title": "Database research at the University of Illinois at Urbana-Champaign",
    "URL": "https://dl.acm.org/doi/10.1145/601858.601881",
    "Full Abstract": "Copyright © 2002 Authors."
  },
  {
    "Title": "Learning to Match the Schemas of Data Sources",
    "URL": "https://dl.acm.org/doi/10.1023/A%3A1021765902788",
    "Full Abstract": "The problem of integrating data from multiple data sources—either on the Internet or within enterprises—has received much attention in the database and AI communities. The focus has been on building data integration systems that provide a"
  },
  {
    "Title": "Object matching for information integration",
    "URL": "https://dl.acm.org/doi/10.5555/3104278.3104289",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Optimal Construction of Edge-Disjoint Paths in Random Graphs",
    "URL": "https://dl.acm.org/doi/10.1137/S0097539795290805",
    "Full Abstract": "Given a graph G=(V,E) with n vertices, m edges, and a family of $\\kappa$ pairs of vertices in"
  },
  {
    "Title": "A technique for measuring the relative size and overlap of public Web search engines",
    "URL": "https://dl.acm.org/doi/10.1016/S0169-7552%2898%2900127-5",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "The connectivity server",
    "URL": "https://dl.acm.org/doi/10.1016/S0169-7552%2898%2980047-0",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "A technique for measuring the relative size and overlap of public Web search engines",
    "URL": "https://dl.acm.org/doi/10.5555/297805.297863",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "The connectivity server",
    "URL": "https://dl.acm.org/doi/10.5555/297805.297941",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Dynamic Packet Routing on Arrays with Bounded Buffers",
    "URL": "https://dl.acm.org/doi/10.5555/646387.690185",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Min-wise independent permutations (extended abstract)",
    "URL": "https://dl.acm.org/doi/10.1145/276698.276781",
    "Full Abstract": "Copyright © 1998 ACM."
  },
  {
    "Title": "A Derandomization Using Min-Wise Independent Permutations",
    "URL": "https://dl.acm.org/doi/10.5555/646975.711400",
    "Full Abstract": "Min-wise independence is a recently introduced notion of limited independence, similar in spirit to pairwise independence. The later has proven essential for the derandomization of many algorithms. Here we show that approximate min-wise independence allows similar uses, by presenting a derandomization of the RNC algorithm for approximate set cover due to S. Rajagopalan and V. Vazirani. We also discuss how to derandomize their set multi-cover and multi-set multi-cover algorithms in restricted cases. The multi-cover case leads us to discuss the concept of"
  },
  {
    "Title": "Summary cache",
    "URL": "https://dl.acm.org/doi/10.1145/285237.285287",
    "Full Abstract": "The sharing of caches among Web proxies is an important technique to reduce Web traffic and alleviate network bottlenecks. Nevertheless it is not widely deployed due to the overhead of existing protocols. In this paper we propose a new protocol called \"Summary Cache\"; each proxy keeps a summary of the URLs of cached documents of each participating proxy and checks these summaries for potential hits before sending any queries. Two factors contribute to the low overhead: the summaries are updated only periodically, and the summary representations are economical --- as low as 8 bits per entry. Using trace-driven simulations and a prototype implementation, we show that compared to the existing Internet Cache Protocol (ICP), Summary Cache reduces the number of inter-cache messages by a factor of 25 to 60, reduces the bandwidth consumption by over 50%, and eliminates between 30% to 95% of the CPU overhead, while at the same time maintaining almost the same hit ratio as ICP. Hence Summary Cache enables cache sharing among a large number of proxies."
  },
  {
    "Title": "Information Retrieval on the Web",
    "URL": "https://dl.acm.org/doi/10.5555/795664.796468",
    "Full Abstract": "The Web explosion offers a bonanza of algorithmic problems. In particular, information retrieval in the web context requires methods and ideas that have not been addressed in the classic IR literature. This tutorial will survey emerging techniques for IR in the web context and discuss some of the pertinent open problems.The list of topics includes search engine technology, ranking and classification methods, web measurements (usage, size, connectivity), and new graph and data structure problems arising in the web IR context."
  },
  {
    "Title": "Static and dynamic path selection on expander graphs",
    "URL": "https://dl.acm.org/doi/10.5555/308215.308231",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Unscrambling address lines",
    "URL": "https://dl.acm.org/doi/10.5555/314500.315057",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Mirror, mirror on the Web",
    "URL": "https://dl.acm.org/doi/10.1016/S1389-1286%2899%2900021-3",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Finding anything in the billion page Web",
    "URL": "https://dl.acm.org/doi/10.5555/313009.313138",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Completeness and Robustness Properties of Min-Wise Independent Permutations",
    "URL": "https://dl.acm.org/doi/10.5555/646976.711541",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Min-Wise versus linear independence (extended abstract)",
    "URL": "https://dl.acm.org/doi/10.5555/338219.338246",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Improved classification via connectivity information",
    "URL": "https://dl.acm.org/doi/10.5555/338219.338610",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Min-Wise Independent Permutations",
    "URL": "https://dl.acm.org/doi/10.1006/jcss.1999.1690",
    "Full Abstract": "We define and study the notion of min-wise independent families of permutations. We say that F Sn (the symmetric group) is min-wise independent if for any set X n and any x X, when is chosen at random in F we havePr(min{ (X)= (x))=1|X| . In other words we require that all the elements of any fixed set X have an equal chance to become the minimum element of the image of X under . Our research was motivated by the fact that such a family (under some relaxations) is essential to the algorithm used in practice by the AltaVista web index software to detect and filter near-duplicate documents. However, in the course of our investigation we have discovered interesting and challenging theoretical questions related to this concept we present the solutions to some of them and we list the rest as open problems."
  },
  {
    "Title": "Graph structure in the Web",
    "URL": "https://dl.acm.org/doi/10.1016/S1389-1286%2800%2900083-9",
    "Full Abstract": "The study of the Web as a graph is not only fascinating in its own right, but also yields valuable insight into Web algorithms for crawling, searching and community discovery, and the sociological phenomena which characterize its evolution. We report on experiments on local and global properties of the Web graph using two AltaVista crawls each with over 200 million pages and 1.5 billion links. Our study indicates that the macroscopic structure of the Web is considerably more intricate than suggested by earlier experiments on a smaller scale."
  },
  {
    "Title": "Operating systems (2nd ed.)",
    "URL": "https://dl.acm.org/doi/book/10.5555/249000",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Locating objects in wide-area systems",
    "URL": "https://dl.acm.org/doi/10.1109/35.649334",
    "Full Abstract": "Locating mobile objects in a worldwide system requires a scalable location service. An object can be a telephone or a notebook computer, but also a software or data object, such as a file or an electronic document. Our service strictly separates an object's name from the addresses where it can be contacted. This is done by introducing a location-independent object handle. An object's name is bound to its unique object handle, which, in turn, is mapped to the addresses where the object can be contacted. To locate an object, we need only its object handle. We present a scalable location service based on a worldwide distributed search tree that adapts dynamically to an object's migration pattern to optimize lookups and updates"
  },
  {
    "Title": "A Framework for Consistent, Replicated Web Objects",
    "URL": "https://dl.acm.org/doi/10.5555/850926.851703",
    "Full Abstract": "Despite the extensive use of caching techniques, the Web is overloaded. While the caching techniques currently used help some, it would be better to use different caching and replication strategies for different Web pages, depending on their characteristics. We propose a framework in which such strategies can be devised independently per Web document.A Web document is constructed as a worldwide, scalable distributed Web object. Depending on the coherence requirements for that document, the most appropriate caching or replication strategy can subsequently be implemented and encapsulated by the Web object. Coherence requirements are formulated from two different perspectives: that of the Web object, and that of clients using the Web object. We have developed a prototype in Java to demonstrate the feasibility of implementing different strategies for different Web objects."
  },
  {
    "Title": "Replicated invocations in wide-area systems",
    "URL": "https://dl.acm.org/doi/10.1145/319195.319215",
    "Full Abstract": "Copyright © 1998 ACM."
  },
  {
    "Title": "Structured Computer Organization",
    "URL": "https://dl.acm.org/doi/book/10.5555/552473",
    "Full Abstract": "From the Publisher:"
  },
  {
    "Title": "Globe",
    "URL": "https://dl.acm.org/doi/10.1109/4434.749137",
    "Full Abstract": "Developing large-scale wide-area applications requires an infrastructure that is presently lacking. Currently, most Internet applications have to be built on top of raw communication services, such as TCP connections. All additional services, including those for naming, replication, migration, persistence, fault tolerance, and security, have to be implemented for each application anew. Not only is this a waste of effort, it also makes interoperability between different applications difficult or even impossible. The authors present a novel, object-based framework for developing wide-area distributed applications. The framework is based on the concept of a distributed shared object, which has the characteristic feature that its state can be physically distributed across multiple machines at the same time. All implementation aspects, including communication protocols, replication strategies, and distribution and migration of state, are part of each object and are hidden behind its interface. The current performance problems of the World-Wide Web are taken as an example to illustrate the benefit of encapsulating state, operations, and implementation strategies on a per-object basis. The authors describe how distributed objects can be used to implement worldwide scalable Web documents."
  },
  {
    "Title": "A Security Design for a Wide-Area Distributed System",
    "URL": "https://dl.acm.org/doi/10.5555/646281.687819",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "From Remote Objects to Physically Distributed Objects",
    "URL": "https://dl.acm.org/doi/10.5555/795674.797051",
    "Full Abstract": "Present-day object-oriented middleware provides little support for the distribution, replication and caching of the state of a distributed object. This makes these platforms unsuitable for the development of large-scale distributed applications. We argue that the model of distributed objects on which these middleware platforms are based hinders the addition of comprehensive distribution and replication support to these platforms. We present an alternative view of distributed objects, in which objects are not only in control of the functional aspects of their implementation but also in control of their nonfunctional aspects, in particular, the distribution and replication of their state. We claim that a middleware platform based on this view of distributed objects is better suited for developing the large-scale applications of the future."
  },
  {
    "Title": "The globe distribution network",
    "URL": "https://dl.acm.org/doi/10.5555/1267724.1267765",
    "Full Abstract": "The goal of the Globe project is to design and build a middleware platform that facilitates the development of large-scale distributed applications, such as those found on the Internet. To demonstrate the feasibility of our design and to test our ideas, we are currently building a new Internet application: The Globe Distribution Network. The Globe Distribution Network, or GDN, is an application for the efficient, worldwide distribution of free software and other free data. The GDN can be seen as an improvement to anonymous FTP and the World Wide Web due to its flexibility and extensive support for replication. This paper describes the design of the GDN. We start by explaining how the replication facilities of the Globe middleware are used to make the GDN efficient, and how these facilities are implemented. Next, we present the architecture of the GDN and discuss how the Domain Name System can be used as a first approach towards a worldwide service for naming software packages and other entities. This is followed by an analysis of the security requirements for the GDN and measures taken to satisfy these requirements. We hope to make Globe and GDN itself available for free under the BSD license by 2001."
  },
  {
    "Title": "A Law-Abiding Peer-to-Peer Network for Free-Software Distribution",
    "URL": "https://dl.acm.org/doi/10.5555/580585.883129",
    "Full Abstract": "The Globe Distribution Network (GDN) is an application for worldwide distribution of freely redistributable software packages. The GDN takes a novel, optimistic approach to stop the illegal distribution of copyrighted and illicit material via the network. Instead of having moderators check the software archives at upload time, illegal content is removed and its uploader's access to the network permanently revoked only when the content is discovered. An important feature of the GDN is that the objects containing the software can run on untrustworthy servers. A first version of the GDN has been implemented and has been running since October 2000 across four European sites."
  },
  {
    "Title": "Scalable Human-Friendly Resource Names",
    "URL": "https://dl.acm.org/doi/10.1109/4236.957891",
    "Full Abstract": "Currently, Uniform Resource Locators (URLs) are used to name and access Web-based resources. However, URLs pose a significant scalability problem because they cannot be used to refer to replicated Web pages. The authors propose a new URI scheme called Human-Friendly Names (HFNs) to solve this scalability problem. HFNs are high-level names that are easy-to-use by humans and name Web resources in a location-independent way. This article describes a scalable HFN-to-URL resolution mechanism that is based on URNs and makes use of the Domain Name System (DNS) and the Globe Location Service."
  },
  {
    "Title": "Distributed Systems",
    "URL": "https://dl.acm.org/doi/book/10.5555/559404",
    "Full Abstract": "From the Publisher: Andrew Tanenbaum and Maarten van Steen cover the principles, advanced concepts, and technologies of distributed systems in detail, including: communication, replication, fault tolerance, and security. Intended for use in a senior/graduate level distributed systems course or by professionals, this text systematically shows how distributed systems are designed and implemented in real systems. Written in the superb writing style of other Tanenbaum books, the material also features unique accessibility and a wide variety of real-world examples and case studies, such as NFS v4, CORBA, DOM, Jini, and the World Wide Web. FEATURES Detailed coverage of seven key principles. An introductory chapter followed by a chapter devoted to each key principle: communication, processes, naming, synchronization, consistency and replication, fault tolerance, and security, including unique comprehensive coverage of middleware models. Four chapters devoted to state-of-the-art real-world examples of middleware. Covers object-based systems, document-based systems, distributed file systems, and coordination-based systems including CORBA, DCOM, Globe, NFS v4, Coda, the World Wide Web, and Jini. Excellent coverage of timely, advanced, distributed systems topics: Security, payment systems, recent Internet and Web protocols, scalability, and caching and replication. NEW-The Prentice Hall Companion Website for this book contains PowerPoint slides, figures in various file formats, and other teaching aids, and a link to the author's Web site."
  },
  {
    "Title": "The distributed ASCI Supercomputer project",
    "URL": "https://dl.acm.org/doi/10.1145/506106.506115",
    "Full Abstract": "The Distributed ASCI Supercomputer (DAS) is a homogeneous wide-area distributed system consisting of four cluster computers at different locations. DAS has been used for research on communication software, parallel languages and programming systems, schedulers, parallel applications, and distributed applications. The paper gives a preview of the most interesting research results obtained so far in the DAS project."
  },
  {
    "Title": "Disallowing Unauthorized State Changes of Distributed Shared Objects",
    "URL": "https://dl.acm.org/doi/10.5555/647183.719499",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Modern Operating Systems",
    "URL": "https://dl.acm.org/doi/book/10.5555/516975",
    "Full Abstract": "From the Publisher: FEATURES \\ NEWNew chapters on computer security, multimedia operating systems, and multiple processor systems. NEWExtensive coverage of Linux, UNIX&#174;, and Windows 2000&#8482; as examples. NEWNow includes coverage of graphical user interfaces, multiprocessor operating systems, trusted systems, viruses, network terminals, CD-ROM file systems, power management on laptops, RAID, soft timers, stable storage, fair-share scheduling, three-level scheduling, and new paging algorithms. NEWMost chapters have a new section on current research on the chapter's topic. NEWFocus on single-processor computer systems; a new book for a follow-up course on distributed systems is also available from Prentice Hall. NEWOver 200 references to books and papers published since the first edition. NEWThe Web site for this book contains PowerPoint slides, simulators, figures in various formats, and other teaching aids."
  },
  {
    "Title": "Differentiated strategies for replicating Web documents",
    "URL": "https://dl.acm.org/doi/10.1016/S0140-3664%2800%2900319-4",
    "Full Abstract": "Replicating Web documents reduces user-perceived delays and wide-area network traffic. Numerous caching and replication protocols have been proposed to manage such replication while keeping the document copies consistent. We claim, however, that no single caching or replication policy can efficiently manage all documents. Instead, we propose that each document be replicated with a policy specifically tailored to it. We have collected traces on our university's Web server and conducted simulations to determine the performance such tailored policies would produce, as opposed to using the same policy for all documents. The results show a significant performance improvement with respect to end-user delays, wide-area network traffic and document consistency. We also present how these results can be used to build adaptive replicated Web documents, capable of automatically selecting the policy that best suits them."
  },
  {
    "Title": "Experiences with the amoeba distributed operating system",
    "URL": "https://dl.acm.org/doi/10.5555/360596.360643",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Dynamically Selecting Optimal Distribution Strategies for Web Documents",
    "URL": "https://dl.acm.org/doi/10.1109/TC.2002.1009149",
    "Full Abstract": "To improve the scalability of the Web, it is common practice to apply caching and replication techniques. Numerous strategies for placing and maintaining multiple copies of Web documents at several sites have been proposed. These approaches essentially apply a global strategy by which a single family of protocols is used to choose replication sites and keep copies mutually consistent. We propose a more flexible approach by allowing each distributed document to have its own associated strategy. We propose a method for assigning an optimal strategy to each document separately and prove that it generates a family of optimal results. Using trace-based simulations, we show that optimal assignments clearly outperform any global strategy. We have designed an architecture for supporting documents that can dynamically select their optimal strategy and evaluate its feasibility."
  },
  {
    "Title": "Access control, reverse access control and replication control in a world wide distributed system",
    "URL": "https://dl.acm.org/doi/10.5555/647802.737168",
    "Full Abstract": "No abstract available."
  }
]
