[
  {
    "Title": "Computing 2002",
    "URL": "https://dl.acm.org/doi/10.1145/543812.543816",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Approaching utopia",
    "URL": "https://dl.acm.org/doi/10.1145/2422436.2422463",
    "Full Abstract": "We introduce and study strongly truthful mechanisms and their applications. We use strongly truthful mechanisms as a tool for implementation in undominated strategies for several problems, including the design of externality resistant auctions and a variant of multi-dimensional scheduling."
  },
  {
    "Title": "Advances in Knowledge Discovery and Data Mining",
    "URL": "https://dl.acm.org/doi/book/10.5555/2821229",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Advances in Knowledge Discovery and Data Mining",
    "URL": "https://dl.acm.org/doi/book/10.5555/2821283",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Interactive Theorem Proving and Program Development",
    "URL": "https://dl.acm.org/doi/book/10.5555/993954",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Visualizing Geometrical Statements with GeoView",
    "URL": "https://dl.acm.org/doi/10.1016/j.entcs.2004.09.013",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "A structured approach to proving compiler optimizations based on dataflow analysis",
    "URL": "https://dl.acm.org/doi/10.1007/11617990_5",
    "Full Abstract": "This paper reports on the correctness proof of compiler optimizations based on data-flow analysis. We formulate the optimizations and analyses as instances of a general framework for data-flow analyses and transformations, and prove that the optimizations preserve the behavior of the compiled programs. This development is a part of a larger effort of certifying an optimizing compiler by proving semantic equivalence between source and compiled code."
  },
  {
    "Title": "Filters on coinductive streams, an application to eratosthenes' sieve",
    "URL": "https://dl.acm.org/doi/10.1007/11417170_9",
    "Full Abstract": "We present the formal description of an algorithm to filter values from an infinite steam using a type theory based prover. The key aspect is that filters are partial co-recursive functions and we solve the problem of expressing partiality. We then show how to prove properties of this filter algorithm and we study an application computing the stream of all prime numbers."
  },
  {
    "Title": "Dependent Types, Theorem Proving, and Applications for a Verifying Compiler",
    "URL": "https://dl.acm.org/doi/10.1007/978-3-540-69149-5_19",
    "Full Abstract": "One approach to Prof. Hoare's challenge is to view the development of verified software from the perspective of interactive theorem provers. This idea is not new and many medium-scale software systems have been developed and verified in this manner. Developments based on HOL, ACL2, or PVS have already been described and advocated and our position stands on the same line: most powerful (higher-order) theorem proving systems already contain a programming language, programs can be developed and the correctness of these programs can be specified and verified, they can then be compiled into traditional executable code. In this sense, we already have a small scale example of a verification aware programming language."
  },
  {
    "Title": "Affine functions and series with co-inductive real numbers",
    "URL": "https://dl.acm.org/doi/10.1017/S0960129506005809",
    "Full Abstract": "We extend the work of A. Ciaffaglione and P. di Gianantonio on the mechanical verification of algorithms for exact computation on real numbers, using infinite streams of digits implemented as a co-inductive type. Four aspects are studied. The first concerns the proof that digit streams correspond to axiomatised real numbers when they are already present in the proof system. The second re-visits the definition of an addition function, looking at techniques to let the proof search engine perform the effective construction of an algorithm that is correct by construction. The third concerns the definition of a function to compute affine formulas with positive rational coefficients. This is an example where we need to combine co-recursion and recursion. Finally, the fourth aspect concerns the definition of a function to compute series, with an application on the series that is used to compute Euler's number"
  },
  {
    "Title": "Inductive and Coinductive Components of Corecursive Functions in Coq",
    "URL": "https://dl.acm.org/doi/10.1016/j.entcs.2008.05.018",
    "Full Abstract": "In Constructive Type Theory, recursive and corecursive definitions are subject to syntactic restrictions which guarantee termination for recursive functions and productivity for corecursive functions. However, many terminating and productive functions do not pass the syntactic tests. Bove proposed in her thesis an elegant reformulation of the method of accessibility predicates that widens the range of terminative recursive functions formalisable in Constructive Type Theory. In this paper, we pursue the same goal for productive corecursive functions. Notably, our method of formalisation of coinductive definitions of productive functions in Coq requires not only the use of ad-hoc predicates, but also a systematic algorithm that separates the inductive and coinductive parts of functions."
  },
  {
    "Title": "Fixed point semantics and partial recursion in Coq",
    "URL": "https://dl.acm.org/doi/10.1145/1389449.1389461",
    "Full Abstract": "We propose to use the Knaster-Tarski least fixed point theorem as a basis to define recursive functions in the Calculus of Inductive Constructions. This widens the class of functions that can be modelled in type-theory based theorem proving tools to potentially nonterminating functions. This is only possible if we extend the logical framework by adding some axioms of classical logic.We claim that the extended framework makes it possible to reason about terminating or non-terminating computations and we show that extraction can also be extended to handle the new functions"
  },
  {
    "Title": "Canonical Big Operators",
    "URL": "https://dl.acm.org/doi/10.1007/978-3-540-71067-7_11",
    "Full Abstract": "In this paper, we present an approach to describe uniformly iterated \"big\" operations, like $\\sum_{i=0}^n f(i)$ or max"
  },
  {
    "Title": "On relations between input and communication/computation in VLSI",
    "URL": "https://dl.acm.org/doi/10.1109/SFCS.1981.26",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Visual Abstractions for Temporal Verification",
    "URL": "https://dl.acm.org/doi/10.5555/646059.678540",
    "Full Abstract": "Generalized Verification Diagrams combine deductive and algorithmic verification to establish general temporal properties of finite-and infinite-state reactive systems. The diagram serves as an abstraction of the system. This abstraction is deductively justified and algorithmically model checked. We present a new simple class of verification diagrams, using Müller acceptance conditions, and show how they can be used to verify general temporal properties of reactive systems."
  },
  {
    "Title": "Visual Verification of Temporal Properties",
    "URL": "https://dl.acm.org/doi/10.5555/832247.832527",
    "Full Abstract": "The deductive approach to verifying temporal properties of reactive systems is based on verification rules, which reduce the system validity of a temporal property to the general validity of first-order verification conditions. This methodology is complete relative to the underlying first-order reasoning. However, the proofs can be difficult to construct and understand, particularly as the complexity of the system increases.We have developed diagram-based formalisms for the verification of general temporal properties of reactive, real-time and hybrid systems. A diagram is a visual abstraction of the system to be verified; it represents the aspects of the system relevant to the property to be proved. The diagram represents a schematic overview of a deductive proof, and therefore it is more intuitive and easier to construct and understand.These methods combine deductive and algorithmic verification, and are being extended to include modularity, abstraction and refinement to facilitate the verification of larger, more complex systems."
  },
  {
    "Title": "Implementation of an interpreter for a parallel language in Centaur",
    "URL": "https://dl.acm.org/doi/10.5555/92011.92016",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Implementation of an Interpreter for a Parallel Language in Centaur",
    "URL": "https://dl.acm.org/doi/10.5555/645388.651572",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Occurrences in debugger specifications",
    "URL": "https://dl.acm.org/doi/10.1145/113446.113473",
    "Full Abstract": "Copyright © 1991 ACM."
  },
  {
    "Title": "Origin Functions in Lambda-Calculus and Term Rewriting Systems",
    "URL": "https://dl.acm.org/doi/10.5555/648221.751377",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Real theorem provers deserve real user-interfaces",
    "URL": "https://dl.acm.org/doi/10.1145/142868.143760",
    "Full Abstract": "This paper explains how to add a modern user interface to existing theorem provers, using principles and tools designed for programming environments."
  },
  {
    "Title": "A canonical calculus of residuals",
    "URL": "https://dl.acm.org/doi/10.5555/185881.185911",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Proof by Pointing",
    "URL": "https://dl.acm.org/doi/10.5555/645868.668515",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Reasoning with Executable Specifications",
    "URL": "https://dl.acm.org/doi/10.5555/646619.697409",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "CtCoq",
    "URL": "https://dl.acm.org/doi/10.5555/646057.678192",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Program Checkers for Probability Generation",
    "URL": "https://dl.acm.org/doi/10.5555/646245.684535",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Combining dimensionality and rate of growth arguments for establishing lower bounds on the number of multiplications",
    "URL": "https://dl.acm.org/doi/10.1145/800119.803912",
    "Full Abstract": "In this paper we describe a new method for establishing lower bounds for the number of multiplications and divisions required to compute rational functions. We shall start by reminding the reader of some standard notations."
  },
  {
    "Title": "Verification of parameterized programs",
    "URL": "https://dl.acm.org/doi/10.5555/233976.233988",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Automatic Generation of Invariants and Assertions",
    "URL": "https://dl.acm.org/doi/10.5555/647484.760398",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Temporal verification of reactive systems",
    "URL": "https://dl.acm.org/doi/book/10.5555/211468",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "STeP: The Stanford Temporal Prover (Educational Release) User''s Manual",
    "URL": "https://dl.acm.org/doi/book/10.5555/892587",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Generalized Temporal Verification Diagrams",
    "URL": "https://dl.acm.org/doi/10.5555/646833.708045",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Clocked Transition Systems",
    "URL": "https://dl.acm.org/doi/book/10.5555/892591",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Verifying clocked transition systems",
    "URL": "https://dl.acm.org/doi/10.5555/239587.239589",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "STeP",
    "URL": "https://dl.acm.org/doi/10.5555/647765.735848",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Temporal Verification by Diagram Transformations",
    "URL": "https://dl.acm.org/doi/10.5555/647765.735983",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Deductive Model Checking",
    "URL": "https://dl.acm.org/doi/10.5555/647765.735990",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Verification of Clocked and Hybrid Systems",
    "URL": "https://dl.acm.org/doi/10.5555/647870.737275",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Design considerations for microprogramming languages",
    "URL": "https://dl.acm.org/doi/10.1145/1500175.1500283",
    "Full Abstract": "Historically, microprograms have been developed using tools which are appropriate to logic designers (block diagrams, register transfer languages), or systems programmers (microcode assemblers). With the growth of user microprogramming, and the increased demands placed upon computer manufacturers for firmware support, improved tools and techniques have been suggested. In particular, microprogram compilers, i.e., compilers which translate high level source statements into sequences of microprogram control words, have been proposed and implemented. The larger issue to be faced is the nebulous task of supporting the needs of a community which includes:"
  },
  {
    "Title": "On Parallel Computation for the Knapsack Problem",
    "URL": "https://dl.acm.org/doi/10.1145/322326.322342",
    "Full Abstract": "Copyright © 1982 ACM."
  },
  {
    "Title": "Fundamentals of Deductive Program Synthesis",
    "URL": "https://dl.acm.org/doi/10.1109/32.153379",
    "Full Abstract": "An informal tutorial for program synthesis is presented, with an emphasis on deductive methods. According to this approach, to construct a program meeting a given specification, the authors prove the existence of an object meeting the specified conditions. The proof is restricted to be sufficiently constructive, in the sense that, in establishing the existence of the desired output, the proof is forced to indicate a computational method for finding it. That method becomes the basis for a program that can be extracted from the proof. The exposition is based on the deductive-tableau system, a theorem-proving framework particularly suitable for program synthesis. The system includes a nonclausal resolution rule, facilities for reasoning about equality, and a well-founded induction rule."
  },
  {
    "Title": "Time for Concurrency",
    "URL": "https://dl.acm.org/doi/10.5555/646324.756790",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Verifying Hybrid Systems",
    "URL": "https://dl.acm.org/doi/10.5555/646874.709969",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Towards Refining Temporal Specifications into Hybrid Systems",
    "URL": "https://dl.acm.org/doi/10.5555/646874.709981",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "The deductive foundations of computer programming",
    "URL": "https://dl.acm.org/doi/book/10.5555/174817",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Temporal Verification of Simulation and Refinement",
    "URL": "https://dl.acm.org/doi/10.5555/648145.750144",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "A Decision Algorithm for Full Propositional Temporal Logic",
    "URL": "https://dl.acm.org/doi/10.5555/647762.735505",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Models for reactivity",
    "URL": "https://dl.acm.org/doi/10.5555/2697441.2697671",
    "Full Abstract": "A hierarchy of models that capture realistic aspects of reactive, real-time, and hybrid systems is introduced. On the most abstract level, the qualitative (non-quantitative) model of"
  },
  {
    "Title": "Temporal Verification Diagrams",
    "URL": "https://dl.acm.org/doi/10.5555/645868.670943",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "STeP: The Stanford Temporal Prover",
    "URL": "https://dl.acm.org/doi/book/10.5555/891757",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Beyond Model Checking",
    "URL": "https://dl.acm.org/doi/10.5555/647763.735670",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "A compact data structure for storing, retrieving and manipulating line drawings",
    "URL": "https://dl.acm.org/doi/10.1145/1465482.1465580",
    "Full Abstract": "The field of graphical man/machine interaction is customarily split into hardware and software areas. The former can be considered to have come of age: there are over twenty-five brands of off-the-shelf consoles with all the requisite input devices, and new techniques and improvements are constantly being developed. Many consoles are also provided with primitive supporting software which allow one to draw points, lines, arcs, etc., in a symbolic language of some sort. Less well understood and developed, however, is that aspect of display software concerned with representing and manipulating the problem model from which these primitive point/line/arc pictures are derived. The \"data structure\" is the machine representation of the often complex and hierarchical problem model. It must be judiciously derived from the model on the one hand and, on the other, lead readily to the reduced console display file of points, lines and arcs which cause the actual visual display. Furthermore, the data structure must be efficiently stored and processed (usually contradictory requirements)."
  },
  {
    "Title": "Data and storage structures for interactive graphics",
    "URL": "https://dl.acm.org/doi/10.1145/1115880.1115891",
    "Full Abstract": "This is a tutorial paper that shows the relationship between the data structure and the rest of an interactive graphics system. The distinction between data structures and storage structures is emphasized, as is the problem of data structure segmentation. The implementation of typical graphical applications is described, along with analysis of various trade-off decisions. Finally, some high-level data structure specification languages are discussed."
  },
  {
    "Title": "On the average-case complexity of selecting the k-th best",
    "URL": "https://dl.acm.org/doi/book/10.5555/892214",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Completing the temporal picture",
    "URL": "https://dl.acm.org/doi/book/10.5555/892484",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "The logical basis for computer programming: vol. 2, deductive systems",
    "URL": "https://dl.acm.org/doi/book/10.5555/78091",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Nonclausal deduction in first-order temporal logic",
    "URL": "https://dl.acm.org/doi/10.1145/77600.77617",
    "Full Abstract": "This paper presents a proof system for first-order temporal logic. The system extends the nonclausal resolution method for ordinary first-order logic with equality, to handle quantifiers and temporal operators. Soundness and completeness issues are considered. The use of the system for verifying concurrent programs is discussed and variants of the system for other modal logics are also described."
  },
  {
    "Title": "Tools and rules for the practicing verifier",
    "URL": "https://dl.acm.org/doi/book/10.5555/892493",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "An exercise in the verification of multi-process programs",
    "URL": "https://dl.acm.org/doi/10.5555/119872.119905",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "A hierarchy of temporal properties (invited paper, 1989)",
    "URL": "https://dl.acm.org/doi/10.1145/93385.93442",
    "Full Abstract": "Copyright © 1990 ACM."
  },
  {
    "Title": "An interleaving model for real time.",
    "URL": "https://dl.acm.org/doi/book/10.5555/892496",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "An interleaving model for real time",
    "URL": "https://dl.acm.org/doi/10.5555/100512.100633",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "A temporal proof methodology for reactive systems",
    "URL": "https://dl.acm.org/doi/10.5555/100512.100637",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Temporal proof methodologies for real-time systems",
    "URL": "https://dl.acm.org/doi/10.1145/99583.99629",
    "Full Abstract": "Copyright © 1991 ACM."
  },
  {
    "Title": "Timed Transition Systems",
    "URL": "https://dl.acm.org/doi/10.5555/648143.749987",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Experience with a regular expression compiler",
    "URL": "https://dl.acm.org/doi/book/10.5555/892299",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Competitive snoopy caching",
    "URL": "https://dl.acm.org/doi/10.1109/SFCS.1986.14",
    "Full Abstract": "In a snoopy cache multiprocessor system, each processor has a cache in which it stores blocks of data. Each cache is connected to a bus used to communicate with the other caches and with main memory. For several of the proposed models of snoopy caching, we present new on-line algorithms which decide, for each cache, which blocks to retain and which to drop in order to minimize communication over the bus. We prove that, for any sequence of operations, our algorithms' communication costs are within a constant factor of the minimum required for that sequence; for some of our algorithms we prove that no on-line algorithm has this property with a smaller constant."
  },
  {
    "Title": "From Timed to Hybrid Systems",
    "URL": "https://dl.acm.org/doi/10.5555/648143.749988",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "A study of concrete computational complexity.",
    "URL": "https://dl.acm.org/doi/book/10.5555/907570",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "On computing the minima of quadratic forms (Preliminary Report)",
    "URL": "https://dl.acm.org/doi/10.1145/800116.803749",
    "Full Abstract": "The following problem was recently raised by C. William Gear [1]: Let F(x"
  },
  {
    "Title": "Special relations in automated deduction",
    "URL": "https://dl.acm.org/doi/10.1145/4904.4905",
    "Full Abstract": "Two deduction rules are introduced to give streamlined treatment to relations of special importance in an automated theorem-proving system. These rules, the"
  },
  {
    "Title": "A timely resolution",
    "URL": "https://dl.acm.org/doi/book/10.5555/892378",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Model theorem proving",
    "URL": "https://dl.acm.org/doi/book/10.5555/892375",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "How to Clear a Block",
    "URL": "https://dl.acm.org/doi/10.5555/648227.749317",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Modal Theorem Proving",
    "URL": "https://dl.acm.org/doi/10.5555/648227.751971",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "A deductive approach to program synthesis",
    "URL": "https://dl.acm.org/doi/10.5555/31870.31871",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Modal theorem proving",
    "URL": "https://dl.acm.org/doi/10.5555/22289.22302",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "How to clear a block: plan formation in situational logic",
    "URL": "https://dl.acm.org/doi/10.5555/22289.22337",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Specification and Verification of Concurrent Programs by forall-Automata",
    "URL": "https://dl.acm.org/doi/10.5555/647236.720395",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "The deductive synthesis of imperative LISP programs",
    "URL": "https://dl.acm.org/doi/10.5555/1856670.1856698",
    "Full Abstract": "A framework is described for the automatic synthesis of imperative programs, which may alter data structures and produce destructive side effects as part of their intended behavior. A program meeting a given specification is extracted from the proof of a theorem in a variant of situational logic, in which the states of a computation are explicit objects. As an example, an in-place reverse program has been derived in an imperative LISP, which includes assignment and destructive list operations (rplaca and rplacd)."
  },
  {
    "Title": "The deductive synthesis of imperative LISP programs",
    "URL": "https://dl.acm.org/doi/10.5555/1863696.1863724",
    "Full Abstract": "A framework is described for the automatic synthesis of imperative programs, which may alter data structures and produce destructive side effects as part of their intended behavior. A program meeting a given specification is extracted from the proof of a theorem in a variant of situational logic, in which the states of a computation are explicit objects. As an example, an in-place reverse program has been derived in an imperative LISP, which includes assignment and destructive list operations (rplaca and rplacd)."
  },
  {
    "Title": "The origin of a binary-search paradigm",
    "URL": "https://dl.acm.org/doi/10.1016/0167-6423%2887%2990025-6",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "A Hierarchy of Temporal Properties",
    "URL": "https://dl.acm.org/doi/book/10.5555/892426",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Scheduling Unit-Time Tasks with Limited Resources",
    "URL": "https://dl.acm.org/doi/10.5555/647406.724133",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Specification and verification of concurrent programs by A ∀ automata",
    "URL": "https://dl.acm.org/doi/10.1145/41625.41626",
    "Full Abstract": "∀-automata are non-deterministic finite-state automata over infinite sequences. They differ from conventional automata in that a sequence is accepted if"
  },
  {
    "Title": "How to clear a block: A theory of plans",
    "URL": "https://dl.acm.org/doi/10.5555/41391.41392",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "A hardware semantics based on temporal intervals",
    "URL": "https://dl.acm.org/doi/book/10.5555/892293",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Proving precedence properties: the temporal way",
    "URL": "https://dl.acm.org/doi/book/10.5555/892294",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Verification of concurrent programs: a temporal proof system",
    "URL": "https://dl.acm.org/doi/book/10.5555/892296",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Reasoning in Interval Temporal Logic",
    "URL": "https://dl.acm.org/doi/10.5555/648064.747582",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Reasoning in interval temporal logic",
    "URL": "https://dl.acm.org/doi/book/10.5555/892297",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "A Hardware Semantics Based on Temporal Intervals",
    "URL": "https://dl.acm.org/doi/10.5555/646237.683015",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Proving Precedence Properties",
    "URL": "https://dl.acm.org/doi/10.5555/646237.683020",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "The temporal logic of branching time",
    "URL": "https://dl.acm.org/doi/10.1007/BF01257083",
    "Full Abstract": "A temporal logic is defined which contains both linear and branching operators. The underlying model is the tree of all possible computations. The following metatheoretical results are proven: 1) an exponential decision procedure for satisfiability; 2) a finite model property; 3) the completeness of an axiomatization."
  },
  {
    "Title": "Synthesis of Communicating Processes from Temporal Logic Specifications",
    "URL": "https://dl.acm.org/doi/10.1145/357233.357237",
    "Full Abstract": "Copyright © 1984 ACM."
  },
  {
    "Title": "Adequate proof principles for invariance and liveness properties of concurrent programs",
    "URL": "https://dl.acm.org/doi/book/10.5555/892313",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "TABLOG: the deductive-tableau programming language",
    "URL": "https://dl.acm.org/doi/book/10.5555/892317",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "TABLOG",
    "URL": "https://dl.acm.org/doi/10.1145/800055.802049",
    "Full Abstract": "TABLOG (Tableau Logic Programming Language) is a language combining functional and logic programming using first-order (quantifier-free) predicate logic with equality. TABLOG incorporates advantages of LISP and PROLOG."
  },
  {
    "Title": "Adequate proof principles for invariance and liveness properties of concurrent programs",
    "URL": "https://dl.acm.org/doi/10.1016/0167-6423%2884%2990003-0",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "The logical basis for computer programming. Volume 1:  deductive reasoning",
    "URL": "https://dl.acm.org/doi/book/10.5555/3510",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Special relations in automated deduction",
    "URL": "https://dl.acm.org/doi/book/10.5555/892351",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Nonclausal temporal deduction",
    "URL": "https://dl.acm.org/doi/book/10.5555/892354",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Nonclausal Temporal Deduction",
    "URL": "https://dl.acm.org/doi/10.5555/648065.747731",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Special Relations in Automated Deduction",
    "URL": "https://dl.acm.org/doi/10.5555/646239.683367",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Structured programming with recursion",
    "URL": "https://dl.acm.org/doi/book/10.5555/892162",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Is “sometime” sometimes better than “always”?",
    "URL": "https://dl.acm.org/doi/10.1145/359340.359353",
    "Full Abstract": "This paper explores a technique for proving the correctness and termination of programs simultaneously. This approach, the"
  },
  {
    "Title": "Proving termination and multiset orderings",
    "URL": "https://dl.acm.org/doi/book/10.5555/892168",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Inference rules for program annotation",
    "URL": "https://dl.acm.org/doi/10.5555/800099.803206",
    "Full Abstract": "Methods are presented whereby an Algol-like program, given together with its specifications, can be documented automatically. The program is incrementally annotated with invariant relationships that hold between program variables at intermediate points in the program and explain the actual workings of the program regardless of whether the program is correct. Thus this documentation can be used for proving the correctness of the program or may serve as an aid in the debugging of an incorrect program."
  },
  {
    "Title": "The synthesis of structure-changing programs",
    "URL": "https://dl.acm.org/doi/10.5555/800099.803208",
    "Full Abstract": "Deductive techniques are presented for deriving programs systematically from given specifications. The specifications express the purpose of the desired program without giving any hint of the algorithm to be employed. The desired program is intended to achieve this purpose by means of such low-level primitives as assignment statements, the conditional statements, and recursion. The basic approach is to transform the specifications repeatedly according to certain rules, until a satisfactory program is produced. The rules are guided by a number of strategic controls."
  },
  {
    "Title": "A deductive approach to program synthesis",
    "URL": "https://dl.acm.org/doi/book/10.5555/892190",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "The translation of 'go to' programs to 'while' programs",
    "URL": "https://dl.acm.org/doi/10.5555/1241515.1241521",
    "Full Abstract": "Some of the papers presented in this book already have been widely circulated; others were published in well-known journals, like IBM Systems Journal but largely were ignored when they first appeared; and then there are the obscure papers like this one by Ashcroft and Manna, which was presented at the 1971 IFIP Conference in Ljubljana, Yugoslavia. It's not that the ideas in the paper are obscure -- it's just that very few people in the mainstream EDP community attended the Conference, and precious few copies of the conference proceedings ever found their way into American libraries. It is, however, a paper that many people over the years have wanted to read, particularly since it deals with a subject also mentioned by Knuth (\"Structured Programming with go to State, ments\" [see Paper 20]), Wulf (\"A Case Against the GOTO\" [Paper 8]), and Böm and Jacopini (\"Flow Diagrams, Turing Machines and Languages with Only Two Formation Rules\" [Paper 2])."
  },
  {
    "Title": "The Modal Logic of Programs",
    "URL": "https://dl.acm.org/doi/10.5555/646233.682234",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Proving termination with Multiset Orderings",
    "URL": "https://dl.acm.org/doi/10.5555/646233.682248",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Proving termination with multiset orderings",
    "URL": "https://dl.acm.org/doi/10.1145/359138.359142",
    "Full Abstract": "A common tool for proving the termination of programs is the"
  },
  {
    "Title": "A deductive approach to program synthesis",
    "URL": "https://dl.acm.org/doi/10.5555/1624861.1624985",
    "Full Abstract": "Program synthesis is the systematic derivation of a program from a given specification. A deductive approach to program synthesis is presented for the construction of recursive programs. This approach regards program synthesis as a theorem-proving task and relies on a theorem-proving method that combines the features of transformation rules, unification, and mathematical induction within a single framework."
  },
  {
    "Title": "A Deductive Approach to Program Synthesis",
    "URL": "https://dl.acm.org/doi/10.1145/357084.357090",
    "Full Abstract": "Program synthesis is the systematic derivation of a program from a given specification. A deductive approach to program synthesis is presented for the construction of recursive programs. This approach regards program synthesis as a theorem-proving task and relies on a theorem-proving method that combines the features of transformation rules, unification, and mathematical induction within a single framework."
  },
  {
    "Title": "Synchronous schemes and their decision problems",
    "URL": "https://dl.acm.org/doi/10.1145/567446.567453",
    "Full Abstract": "A class of schemes called synchronous schemes is defined. A synchronous scheme can have several variables, but all the active ones are required to keep a synchronized rate of computation as measured by the height of their respective Herbrand values. A \"reset\" statement, which causes all the variables to restart a new computation, is admitted. It is shown that equivalence, convergence, and other properties are decidable for schemes in this class. The class of synchronous schemes contains, as special cases, the known decidable classes of Ianov schemes, one-variable schemes with resets, and progressive schemes."
  },
  {
    "Title": "Problematic features of programming languages: a situational-calculus approach",
    "URL": "https://dl.acm.org/doi/book/10.5555/892247",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "The temporal logic of branching time",
    "URL": "https://dl.acm.org/doi/10.1145/567532.567551",
    "Full Abstract": "A temporal language and system are presented which are based on branching time structure. By the introduction of symmetrically dual sets of temporal operators, it is possible to discuss properties which hold either along one path or along all paths. Consequently it is possible to express in this system all the properties that were previously expressible in linear time or branching time systems. We present an exponential decision procedure for satisfiability in the language based on tableaux methods, and a complete deduction system. As associated temporal semantics is illustrated for both structured and graph representation of programs."
  },
  {
    "Title": "Verification of Concurrent Programs",
    "URL": "https://dl.acm.org/doi/10.5555/648063.747433",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Synthesis of Communicating Processes from Temporal Logic Specifications",
    "URL": "https://dl.acm.org/doi/10.5555/648063.747434",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Towards automatic debugging of programs",
    "URL": "https://dl.acm.org/doi/10.1145/390016.808434",
    "Full Abstract": "We present the germ of an idea for automatically correcting logical errors in programs by manipulating the invariants of the program. An invariant tree is defined, and we show how it can be used to change the program in order to guarantee correctness."
  },
  {
    "Title": "The optimal fixedpoint of recursive programs",
    "URL": "https://dl.acm.org/doi/10.1145/800116.803769",
    "Full Abstract": "In this paper a new fixedpoint approach towards the semantics of recursive programs is presented. The fixedpoint defined by a recursive program under this semantics contains, in some sense, the maximal amount of “interesting” information which can be extracted from the program. This optimal fixedpoint (which always uniquely exists) may be strictly more defined than the program's least fixedpoint. We consider both the theoretical and the computational aspects of the approach, as well as some techniques for proving properties of the optimal fixedpoint of a given recursive program."
  },
  {
    "Title": "Translating Program Schemas to While-Schemas",
    "URL": "https://dl.acm.org/doi/10.1137/0204011",
    "Full Abstract": "While-schemas are defined as program schemas without goto statements, in which iteration is achieved using while statements. We present two translations of program schemas into equivalent while-schemas, the first one by adding extra program variables, and the second one by adding extra logical variables. In both cases we aim to preserve as much of the structure of the original program schemas as possible."
  },
  {
    "Title": "Knowledge and reasoning in program synthesis",
    "URL": "https://dl.acm.org/doi/10.5555/1624626.1624670",
    "Full Abstract": "Prograin synthesis is the construction of a computer program from given specifications. An automatic program synthesis system must combine reasoning and programming ability with a good deal of knowledge about the subject matter of the program. This ability and knowledge must be manifested both procedurally (by programs) and structurally (by choice of representation)."
  },
  {
    "Title": "A new approach to recursive programs.",
    "URL": "https://dl.acm.org/doi/book/10.5555/892089",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "The theoretical aspects of the optimal fixedpoint",
    "URL": "https://dl.acm.org/doi/book/10.5555/892093",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Logical analysis of programs",
    "URL": "https://dl.acm.org/doi/10.1145/360032.360048",
    "Full Abstract": "Most present systems for verification of computer programs are incomplete in that intermediate inductive assertions must be provided manually by the user, termination is not proven, and incorrect programs are not treated. As a unified solution to these problems, this paper suggests conducting a logical analysis of programs by using invariants which express what is actually occurring in the program."
  },
  {
    "Title": "The Theoretical Aspects of the Optimal Fixedpoint",
    "URL": "https://dl.acm.org/doi/10.1137/0205033",
    "Full Abstract": "In this paper we define a new type of fixedpoint of recursive definitions and investigate some of its properties. This optimal fixedpoint (which always uniquely exists) contains, in some sense, the maximal amount of “interesting” information which can be extracted from the recursive definition, and it may be strictly more defined than the program’s least fixedpoint. This fixedpoint can be the basis for assigning a new semantics to recursive programs."
  },
  {
    "Title": "Is “sometime” sometimes better than “always”?",
    "URL": "https://dl.acm.org/doi/10.5555/800253.807645",
    "Full Abstract": "This paper explores a technique for proving the correctness and termination of programs simultaneously. This approach, which we call the"
  },
  {
    "Title": "The evolution of programs: a system for automatic program modification",
    "URL": "https://dl.acm.org/doi/book/10.5555/892128",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Studies in Automatic Programming Logic",
    "URL": "https://dl.acm.org/doi/book/10.5555/578683",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Studies in Automatic Programming Logic",
    "URL": "https://dl.acm.org/doi/book/10.5555/578684",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "The evolution of programs",
    "URL": "https://dl.acm.org/doi/10.1145/512950.512964",
    "Full Abstract": "A programmer spends more time modifying already existing programs than constructing original ones. An attempt is made to formulate techniques of program modification, whereby a program that achieves one result can be transformed into a new program that uses the same principles to achieve a different goal. For example, a program that uses the binary search paradigm to divide two numbers may be modified to calculate the square-root of a number in a similar manner.Program debugging is considered as a special case of modification if a program computers wrong results, it must be modified to achieve the intended results The application of abstract program schemata to concrete problems is also viewed from the perspective of modification techniques.We, have embedded this approach in a running implementation; our methods are illustrated with several examples that have been performed by it."
  },
  {
    "Title": "Is \"sometime\" sometimes better than \"always\"? Intermittent assertions in proving program correctness",
    "URL": "https://dl.acm.org/doi/book/10.5555/892103",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "The convergence of functions to fixedpoints of recursive definitions",
    "URL": "https://dl.acm.org/doi/book/10.5555/892143",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "The automatic synthesis of recursive programs",
    "URL": "https://dl.acm.org/doi/10.1145/872734.806929",
    "Full Abstract": "We describe a deductive technique for the automatic construction of recursive programs to meet given input-output specifications. These specifications express what conditions the output of the desired program is expected to satisfy. The deductive technique involves transforming the specifications by a collection of rules, summoned by pattern-directed function invocation. Some of these transformation rules express the semantics of the subject domain; others represent more general programming techniques. The rules that introduce conditional expressions and recursive calls into the program are discussed in some detail."
  },
  {
    "Title": "Formalization of Properties of Functional Programs",
    "URL": "https://dl.acm.org/doi/10.1145/321592.321606",
    "Full Abstract": "The problems of convergence, correctness, and equivalence of computer programs can be formulated by means of the satisfiability or validity of certain first-order formulas. An algorithm is presented for constructing such formulas for functional programs, i.e. programs defined by LISP-like conditional recursive expressions."
  },
  {
    "Title": "Towards automatic program synthesis",
    "URL": "https://dl.acm.org/doi/book/10.5555/891872",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "The translation of ''go to'' programs to ''while'' programs",
    "URL": "https://dl.acm.org/doi/book/10.5555/891881",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Toward automatic program synthesis",
    "URL": "https://dl.acm.org/doi/10.1145/362566.362568",
    "Full Abstract": "An elementary outline of the theorem-proving approach to automatic program synthesis is given, without dwelling on technical details. The method is illustrated by the automatic construction of both recursive and iterative programs operating on natural numbers, lists, and trees."
  },
  {
    "Title": "Decidable properties of monadic functional schemas",
    "URL": "https://dl.acm.org/doi/book/10.5555/891910",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Computation of recursive programs",
    "URL": "https://dl.acm.org/doi/10.1145/1478873.1478902",
    "Full Abstract": "This note is actually an informal exposition of a part of a recent paper by Manna, Ness and Vuillemin. We have two main purposes in this note. First, we present some known results about computation of recursive programs, emphasizing some differences between the theoretical and practical approaches. Second, we introduce the computational induction method for proving properties of recursive programs. It turns out that most known methods for proving properties of programs are very closely related to the computational induction method. We illustrate this point by showing how Floyd's inductive assertions method for proving properties of \"flowchart programs\" can be expressed in terms of computational induction on recursive programs."
  },
  {
    "Title": "Program schemas with equality",
    "URL": "https://dl.acm.org/doi/book/10.5555/891927",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Recursive definitions of partial functions and their computations",
    "URL": "https://dl.acm.org/doi/10.1145/942578.807072",
    "Full Abstract": "The object of this paper is to present a syntactic and semantic model for recursive definitions, and to study the relation between their computed functions and their fixpoints. The recursive definitions that we consider are syntactic generalizations of those introduced in [2] by Kleene and in [5] by McCarthy."
  },
  {
    "Title": "Inductive methods for proving properties of programs",
    "URL": "https://dl.acm.org/doi/10.1145/942580.807070",
    "Full Abstract": "We have two main purposes in this paper. First, we clarify and extend known results about computation of recursive programs, emphasizing the difference between the theoretical and practical approaches. Secondly, we present and examine various known methods for proving properties of recursive programs. We discuss in detail two powerful inductive methods, computational induction and structural induction, illustrating their applications by various examples. We also briefly discuss some other related methods."
  },
  {
    "Title": "Fixpoint approach to the theory of computation.",
    "URL": "https://dl.acm.org/doi/book/10.5555/891944",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Program schemas with equality",
    "URL": "https://dl.acm.org/doi/10.1145/800152.804896",
    "Full Abstract": "We discuss the class of program schemas augmented with equality tests, that is, tests of equality between terms."
  },
  {
    "Title": "Fixpoint approach to the theory of computation",
    "URL": "https://dl.acm.org/doi/10.1145/361454.361460",
    "Full Abstract": "Following the fixpoint theory of Scott, the semantics of computer programs are defined in terms of the least fixpoints of recursive programs. This allows not only the justification of all existing verification techniques, but also their extension to the handling, in a uniform manner of various properties of computer programs, including correctness, termination, and equivalence."
  },
  {
    "Title": "On the power of programming features.",
    "URL": "https://dl.acm.org/doi/book/10.5555/891979",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "A heuristic approach to program verification.",
    "URL": "https://dl.acm.org/doi/book/10.5555/891986",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Decidable Properties of Monadic Functional Schemas",
    "URL": "https://dl.acm.org/doi/10.1145/321765.321780",
    "Full Abstract": "A class of (monadic) functional schemas which properly includes “Ianov” flowchart schemas is defined. It is shown that the termination, divergence, and freedom problems for functional schemas are decidable. Although it is possible to translate a large class of non-free functional schemas into equivalent free functional schemas, it is shown that in general this cannot be done. It is also shown that the equivalence problem for free functional schemas is decidable. Most of the results are obtained from well-known results in formal languages and automata theory."
  },
  {
    "Title": "Axiomatic approach to total correctness of programs.",
    "URL": "https://dl.acm.org/doi/book/10.5555/891989",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Termination of algorithms",
    "URL": "https://dl.acm.org/doi/book/10.5555/904866",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Properties of Programs and the First-Order Predicate Calculus",
    "URL": "https://dl.acm.org/doi/10.1145/321510.321516",
    "Full Abstract": "This paper is concerned with the relationship of the termination problem for programs and abstract programs to the validity of certain formulas in the first-order predicate calculus. By exploiting this relationship, subclasses of abstract programs for which the termination problem is decidable can be isolated. Moreover, known proof procedures for the first-order predicate calculus (e.g. resolution) can be applied to prove the termination of both programs and abstract programs. The correctness and equivalence problems of abstract programs are shown to be reducible to the termination problem."
  },
  {
    "Title": "Formalization of properties of recursively defined functions",
    "URL": "https://dl.acm.org/doi/10.1145/800169.805434",
    "Full Abstract": "This paper is concerned with the relationship between the convergence, correctness and equivalence of recursively defined functions and the satisfiability (or unsatisfiability) of certain first-order formulas."
  },
  {
    "Title": "Second-order mathematical theory of computation",
    "URL": "https://dl.acm.org/doi/10.1145/800161.805161",
    "Full Abstract": "In this work we show that it is possible to formalize all properties regularly observed in (deterministic and non-deterministic) algorithms in second-order predicate calculus."
  },
  {
    "Title": "Inductive methods for proving properties of programs",
    "URL": "https://dl.acm.org/doi/10.1145/355609.362336",
    "Full Abstract": "There are two main purposes in this paper: first, clarification and extension of known results about computation of recursive programs, with emphasis on the difference between the theoretical and practical approaches; second, presentation and examination of various known methods for proving properties of recursive programs. Discussed in detail are two powerful inductive methods, computational induction and structural induction, including examples of their applications."
  },
  {
    "Title": "A heuristic approach to program verification",
    "URL": "https://dl.acm.org/doi/10.5555/1624775.1624837",
    "Full Abstract": "We present various heuristic techniques for use in proving the correctness of computer programs. The techniques are designed to obtain automatically the \"inductive assertions\" attached to the loops of the program which previously required human \"understanding\" of the program's performance. We distinguish between two general approaches: one in which we obtain the inductive assertion by analyzing predicates which are known to be true at the entrances and exits of the loop (top-down approach), and another in which we generate the inductive assertion directly from the statements of the loop (bottom-up approach)."
  },
  {
    "Title": "Knowledge and Reasoning in Program Synthesis",
    "URL": "https://dl.acm.org/doi/10.5555/647950.742874",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Introduction to Mathematical Theory of Computation",
    "URL": "https://dl.acm.org/doi/book/10.5555/542899",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "The logic of computer programming",
    "URL": "https://dl.acm.org/doi/book/10.5555/892142",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "The automatic synthesis of systems of recursive programs",
    "URL": "https://dl.acm.org/doi/10.5555/1624435.1624526",
    "Full Abstract": "A technique is presented for constructing, a program from given specifications. The basic approach is to transform the specifications repeatedly, according to certain rules, until the desired program is produced. Two important transformation rules are those responsible for introducing conditional expressions and recursion into the target program. These transformations have been introduced in previous publications, and are discussed here briefly."
  },
  {
    "Title": "Inference rules for program annotation",
    "URL": "https://dl.acm.org/doi/book/10.5555/892155",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "The optimal approach to recursive programs",
    "URL": "https://dl.acm.org/doi/10.1145/359863.359885",
    "Full Abstract": "The classical fixedpoint approach toward recursive programs suggests choosing the “least defined fixedpoint” as the most appropriate solution to a recursive program. A new approach is described which introduces an “optimal fixedpoint,” which, in contrast to the least defined fixedpoint, embodies the maximal amount of valuable information embedded in the program. The practical implications of this approach are discussed and techniques for proving properties of optimal fixedpoints are given. The presentation is informal, with emphasis on examples."
  },
  {
    "Title": "Verification of concurrent programs, Part I: The temporal framework",
    "URL": "https://dl.acm.org/doi/book/10.5555/892270",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Verification of concurrent programs: proving eventualities by well-founded ranking",
    "URL": "https://dl.acm.org/doi/book/10.5555/892275",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "How to cook a temporal proof system for your pet language",
    "URL": "https://dl.acm.org/doi/10.1145/567067.567082",
    "Full Abstract": "An abstract temporal proof system is presented whose program-dependent part has a high-level interface with the programming language actually studied. Given a new language, it is sufficient to deline the interface notions of atomic transitions, justice, and fairness in order to obtain a full temporal proof system for this language. This construction is particularly useful for the analysis of concurrent systems. We illustrate the construction on the shared-variable model and on CSP. The generic proof system is shown to be relatively complete with respect to pure first-order temporal logic."
  },
  {
    "Title": "The origin of the binary-search paradigm",
    "URL": "https://dl.acm.org/doi/10.5555/1625135.1625176",
    "Full Abstract": "In a binary-search algorithm for the computation of a numerical function, the interval in which the desired output is sought is divided in half at each iteration. The paper considers how such algorithms might be derived from their specifications by an automatic program-synthesis system. The derivation of the binary-search concept has been found to be surprisingly straightforward. The programs obtained, though reasonably simple and efficient, are quite different from those that would have been constructed by informal means."
  },
  {
    "Title": "Deduction with Relation Matching",
    "URL": "https://dl.acm.org/doi/10.5555/646823.706894",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "A hierarchy of temporal properties",
    "URL": "https://dl.acm.org/doi/10.1145/41840.41857",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "The anchored version of the temporal framework",
    "URL": "https://dl.acm.org/doi/10.5555/648140.749663",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Specification and Verification of Concurrent Programs by For-All Automata",
    "URL": "https://dl.acm.org/doi/book/10.5555/892457",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Completing the Temporal Picture",
    "URL": "https://dl.acm.org/doi/10.5555/646243.681453",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Temporal logic programming",
    "URL": "https://dl.acm.org/doi/10.1016/S0747-7171%2889%2980070-7",
    "Full Abstract": "Temporal logic, often used as a specification language for programs, can serve directly as a programming language. We propose a specific programming language TEMPLOG, which extends the classical PROLOG-like languages to include temporal operators. PROLOG progams are collections of classical Horn clauses and they are efficiently interpreted by SLD-resolution. Similarly, TEMPLOG programs are collections of temporal Horn clauses and we interpret them with temporal SLD-resolution, a restricted form of a general temporal resolution method."
  },
  {
    "Title": "Addition chains with multiplicative cost",
    "URL": "https://dl.acm.org/doi/book/10.5555/892092",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "On the average behavior of set merging algorithms (Extended Abstract)",
    "URL": "https://dl.acm.org/doi/10.1145/800113.803648",
    "Full Abstract": "In this paper we study the expected running time of a variety of algorithms that perform set merging. The set merging problem (for example, see AHU [1]) is concerned with using suitable data structures to represent partition of a set S = { 1,2, ....,n} so that a sequence of instructions of the form “x Ξ y”, meaning"
  },
  {
    "Title": "Lower Bounds on Merging Networks",
    "URL": "https://dl.acm.org/doi/10.1145/321958.321976",
    "Full Abstract": "Let"
  },
  {
    "Title": "K + 1 heads are better than K",
    "URL": "https://dl.acm.org/doi/10.1109/SFCS.1976.18",
    "Full Abstract": "There are languages which can be recognized by a deterministic (k + 1)-headed oneway finite automaton but which cannot be recognized by a k-headed one-way (deterministic or non-deterministic) finite automaton. Furthermore, there is a language accepted by a 2-headed nondeterministic finite automaton which is accepted by no k-headed deterministic finite automaton."
  },
  {
    "Title": "The complexity of searching an ordered random table",
    "URL": "https://dl.acm.org/doi/10.1109/SFCS.1976.32",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "An Ω(n",
    "URL": "https://dl.acm.org/doi/10.1145/800105.803391",
    "Full Abstract": "Let P be a polyhedron with f"
  },
  {
    "Title": "On the loop switching addressing problem",
    "URL": "https://dl.acm.org/doi/book/10.5555/892151",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "The complexity of pattern matching for a random string",
    "URL": "https://dl.acm.org/doi/book/10.5555/892154",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "A lower bound to palindrome recognition by probabilistic Turing machines",
    "URL": "https://dl.acm.org/doi/book/10.5555/892157",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "On constructing minimum spanning trees in k-dimensional spaces and related problems",
    "URL": "https://dl.acm.org/doi/book/10.5555/892163",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "k",
    "URL": "https://dl.acm.org/doi/10.1145/322063.322076",
    "Full Abstract": "Copyright © 1978 ACM."
  },
  {
    "Title": "New algorithms in bin packing",
    "URL": "https://dl.acm.org/doi/book/10.5555/892175",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Information bounds are weak in the shortest distance problem",
    "URL": "https://dl.acm.org/doi/book/10.5555/892180",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "On the average-case complexity of selecting k-th best",
    "URL": "https://dl.acm.org/doi/10.1109/SFCS.1978.29",
    "Full Abstract": "Let Vk (n) be the minimum average number of pairwise comparisons needed to find the k-th largest of n numbers (k≥2), assuming that all n! orderings are equally likely. D. W. Matula proved that, for some absolute constant c, Vk(n)- n ≤ ck log log n as n → ∞. In the present paper, we show that there exists an absolute constant c′ > 0 such that Vk(n) - n ≥ c′k log log n as n → ∞, proving a conjecture by Matula."
  },
  {
    "Title": "An analysis of a memory allocation scheme for implementing stacks",
    "URL": "https://dl.acm.org/doi/book/10.5555/892201",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "On fault-tolerant networks for sorting",
    "URL": "https://dl.acm.org/doi/book/10.5555/892209",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "An analysis of (h,k,l)-shellsort",
    "URL": "https://dl.acm.org/doi/book/10.5555/892211",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "A lower bound to finding convex hulls",
    "URL": "https://dl.acm.org/doi/book/10.5555/891707",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Completing the temporal picture",
    "URL": "https://dl.acm.org/doi/10.1016/0304-3975%2891%2990041-Y",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Completing the temporal picture",
    "URL": "https://dl.acm.org/doi/10.5555/111774.111780",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Temporal proof methodologies for real-time systems",
    "URL": "https://dl.acm.org/doi/book/10.5555/892514",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Monotonicity properties in automated deduction",
    "URL": "https://dl.acm.org/doi/10.5555/132218.132234",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "The temporal logic of reactive and concurrent systems",
    "URL": "https://dl.acm.org/doi/book/10.5555/128869",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "The Special-Relation Rules are Incomplete",
    "URL": "https://dl.acm.org/doi/10.5555/648230.752615",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "What Good Are Digital Clocks?",
    "URL": "https://dl.acm.org/doi/10.5555/646246.684870",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Characterization of Temporal Property Classes",
    "URL": "https://dl.acm.org/doi/10.5555/646246.684871",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Some complexity questions related to distributive computing(Preliminary Report)",
    "URL": "https://dl.acm.org/doi/10.1145/800135.804414",
    "Full Abstract": "Let"
  },
  {
    "Title": "Should tables by sorted?",
    "URL": "https://dl.acm.org/doi/book/10.5555/892229",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "The Complexity of Pattern Matching for a Random String",
    "URL": "https://dl.acm.org/doi/10.1137/0208029",
    "Full Abstract": "We study the average-case complexity of finding all occurrences of a given pattern $\\alpha $ in an input text string. Over an alphabet of"
  },
  {
    "Title": "On the time-space tradeoff for sorting with linear queries",
    "URL": "https://dl.acm.org/doi/book/10.5555/892226",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Some monotonicity properties of partial orders",
    "URL": "https://dl.acm.org/doi/book/10.5555/892231",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Storing a sparse table",
    "URL": "https://dl.acm.org/doi/10.1145/359168.359175",
    "Full Abstract": "The problem of storing and searching large sparse tables is ubiquitous in computer science. The standard technique for storing such tables is hashing, but hashing has poor worst-case performance. We propose a good worst-case method for storing a static table of"
  },
  {
    "Title": "External Hashing Schemes for Collections of Data Structures",
    "URL": "https://dl.acm.org/doi/10.1145/322169.322177",
    "Full Abstract": "Copyright © 1980 ACM."
  },
  {
    "Title": "New Algorithms for Bin Packing",
    "URL": "https://dl.acm.org/doi/10.1145/322186.322187",
    "Full Abstract": "In the bin-packing problem a list"
  },
  {
    "Title": "Information Bounds Are Weak in the Shortest Distance Problem",
    "URL": "https://dl.acm.org/doi/10.1145/322203.322206",
    "Full Abstract": "Copyright © 1980 ACM."
  },
  {
    "Title": "Bounds on Selection Networks",
    "URL": "https://dl.acm.org/doi/10.1137/0209043",
    "Full Abstract": "We investigate the complexity of network selection by measuring it in terms of $U(t,N)$, the minimum number of comparators needed, and $T(t,N)$, the minimum delay time possible, for networks selecting the smallest"
  },
  {
    "Title": "On the parallel computation for the knapsack problem",
    "URL": "https://dl.acm.org/doi/book/10.5555/892256",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Optimal Expected-Time Algorithms for Closest Point Problems",
    "URL": "https://dl.acm.org/doi/10.1145/355921.355927",
    "Full Abstract": "Copyright © 1980 ACM."
  },
  {
    "Title": "On the security of public key protocols",
    "URL": "https://dl.acm.org/doi/book/10.5555/891726",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "On the parallel computation for the knapsack problem",
    "URL": "https://dl.acm.org/doi/10.1145/800076.802465",
    "Full Abstract": "We are interested in the complexity of solving the knapsack problem with"
  },
  {
    "Title": "The entropic limitations on VLSI computations(Extended Abstract)",
    "URL": "https://dl.acm.org/doi/10.1145/800076.802483",
    "Full Abstract": "In this paper we will explore the limitations imposed by entropic constraints, both in generality and for specific problems. We list below the main questions that we will address."
  },
  {
    "Title": "Should Tables Be Sorted?",
    "URL": "https://dl.acm.org/doi/10.1145/322261.322274",
    "Full Abstract": "Copyright © 1981 ACM."
  },
  {
    "Title": "A Lower Bound to Finding Convex Hulls",
    "URL": "https://dl.acm.org/doi/10.1145/322276.322289",
    "Full Abstract": "Copyright © 1981 ACM."
  },
  {
    "Title": "On the security of public key protocols",
    "URL": "https://dl.acm.org/doi/10.1109/SFCS.1981.32",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Space-time tradeoff for answering range queries (Extended Abstract)",
    "URL": "https://dl.acm.org/doi/10.1145/800070.802185",
    "Full Abstract": "In this paper, we raise and investigate the question of (storage) space- (retrieval) time tradeoff for a static database, in the general framework of Fredman's. As will be seen, such tradeoff results also lead to lower bounds on the complexity of processing a sequence of m INSERT and QUERY instructions. The latter results are incomparable to Fredman's, since the presence of DELETE instructions was crucial for his proof technique. We will present our results in detail in the next few sections. Here we will only mention three main conclusions. Firstly, circular query is shown to be intrinsically hard in the sense that, for some static database with n records, there is a space-time tradeoff TS > n"
  },
  {
    "Title": "A Microprogrammed Intelligent Graphics Terminal",
    "URL": "https://dl.acm.org/doi/10.1109/T-C.1971.223346",
    "Full Abstract": "This paper describes a small computer, Interdata Model 3, that has been microprogrammed to serve as an intelligent terminal. The Interdata is connected to a System/360 multiplexor channel with a high-speed interface, and uses an ARDS direct view storage tube as a display console. The new Interdata target machine is patterned after the /360 (including all five instruction formats), but also has instructions particularly designed for intelligent terminal programming. These include instructions for character string manipulation, code conversion, list processing, coordinate manipulation, and virtual addressing. A powerful multiplexor channel, which allows the programmer to \"overlap\" I/O to several devices with a CPU program, has also been microprogrammed."
  },
  {
    "Title": "On-line Text Editing: A Survey",
    "URL": "https://dl.acm.org/doi/10.1145/356589.356591",
    "Full Abstract": "This paper is a survey of current methods for the on-line creation and editing of computer programs and of ordinary manuscripts text. The characteristics of on-line editing systems are examined and examples of various implementations are described in three categories: program editors, text editors, and terminals with local editing facilities."
  },
  {
    "Title": "Language for Systems Development",
    "URL": "https://dl.acm.org/doi/10.1145/800234.807060",
    "Full Abstract": "Well-designed efficient systems programming languages are an absolute necessity if programmers are to keep pace with the demand for systems. This paper presents briefly some criteria to be applied to the design of a general purpose systems programming language and a description of the Language for Systems Development that is being implemented at Brown University for the IBM S/360. The paper is a revised and condensed version of a much larger survey paper [3]. The research and writing of this paper and the design of LSD were partially supported by a National Science Foundation grant (No. GJ-181) and by Brown University. We would like to acknowledge the help and invaluable suggestions given us by Richard Wexelblat of Bell Laboratories, Robert Balzer of the RAND Corporation, John Brackett and Douglas Ross of Softech, Inc., and Robert Rosin of the State University of New York at Buffalo. Special thanks should be given to Paul Knueven of Digital Equipment Corporation who helped initiate the entire effort and has been a source of help and encouragement through many iterations. The authors would also like to thank Frank Tompa of the University of Toronto and Diane Shecter who were among the original designers of LSD."
  },
  {
    "Title": "Microprogramming for computer graphics",
    "URL": "https://dl.acm.org/doi/10.1145/1316535.1316536",
    "Full Abstract": "Interactive computer graphics (graphics) is the construction, storage, retrieval, manipulation, alteration and analysis of pictorial data, using an on-line display console with manual input (interaction) devices. Among such input devices are the alphanumeric and function keyboards for typing text and activating preprogrammed subroutines respectively, and the light pen and data tablet for identifying and entering graphic data by means of pointing and drawing."
  },
  {
    "Title": "Computer assisted tracing of text evolution",
    "URL": "https://dl.acm.org/doi/10.1145/1479064.1479160",
    "Full Abstract": "Many situations exist in which convenient access to the detailed evolutionary information associated with a text's development is desirable:"
  },
  {
    "Title": "Intelligent satellites for interactive graphics",
    "URL": "https://dl.acm.org/doi/10.1145/1499586.1499655",
    "Full Abstract": "In the last four or five years it has become increasingly fashionable to speak of \"intelligent,\" \"smart,\" or \"programmable\" terminals and systems. Very few mainframe or peripheral manufacturers omit such a device from their standard product line. Although \"intelligence,\" like beauty or pornography, is in the eye of the beholder, the adjective generally connotes that the device has a degree of autonomy or processing ability which allows it to perform certain (classes of) tasks without assistance from the mainframe to which it is connected. Many such devices are programmable by virtue of including a mini, microprogrammable or micro computer."
  },
  {
    "Title": "Computer architecture and instruction set design",
    "URL": "https://dl.acm.org/doi/10.1145/1499586.1499720",
    "Full Abstract": "A group of computer scientists and mathematicians at Brown University has been engaged in the study of computer graphics for the past eight years. During the course of these studies a variety of topics has been investigated, in particular, during the last few years, the use of microprogramming for implementing graphics systems. In early 1971, Professor Andries van Dam and his associates submitted a threefold research proposal to the National Science Foundation."
  },
  {
    "Title": "Operating system design considerations for microprogrammed mini-computer satellite systems",
    "URL": "https://dl.acm.org/doi/10.1145/1499586.1499724",
    "Full Abstract": "The operating system described in this paper was developed as part of research sponsored by The National Science Foundation and the Office of Naval Research on satellite processing and symbolic debugging of data structures. This system runs on a small (32K bytes), dual processor, microprogrammable computer equipped with a high-speed graphic display unit and attached in satellite mode to the multiplexor channel of an IBM System/360-67."
  },
  {
    "Title": "A survey of introductory and advanced programming courses",
    "URL": "https://dl.acm.org/doi/10.1145/800183.810465",
    "Full Abstract": "In the process of establishing equitable and practical computer time allocations for our computer science courses this fall, we compared our seemingly high request with standards in other universities. Twenty-three private and state universities were chosen for the comparison and a questionnaire (appendix 1) was designed to elicit information about large introductory programming courses and more specialized systems programming/software engineering courses."
  },
  {
    "Title": "Design considerations for microprogramming languages",
    "URL": "https://dl.acm.org/doi/10.1145/1217149.1217152",
    "Full Abstract": "The growing acceptance of user-microprogrammable computers indicates that microprogramming, as a discipline, will require development of user-oriented microprogramming support. A number of approaches (definition of sophisticated target machines, microcode assemblers, and higher level microprogramming languages) have been proposed. The issues involved in choosing support tools include the range of proposed applications, hardware parallelism (horizental or minimally encoded control vs. vertically encoded control) and constraints on performance. After reviewing some of these tradeoffs, design considerations for higher level microprogramming languages are considered. One of the most important design decisions is fixing the level of the language, defined on a continuum from symbolic assemblers, through general purpose programming languages such as PL/I. A tailored language concept is defined and illustrated, using as an example a microprogramming language for a horizontally encoded microprogrammable computer currently under development."
  },
  {
    "Title": "Parallel hashing—an efficient implementation of shared memory",
    "URL": "https://dl.acm.org/doi/10.1145/12130.12146",
    "Full Abstract": "Copyright © 1986 ACM."
  },
  {
    "Title": "Sharing memory in distributed systems—methods and applications",
    "URL": "https://dl.acm.org/doi/book/10.5555/37653",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Algorithms for the compilation of regular expressions into PLAs",
    "URL": "https://dl.acm.org/doi/10.1007/BF01840364",
    "Full Abstract": "The language of regular expressions is a useful one for specifying certain sequential processes at a very high level. They allow easy modification of designs for circuits, like controllers, that are described by patterns of events they must recognize and the responses they must make to those patterns. This paper discusses the compilation of such expressions into specifications for programmable logic arrays (PLAs) that will implement the required function. A regular expression is converted into a nondeterministic finite automaton, and then the automaton states are encoded as values on wires that are inputs and outputs of a PLA. The translation of regular expressions into nondeterministic automata by two different methods is discussed, along with the advantages of each method. A major part of the compilation problem is selection of good state codes for the nondeterministic automata; one successful strategy and its application to microcode compaction is explained in the paper."
  },
  {
    "Title": "Parallel hashing",
    "URL": "https://dl.acm.org/doi/10.1145/48014.350550",
    "Full Abstract": "Copyright © 1988 ACM."
  },
  {
    "Title": "Bounds on the cover time",
    "URL": "https://dl.acm.org/doi/10.1109/SFCS.1988.21964",
    "Full Abstract": "A particle that moves on a connected unidirected graph G with n vertices is considered. At each step the particle goes from the current vertex to one of its neighbors, chosen uniformly at random. The cover time is the first time when the particle has visited all the vertices in the graph, starting from a given vertex. Upper and lower bounds are presented that relate the expected cover time for a graph to the eigenvalues of the Markov chain that describes the above random walk. An interesting consequence is that regular expander graphs have expected cover time theta (n log n)."
  },
  {
    "Title": "Dynamic perfect hashing",
    "URL": "https://dl.acm.org/doi/10.1109/SFCS.1988.21968",
    "Full Abstract": "A randomized algorithm is given for the dictionary problem with O(1) worst-case time for lookup and O(1) amortized expected time for insertion and deletion. An Omega (log n) lower bound is proved for the amortized worst-case time complexity of any deterministic algorithm in a class of algorithms encompassing realistic hashing-based schemes. If the worst-case lookup time is restricted to k, then the lower bound for insertion becomes Omega (kn/sup 1/k/)."
  },
  {
    "Title": "Competitive snoopy caching",
    "URL": "https://dl.acm.org/doi/10.1007/BF01762111",
    "Full Abstract": "In a snoopy cache multiprocessor system, each processor has a cache in which it stores blocks of data. Each cache is connected to a bus used to communicate with the other caches and with main memory. Each cache monitors the activity on the bus and in its own processor and decides which blocks of data to keep and which to discard. For several of the proposed architectures for snoopy caching systems, we present new on-line algorithms to be used by the caches to decide which blocks to retain and which to drop in order to minimize communication over the bus. We prove that, for any sequence of operations, our algorithms' communication costs are within a constant factor of the minimum required for that sequence; for some of our algorithms we prove that no on-line algorithm has this property with a smaller constant."
  },
  {
    "Title": "Trading space for time in undirected ",
    "URL": "https://dl.acm.org/doi/10.1145/73007.73059",
    "Full Abstract": "Aleliunas"
  },
  {
    "Title": "Multilevel adaptive hashing",
    "URL": "https://dl.acm.org/doi/10.5555/320176.320181",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Competitive randomized algorithms for non-uniform problems",
    "URL": "https://dl.acm.org/doi/10.5555/320176.320216",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Asymptotically tight bounds for computing with faulty arrays of processors",
    "URL": "https://dl.acm.org/doi/10.1109/FSCS.1990.89547",
    "Full Abstract": "The computational power of 2-D and 3-D processor arrays that contain a potentially large number of faults is analyzed. Both a random and a worst-case fault model are considered, and it is proved that in either scenario low-dimensional arrays are surprisingly fault tolerant. It is also shown how to route, sort, and perform systolic algorithms for problems such as matrix multiplication in optimal time on faulty arrays. In many cases, the running time is the same as if there were no faults in the array (up to constant factors). On the negative side, it is shown that any constant congestion embedding of an n*n fault-free array on an n*n array with Theta (n/sup 2/) random faults (or Theta (log n) worst-case faults) requires dilation Theta (log n). For 3-D arrays, knot theory is used to prove that the required dilation is Omega ( square root log n)."
  },
  {
    "Title": "On the parallel complexity of evaluating game trees",
    "URL": "https://dl.acm.org/doi/10.5555/127787.127858",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Empirical studies of competitve spinning for a shared-memory multiprocessor",
    "URL": "https://dl.acm.org/doi/10.1145/121132.286599",
    "Full Abstract": "A common operation in multiprocessor programs is acquiring a lock to protect access to shared data. Typically, the requesting thread is blocked if the lock it needs is held by another thread. The cost of blocking one thread and activating another can be a substantial part of program execution time. Alternatively, the thread could spin until the lock is free, or spin for a while and then block. This may avoid context-switch overhead, but processor cycles may be wasted in unproductive spinning. This paper studies seven strategies for determining whether and how long to spin before blocking. Of particular interest are"
  },
  {
    "Title": "Factors in the performance of the AN1 computer network",
    "URL": "https://dl.acm.org/doi/10.1145/133057.133102",
    "Full Abstract": "AN1 (formerly known as Autonet) is a local area network composed of crossbar switches interconnected by 100Mbit/second, full-duplex links. In this paper, we evaluate the performance impact of certain choices in the AN1 design. These include the use of FIFO input buffering in the crossbar switch, the deadlock-avoidance mechanism, cut-through routing, back-pressure for flow control, and multi-path routing. AN1's performance goals were to provide low latency and high bandwidth in a lightly loaded network. In this it is successful. Under heavy load, the most serious impediment to good performance is the use of FIFO input buffers. The deadlock-avoidance technique has an adverse effect on the performance of some topologies, but it seems to be the best alternative, given the goals and constraints of the AN1 design. Cut-through switching performs well relative to store-and-forward switching, even under heavy load. Back-pressure deals adequately with congestion in a lightly-loaded network; under moderate load, performance is acceptable when coupled with end-to-end flow control for bursts. Multi-path routing successfully exploits redundant paths between hosts to improve performance in the face of congestion."
  },
  {
    "Title": "Biased random walks",
    "URL": "https://dl.acm.org/doi/10.1145/129712.129713",
    "Full Abstract": "How much can an imperfect source of randomness affect an algorithm? We examine several simple questions of this type concerning the long-term behavior of a random walk on a finite graph. In our setup, each step of the random walk a “controller” can, with a certain small probability, fix the next step, thus introducing a bias. We analyze the extent to which the bias can affect the limit behavior of the walk. The controller is assumed to associate a real, nonnegative, “benefit” with each state, and to strive to maximize the long-term expected benefit. We derive tight bounds on the maximum of this objective function over all controller's strategies, and present polynomial time algorithms for computing the optimal controller strategy."
  },
  {
    "Title": "Strongly competitive algorithms for paging with locality of reference",
    "URL": "https://dl.acm.org/doi/10.5555/139404.139455",
    "Full Abstract": "What is the best paging algorithm if one has partial information about the possible sequences of page requests? We give a partial answer to this question, by presenting the analysis of strongly competitive paging algorithms in the access graph model. This model restricts page requests so that they conform to a notion of locality of reference, given by an arbitrary access graph."
  },
  {
    "Title": "On-line load balancing",
    "URL": "https://dl.acm.org/doi/10.1109/SFCS.1992.267770",
    "Full Abstract": "The setup for the authors' problem consists of n servers that must complete a set of tasks. Each task can be handled only by a subset of the servers, requires a different level of service, and once assigned can not be re-assigned. They make the natural assumption that the level of service is known at arrival time, but that the duration of service is not. The on-line load balancing problem is to assign each task to an appropriate server in such a way that the maximum load on the servers is minimized. The authors derive matching upper and lower bounds for the competitive ratio of the on-line greedy algorithm for this problem, namely /sup (3n)2/3///sub 2/(1+o(1)), and derive a lower bound, Omega ( square root n), for any other deterministic or randomized on-line algorithm."
  },
  {
    "Title": "Markov paging",
    "URL": "https://dl.acm.org/doi/10.1109/SFCS.1992.267771",
    "Full Abstract": "This paper considers the problem of paging under the assumption that the sequence of pages accessed is generated by a Markov chain. The authors use this model to study the fault-rate of paging algorithms, a quantity of interest to practitioners. They first draw on the theory of Markov decision processes to characterize the paging algorithm that achieves optimal fault-rate on any Markov chain. They address the problem of efficiently devising a paging strategy with low fault-rate for a given Markov chain. They show that a number of intuitively good approaches fail. Their main result is an efficient procedure that, on any Markov chain, will give a paging algorithm with fault-rate at most a constant times optimal. Their techniques also show that some algorithms that do poorly in practice fail in the Markov setting, despite known (good) performance guarantees when the requests are generated independently from a probability distribution."
  },
  {
    "Title": "Trading Space for Time in Undirected $s-t$ Connectivity",
    "URL": "https://dl.acm.org/doi/10.1137/S0097539790190144",
    "Full Abstract": "Aleliunas et al. [20th Annual Symposium on Foundations of Computer Science, IEEE Computer Society Press, Los Alamitos, CA, 1979, pp. 218--223] posed the following question: \"The reachability problem for undirected graphs can be solved in log space and $O(mn)$ time [$m$ is the number of edges and $n$ is the number of vertices] by a probabilistic algorithm that simulates a random walk, or in linear time and space by a conventional deterministic graph traversal algorithm. Is there a spectrum of time-space trade-offs between these extremes?\" This question is answered in the affirmative for sparse graphs by presentation of an algorithm that is faster than the random walk by a factor essentially proportional to the size of its workspace. For denser graphs, this algorithm is faster than the random walk but the speed-up factor is smaller."
  },
  {
    "Title": "On the fault tolerance of the butterfly",
    "URL": "https://dl.acm.org/doi/10.1145/195058.195117",
    "Full Abstract": "Copyright © 1994 ACM."
  },
  {
    "Title": "Realizability and Synthesis of Reactive Modules",
    "URL": "https://dl.acm.org/doi/10.5555/647763.760718",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Annotation-Based Deduction in Temporal Logic",
    "URL": "https://dl.acm.org/doi/10.5555/645548.659006",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Temporal Proof Methodologies for Timed Transition-Systems",
    "URL": "https://dl.acm.org/doi/10.1006/inco.1994.1060",
    "Full Abstract": "We extend the specification language of temporal logic, the corresponding verification framework, and the underlying computational model to deal with real-;time properties of reactive systems. The abstract notion of timed transition systems generalizes traditional transition systems conservatively: qualitative fairness requirements are replaced (and superseded) by quantitative lower-bound and upper-bound timing constraints on transitions. This framework can model real-time systems that communicate either through shared variables or by message passing and real-time issues such as timeouts, process priorities (interrupts), and process scheduling. We exhibit two styles for the specification of real-time systems. While the first approach uses time-bounded versions of the temporal operators, the second approach allows explicit references to time through a special clock variable. Corresponding to the two styles of specification, we present and compare two different proof methodologies for the verification of timing requirements that are expressed in these styles. For the bounded-operator style, we provide a set of proof rules for establishing bounded-invariance and bounded-responce properties of timed transition systems. This approach generalizes the standard temporal proof rules for verifying invariance and response properties conservatively. For the explicit-clock style, we exploit the observation that every time-bounded property is a safety property and use the standard temporal proof rules for establishing safety properties."
  },
  {
    "Title": "Continuous Verification by Discrete Reasoning",
    "URL": "https://dl.acm.org/doi/book/10.5555/891763",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Differential BDDs",
    "URL": "https://dl.acm.org/doi/book/10.5555/891764",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Prooving Safety Properties of Hybrid Systems",
    "URL": "https://dl.acm.org/doi/10.5555/646843.706648",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Specification and Verification of Controlled Systems",
    "URL": "https://dl.acm.org/doi/10.5555/646843.706772",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "STeP",
    "URL": "https://dl.acm.org/doi/10.5555/646619.697420",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Verification in Continuous Time by Discrete Reasoning",
    "URL": "https://dl.acm.org/doi/10.5555/646056.678059",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "On the Average-Case Complexity of Selecting the ",
    "URL": "https://dl.acm.org/doi/10.1137/0211034",
    "Full Abstract": "Let $\\bar V_k (n)$ be the minimum average number of pairwise comparisons needed to find the"
  },
  {
    "Title": "Protocols for secure computations",
    "URL": "https://dl.acm.org/doi/10.5555/1382436.1382751",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Strong signature schemes",
    "URL": "https://dl.acm.org/doi/10.1145/800061.808774",
    "Full Abstract": "The notion of digital signature based on trapdoor functions has been introduced by Diffie and Hellman[3]. Rivest, Shamir and Adleman[8] gave the first number theoretic implementation of a signature scheme based on a trapdoor function. If"
  },
  {
    "Title": "Uniform hashing is optimal",
    "URL": "https://dl.acm.org/doi/book/10.5555/892340",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "On the expected performance of path compression algorithms",
    "URL": "https://dl.acm.org/doi/10.1137/0214010",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "On the Complexity of Maintaining Partial Sums",
    "URL": "https://dl.acm.org/doi/10.1137/0214022",
    "Full Abstract": "Let $F = \\{ ({\\bf r}_i,s_i )|0 \\leqq i < n\\} $ be a file of"
  },
  {
    "Title": "On optimal arrangements of keys with double hashing",
    "URL": "https://dl.acm.org/doi/10.1016/0196-6774%2885%2990042-2",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Uniform hashing is optimal",
    "URL": "https://dl.acm.org/doi/10.1145/3828.3836",
    "Full Abstract": "It was conjectured by J. Ullman that uniform hashing is optimal in its expected retrieval cost among all open-address hashing schemes [4]. In this paper, we show that, for any open-address hashing scheme, the expected cost of retrieving a record from a large table that is α-fraction full is at least (1/α) log (1/(1 - α)) +"
  },
  {
    "Title": "Separating the polynomial-time hierarchy by oracles",
    "URL": "https://dl.acm.org/doi/10.5555/4479.4487",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "A general approach to d-dimensional geometric queries",
    "URL": "https://dl.acm.org/doi/10.1145/22145.22163",
    "Full Abstract": "It is shown that any bounded region in"
  },
  {
    "Title": "Lower bounds to randomized algorithms for graph properties",
    "URL": "https://dl.acm.org/doi/10.1109/SFCS.1987.39",
    "Full Abstract": "For any property P on n-vertex graphs, let C(P) be the minimum number of edges that need to be examined by any decision tree algorithm for determining P. In 1975 Rivest and Vuillemin settled the Aanderra-Rosenberg Conjecture, proving that C(P) = Ω(n2) for every nontrivial monotone graph property P. An intriguing open question is whether the theorem remains true when randomized algorithms are allowed. In this paper we report progress on this problem, showing that Ω(n(log n)1/12) edges must be examined by a randomized algorithm for determining any nontrivial monotone graph property."
  },
  {
    "Title": "Monotone bipartite graph properties are evasive",
    "URL": "https://dl.acm.org/doi/10.1137/0217031",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Computational information theory",
    "URL": "https://dl.acm.org/doi/10.5555/60364.60365",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Circuits and local computation",
    "URL": "https://dl.acm.org/doi/10.1145/73007.73025",
    "Full Abstract": "This paper contains two parts. In Part I, we show that polynomial-size monotone threshold circuits of depth"
  },
  {
    "Title": "On the improbability of reaching Byzantine agreements",
    "URL": "https://dl.acm.org/doi/10.1145/73007.73052",
    "Full Abstract": "It is well known that for the Byzantine Generals Problem, no deterministic protocol can exist for an"
  },
  {
    "Title": "On the complexity of partial order productions",
    "URL": "https://dl.acm.org/doi/10.1137/0218047",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Coherent functions and program checkers",
    "URL": "https://dl.acm.org/doi/10.1145/100216.100226",
    "Full Abstract": "Copyright © 1990 ACM."
  },
  {
    "Title": "Lower bounds to randomized algorithms for graph properties",
    "URL": "https://dl.acm.org/doi/10.1016/0022-0000%2891%2990003-N",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Program checkers for probability generation",
    "URL": "https://dl.acm.org/doi/10.5555/111713.111724",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Toward the development of machine",
    "URL": "https://dl.acm.org/doi/10.1145/1500175.1500301",
    "Full Abstract": "One of the reasons for developing high level languages has been the desire for program portability from one type of machine to another. To achieve the high degree of machine independence necessary for program portability, these languages have included general features such as arithmetic expressions, arrays, and subroutine calls which can be implemented on many machines. Facilities such as the interrupt mechanism, program status word, and device dependent input/output which are available to the assembly language programmer are hidden from the high level programmer. Unfortunately, the code generated by compilers for these high level languages is often very inefficient compared to that produced by experienced assembly language programmers. However, the added expressiveness and the ability to leave details to the compiler usually offset the inefficiency of generated code, particularly for non-systems applications. For such applications, the facilities which the high level programmer cannot use are not needed anyway."
  },
  {
    "Title": "Intelligent satellites for interactive graphics",
    "URL": "https://dl.acm.org/doi/10.1145/988026.988039",
    "Full Abstract": "The spectrum of remote user stations with local processing ability, ranging from simple \"smart\" terminals to nearly self-sufficient intelligent systems called satellites, is considered. The emphasis is on the latter category, drawing on the authors' research on intelligent satellites for interactive graphics. The necessity of meeting a \"critical intelligence threshold\" criterion for the satellite is stressed, and some difficult problems and potential solutions in the division of labor between mainframe and satellite are briefly examined. It is hoped that many of the problems and solutions in satellite graphics apply to other areas such as network or satellite process control, experiment control, and signal processing."
  },
  {
    "Title": "STRUCT programming analysis system",
    "URL": "https://dl.acm.org/doi/10.1109/TSE.1975.6312869",
    "Full Abstract": "The STRUCT system utilizes the flexibility of a powerful graphics display system to provide a set of tools for program analysis. These tools allow the analysis of the static prograin structure and the dynamic execution behavior. of programs within the entire operating system/user program environment of the Brown University Graphics System (BUGS). Information is collected and presented in a manner which fully exploits two aspects of this environment. First, the operating system has been developed in a well-structured hierarcal manner following principles laid down by other researchers (2), (3). Second the programs under analysis have been written in a structured programming language following coding conventions which make available, at the source code level, valuable program control information. A new set of pictorial constructs is introduced for presenting a. program structure (static or dynamic) for inspection. These constructs combine the best features of an indented structured source code listing and the box odented nature of traditional flow charts. The graphical tools available are USed to provide for swift changes in. the desired level of detail displayed within a program structure, for traveling linearly through a program structure, for traveling through a complex program structure (following subroutine or system calls), for concurrently viewing multiple related program structures, and for presenting dynamic program behavior data using three-dimensional projections, The volume of a three-dimensional box representing a program block is proportional to the block's resource utilization. The scope of this paper is limited to a description of the STRUCT system. This system is currently being used to predict and analyze the performance advantages available through the migration of function (program modules) between levels of software and between software and firmware within BUGS. The results of this research on migration will be included in a doctoral dissertation currently being written."
  },
  {
    "Title": "Experience with distributed processing on a host/satellite graphics system",
    "URL": "https://dl.acm.org/doi/10.1145/563274.563310",
    "Full Abstract": "The problem cf distributing an application between two processors has been investigated by studying an interactive graphics application that is divided between a time-shared host computer and a dedicated satellite system. The division of labor in the application is determined by a network flow assignment algorithm. The effect of variation in availability of the host computer on the distribution of the application is also studied. In particular, host availability is an important factor in determining the task distribution. As host availability decreased, procedures miqrate from the host to the satellite."
  },
  {
    "Title": "Structured programming in assembly language",
    "URL": "https://dl.acm.org/doi/10.1145/382222.382464",
    "Full Abstract": "Structured design and programming techniques can be extended from high-level languages to assembly language. Over the past three years at Brown University, beginning assembly language programmers have been successfully taught these techniques using clearly defined standards. These standards and the solutions to several of the typical problems that arise in structured assembly language programming are discussed in this paper."
  },
  {
    "Title": "A multi-microprocessor implementation of a general purpose pipelined CPU",
    "URL": "https://dl.acm.org/doi/10.1145/800255.810649",
    "Full Abstract": "This paper discusses and shows by example the potential of a network of microprogrammable microprocessors as a cost-effective alternative to traditional hardwired medium- and large-scale mainframes. While biased towards vector processing, this system is not intended to compete with multi-million dollar supercomputers such as the 360/195, CDC STAR, Illiac IV, CRAY-1, TI ASC, etc., which use special algorithms and the fastest circuitry available."
  },
  {
    "Title": "GPGS",
    "URL": "https://dl.acm.org/doi/10.1145/563858.563878",
    "Full Abstract": "GPGS is a subroutine package offering powerful and versatile support for passive and interactive vector graphics, for time-sharing, batch, and stand-alone minicomputer systems. The package is computer, language, and operating system, as well as display device independent. Its key purpose is to allow for transportabiliit of programs and programmers by providing easy to learn, high level features. The applications programmer writes his program once and then executes it on any supported graphics equipment without recompiling or relinking it. Device-independence was implemented by dividing GPGS into a device-independent part invoked by the applications programmer, and internal, \"device drivers\", one per display device. Like the GSPC \"Core System\" whose design it influenced, GPGS is a general purpose package. It has a subset of graphics facilities to handle output of line and character primitives with attributes such as line style and character size, and input from interaction tools such as lightpens, keyboards, valuators, and function keys. It also supports 2D and 3D viewin transformationss for clipping and window to viewport mapping, and coordinate transformations.Unlike the GSPC Core System, GPGS also includes a set of basic features for modelling objects which allows definition of device independent masters called seudo picture segment. These are distinguished from normal, device (DPU) dependent pictur segments into which primitives and their attribute-value settings are ordinarily compiled. These masters may be instanced subject to affine transformations (translate, rotate, and scale) to create a typical master-instance hierarchy. The hierarchy may be stored in a disk based library or compiled into a normal picture segment for output to a display device.The images of objects stored in device dependent picture segments may be transformed on the display surface by v port (image) transformations. These typically allow use of hardware transformation capabilities for dragging or tumbling object images.Host/satellite graphics is accommodated by having the device independent part of GPGS in the host and splitting the device drivers across host and satellite. At the source code level it therefore makes no difference on which.configuration a program will be executed.Among the existing implementations are versions written in assembler for the IB 360/370 and the PDP 11, in both stand-alone and satellite mode, and under a variety of operating systems. They support plotters, storage tubes, and high performance refresh displays. FORTRAN based implementations exist for the Univac 1108, the PDP 10, and a Harris minicomputer."
  },
  {
    "Title": "Distributed Processing",
    "URL": "https://dl.acm.org/doi/10.1109/C-M.1978.217899",
    "Full Abstract": "This issue of Computer is based on two workshops in distributed processing held at Brown University August 17-19, 1976, and August 3-5, 1977. Sponsored by the Army Research Office, the National Science Foundation, and the Office of Naval Research, the workshops attempted to define what distributed processing means and to develop a taxonomy of distributed processing applications and techniques. Achievements to date and outstanding research problems were examined in an attempt to find either commonality of problems and solutions or substantial differences."
  },
  {
    "Title": "Issues in Distributed Processing - an Overview of Two Workshops",
    "URL": "https://dl.acm.org/doi/10.1109/C-M.1978.217902",
    "Full Abstract": "Two workshops on distributed processing were held at Brown University in 1976 and 1977, sponsored by the Army Research Office, the National Science Foundation, and the Office of Naval Research. The workshops had three goals:"
  },
  {
    "Title": "Vertical Migration for Performance Enhancement in Layered Hardware/Firmware/Software Systems",
    "URL": "https://dl.acm.org/doi/10.1109/C-M.1978.218182",
    "Full Abstract": "Vertical migration is a technique which improves system performance by moving software primitives through layers of application program and operating system software and microcode."
  },
  {
    "Title": "Recent Efforts Towards Graphics Standardization",
    "URL": "https://dl.acm.org/doi/10.1145/356744.356746",
    "Full Abstract": "Copyright © 1978 ACM."
  },
  {
    "Title": "Functional Overview of the Core System with Glossary",
    "URL": "https://dl.acm.org/doi/10.1145/356744.356747",
    "Full Abstract": "Copyright © 1978 ACM."
  },
  {
    "Title": "Architectural considerations for a microprogrammable emulating engine using bit-slices",
    "URL": "https://dl.acm.org/doi/10.1145/800053.801936",
    "Full Abstract": "This paper describes architectural considerations which led to the design of a fast programmable processor made from ECL bit-slioes. The processor will be used as an on-line data filtering engine for high energy physics experiments. Unlike prior designs of such engines, the processor supports both user (horizontal) microcode and emulation of the PDP-11 fixed point instruction set (without memory management and multiple interrupt levels). In addition to an overview of the techniques used to achieve an execution speed of roughly three times that of the PDP-11/70 CPU, strengths and weaknesses of bit- slices are discussed, as are the use of a Signetics meta assembler and the ISPS Architecture simulation system."
  },
  {
    "Title": "BUMPS",
    "URL": "https://dl.acm.org/doi/10.1145/800250.807498",
    "Full Abstract": "BUMPS (Brown University Multiple Projection System) is a program that illustrates the implementation of viewing transformations using animation. The program uses the viewing model defined in the Core Graphics System. BUMPS employs interactive computer graphics to demonstrate how planar geometric projections are generated, what the effects of different projections and projection parameters are on the projected object, and how the viewing functions of the Core Graphics System work. After presenting background material on projections, the features of BUMPS are described, followed by a pictorial user scenario of BUMPS in action. The paper concludes with a discussion of the merits of user controlled animation for teaching and possible improvements to the program."
  },
  {
    "Title": "MIDAS",
    "URL": "https://dl.acm.org/doi/10.1109/TE.1981.4321464",
    "Full Abstract": "An interactive graphics program has been developed to simulate and animate the operation of a typical microcomputer system. MIDAS, a microprocessor interpreter display and animation system, allows the user full control over the simulation and the display and provides several auxiliary functions that enhance its capabilities as an instructional tool. The illustration of the activity of the computer, based on the Intel 8080 microprocessor, takes the form of an animated block diagram of the CPU and its peripherals. It shows the operation of the system at various levels of detail, down to the level of the devices' internal registers, buffers, control lines, and buses. This paper describes the design, implementation, and use of MIDAS. It discusses its effectiveness as a tool for teaching the complex, asynchronous interaction between devices of a computer system (known as \"handshaking\"). It also discusses a strategy for developing a generalized tool for simulating and animating arbitrary computer systems."
  },
  {
    "Title": "Vertical and outboard migration",
    "URL": "https://dl.acm.org/doi/10.1145/1500412.1500422",
    "Full Abstract": "The primary method for gaining performance improvement on a fixed-hardware architecture is to tailor the soft components, i.e. the application program, the operating system, or the firmware, to the performance requirements. This paper deals with two specific forms of performance tuning called"
  },
  {
    "Title": "Simulation of a Horizontal Bit-Sliced Processor Using the ISPS Architecture Simulation Facility",
    "URL": "https://dl.acm.org/doi/10.1109/TC.1981.1675830",
    "Full Abstract": "The microprogrammed filter engine (MICE) is a fast, microprogrammable processor built with ECL bit slices (Motorola ECL 10800 series) intended primarily to be used as an on-line data filtering engine for high energy physics experiments. In this note we describe the use of a hardware description language used to model and simulate the hardware during its development. We treat the problem of describing a pipelined, horizontal (112 bits wide) host machine, implemented using bit slices with considerable potential for parallelism. Several levels of modeling are conceptually applicable to a problem of this nature and the note describes the thorough process followed before we decided on a particular style of description and simulation."
  },
  {
    "Title": "An integrated system for creating and presenting complex computer-based documents",
    "URL": "https://dl.acm.org/doi/10.1145/800224.806805",
    "Full Abstract": "An experimental system is described for the design, development, and presentation of computer-based documents that combine pictures and text on a high-resolution raster color display. Such documents can be used, for example, for maintenance and repair tasks or computer-aided instruction."
  },
  {
    "Title": "An experimental system for creating and presenting interactive graphical documents",
    "URL": "https://dl.acm.org/doi/10.1145/357290.357296",
    "Full Abstract": "Copyright © 1982 ACM."
  },
  {
    "Title": "Balanced allocations (extended abstract)",
    "URL": "https://dl.acm.org/doi/10.1145/195058.195412",
    "Full Abstract": "Copyright © 1994 ACM."
  },
  {
    "Title": "Competitive randomized algorithms for nonuniform problems",
    "URL": "https://dl.acm.org/doi/10.1007/BF01189993",
    "Full Abstract": "Competitive analysis is concerned with comparing the performance of on-line algorithms with that of optimal off-line algorithms. In some cases randomization can lead to algorithms with improved performance ratios on worst-case sequences. In this paper we present new randomized on-line algorithms for snoopy caching and the spin-block problem. These algorithms achieve competitive ratios approachinge/(eź1) ź 1.58 against an oblivious adversary. These ratios are optimal and are a surprising improvement over the best possible ratio in the deterministic case, which is 2. We also consider the situation when the request sequences for these problems are generated according to an unknown probability distribution. In this case we show that deterministic algorithms that adapt to the observed request statistics also have competitive factors approachinge/(eź1). Finally, we obtain randomized algorithms for the 2-server problem on a class of isosceles triangles. These algorithms are optimal against an oblivious adversary and have competitive ratios that approache/(eź1). This compares with the ratio of 3/2 that can be achieved on an equilateral triangle."
  },
  {
    "Title": "On-line load balancing",
    "URL": "https://dl.acm.org/doi/10.1016/0304-3975%2894%2990153-8",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Dynamic Perfect Hashing",
    "URL": "https://dl.acm.org/doi/10.1137/S0097539791194094",
    "Full Abstract": "The dynamic dictionary problem is considered: provide an algorithm for storing a dynamic set, allowing the operations insert, delete, and lookup. A dynamic perfect hashing strategy is given: a randomized algorithm for the dynamic dictionary problem that takes $O(1)$ worst-case time for lookups and $O(1)$ amortized expected time for insertions and deletions; it uses space proportional to the size of the set stored. Furthermore, lower bounds for the time complexity of a class of deterministic algorithms for the dictionary problem are proved. This class encompasses realistic hashing-based schemes that use linear space. Such algorithms have amortized worst-case time complexity $\\Omega(\\log n)$ for a sequence of $n$ insertions and lookups; if the worst-case lookup time is restricted to $k$, then the lower bound becomes $\\Omega(k\\cdot n^{1/k})$."
  },
  {
    "Title": "Balanced Allocations (Extended abstract)",
    "URL": "https://dl.acm.org/doi/book/10.5555/903741",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "A study of integrated prefetching and caching strategies",
    "URL": "https://dl.acm.org/doi/10.1145/223587.223608",
    "Full Abstract": "Prefetching and caching are effective techniques for improving the performance of file systems, but they have not been studied in an integrated fashion. This paper proposes four properties that optimal integrated strategies for prefetching and caching must satisfy, and then presents and studies two such integrated strategies, called"
  },
  {
    "Title": "Reducing TLB and memory overhead using online superpage promotion",
    "URL": "https://dl.acm.org/doi/10.1145/223982.224419",
    "Full Abstract": "Modern microprocessors contain small TLBs that maintain a cache of recently used translations. A TLB's"
  },
  {
    "Title": "Randomized and multipointer paging with locality of reference",
    "URL": "https://dl.acm.org/doi/10.1145/225058.225280",
    "Full Abstract": "Copyright © 1995 ACM."
  },
  {
    "Title": "Implementing global memory management in a workstation cluster",
    "URL": "https://dl.acm.org/doi/10.1145/224056.224072",
    "Full Abstract": "Copyright © 1995 ACM."
  },
  {
    "Title": "Two Adaptive Hybrid Cache Coherency Protocols",
    "URL": "https://dl.acm.org/doi/10.5555/525424.822636",
    "Full Abstract": "We present and evaluate adaptive, hybrid cache coherence protocols for bus-based, shared-memory multiprocessors. Such protocols are motivated by the observation that sharing patterns vary substantially between different programs and even cache blocks within the same program. Performance measurements across a range of parallel applications indicate that the adaptive protocols we present perform well compared to both Write-Invalidate and Write-Update protocols."
  },
  {
    "Title": "Integrated parallel prefetching and caching",
    "URL": "https://dl.acm.org/doi/10.1145/233013.233052",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Strongly Competitive Algorithms for Paging with Locality of Reference",
    "URL": "https://dl.acm.org/doi/10.1137/S0097539792236353",
    "Full Abstract": "What is the best paging algorithm if one has partial information about the possible sequences of page requests__ __ We give a partial answer to this question by presenting the analysis of strongly competitive paging algorithms in the access graph model. This model restricts page requests so that they conform to a notion of locality of reference given by an arbitrary access graph."
  },
  {
    "Title": "Online computation",
    "URL": "https://dl.acm.org/doi/10.5555/241938.241951",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Reducing network latency using subpages in a global memory environment",
    "URL": "https://dl.acm.org/doi/10.1145/237090.237198",
    "Full Abstract": "New high-speed networks greatly encourage the use of network memory as a cache for virtual memory and file pages, thereby reducing the need for disk access. Because pages are the fundamental transfer and access units in remote memory systems, page size is a key performance factor. Recently, page sizes of modern processors have been increasing in order to provide more TLB coverage and amortize disk access costs. Unfortunately, for high-speed networks,"
  },
  {
    "Title": "Near-optimal parallel prefetching and caching",
    "URL": "https://dl.acm.org/doi/10.5555/874062.875485",
    "Full Abstract": "The authors consider algorithms for integrated prefetching and caching in a model with a fixed-size cache and any number of backing storage devices (disks). Previously, the single disk case was considered by Cao et al. (1995). They show that the natural extension of their aggressive algorithm to the parallel disk case is suboptimal by a factor near the number of disks in the worst case. The main result is a new algorithm, reverse aggressive, with near-optimal performance in the presence of multiple disks."
  },
  {
    "Title": "A trace-driven comparison of algorithms for parallel prefetching and caching",
    "URL": "https://dl.acm.org/doi/10.1145/238721.238737",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Implementation and performance of integrated application-controlled file caching, prefetching, and disk scheduling",
    "URL": "https://dl.acm.org/doi/10.1145/235543.235544",
    "Full Abstract": "As the performance gap between disks and micropocessors continues to increase, effective utilization of the file cache becomes increasingly immportant. Application-controlled file caching and prefetching can apply application-specific knowledge to improve file cache management. However, supporting application-controlled file caching and prefetching is nontrivial because caching and prefetching need to be integrated carefully, and the kernel needs to allocate cache blocks among processes appropriately. This article presents the design, implementation, and performance of a file system that integrates application-controlled caching, prefetching, and disk scheduling. We use a two-level cache management strategy. The kernel uses the LRU-SP (Least-Recently-Used with Swapping and Placeholders) policy to allocate blocks to processes, and each process integrates application-specific caching and prefetching based on the"
  },
  {
    "Title": "On the Performance of Competitive Algorithms in Practice",
    "URL": "https://dl.acm.org/doi/10.5555/647371.724037",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Implementing cooperative prefetching and caching in a globally-managed memory system",
    "URL": "https://dl.acm.org/doi/10.1145/277851.277869",
    "Full Abstract": "This paper presents"
  },
  {
    "Title": "A Note on the Influence of an ε-Biased Random Source",
    "URL": "https://dl.acm.org/doi/10.1006/jcss.1997.1551",
    "Full Abstract": "An -biased random source is a sequenceX=(X1,X2,Xn) of 0, 1-valued random variables such that the conditional probability PrXi=1|X1,X2,Xi 1 is always between 12 and 12+ . Given a familyS {0,1}nof binary strings of lengthn, its -enhanced probability Pr (S) is defined as the maximum of PrX(S) over all -biased random sourcesX. In this paper we establish a tight lower bound on Pr (S) as a function of |S|,nand ."
  },
  {
    "Title": "Hierarchical Verification Using Verification Diagrams",
    "URL": "https://dl.acm.org/doi/10.5555/646063.676473",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Automatic generation of invariants and intermediate assertions",
    "URL": "https://dl.acm.org/doi/10.1016/S0304-3975%2896%2900191-0",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Hybrid Diagrams",
    "URL": "https://dl.acm.org/doi/10.5555/646512.695481",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Visual Verification of Reactive Systems",
    "URL": "https://dl.acm.org/doi/10.5555/646481.691436",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Deductive Verification of Real-Time Systems Using STeP",
    "URL": "https://dl.acm.org/doi/10.5555/648201.749120",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Deductive Verification of Modular Systems",
    "URL": "https://dl.acm.org/doi/10.5555/646738.701965",
    "Full Abstract": "Effective verification methods, both deductive and algorithmic, exist for the verification of global system properties. In this paper, we introduce a formal framework for the modular description and verification of parameterized fair transition systems. The framework allows us to apply existing global verification methods, such as verification rules and diagrams, in a modular setting. Transition systems and transition modules can be described by recursive module expressions, allowing the description of hierarchical systems of unbounded depth. Apart from the usual parallel composition, hiding and renaming operations, our module description language provides constructs to augment and restrict the module interface, capablilities that are essential for recursive descriptions. We present proof rules for property inheritance between modules. Finally, module abstraction and induction allow the verification of recursively defined systems. Our approach is illustrated with a recursively defined arbiter for which we verify mutual exclusion and eventual access."
  },
  {
    "Title": "Abstraction and Modular Verification of Infinite-State Reactive Systems",
    "URL": "https://dl.acm.org/doi/10.5555/645866.670769",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Deductive Verification of Hybrid Systems Using STeP",
    "URL": "https://dl.acm.org/doi/10.5555/646878.710285",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Decomposing, Transforming and Composing Diagrams: The Joys of Modular Verification",
    "URL": "https://dl.acm.org/doi/book/10.5555/892633",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "COMBINING DIMENSIONALITY AND RATE OF GROWTH ARGUMENTS FOR ESTABLISHING LOWER BOUNDS ON THE NUMBER OF MULTIPLICATIONS",
    "URL": "https://dl.acm.org/doi/book/10.5555/889589",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "THE REDUCTION METHOD FOR ESTABLISHING LOWER BOUNDS ON THE NUMBER OF ADDITIONS",
    "URL": "https://dl.acm.org/doi/book/10.5555/889600",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Addition Requirements for Rational Functions",
    "URL": "https://dl.acm.org/doi/book/10.5555/867356",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Addition Requirements for Rational Functions",
    "URL": "https://dl.acm.org/doi/10.1137/0206015",
    "Full Abstract": "A notion of rank or independence for arbitrary sets of rational functions is developed, which bounds from below the number of additions and subtractions required of all straight-line algorithms which compute those functions. This permits a uniform derivation of the best lower bounds known for a number of familiar sets of rational functions."
  },
  {
    "Title": "Optimal surface reconstruction from planar contours",
    "URL": "https://dl.acm.org/doi/10.1145/563858.563899",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Optimal surface reconstruction from planar contours",
    "URL": "https://dl.acm.org/doi/10.1145/359842.359846",
    "Full Abstract": "In many scientific and technical endeavors, a three-dimensional solid must be reconstructed from serial sections, either to aid in the comprehension of the object's structure or to facilitate its automatic manipulation and analysis. This paper presents a general solution to the problem of constructing a surface over a set of cross-sectional contours. This surface, to be composed of triangular tiles, is constructed by separately determining an optimal surface between each pair of consecutive contours. Determining such a surface is reduced to the problem of finding certain minimum cost cycles in a directed toroidal graph. A new fast algorithm for finding such cycles is utilized. Also developed is a closed-form expression, in terms of the number of contour points, for an upper bound on the number of operations required to execute the algorithm. An illustrated example which involves the construction of a minimum area surface describing a human head is included."
  },
  {
    "Title": "The “highly intelligent” tablet as an efficient pointing device for interactive graphics (Preliminary Report)",
    "URL": "https://dl.acm.org/doi/10.1145/800178.810125",
    "Full Abstract": "Described is a simple, efficient algorithm for determining the nearest displayed point on a screen to an arbitrary cursor position. The algorithm seems particularly appropriate for interactive systems using a data tablet with a “smart” controller. The algorithm is based on partitioning the screen among the currently displayed points and minimally modifing this structure as points are added and deleted. Finding the nearest point for cursor position consists then of moving through this partitioning structure until the region is determined. A divide-and-conquer method is used for both inclusion testing in a particular region and also for speeding the search for the proper nearest point."
  },
  {
    "Title": "Combining Dimensionality and Rate of Growth Arguments for Establishing Lower Bounds on the Number of Multiplications and Divisions",
    "URL": "https://dl.acm.org/doi/10.1145/322139.322153",
    "Full Abstract": "Copyright © 1979 ACM."
  },
  {
    "Title": "Predetermining visibility priority in 3-D scenes (Preliminary Report)",
    "URL": "https://dl.acm.org/doi/10.1145/800249.807441",
    "Full Abstract": "The principal calculation performed by all visible surface algorithms is the determination of the visible polygon at each pixel in the image. Of the many possible speedups and efficiencies found for this problem, only one published algorithm (developed almost a decade ago by a group at General Electric) took advantage of an observation that many visibility calculations could be performed without knowledge of the eventual viewing position and orientation—"
  },
  {
    "Title": "Controlling concurrency using locking protocols",
    "URL": "https://dl.acm.org/doi/10.1109/SFCS.1979.12",
    "Full Abstract": "This paper is concerned with the problem of developing locking protocols for ensuring the consistency of database systems that are accessed concurrently by a number of independent transactions. It is assumed that the database is modelled by a directed acyclic graph whose vertices correspond to the database entities, and whose arcs correspond to certain locking restrictions. Several locking protocols are presented. The weak protocol is shown to ensure consistency and deadlock-freedom only for databases that are organized as trees. For the databases that are organized as directed acyclic graphs, the strong protocol is presented. Discussion of SHARED and EXCLUSIVE locks is also included."
  },
  {
    "Title": "Consistency in Hierarchical Database Systems",
    "URL": "https://dl.acm.org/doi/10.1145/322169.322176",
    "Full Abstract": "Copyright © 1980 ACM."
  },
  {
    "Title": "On visible surface generation by a priori tree structures",
    "URL": "https://dl.acm.org/doi/10.1145/800250.807481",
    "Full Abstract": "This paper describes a new algorithm for solving the hidden surface (or line) problem, to more rapidly generate realistic images of 3-D scenes composed of polygons, and presents the development of theoretical foundations in the area as well as additional related algorithms. As in many applications the environment to be displayed consists of polygons many of whose relative geometric relations are static, we attempt to capitalize on this by preprocessing the environment's database so as to decrease the run-time computations required to generate a scene. This preprocessing is based on generating a “binary space partitioning” tree whose in order traversal of visibility priority at run-time will produce a linear order, dependent upon the viewing position, on (parts of) the polygons, which can then be used to easily solve the hidden surface problem. In the application where the entire environment is static with only the viewing-position changing, as is common in simulation, the results presented will be sufficient to solve completely the hidden surface problem."
  },
  {
    "Title": "Non-two-phase locking protocols with shared and exclusive locks",
    "URL": "https://dl.acm.org/doi/10.5555/1286887.1286920",
    "Full Abstract": "This paper is concerned with the problem of developing a family of locking protocols which employ both SHARED and EXCLUSIVE locks and which ensure the consistency of database systems that are accessed concurrently by a number of asynchronously running transactions. The protocols in the family are not two-phase. They are applicable to database systems which are hierarchically organized as well as database systems which are modeled by directed acyclic graphs. A comparison with other previously published protocols is also presented."
  },
  {
    "Title": "Deadlock removal using partial rollback in database systems",
    "URL": "https://dl.acm.org/doi/10.1145/582318.582329",
    "Full Abstract": "The problem of removing deadlocks from concurrent database systems using the two-phase locking protocol is considered. In particular, for systems which use no a priori information about transaction behavior in order to avoid deadlocks, it has generally been assumed necessary to totally remove and restart some transaction involved in a deadlock in order to relieve the situation. In this paper, a new approach to deadlock removal in such systems based on partial rollbacks is introduced. This approach does not in general require the total removal of a transaction to eliminate a deadlock. The task of optimizing deadlock removal using this method is discussed for systems allowing both exclusive and shared locking. A method is given for implementing this approach with no more storage overhead than that required for total removal and restart."
  },
  {
    "Title": "A theory of correct locking protocols for database systems",
    "URL": "https://dl.acm.org/doi/10.5555/1286831.1286843",
    "Full Abstract": "In database systems which allow concurrent processing, it is necessary to control the interaction among the concurrent transactions in order to prevent them from destroying the consistency of the database. The most common mechanism proposed to achieve this involves the use of locking and unlocking instrucions to provide controlled access to units of shared data. These instructions are embedded in the transactions according to rules which are called locking protocols. A correct locking protocol assures that the consistency of the database is preserved and that no deadlocks occur to prevent termination of the transactions. In this paper, a theory is developed of how a priori syntactic information about the behavior of the transactions in a system can be used to construct correct protocols. The relationship between the problems of assuring correctness and deadlock-freedom is explored in a unified model which applies to systems which allow only exclusive locks as well as to systems which allow both exclusive and shared access nodes."
  },
  {
    "Title": "Lower bounds for algebraic computation trees with integer inputs",
    "URL": "https://dl.acm.org/doi/10.1137/0220041",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Recent Progress in Circuit and Communication Complexity (Abstract)",
    "URL": "https://dl.acm.org/doi/10.5555/647895.740433",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Weighted Random Assignments with Application to Hashing",
    "URL": "https://dl.acm.org/doi/10.5555/648003.743107",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Linear decision trees",
    "URL": "https://dl.acm.org/doi/10.1145/129712.129730",
    "Full Abstract": "Copyright © 1992 ACM."
  },
  {
    "Title": "A circuit-based proof of Toda's theorem",
    "URL": "https://dl.acm.org/doi/10.1006/inco.1993.1033",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Groups and Algebraic Complexity (Abstract)",
    "URL": "https://dl.acm.org/doi/10.5555/645929.672557",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "A randomized algorithm for finding maximum with ",
    "URL": "https://dl.acm.org/doi/10.1016/0020-0190%2894%2990052-3",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Decision tree complexity and Betti numbers",
    "URL": "https://dl.acm.org/doi/10.1145/195058.195414",
    "Full Abstract": "Copyright © 1994 ACM."
  },
  {
    "Title": "Near-Optimal Time-Space Tradeoff for Element Distinctness",
    "URL": "https://dl.acm.org/doi/10.1137/S0097539788148959",
    "Full Abstract": "It was conjectured in Borodin et al. ["
  },
  {
    "Title": "On Computing Algebraic Functions using Logarithms andExponentials",
    "URL": "https://dl.acm.org/doi/10.1137/S0097539793245015",
    "Full Abstract": "Let $\\rho$ be a set of algebraic expressions constructed with radicals and arithmetic operations, and which generate the splitting field $F$ of some polynomial. Let $N_{\\beta}(\\rho)$ be the minimum total number of root-takings and exponentiations used in any straightline program for computing the functions in $\\rho$ by taking roots, exponentials, logarithms, and performing arithmetic operations. In this paper it is proved that $N_{\\beta}(\\rho) = \\nu(G)$, where $\\nu(G)$ is the minimum length of any cyclic Jordan--Holder tower for the Galois group $G$ of $F$. This generalizes a result of Ja'Ja' ["
  },
  {
    "Title": "On the shrinkage exponent for read-once formulae",
    "URL": "https://dl.acm.org/doi/10.1016/0304-3975%2894%2900081-S",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Algebraic decision trees and Euler characteristics",
    "URL": "https://dl.acm.org/doi/10.1016/0304-3975%2894%2900082-T",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Security of quantum protocols against coherent measurements",
    "URL": "https://dl.acm.org/doi/10.1145/225058.225085",
    "Full Abstract": "Copyright © 1995 ACM."
  },
  {
    "Title": "A Lower Bound on the Size of Algebraic Decision Trees for the MAX Problem",
    "URL": "https://dl.acm.org/doi/book/10.5555/895380",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Hypergraphs and Decision Trees (Abstract)",
    "URL": "https://dl.acm.org/doi/10.5555/647677.731843",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Read-once branching programs, rectangular proofs of the pigeonhole principle and the transversal calculus",
    "URL": "https://dl.acm.org/doi/10.1145/258533.258673",
    "Full Abstract": "Copyright © 1997 ACM."
  },
  {
    "Title": "Decision Tree Complexity and Betti Numbers",
    "URL": "https://dl.acm.org/doi/10.1006/jcss.1997.1495",
    "Full Abstract": "We show that any algebraic computation tree or any fixed-degree algebraic tree for solving the membership question of a compact setS Rnmust have height greater than (log( i(S))) cnfor eachi, where i(S) is theith Betti number. This generalizes a well-known result by Ben-Or who proved this lower bound for the casei=0, and a recent result by Bj rner and Lov sz who proved this lower bound for allifor linear decision trees."
  },
  {
    "Title": "RAPID",
    "URL": "https://dl.acm.org/doi/10.1145/262839.262993",
    "Full Abstract": "Copyright © 1997 ACM."
  },
  {
    "Title": "Dictionary Look-Up with One Error",
    "URL": "https://dl.acm.org/doi/10.1006/jagm.1997.0875",
    "Full Abstract": "LetWbe a set ofnbinary strings of lengthmeach. We are interested in designing data structures forWthat can answerd-queriesquickly; that is, given in a binary string, decide whether there is any member ofWwithin Hamming distancedof . The problem, originally raised by Minsky and Papert, remains a challenge in data structure design. In this paper, we make an initial effort toward a theoretical study of the smalldcase. Our main result is a data structure that achievesO(mloglogn) query time withO(nmlogm) space for thed=1 case."
  },
  {
    "Title": "Interactive Editing Systems: Part I",
    "URL": "https://dl.acm.org/doi/10.1145/356887.356889",
    "Full Abstract": "Copyright © 1982 ACM."
  },
  {
    "Title": "Interactive Editing Systems: Part II",
    "URL": "https://dl.acm.org/doi/10.1145/356887.356890",
    "Full Abstract": "Copyright © 1982 ACM."
  },
  {
    "Title": "Fundamentals of interactive computer graphics",
    "URL": "https://dl.acm.org/doi/book/10.5555/6684",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Computer graphics in higher education (Panel Session)",
    "URL": "https://dl.acm.org/doi/10.1145/800059.801129",
    "Full Abstract": "Copyright © 1983 ACM."
  },
  {
    "Title": "Meeting the Crisis in Computer Science",
    "URL": "https://dl.acm.org/doi/10.1109/MC.1983.1654271",
    "Full Abstract": "First Page of the Article"
  },
  {
    "Title": "Meeting the crisis in computer science",
    "URL": "https://dl.acm.org/doi/10.1145/358476.358488",
    "Full Abstract": "Copyright © 1983 ACM."
  },
  {
    "Title": "The electronic classroom",
    "URL": "https://dl.acm.org/doi/10.1145/800014.808141",
    "Full Abstract": "Continuing advances in hardware have made it possible to replace mainframe time-sharing systems (with their inherent performance limitations and poor user interfaces based on low-speed alphanumeric terminals) by powerful personal computers. When these personal computers have high-resolution bit-mapped graphics displays, fast processors, and virtual memory, and are linked in networks, they combine the best of dedicated computing (e.g., immediate response) with the best of time-sharing (e.g., resource-sharing of programs, data and peripherals). Personal computers so configured are typically called workstations. Such workstations have been introduced in the last few years primarily for professionals in productivity-sensitive areas like engineering design and office automation, but recent price/performance improvement has made it possible to consider them for use in education as well."
  },
  {
    "Title": "Computer graphics comes of age",
    "URL": "https://dl.acm.org/doi/10.1145/358105.358190",
    "Full Abstract": "Copyright © 1984 ACM."
  },
  {
    "Title": "The electronic classroom:  workstations for teaching",
    "URL": "https://dl.acm.org/doi/10.1016/S0020-7373%2884%2980053-X",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "1984 Snowbird Report",
    "URL": "https://dl.acm.org/doi/10.1109/MC.1985.1662897",
    "Full Abstract": "First Page of the Article"
  },
  {
    "Title": "Reading and Writing the Electronic Book",
    "URL": "https://dl.acm.org/doi/10.1109/MC.1985.1662710",
    "Full Abstract": "First Page of the Article"
  },
  {
    "Title": "High performance graphics systems (panel session)",
    "URL": "https://dl.acm.org/doi/10.1145/320435.320518",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Pascal on the Macintosh: a graphical approach",
    "URL": "https://dl.acm.org/doi/book/10.5555/21671",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Hypertext '87: keynote address",
    "URL": "https://dl.acm.org/doi/10.1145/48511.48519",
    "Full Abstract": "Copyright © 1988 ACM."
  },
  {
    "Title": "PHIGS+ functional description revision",
    "URL": "https://dl.acm.org/doi/10.1145/51683.51684",
    "Full Abstract": "This is a set of proposed extensions to the proposed PHIGS graphics standard (dpANS X3.144-198x. DIS 9592) to cover the areas of lighting, shading and advanced primitives which have thus far not been addressed by that standard. This document is organized to promote its eventual integration with the existing PHIGS documentation and is therefore not tutorial in nature. It assumes that the reader is familiar with PHIGS. with rendering and with curves and surfaces. This specification has been made available to standards bodies for their consideration."
  },
  {
    "Title": "The Application Visualization System",
    "URL": "https://dl.acm.org/doi/10.1109/38.31462",
    "Full Abstract": "A software system for developing interactive scientific visualization applications quickly, with a minimum of programming effort, is described. This application visualization system (AVS) is an application framework targeted at scientists and engineers. The goal of the system is to make applications that combine interactive graphics and high computational requirements easier to develop for both programmers and nonprogrammers. AVS is designed around the concept of software building blocks, or modules, which can be interconnected to form visualization applications. AVS allows flow networks of existing modules to be constructed using a direct-manipulation user interface, and it automatically generates a simple user interface to each module."
  },
  {
    "Title": "Simulation of a horizontal bit-sliced processor using the ISPS architecture simulation facility",
    "URL": "https://dl.acm.org/doi/10.5555/72832.72865",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Trends in Computer Graphics",
    "URL": "https://dl.acm.org/doi/10.5555/645819.669395",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Computer graphics: principles and practice (2nd ed.)",
    "URL": "https://dl.acm.org/doi/book/10.5555/83821",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "An Object-Oriented Framework for the Integration of Interactive Animation Techniques",
    "URL": "https://dl.acm.org/doi/book/10.5555/864881",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Potentials and limitations of fault-based Markov prefetching for virtual memory pages",
    "URL": "https://dl.acm.org/doi/10.1145/301453.301572",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "On List Update and Work Function Algorithms",
    "URL": "https://dl.acm.org/doi/10.5555/647909.740306",
    "Full Abstract": "The list update problem, a well-studied problem in dynamic data structures, can be described abstractly as a metrical task system. In this paper, we prove that a generic metrical task system algorithm, called the work function algorithm, has constant competitive ratio for list update. In the process, we present a new formulation of the well-known \"list factoring\" technique in terms of a partial order on the elements of the list. This approach leads to a new simple proof that a large class of online algorithms, including Move-To-Front, is (2 - 1/"
  },
  {
    "Title": "Balanced Allocations",
    "URL": "https://dl.acm.org/doi/10.1137/S0097539795288490",
    "Full Abstract": "Suppose that we sequentially place $n$ balls into"
  },
  {
    "Title": "Organization-based analysis of web-object sharing and caching",
    "URL": "https://dl.acm.org/doi/10.5555/1251480.1251483",
    "Full Abstract": "Performance-enhancing mechanisms in the World Wide Web primarily exploit repeated requests to Web documents by multiple clients. However, little is known about patterns of shared document access, particularly from diverse client populations. The principal goal of this paper is to examine the sharing of Web documents from an organizational point of view. An organizational analysis of sharing is important, because caching is often performed on an organizational basis; i.e., proxies are typically placed in front of large and small companies, universities, departments, and so on. Unfortunately, simultaneous multi-organizational traces do not currently exist and are difficult to obtain in practice."
  },
  {
    "Title": "On the scale and performance of cooperative Web proxy caching",
    "URL": "https://dl.acm.org/doi/10.1145/319151.319153",
    "Full Abstract": "While algorithms for cooperative proxy caching have been widely studied, little is understood about cooperative-caching performance in the large-scale World Wide Web environment. This paper uses both trace-based analysis and analytic modelling to show the potential advantages and drawbacks of inter-proxy cooperation. With our traces, we evaluate quantitatively the performance-improvement potential of cooperation between 200 small-organization proxies within a university environment, and between two large-organization proxies handling 23,000 and 60,000 clients, respectively. With our model, we extend beyond these populations to project cooperative caching behavior in regions with millions of clients. Overall, we demonstrate that cooperative caching has performance benefits only within limited population bounds. We also use our model to examine the implications of future trends in Web-access behavior and traffic."
  },
  {
    "Title": "Near-Optimal Parallel Prefetching and Caching",
    "URL": "https://dl.acm.org/doi/10.1137/S0097539797326976",
    "Full Abstract": "Recently there has been a great deal of interest in the operating systems research community in prefetching and caching data from parallel disks, as a technique for enabling serial applications to improve input--output (I/O) performance. In this paper, algorithms are considered for integrated prefetching and caching in a model with a fixed-size cache and any number of backing storage devices (disks). The integration of caching and prefetching with a single disk was previously considered by Cao, Felten, Karlin, and Li. Here, it is shown that the natural extension of their"
  },
  {
    "Title": "On the scale and performance of cooperative Web proxy caching",
    "URL": "https://dl.acm.org/doi/10.1145/346152.346166",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Markov Paging",
    "URL": "https://dl.acm.org/doi/10.1137/S0097539794268042",
    "Full Abstract": "This paper considers the problem of paging under the assumption that the sequence of pages accessed is generated by a Markov chain. We use this model to study the fault-rate of paging algorithms. We first draw on the theory of Markov decision processes to characterize the paging algorithm that achieves optimal fault-rate on any Markov chain. Next, we address the problem of devising a paging strategy with low fault-rate for a given Markov chain. We show that a number of intuitive approaches fail. Our main result is a polynomial-time procedure that, on any Markov chain, will give a paging algorithm with fault-rate at most a constant times optimal. Our techniques show also that some algorithms that do poorly in practice fail in the Markov setting, despite known (good) performance guarantees when the requests are generated independently from a probability distribution."
  },
  {
    "Title": "Random walks with “back buttons” (extended abstract)",
    "URL": "https://dl.acm.org/doi/10.1145/335305.335362",
    "Full Abstract": "Copyright © 2000 ACM."
  },
  {
    "Title": "Practical network support for IP traceback",
    "URL": "https://dl.acm.org/doi/10.1145/347059.347560",
    "Full Abstract": "This paper describes a technique for tracing anonymous packet flooding attacks in the Internet back towards their source. This work is motivated by the increased frequency and sophistication of denial-of-service attacks and by the difficulty in tracing packets with incorrect, or ``spoofed'', source addresses. In this paper we describe a general purpose traceback mechanism based on probabilistic packet marking in the network. Our approach allows a victim to identify the network path(s) traversed by attack traffic without requiring interactive operational support from Internet Service Providers (ISPs). Moreover, this traceback can be performed ``post-mortem'' -- after an attack has completed. We present an implementation of this technology that is incrementally deployable, (mostly) backwards compatible and can be efficiently implemented using conventional technology."
  },
  {
    "Title": "Spectral Analysis for Data Mining",
    "URL": "https://dl.acm.org/doi/10.5555/646679.702315",
    "Full Abstract": "Experimental evidence suggests that spectral techniques are valuable for a wide range of applications. A partial list of such applications include (i) semantic analysis of documents used to cluster documents into areas of interest, (ii) collaborative filtering -- the reconstruction of missing data items, and (iii) determining the relative importance of documents based on citation/link structure. Intuitive arguments can explain some of the phenomena that has been observed but little theoretical study has been done. In this talk, we present a model for framing data mining tasks and a unified approach to solving the resulting data mining problems using spectral analysis. In particular we describe the solution to an open problem of Papadimitriou, Ragha van, Tamaki and Vempala in the context of modeling latent semantic indexing. We also give theoretical justification for the use of spectral algorithms for collaborative filtering, and show how a reasonable model of web links justifies the robustness of Kleinberg's web authority/hub algorithm. A major focus of the talk will be a description of the tight feedback loop between theory and empirical work and how it has led on this project to both new theory and new empirical questions of interest."
  },
  {
    "Title": "On algorithms for efficient data migration",
    "URL": "https://dl.acm.org/doi/10.5555/365411.365549",
    "Full Abstract": "The"
  },
  {
    "Title": "Network support for IP traceback",
    "URL": "https://dl.acm.org/doi/10.1109/90.929847",
    "Full Abstract": "This paper describes a technique for tracing anonymous packet flooding attacks in the Internet back toward their source. This work is motivated by the increased frequency and sophistication of denial-of-service attacks and by the difficulty in tracing packets with incorrect, or “spoofed,” source addresses. In this paper, we describe a general purpose traceback mechanism based on probabilistic packet marking in the network. Our approach allows a victim to identify the network path(s) traversed by attack traffic without requiring interactive operational support from Internet Service Providers (ISPs). Moreover, this traceback can be performed “post mortem”—after an attack has completed. We present an implementation of this technology that is incrementally deployable, (mostly) backward compatible, and can be efficiently implemented using conventional technology."
  },
  {
    "Title": "Dynamic TCP acknowledgement and other stories about e/(e-1)",
    "URL": "https://dl.acm.org/doi/10.1145/380752.380845",
    "Full Abstract": "We present the first optimal randomized online algorithms for the TCP acknowledgment problem [5] and the Bahncard problem [7]. These problems are well-known to be generalizations of the classical online ski rental problem, however, they appeared to be harder. In this paper, we demonstrate that a number of online algorithms which have optimal competitive ratios of"
  },
  {
    "Title": "Spectral analysis of data",
    "URL": "https://dl.acm.org/doi/10.1145/380752.380859",
    "Full Abstract": "Experimental evidence suggests that spectral techniques are valuable for a wide range of applications. A partial list of such applications include (i) semantic analysis of documents used to cluster documents into areas of interest, (ii) collaborative filtering --- the reconstruction of missing data items, and (iii) determining the relative importance of documents based on citation/link structure. Intuitive arguments can explain some of the phenomena that has been observed but little theoretical study has been done. In this paper we present a model for framing data mining tasks and a unified approach to solving the resulting data mining problems using spectral analysis. These results give strong justification to the use of spectral techniques for latent semantic indexing, collaborative filtering, and web site ranking."
  },
  {
    "Title": "Web Search via Hub Synthesis",
    "URL": "https://dl.acm.org/doi/10.5555/646977.711699",
    "Full Abstract": "We present a probabilistic generative model for web search which captures in a unified manner three critical components of web search: how the link structure of the web is generated, how the content of a web document is generated, and how a human searcher generates a query. The key to this unification lies in capturing the correlations between each of these components in terms of proximity in latent semantic space. Given such a combined model, the correct answer to a search query is well defined, and thus it becomes possible to evaluate web search algorithms rigorously. We present a new web search algorithm, based on spectral techniques, and prove that it is guaranteed to produce an approximately correct answer in our model. The algorithm assumes no knowledge of the model, and is well-defined regardless of the accuracy of the model."
  },
  {
    "Title": "An Experimental Study of Data Migration Algorithms",
    "URL": "https://dl.acm.org/doi/10.5555/647258.720796",
    "Full Abstract": "The data migration problem is the problem ofc omputing a plan for moving data objects stored on devices in a network from one configuration to another. Load balancing or changing usage patterns might necessitate such a rearrangement ofda ta. In this paper, we consider the case where the objects are fixed-size and the network is complete. We introduce two new data migration algorithms, one ofwh ich has provably good bounds. We empirically compare the performance of these new algorithms against similar algorithms from Hall et al. [7] which have better theoretical guarantees and find that in almost all cases, the new algorithms perform better. We also find that both the new algorithms and the ones from Hall et al. perform much better in practice than the theoretical bounds suggest."
  },
  {
    "Title": "Web Search via Hub Synthesis",
    "URL": "https://dl.acm.org/doi/10.5555/874063.875586",
    "Full Abstract": "We present a model for web search that captures in a unified manner three critical components of the problem: how the link structure of the web is generated, how the contentof a web document is generated, and how a human searcher generates a query. The key to this unification lies in capturing the correlations between these components in terms of proximity in a shared latent semantic space. Given such a combined model, the correct answer to a search query is well defined, and thus it becomes possible to evaluate web search algorithms rigorously. We present a new web search algorithm, based on spectral techniques, and prove that it is guaranteed to produce an approximately correct answer in our model. The algorithm assumes no knowledge of the model, and is well-defined regardless of the model's accuracy."
  },
  {
    "Title": "A quantitative evaluation of traffic-aware routing strategies",
    "URL": "https://dl.acm.org/doi/10.1145/510726.510741",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "CtCoq",
    "URL": "https://dl.acm.org/doi/10.5555/648232.752990",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Dynamically Fault-Tolerant Content Addressable Networks",
    "URL": "https://dl.acm.org/doi/10.5555/646334.687807",
    "Full Abstract": "We describe a content addressable network which is robust in the face of massive adversarial attacks and in a highly dynamic environment. Our network is robust in the sense that at any time, an arbitrarily large fraction of the peers can reach an arbitrarily large fraction of the data items. The network can be created and maintained in a completely distributed fashion."
  },
  {
    "Title": "Head-Tactics Simplification",
    "URL": "https://dl.acm.org/doi/10.5555/646058.678365",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Fix-Point Equations for Well-Founded Recursion in Type Theory",
    "URL": "https://dl.acm.org/doi/10.5555/646527.695036",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Changing Data Structures in Type Theory",
    "URL": "https://dl.acm.org/doi/10.5555/646540.696039",
    "Full Abstract": "In type-theory based proof systems that provide inductive structures, computation tools are automatically associated to inductive definitions. Choosing a particular representation for a given concept has a strong influence on proof structure. We propose a method to make the change from one representation to another easier, by systematically translating proofs from one context to another. Weshow how this method works by using it on natural numbers, for which a unary representation (based on Peano axioms) and a binary representation are available. This method leads to an automatic translation tool that we have implemented in Coq and successfully applied to several arithmetical theorems."
  },
  {
    "Title": "Formalizing a JVML Verifier for Initialization in a Theorem Prover",
    "URL": "https://dl.acm.org/doi/10.5555/647770.734123",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "A Generic Approach to Building User Interfaces for Theorem Provers",
    "URL": "https://dl.acm.org/doi/10.1006/jsco.1997.0171",
    "Full Abstract": "In this paper, we present the results of an ongoing effort in building user interfaces for proof systems. Our approach is generic: we are not constructing a user interface for a particular proof system, rather we have developed techniques and tools that have been applied to several proof systems. We first propose and motivate a distributed architecture, where the proof system and the interface are two separate processes communicating through a protocol. Then we describe three high-level features:proof-by-pointing,script management, andtextual explanation. Altogether, they take advantage of the underlying architecture and yield a more user-friendly proof environment."
  },
  {
    "Title": "Type-Theoretic Functional Semantics",
    "URL": "https://dl.acm.org/doi/10.5555/646529.695218",
    "Full Abstract": "We describe the operational and denotational semantics of a small imperative language in type theory with inductive and recursive definitions. The operational semantics is given by natural inference rules, implemented as an inductive relation. The realization of the denotational semantics is more delicate: The nature of the language imposes a few difficulties on us. First, the language is Turing-complete, and therefore the interpretation function we consider is necessarily partial. Second, the language contains strict sequential operators, and therefore the function necessarily exhibits nested recursion. Our solution combines and extends recent work by the authors and others on the treatment of general recursive functions and partial and nested recursive functions. The first new result is a technique to encode the approach of Bove and Capretta for partial and nested recursive functions in type theories that do not provide simultaneous induction-recursion. A second result is a clear understanding of the characterization of the definition domain for general recursive functions, a key aspect in the approach by iteration of Balaa and Bertot. In this respect, the work on operational semantics is a meaningful example, but the applicability of the technique should extend to other circumstances where complex recursive functions need to be described formally."
  },
  {
    "Title": "Formalizing Convex Hull Algorithms",
    "URL": "https://dl.acm.org/doi/10.5555/646528.695057",
    "Full Abstract": "We study the development of formally proved algorithms for computational geometry. The result of this work is a formal description of the basic principles that make convex hull algorithms work and two programs that implement convex hull computation and have been automatically obtained from formally verified mathematical proofs. A special attention has been given to handling degenerate cases that are often overlooked by conventional algorithm presentations."
  },
  {
    "Title": "Verification of Parameterized Systems by Dynamic Induction on Diagrams",
    "URL": "https://dl.acm.org/doi/10.5555/647768.733794",
    "Full Abstract": "In this paper we present a visual approach to proving progress properties of parameterized systems using induction on verification diagrams. The inductive hypothesis is represented by an automaton and is based on a state-dependent order on process indices, for increased flexibility. This approach yields more intuitive proofs for progress properties and simpler verification conditions that are more likely to be proved automatically."
  },
  {
    "Title": "A Proof of GMP Square Root",
    "URL": "https://dl.acm.org/doi/10.1023/A%3A1021987403425",
    "Full Abstract": "We present a formal proof (at the implementation level) of an efficient algorithm proposed by P. Zimmermann in 1999 to compute square roots of arbitrarily large integers. This program, which is part of the GNU Multiple Precision Arithmetic Library, is completely proven within the COQ system. Proofs are developed using the CORRECTNESS tool to deal with imperative features of the program. The formalization is rather large (more than 13,000 lines) and requires some advanced techniques for proof management and reuse."
  },
  {
    "Title": "Verifying Temporal Properties of Reactive Systems",
    "URL": "https://dl.acm.org/doi/10.1023/A%3A1008700623084",
    "Full Abstract": "We review a number of formal verification techniques supported by STeP, the Stanford Temporal Prover, describing how the tool can be used to verify properties of several versions of the Bakery Mutual exclusion algorithm for mutual exclusion. We verify the classic two-process algorithm and simple variants, as well as an atomic parameterized version. The methods used include deductive verification rules, verification diagrams, automatic invariant generation, and finite-state model checking and abstraction."
  },
  {
    "Title": "Deductive Model Checking",
    "URL": "https://dl.acm.org/doi/10.1023/A%3A1008791913551",
    "Full Abstract": "We present an extension of classical tableau-based model checking procedures to the case of infinite-state systems, using deductive methods in an incremental construction of the behavior graph. Logical formulas are used to represent infinite sets of states in an abstraction of this graph, which is repeatedly refined in the search for a counterexample computation, ruling out large portions of the graph before they are expanded to the state-level. This can lead to large savings, even in the case of finite-state systems. Only local conditions need to be checked at each step, and previously proven properties can be used to further constrain the search. Although the resulting method is not always automatic, it provides a flexible, general and complete framework that can integrate a diverse number of other verification tools."
  },
  {
    "Title": "Alternating the Temporal Picture for Safety",
    "URL": "https://dl.acm.org/doi/10.5555/646253.686326",
    "Full Abstract": "We use alternating automata on infinite words to reduce the verification of linear temporal logic (LTL) safety properties over infinite-state systems to the proof of first-order verification conditions. Thus method generalizes the traditional deductive verification approach of providing verification rules for particular classes of formulas, such as invariances, nested precedence formulas, etc. It facilitates the deductive verification of arbitrary safety properties without the need for explicit temporal reasoning."
  },
  {
    "Title": "Deductive verification of real-time systems using STeP",
    "URL": "https://dl.acm.org/doi/10.1016/S0304-3975%2800%2900088-8",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "The ‘Cash-Point’ Service: A Verification Case Study Using STeP",
    "URL": "https://dl.acm.org/doi/10.1007/s001650070014",
    "Full Abstract": "STeP, the Stanford Temporal Prover, supports the computer-aided formal verification of concurrent and reactive systems based on temporal specifications [MBB99]. Automated"
  },
  {
    "Title": "Non-linear loop invariant generation using Gröbner bases",
    "URL": "https://dl.acm.org/doi/10.1145/964001.964028",
    "Full Abstract": "We present a new technique for the generation of non-linear (algebraic) invariants of a program. Our technique uses the theory of ideals over polynomial rings to reduce the non-linear invariant generation problem to a numerical constraint solving problem. So far, the literature on invariant generation has been focussed on the construction of linear invariants for linear programs. Consequently, there has been little progress toward non-linear invariant generation. In this paper, we demonstrate a technique that encodes the conditions for a given template assertion being an invariant into a set of constraints, such that all the solutions to these constraints correspond to non-linear (algebraic) loop invariants of the program. We discuss some trade-offs between the completeness of the technique and the tractability of the constraint-solving problem generated. The application of the technique is demonstrated on a few examples."
  },
  {
    "Title": "Scalable analysis of linear systems using mathematical programming",
    "URL": "https://dl.acm.org/doi/10.1007/978-3-540-30579-8_2",
    "Full Abstract": "We present a method for generating linear invariants for large systems. The method performs forward propagation in an abstract domain consisting of arbitrary polyhedra of a predefined fixed shape. The basic operations on the domain like abstraction, intersection, join and inclusion tests are all posed as linear optimization queries, which can be solved efficiently by existing LP solvers. The number and dimensionality of the LP queries are polynomial in the program dimensionality, size and the number of target invariants. The method generalizes similar analyses in the interval, octagon, and octahedra domains, without resorting to polyhedral manipulations. We demonstrate the performance of our method on some benchmark programs."
  },
  {
    "Title": "Termination of polynomial programs",
    "URL": "https://dl.acm.org/doi/10.1007/978-3-540-30579-8_8",
    "Full Abstract": "We present a technique to prove termination of multipath polynomial programs, an expressive class of loops that enables practical code abstraction and analysis. The technique is based on finite differences of expressions over transition systems. Although no complete method exists for determining termination for this class of loops, we show that our technique is useful in practice. We demonstrate that our prototype implementation for C source code readily scales to large software projects, proving termination for a high percentage of targeted loops."
  },
  {
    "Title": "LOLA",
    "URL": "https://dl.acm.org/doi/10.1109/TIME.2005.26",
    "Full Abstract": "We present a specification language and algorithms for the online and offline monitoring of synchronous systems including circuits and embedded systems. Such monitoring is useful not only for testing, but also under actual deployment. The specification language is simple and expressive; it can describe both correctness/failure assertions along with interesting statistical measures that are useful for system profiling and coverage analysis. The algorithm for online monitoring of queries in this language follows a partial evaluation strategy: it incrementally constructs output streams from input streams, while maintaining a store of partially evaluated expressions for forward references. We identify a class of specifications, characterized syntactically, for which the algorithmýs memory requirement is independent of the length of the input streams. Being able to bound memory requirements is especially important in online monitoring of large input streams. We extend the concepts used in the online algorithm to construct an efficient offline monitoring algorithm for large traces. We have implemented our algorithm and applied it to two industrial systems, the PCI bus protocol and a memory controller. The results demonstrate that our algorithms are practical and that our specification language is sufficiently expressive to handle specifications of interest to industry."
  },
  {
    "Title": "Linear ranking with reachability",
    "URL": "https://dl.acm.org/doi/10.1007/11513988_48",
    "Full Abstract": "We present a complete method for synthesizing"
  },
  {
    "Title": "The polyranking principle",
    "URL": "https://dl.acm.org/doi/10.1007/11523468_109",
    "Full Abstract": "Although every terminating loop has a ranking function, not every loop has a ranking function of a restricted form, such as a lexicographic tuple of polynomials over program variables. The"
  },
  {
    "Title": "The decidability of the first-order theory of knuth-bendix order",
    "URL": "https://dl.acm.org/doi/10.1007/11532231_10",
    "Full Abstract": "Two kinds of orderings are widely used in term rewriting and theorem proving, namely"
  },
  {
    "Title": "Termination analysis of integer linear loops",
    "URL": "https://dl.acm.org/doi/10.1007/11539452_37",
    "Full Abstract": "Usually, ranking function synthesis and invariant generation over a loop with integer variables involves abstracting the loop to have real variables. Integer division and modulo arithmetic must be soundly abstracted away so that the analysis over the abstracted loop is sound for the original loop. Consequently, the analysis loses precision. In contrast, we introduce a technique for handling loops over integer variables directly. The resulting analysis is more precise than previous analyses."
  },
  {
    "Title": "Final semantics for event-pattern reactive programs",
    "URL": "https://dl.acm.org/doi/10.1007/11548133_23",
    "Full Abstract": "Event-pattern reactive programs are front-end programs for distributed reactive components that preprocess an incoming stream of event stimuli. Their purpose is to recognize temporal patterns of events that are relevant to the serviced program and ignore all other events, outsourcing some of the component's complexity and shielding it from event overload. Correctness of event-pattern reactive programs is essential, because bugs may result in loss of relevant events and hence failure to react appropriately."
  },
  {
    "Title": "Thread allocation protocols for distributed real-time and embedded systems",
    "URL": "https://dl.acm.org/doi/10.1007/11562436_13",
    "Full Abstract": "We study the problem of thread allocation in asynchronous distributed real-time and embedded systems. Each distributed node handles a limited set of resources, in particular a limited thread pool. Different methods can be invoked concurrently in each node, either by external agents or as a remote call during the execution of a method. In this pa- per we study thread allocation under a"
  },
  {
    "Title": "Expressive completeness of an event-pattern reactive programming language",
    "URL": "https://dl.acm.org/doi/10.1007/11562436_39",
    "Full Abstract": "Event-pattern reactive programs serve reactive components by pre-processing the input event stream and generating notifications according to temporal patterns. The declarative language PAR allows the expression of complex event-pattern reactions. Despite its simplicity and deterministic nature, PAR is expressively complete in the following sense:"
  },
  {
    "Title": "Termination and invariance analysis of loops",
    "URL": "https://dl.acm.org/doi/10.1007/11562948_2",
    "Full Abstract": "Deductive verification aims to prove deep properties about programs. The classic Floyd-Hoare-style approach to verifying sequential programs reduces program validity queries to first-order validity queries via verification conditions. Proving that a program is totally correct requires proving the safety aspect with invariants and the progress aspect with invariants and ranking functions. Where do the invariants and ranking functions come from?"
  },
  {
    "Title": "An Efficient Deadlock Removal Scheme for Non-Two-Phase Locking Protocols",
    "URL": "https://dl.acm.org/doi/10.5555/645910.673597",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Optimal allocation of computational resources in VLSI",
    "URL": "https://dl.acm.org/doi/10.5555/1382436.1382776",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Locking Protocols",
    "URL": "https://dl.acm.org/doi/10.1145/2157.322406",
    "Full Abstract": "Copyright © 1983 ACM."
  },
  {
    "Title": "A Non-Two-Phase Locking Protocol for Concurrency Control in General Databases",
    "URL": "https://dl.acm.org/doi/10.5555/645911.673599",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Optimal Allocation of Area for Single-Chip Computations",
    "URL": "https://dl.acm.org/doi/10.1137/0214053",
    "Full Abstract": "This paper presents initial results on the problem of allocation of the available VLSI chip’s area among various functional components such as I/Q pads, memory cells, and internal wiring. First, a general lower bound for any chip computing a transitive function is derived; this bound is tight for certain functions. The arguments used in the various derivations are later used to specify which of the components are critical depending on the relative sizes of the chip and the number of variables of the function to be computed. The general lower bound is powerful enough that many of the previously proved lower bounds (which could account only for some of the functional requirements) are obtained as explicit special cases of the new result."
  },
  {
    "Title": "On high-speed computing with a programmable linear array",
    "URL": "https://dl.acm.org/doi/10.5555/62972.63026",
    "Full Abstract": "It has been observed by many researchers that systolic arrays are very suitable for certain high-speed computations. In this paper, using a formal methodology, a single simple programmable linear systolic array capable of solving large number of problems drawn from a variety of applications is designed. The methodology is applicable to problems solvable by sequential algorithms that can be specified as nested for loops of arbitrary depth. The algorithms of this form that can be computed on the array presented in this paper include 25 algorithms dealing with signal and image processing, algebraic computations, matrix arithmetic, pattern matching, database operations, sorting, and transitive closure. Assuming bounded I/O, for 18 of those algorithms the time and storage complexities are optimal, and therefore no improvement can be expected by utilizing dedicated special purpose linear systolic arrays designed for individual algorithms."
  },
  {
    "Title": "Synthesizing Linear Array Algorithms from Nested FOR Loop Algorithms",
    "URL": "https://dl.acm.org/doi/10.1109/12.9735",
    "Full Abstract": "The mapping of algorithms structured as depth-p nested FOR loops into special-purpose systolic VLSI linear arrays is addressed. The mappings are done by using linear functions to transform the original sequential algorithms into a form suitable for parallel execution on linear arrays. A feasible mapping is derived by identifying formal criteria to be satisfied by both the original sequential algorithm and the proposed transformation function. The methodology is illustrated by synthesizing algorithms for matrix multiplication and a version of the Warshall-Floyd transitive closure algorithm."
  },
  {
    "Title": "On visible surface generation by a priori tree structures",
    "URL": "https://dl.acm.org/doi/10.5555/95075.95084",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Querying and Controlling the Future Behaviour of Complex Objects",
    "URL": "https://dl.acm.org/doi/10.5555/645474.653854",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Optimal parallel suffix-prefix matching algorithm and applications",
    "URL": "https://dl.acm.org/doi/10.1145/72935.72977",
    "Full Abstract": "Copyright © 1989 ACM."
  },
  {
    "Title": "Relational database behavior: utilizing relational discrete event systems and models",
    "URL": "https://dl.acm.org/doi/10.1145/73721.73754",
    "Full Abstract": "Behavior of relational databases is studied within the framework of"
  },
  {
    "Title": "Mapping Nested Loop Algorithms into Multidimensional Systolic Arrays",
    "URL": "https://dl.acm.org/doi/10.1109/71.80125",
    "Full Abstract": "Consideration is given to transforming depth p-nested for loop algorithms into q-dimensional systolic VLSI arrays where 1>or=q>or=p-1. Previously, there existed complete characterizations of correct transformation only for the cases where q=p-1 orq=1. This gap is filled by giving formal necessary and sufficient conditions for correct transformation of a p-nested loop algorithm into a q-dimensional systolic array for any q,1>or=q>or=p-1. Practical methods are presented. The techniques developed are applied to the automatic design of special purpose and programmable systolic arrays. The results also contribute toward automatic compilation onto more general purpose programmable arrays. Synthesis of linear and planar systolic array implementations for a three-dimensional cube-graph algorithm and a reindexed Warshall-Floyd path-finding algorithm are used to illustrate the method."
  },
  {
    "Title": "Efficient robust parallel computations",
    "URL": "https://dl.acm.org/doi/10.1145/100216.100231",
    "Full Abstract": "Copyright © 1990 ACM."
  },
  {
    "Title": "The ",
    "URL": "https://dl.acm.org/doi/10.1145/78922.78927",
    "Full Abstract": "Concurrency control protocols based on two-phase locking are a popular family of locking protocols that preserve serializability in general (unstructured) database systems. A concurrency control algorithm (for databases with no inherent structure) is presented that is practical, non two-phase, and allows varieties of serializable logs not possible with any commonly known locking schemes. All transactions are required to predeclare the data they intend to read or write. Using this information, the protocol anticipates the existence (or absence) of possible conflicts and hence can allow non-two-phase locking."
  },
  {
    "Title": "On high-speed computing with a programmable linear array",
    "URL": "https://dl.acm.org/doi/10.1007/BF00127833",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Combining tentative and definite executions for dependable parallel computing",
    "URL": "https://dl.acm.org/doi/book/10.5555/99342",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Combining tentative and definite executions for very fast dependable parallel computing",
    "URL": "https://dl.acm.org/doi/10.1145/103418.103459",
    "Full Abstract": "Copyright © 1991 ACM."
  },
  {
    "Title": "Fast Parallel Algorithms for Coloring Random Graphs",
    "URL": "https://dl.acm.org/doi/10.5555/647672.757138",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Optimal parallel algorithms for forest and term matching",
    "URL": "https://dl.acm.org/doi/10.1016/0304-3975%2892%2990332-A",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "RAPID",
    "URL": "https://dl.acm.org/doi/10.1016/S0925-7721%2898%2900008-X",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Quantum Cryptography with Imperfect Apparatus",
    "URL": "https://dl.acm.org/doi/10.5555/795664.796390",
    "Full Abstract": "Quantum key distribution, first proposed by Bennett and Brassard, provides a possible key distribution scheme whose security depends only on the quantum laws of physics. So far the protocol has been proved secure even under channel noise and detector faults of the receiver, but is vulnerable if the photon source used is imperfect. In this paper we propose and give a concrete design for a new concept, \"self-checking source\", which requires the manufacturer of the photon source to provide certain tests; these tests are designed such that, if passed, the source is guaranteed to be adequate for the security of the quantum key distribution protocol, even though the testing devices may not be built to the original specification. The main mathematical result is a structural theorem which states that, for any state in a Hilbert space, if certain EPR-type equations are satisfied, the state must be essentially the orthogonal sum of EPR pairs."
  },
  {
    "Title": "An exponential lower bound on the size of algebraic decision trees for max",
    "URL": "https://dl.acm.org/doi/10.1007/s000370050010",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "NQP",
    "URL": "https://dl.acm.org/doi/10.1016/S0020-0190%2899%2900084-8",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Quantum bit escrow",
    "URL": "https://dl.acm.org/doi/10.1145/335305.335404",
    "Full Abstract": "Copyright © 2000 ACM."
  },
  {
    "Title": "Some perspectives on computational complexity",
    "URL": "https://dl.acm.org/doi/10.1145/380752.380856",
    "Full Abstract": "In past decades, the theory of computational complexity has flourished in terms of both the revelation of its internal structures and the unfolding of its numerous applications. In this paper we discuss several persistent and interwoven themes underlying many of these accomplishments. Chief among them are the interplay between communication and computation, the power of problem reduction, and the increasingly prominent role played by classical mathematics. We will also speculate on a few promising directions for future development of computational complexity."
  },
  {
    "Title": "Read-Once Branching Programs, Rectangular Proofs of the Pigeonhole Principle and the Transversal Calculus",
    "URL": "https://dl.acm.org/doi/10.1007/s00493-002-0007-7",
    "Full Abstract": "We investigate read-once branching programs for the following search problem: given a Boolean"
  },
  {
    "Title": "Classical physics and the Church--Turing Thesis",
    "URL": "https://dl.acm.org/doi/10.1145/602382.602411",
    "Full Abstract": "Would physical laws permit the construction of computing machines that are capable of solving some problems much faster than the standard computational model? Recent evidence suggests that this might be the case in the quantum world. But the question is of great interest even in the realm of classical physics. In this article, we observe that there is fundamental tension between the Extended Church--Turing Thesis and the existence of numerous seemingly intractable computational problems arising from classical physics. Efforts to resolve this incompatibility could both advance our knowledge of the theory of computation, as well as serve the needs of scientific computing."
  },
  {
    "Title": "On the power of quantum fingerprinting",
    "URL": "https://dl.acm.org/doi/10.1145/780542.780554",
    "Full Abstract": "In the simultaneous message model, two parties holding"
  },
  {
    "Title": "Graph entropy and quantum sorting problems",
    "URL": "https://dl.acm.org/doi/10.1145/1007352.1007377",
    "Full Abstract": "Let P = (X, <"
  },
  {
    "Title": "Graph Properties and Circular Functions",
    "URL": "https://dl.acm.org/doi/10.5555/1009378.1009564",
    "Full Abstract": "In decision tree models, considerable attention has beenpaid on the effect of symmetry on computational complexity.That is, for a permutation group, how low can thecomplexity be for any boolean function invariant under __ __In this paper we investigate this question for quantum decisiontrees for graph properties, directed graph properties,and circular functions. In particular, we prove that the n-vertexScorpion graph property has quantum query complexity\\widetilde\\Theta (n^{1/2}), which implies that the minimum quantumcomplexity for graph properties is strictly less than thatfor monotone graph properties (known to be \\widetilde\\Theta (n^{2/3})). Adirected graph property, SINK, is also shown to have the\\widetilde\\Theta (n^{1/2}) quantum query complexity. Furthermore, we givean N-ary circular function which has the quantum querycomplexity \\widetilde\\Theta (n^{1/4}). Finally, we show that for any permutationgroup, as long as is transitive, the quantumquery complexity of any function invariant to is at least\\widetilde\\Theta (n^{1/4}), which implies that our examples are (almost) thebest ones in the sense of pinning down the complexity forthe corresponding permutation group."
  },
  {
    "Title": "Self testing quantum apparatus",
    "URL": "https://dl.acm.org/doi/10.5555/2011827.2011830",
    "Full Abstract": "We study, in the context of quantum information and quantum communication, a configuration of devices that includes (1) a source of some unknown bipartite quantum state that is claimed to be the Bell state Φ"
  },
  {
    "Title": "Oblivious and Adaptive Strategies for the Majority and Plurality Problems",
    "URL": "https://dl.acm.org/doi/10.5555/2958119.2958222",
    "Full Abstract": "In the well-studied Majority problem, we are given a set of n balls colored with two or more colors, and the goal is to use the minimum number of color comparisons to find a ball of the majority color i.e., a color that occurs for more than ï ź n/2 ï ź times. The Plurality problem has exactly the same setting while the goal is to find a ball of the dominant color i.e., a color that occurs most often. Previous literature regarding this topic dealt mainly with adaptive strategies, whereas in this paper we focus more on the oblivious i.e., non-adaptive strategies. Given that our strategies are oblivious, we establish a linear upper bound for the Majority problem with arbitrarily many different colors. We then show that the Plurality problem is significantly more difficult by establishing quadratic lower and upper bounds. In the end, we also discuss some generalized upper bounds for adaptive strategies in the k-color Plurality problem."
  },
  {
    "Title": "On the communication complexity of co-linearity problems",
    "URL": "https://dl.acm.org/doi/10.1007/11549345_6",
    "Full Abstract": "In the"
  },
  {
    "Title": "On the security of public key protocols",
    "URL": "https://dl.acm.org/doi/10.1109/TIT.1983.1056650",
    "Full Abstract": "Recently the use of public key encryption to provide secure network communication has received considerable attention. Such public key systems are usually effective against passive eavesdroppers, who merely tap the lines and try to decipher the message. It has been pointed out, however, that an improperly designed protocol could be vulnerable to an active saboteur, one who may impersonate another user or alter the message being transmitted. Several models are formulated in which the security of protocols can be discussed precisely. Algorithms and characterizations that can be used to determine protocol security in these models are given."
  },
  {
    "Title": "On the Quantum Query Complexity of Local Search in Two and Three Dimensions",
    "URL": "https://dl.acm.org/doi/10.1109/FOCS.2006.57",
    "Full Abstract": "The quantum query complexity of searching for local optima has been a subject of much interest in the recent literature. For the d-dimensional grid graphs, the complexity has been determined asymptotically for all fixed d \\geqslant 5, but the lower dimensional cases present special difficulties, and considerable gaps exist in our knowledge. In the present paper we present near-optimal lower bounds, showing that the quantum query complexity for the 2-dimensional grid [n]^2 is \\Omega \\left( {n^{1/2 - \\delta } } \\right), and that for the 3-dimensional grid [n]^3 is \\Omega (n^{1- \\delta } ), for any fixed \\delta \\ge 0. A general lower bound approach for this problem, initiated by Aaronson [1](based on Ambainis' adversary method [3] for quantum lower bounds), uses random walks with low collision probabilities. This approach encounters obstacles in deriving tight lower bounds in low dimensions due to the lack of degrees of freedom in such spaces. We solve this problem by the novel construction and analysis of random walks with non-uniform step lengths. The proof employs in a nontrivial way sophisticated results of Sarkozy and Szemeredi [14], Bose and Chowla [5], and Halasz [9] from combinatorial number theory, as well as less familiar probability tools like Esseen's Inequality."
  },
  {
    "Title": "Oblivious and Adaptive Strategies for the Majority and Plurality Problems",
    "URL": "https://dl.acm.org/doi/10.1007/s00453-007-0060-0",
    "Full Abstract": "In the well-studied Majority problem, we are given a set of n balls colored with two or more colors, and the goal is to use the minimum number of color comparisons to find a ball of the majority color (i.e., a color that occurs for more than n/2 times). The Plurality problem has exactly the same setting while the goal is to find a ball of the dominant color (i.e., a color that occurs most often). Previous literature regarding this topic dealt mainly with adaptive strategies, whereas in this paper we focus more on the oblivious (i.e., non-adaptive) strategies. Given that our strategies are oblivious, we establish a linear upper bound for the Majority problem with arbitrarily many different colors assuming a majority label exists. We then show that the Plurality problem is significantly more difficult by establishing quadratic lower and upper bounds. In the end we also discuss some generalized upper bounds for adaptive strategies in the k-color Plurality problem."
  },
  {
    "Title": "A note on universal composable zero knowledge in common reference string model",
    "URL": "https://dl.acm.org/doi/10.5555/1767854.1767898",
    "Full Abstract": "Pass observed that universal composable zero-knowledge (UCZK) protocols in the common reference string (CRS) model, where a common reference string is selected trustily by a trusted third party and is known to all players, lose deniability that is a natural property of any ZK protocol in the plain model [33]. An open problem (or, natural query) raised in the literature is: are there any other essential security properties, other than the well-known deniability property, that could be lost by universal composable zero-knowledge in the common reference string model, in comparison with UC security in the plain model? In this work, we answer this open question (or, natural query), by showing that UCZK protocols in the CRS model could lose concurrent general composability (CGC) and proof of knowledge (POK) properties that are very important and essential security implications of UCZK in the plain model. This is demonstrated by concrete attacks."
  },
  {
    "Title": "A note on the feasibility of generalized universal composability",
    "URL": "https://dl.acm.org/doi/10.5555/1767854.1767899",
    "Full Abstract": "We clarify the potential limitation of the general feasibility for generalized universal composability (GUC) proposed in the recent work [8], and discuss a general principle for fully realizing universal composability. This in particular demonstrates the hardness of achieving generalized universal composability, and prevents potential misinterpretation in applications. We also propose some fixing approaches, which involve a source/session-authentic ID-based trapdoor commitment scheme via the hash-then-commit paradigm that could possibly be of independent interest."
  },
  {
    "Title": "Graph Design for Secure Multiparty Computation over Non-Abelian Groups",
    "URL": "https://dl.acm.org/doi/10.1007/978-3-540-89255-7_3",
    "Full Abstract": "Recently, Desmedt et al. studied the problem of achieving secure<em>n</em> -party computation over non-Abelian groups. Theyconsidered the passive adversary model and they assumed that theparties were only allowed to perform black-box operations over thefinite group <em>G</em> . They showed three results for the<em>n</em> -product function <em>f</em>"
  },
  {
    "Title": "An object-oriented framework for the integration of interactive animation techniques",
    "URL": "https://dl.acm.org/doi/10.1145/122718.122730",
    "Full Abstract": "We present an interactive modeling and animation system that facilitates the integration of a variety of simulation and animation paradigms. This system permits the modeling of diverse objects that change in shape, appearance, and behaviour over time. Our system thus extends modeling tools to include animation controls. Changes can be effected by various methods of control, including scripted, gestural, and behavioral specification. The system is an extensible testbed that supports research in the interaction of disparate control methods embodied in controller objects. This paper discusses some of the issues involved in modeling such interactions and the mechanisms implemented to provide solutions to some of these issues.The system's object-oriented architecture uses delegation hierarchies to let objects change all of their attributes dynamically. Objects include displayable objects, controllers, cameras, lights, renderers, and user interfaces. Techniques used to obtain interactive performance include the use of data-dependency networks, lazy evaluation, and extensive caching to exploit inter- and intra-frame coherency."
  },
  {
    "Title": "User-Interface Developments for the Nineties",
    "URL": "https://dl.acm.org/doi/10.1109/2.84899",
    "Full Abstract": "The purpose and history of user interfaces are briefly recounted. The language model and the implementation model of the user-computer dialogue are examined. User-centered design is discussed, and approaches to design tools are described. Key developments for the 1990s are considered. These include base technologies, 3-D user interfaces, virtual realities, multimedia and hypermedia, groupware, and intelligent agents, i.e., computer-based assistants or guides"
  },
  {
    "Title": "Three-dimensional widgets",
    "URL": "https://dl.acm.org/doi/10.1145/147156.147199",
    "Full Abstract": "Copyright © 1992 ACM."
  },
  {
    "Title": "Using deformations to explore 3D widget design",
    "URL": "https://dl.acm.org/doi/10.1145/133994.134091",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "From Discipline in Crisis to Mature Science",
    "URL": "https://dl.acm.org/doi/10.5555/618976.619846",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Interactive shadows",
    "URL": "https://dl.acm.org/doi/10.1145/142621.142622",
    "Full Abstract": "It is often difficult in computer graphics applications to understand spatial relationships between objects in a 3D scene or effect changes to those objects without specialized visualization and manipulation techniques. We present a set of three-dimensional tools (widgets) called “shadows” that not only provide valuable perceptual cues about the spatial relationships between objects, but also provide a direct manipulation interface to constrained transformation techniques. These shadow widgets provide two advances over previous techniques. First, they provide high correlation between their own geometric feedback and their effects on the objects they control. Second, unlike some other 3D widgets, they do not obscure the objects they control."
  },
  {
    "Title": "The challenges of 3D interaction",
    "URL": "https://dl.acm.org/doi/10.1145/259963.260500",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Implementing virtual reality",
    "URL": "https://dl.acm.org/doi/10.1145/259963.260525",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Introduction to Computer Graphics Macintosh Version Software of SRGP and SPHIGS Software",
    "URL": "https://dl.acm.org/doi/book/10.5555/1208920",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Introduction to Computer Graphics",
    "URL": "https://dl.acm.org/doi/book/10.5555/561541",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Research frontiers in virtual reality",
    "URL": "https://dl.acm.org/doi/10.1145/192161.192287",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Why is 3-D interaction so hard and what can we really do about it?",
    "URL": "https://dl.acm.org/doi/10.1145/192161.192299",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "The challenges of 3D interaction",
    "URL": "https://dl.acm.org/doi/10.1145/191642.191652",
    "Full Abstract": "3D computer graphics is becoming more and more popular due to the increased availability of 3D hardware and software on all classes of computers. However, despite this growing popularity and the existence of a number of successful 3D graphics applications, particularly in CAD, CAE, and medical and scientific visualization, the field is still very immature, There are no widely accepted standards for hardware or software platforms; learning to implement or use 3D graphics software is still extremely laborious; and the most effective ways for humans to interact with synthetic 3D environments are still not clear."
  },
  {
    "Title": "Interactive visualization via 3D user interfaces",
    "URL": "https://dl.acm.org/doi/10.5555/951087.951089",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Computer Graphics SRGP/SPHIGS for Macintosh",
    "URL": "https://dl.acm.org/doi/book/10.5555/1211196",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Computer graphics (2nd ed. in C)",
    "URL": "https://dl.acm.org/doi/book/10.5555/208249",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Standardisation—opportunity or constraint? (panel session)",
    "URL": "https://dl.acm.org/doi/10.1145/218380.218534",
    "Full Abstract": "Copyright © 1995 Copyright is held by the owner/author(s)."
  },
  {
    "Title": "50 years after “As we may think”",
    "URL": "https://dl.acm.org/doi/10.1145/227181.227187",
    "Full Abstract": "Copyright © 1996 ACM."
  },
  {
    "Title": "A case study in high-end communications technology in distance learning",
    "URL": "https://dl.acm.org/doi/10.5555/1253524.1253778",
    "Full Abstract": "The five principal investigators (PIs) of the graphics and visualization center, a distributed NSF science and technology center, report on the lessons learned from reaching an interactive graduate-level seminar involving their five sites over a high-end communications infrastructure. The experiences related will be of value to institutions presently conducting or considering distance learning. Although the experiences reported here are based an a high-end scenario available to this research center, the present trends in technology and distance education should make these observations applicable in the imminent future to a large number of educational institutions."
  },
  {
    "Title": "Reflections and observations",
    "URL": "https://dl.acm.org/doi/10.5555/1253524.1253826",
    "Full Abstract": "van Dam began teaching computer graphics just as the field was beginning, in the early 1960s. His first class was not of graduate students or post-docs, but was a group of forward thinking high school teachers and their best students. It was this experience that inspired van Dam to pursue a career in academia. For the past 30 years he has taught at Brown University where he co-founded the department of computer science and for 10 years served as its first chairman. The past five years have seen exceptionally strong demand for integration of computers into K-12 curricula driven both by the media hype surrounding computer technology and networks and the increasing pressure on educational institutions to improve scope and quality of education in a publicly demonstrable fashion. These forces have combined to produce a time of great potential for education but also one of great danger. Educators and administrators must consider how can this technology be used to promote rigorous and useful learning rather merely adding glitz to traditional types of assignments. Educators and administrators must also be aware that although computers can bring education to a more diverse and expanding audience, the same technology can serve to divide societies into groups of haves and have nots. van Dam analyzes several means of approaching these and other issues, drawing on current research findings and using real life examples from his experience as a researcher educator, and Director of the Graphics and Visualization Center."
  },
  {
    "Title": "Competitive generalized auctions",
    "URL": "https://dl.acm.org/doi/10.1145/509907.509921",
    "Full Abstract": "We describe mechanisms for auctions that are simultaneously truthful (alternately known as strategy-proof or incentive compatible) and guarantee high \"net\" profit. We make use of appropriate variants of competitive analysis of algorithms in designing and analyzing our mechanisms. Thus, we do not require any probabilistic assumptions on bids.We present two new concepts regarding auctions, that of a cancellable auction and that of a generalized auction. We use cancellable auctions in the design of generalized auctions, but they are of independent interest as well. Cancellable auctions have the property that if the revenue collected does not meet certain predetermined criteria, then the auction can be cancelled and the resulting auction is still truthful. The trivial approach (run a truthful auction and cancel if needed) yields an auction that is not necessarily truthfu.Generalized auctions can be used to model many problems previously considered in the literature, as well as numerous new problems. In particular, we give the first truthful profit-maximizing auctions for problems such as conditional financing and multicast."
  },
  {
    "Title": "Truthful and Competitive Double Auctions",
    "URL": "https://dl.acm.org/doi/10.5555/647912.740970",
    "Full Abstract": "In this paper we consider the problem of designing a mechanism for double auctions where bidders each bid to buy or sell one unit of a single commodity. We assume that each bidder's utility value for the item is private to them and we focus on truthful mechanisms, ones were the bidders' optimal strategy is to bid their true utility. The profit of the auctioneer is the difference between the total payments from buyers and total to the sellers. We aim to maximize this profit. We extend the competitive analysis framework of basic auctions [9] and give an upper bound on the profit of any truthful double auction. We then reduce the competitive double auction problem to basic auctions by showing that any competitive basic auction can be converted into a competitive double auction with a competitive ratio of twice that of the basic auction. In addition, we show that better competitive ratios can be obtained by directly adapting basic auction techniques to the double auction problem. This result provides insight into the design of profit maximizing mechanisms in general."
  },
  {
    "Title": "Mechanism Design for Fun and Profit",
    "URL": "https://dl.acm.org/doi/10.5555/647912.740971",
    "Full Abstract": "The emergence of the Internet as one of the most important arenas for resource sharing between parties with diverse and selfish interests has led to a number of fascinating and new algorithmic problems. In these problems, one must solicit the inputs to each computation from participants (or agents) whose goal is to manipulate the computation to their own advantage. Until fairly recently, failure models in computer science have not dealt the notion of selfish participants who \"play by the rules\" only when it fits them. To deal with this, algorithms must be designed so as to provide motivation to the participants to \"play along\". Recent work in this area, has drawn on ideas from game theory and microeconomics, and specifically from the field of mechanism design. The goal is to design protocols so that rational agents will be motivated to adhere to the protocol. A specific focus has been on truthful mechanisms in which selfish agents are motivated to reveal their true inputs.In the first part of the talk, we survey recent work in the area of algorithm mechanism design. In the second part of the talk, we focus on mechanism design specifically geared at maximizing the profit of the mechanism designer. In particular, we consider a class of dynamic pricing problems motivated by the same computational and economic trends. We describe a class of generalized auction problems as well as a competitive framework that can be used to evaluate solutions to these problems. We present a number of results on the design of profit-maximizing truthful generalized auctions. This is joint work with Amos Fiat, Andrew Goldberg and Jason Hartline."
  },
  {
    "Title": "On list update and work function algorithms",
    "URL": "https://dl.acm.org/doi/10.1016/S0304-3975%2801%2900253-5",
    "Full Abstract": "The"
  },
  {
    "Title": "On profit-maximizing envy-free pricing",
    "URL": "https://dl.acm.org/doi/10.5555/1070432.1070598",
    "Full Abstract": "We study the problem of pricing items for sale to consumers so as to maximize the seller's revenue. We assume that for each consumer, we know the maximum amount he would be willing to pay for each bundle of items, and want to find pricings of the items with corresponding allocations that maximize seller profit and at the same time are"
  },
  {
    "Title": "Beyond VCG",
    "URL": "https://dl.acm.org/doi/10.1109/SFCS.2005.25",
    "Full Abstract": "We study truthful mechanisms for auctions in which the auctioneer is trying to hire a team of agents to perform a complex task, and paying them for their work. As common in the field of mechanism design, we assume that the agents are selfish and will act in such a way as to maximize their profit, which in particular may include misrepresenting their true incurred cost. Our first contribution is a new and natural definition of the frugality ratio of a mechanism, measuring the amount by which a mechanism \"overpays\", and extending previous definitions to all monopoly-free set systems. After reexamining several known results in light of this new definition, we proceed to study in detail shortest path auctions and \"r-out-of-k sets\" auctions. We show that when individual set systems (e.g., graphs) are considered instead of worst cases over all instances, these problems exhibit a rich structure, and the performance of mechanisms may be vastly different. In particular, we show that the wellknown VCG mechanism may be far from optimal in these settings, and we propose and analyze a mechanism that is always within a constant factor of optimal."
  },
  {
    "Title": "Is the Open Way a Better Way? Digital Forensics Using Open Source Tools",
    "URL": "https://dl.acm.org/doi/10.1109/HICSS.2007.301",
    "Full Abstract": "The subject of digital forensics can be quite challenging. Digital forensics is in its infancy and teaching digital forensics includes the techniques as well as the tools that assist in the process. This article discusses the tools used in computer forensics, compares an open source tool to two commercial tools, and the advantages and disadvantages of all three tools in an academic environment. A team of four senior students sponsored by two faculty members established the project scope and requirements, presented three prototypes, and detailed the considerations of using open source tools. The same image was used to measure the performance of each software tool. The team found that the three tools provided the same results with different degrees of difficulty. The end results indicate that Open Source tools are a very good verification of evidence found using other products and should be included in the academic environment."
  },
  {
    "Title": "Cheap labor can be expensive",
    "URL": "https://dl.acm.org/doi/10.5555/1283383.1283459",
    "Full Abstract": "We study markets in which consumers are trying to hire a team of agents to perform a complex task. Each agent in the market prices their labor, and based on these prices, consumers hire the cheapest available team capable of doing the job they need done. We define the"
  },
  {
    "Title": "Ad Auctions --- Current and Future Research",
    "URL": "https://dl.acm.org/doi/10.1007/978-3-540-72870-2_41",
    "Full Abstract": "An exploding market has emerged during the last few years on the internet, the market of sponsored search slots. Advertisers are able to buy space on the webpages produced by popular search engines and place advertisements to promote their products alongside the regular algorithmic search results. The allocation of these advertising slots and their pricing is done via auctions. Since the introduction of this concept in 1998, sponsored search has evolved into a major source of revenue for internet giants such as Google, Yahoo!, MSN and others. Its success can be attributed partly to its effectiveness as a form of highly targeted advertising, and partly to the appealing framework that allows even small-scale advertisers to use it easily and effectively while only paying when their ad is clicked upon."
  },
  {
    "Title": "Greedy bidding strategies for keyword auctions",
    "URL": "https://dl.acm.org/doi/10.1145/1250910.1250949",
    "Full Abstract": "How should players bid in keyword auctions such as those used by Google, Yahoo! and MSN?allWe consider greedy bidding strategies for a repeated auction on a single keyword, where in each round, each player chooses some optimal bid for the next round, assuming that the other players merely repeat their previous bid. We study the revenue, convergence and robustness properties of such strategies. Most interesting among these is a strategy we call the"
  },
  {
    "Title": "Balloon Popping With Applications to Ascending Auctions",
    "URL": "https://dl.acm.org/doi/10.1109/FOCS.2007.15",
    "Full Abstract": "We study the power of ascending auctions in a scenario in which a seller is selling a collection of identical items to anonymous unit-demand bidders. We show that even with full knowledge of the set of bidders' private valuations for the items, if the bidders are ex-ante identical, no ascending auction can extract more than a constant times the revenue of the best fixed price scheme. This problem is equivalent to the problem of coming up with an optimal strategy for blowing up indistinguishable balloons with known capacities in order to maximize the amount of contained air. We show that the algorithm which simply inflates all balloons to a fixed volume is close to optimal in this setting."
  },
  {
    "Title": "Auctions for structured procurement",
    "URL": "https://dl.acm.org/doi/10.5555/1347082.1347116",
    "Full Abstract": "This paper considers a general setting for structured procurement and the problem a buyer faces in designing a procurement mechanism to maximize profit. This brings together two agendas in algorithmic mechanism design, frugality in procurement mechanisms (e.g., for paths and spanning trees) and profit maximization in auctions (e.g., for digital goods). In the standard approach to frugality in procurement, a buyer attempts to purchase a set of elements that satisfy a feasibility requirement as cheaply as possible. For profit maximization in auctions, a seller wishes to sell some number of goods for as much as possible. We unify these objectives by endowing the buyer with a decreasing marginal benefit per feasible set purchased and then considering the problem of designing a mechanism to buy a number of sets which maximize the buyer's profit, i.e., the difference between their benefit for the sets and the cost of procurement. For the case where the feasible sets are bases of a matroid, we follow the approach of reducing the mechanism design optimization problem to a mechanism design decision problem. We give a"
  },
  {
    "Title": "Improved Approximation Algorithms for Budgeted Allocations",
    "URL": "https://dl.acm.org/doi/10.1007/978-3-540-70575-8_16",
    "Full Abstract": "We provide a 3/2-approximation algorithm for an offline budgetedallocations problem with applications to sponsored search auctions.This an improvement over the"
  },
  {
    "Title": "On the Equilibria and Efficiency of the GSP Mechanism in Keyword Auctions with Externalities",
    "URL": "https://dl.acm.org/doi/10.1007/978-3-540-92185-1_69",
    "Full Abstract": "In the increasingly important market of online search advertising, a multitude of parameters affect the performance of advertising campaigns and their ability to attract users' attention enough to produce clicks. Thus far, the majority of the relevant literature assumed an advertisement's probability of receiving a click to be dependent on the advertisement's quality and its position in the sponsored search list, but independent of the other advertisements shown on the same webpage."
  },
  {
    "Title": "Approximating Matches Made in Heaven",
    "URL": "https://dl.acm.org/doi/10.1007/978-3-642-02927-1_23",
    "Full Abstract": "Motivated by applications in online dating and kidney exchange, we study a stochastic matching problem in which we have a random graph"
  },
  {
    "Title": "Algorithms for Data Migration",
    "URL": "https://dl.acm.org/doi/10.5555/3118232.3118517",
    "Full Abstract": "The data migration problem is the problem of computing a plan for moving data objects stored on devices in a network from one configuration to another. Load balancing or changing usage patterns might necessitate such a rearrangement of data. In this paper, we consider the case where the objects are fixed-size and the network is complete. Our results are both theoretical and empirical. Our main theoretical results are (1) a polynomial time algorithm for finding a near-optimal migration plan in the presence of space constraints when a certain number of additional nodes is available as temporary storage, and (2) a 3/2-approximation algorithm for the case where data must be migrated directly to its destination. We also run extensive experiments on several algorithms for various data migration problems and show that empirically, many algorithms perform better in practice than their theoretical bounds suggest. We conclude that many of the algorithms we present are both practical and effective for data migration."
  },
  {
    "Title": "Integrality gaps of linear and semi-definite programming relaxations for Knapsack",
    "URL": "https://dl.acm.org/doi/10.5555/2018158.2018182",
    "Full Abstract": "In this paper, we study the integrality gap of the Knapsack linear program in the Sherali-Adams and Lasserre hierarchies. First, we show that an integrality gap of 2 - ε persists up to a linear number of rounds of Sherali-Adams, despite the fact that Knapsack admits a fully polynomial time approximation scheme [24, 30]. Second, we show that the Lasserre hierarchy closes the gap quickly. Specifically, after"
  },
  {
    "Title": "Prior-independent multi-parameter mechanism design",
    "URL": "https://dl.acm.org/doi/10.1007/978-3-642-25510-6_11",
    "Full Abstract": "In a unit-demand multi-unit multi-item auction, an auctioneer is selling a collection of different items to a set of agents each interested in buying at most unit. Each agent has a different private value for each of the items. We consider the problem of designing a truthful auction that maximizes the auctioneer's profit in this setting. Previously, there has been progress on this problem in the setting in which each value is drawn from a known prior distribution. Specifically, it has been shown how to design auctions tailored to these priors that achieve a constant factor approximation ratio [2, 5]. In this paper, we present a prior-independent auction for this setting. This auction is guaranteed to achieve a constant fraction of the optimal expected profit for a large class of, so called, \"regular\" distributions, without specific knowledge of the distributions."
  },
  {
    "Title": "Approximately revenue-maximizing auctions for deliberative agents",
    "URL": "https://dl.acm.org/doi/10.5555/2900728.2900914",
    "Full Abstract": "In many real-world auctions, a bidder does not know her exact value for an item, but can perform a costly deliberation to reduce her uncertainty. Relatively little is known about such deliberative environments, which are fundamentally different from classical auction environments. In this paper, we propose a new approach that allows us to leverage classical revenue-maximization results in deliberative environments. In particular, we use Myerson (1981) to construct the first nontrivial (i.e., dependent on deliberation costs) upper bound on revenue in deliberative auctions. This bound allows us to apply existing results in the classical environment to a deliberative environment. In addition, we show that in many deliberative environments the only optimal dominant-strategy mechanisms take the form of sequential posted-price auctions."
  },
  {
    "Title": "Evaluating competitive game balance with restricted play",
    "URL": "https://dl.acm.org/doi/10.5555/3014629.3014635",
    "Full Abstract": "Game balancing is the fine-tuning phase in which a functioning game is adjusted to be deep, fair, and interesting. Balancing is difficult and time-consuming, as designers must repeatedly tweak parameters, and run lengthy playtests to evaluate the effects of these changes. If designers could receive immediate feedback on their designs, they could explore a vast space of variations, and select only the most promising games for playtesting. Such automated design feedback has been difficult to achieve, as there is no mathematical formulation of game balance that unifies many of its forms. We argue for a formulation in which carefully restricted agents are played against standard agents. We develop this"
  },
  {
    "Title": "A Short Presentation of Coq",
    "URL": "https://dl.acm.org/doi/10.1007/978-3-540-71067-7_3",
    "Full Abstract": "The Coq proof assistant has been developed at INRIA, Ecole Normale Supérieure de Lyon, and University of Paris South for more than twenty years [6]. Its theoretical foundation is known as the \"Calculus of Inductive Constructions\" [4,5]. Versions of the system were distributed regularly from 1989 (version 4.10). The current revision is 8.1 and a revision 8.2 is about to come out. This 8th generation was started in 2004, at the time when a radical change in syntax was enforced and a textbook [2] was published. A more complete historical overview, provided by G. Huet and C. Paulin-Mohring, is available in the book foreword."
  },
  {
    "Title": "Using Structural Recursion for Corecursion",
    "URL": "https://dl.acm.org/doi/10.1007/978-3-642-02444-3_14",
    "Full Abstract": "We propose a (limited) solution to the problem of constructing stream values defined by recursive equations that do not respect the guardedness condition. The guardedness condition is imposed on definitions of corecursive functions in Coq, AGDA, and other higher-order proof assistants. In this paper, we concentrate in particular on those non-guarded equations where recursive calls appear under functions. We use a correspondence between streams and functions over natural numbers to show that some classes of non-guarded definitions can be modelled through the encoding as structural recursive functions. In practice, this work extends the class of stream values that can be defined in a constructive type theory-based theorem prover with inductive and coinductive types, structural recursion and guarded corecursion."
  },
  {
    "Title": "From Semantics to Computer Science",
    "URL": "https://dl.acm.org/doi/book/10.5555/1658177",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Formal study of plane delaunay triangulation",
    "URL": "https://dl.acm.org/doi/10.1007/978-3-642-14052-5_16",
    "Full Abstract": "This article presents the formal proof of correctness for a plane Delaunay triangulation algorithm. It consists in repeating a sequence of edge flippings from an initial triangulation until the Delaunay property is achieved. To describe triangulations, we rely on a combinatorial hypermap specification framework we have been developing for years. We embed hypermaps in the plane by attaching coordinates to elements in a consistent way. We then describe what are legal and illegal Delaunay edges and a flipping operation which we show preserves hypermap, triangulation, and embedding invariants. To prove the termination of the algorithm, we use a generic approach expressing that any non-cyclic relation is well-founded when working on a finite set."
  },
  {
    "Title": "Interactive Theorem Proving and Program Development",
    "URL": "https://dl.acm.org/doi/book/10.5555/1965123",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "A coq-based library for interactive and automated theorem proving in plane geometry",
    "URL": "https://dl.acm.org/doi/10.5555/2029365.2029401",
    "Full Abstract": "In this article, we present the development of a library of formal proofs for theorem proving in plane geometry in a pedagogical context. We use the Coq proof assistant. This library includes the basic geometric notions to state theorems and provides a database of theorems to construct interactive proofs more easily. It is an extension of the library of F. Guilhot for interactive theorem proving at the level of high-school geometry, where we eliminate redundant axioms and give formalizations for the geometric concepts using a vector approach. We also enrich this library by offering an automated deduction method which can be used as a complement to interactive proof. For that purpose, we integrate the formalization of the area method which was developed by J. Narboux in Coq."
  },
  {
    "Title": "A Combination of a Dynamic Geometry Software With a Proof Assistant for Interactive Formal Proofs",
    "URL": "https://dl.acm.org/doi/10.1016/j.entcs.2012.06.005",
    "Full Abstract": "This paper presents an interface for geometry proving. It is a combination of a dynamic geometry software, Geogebra Geogebra development team, Introduction to GeoGebra. http://www.geogebra.org/book/intro-en/ with a proof assistant, Coq Coq development team, The Coq proof assitant reference manual. http://coq.inria.fr/refman/. Thanks to the features of Geogebra, users can create and manipulate geometric constructions, they discover conjectures and interactively build formal proofs with the support of Coq. Our system allows users to construct fully traditional proofs in the same style as the ones in high school. For each step of proving, we provide a set of applicable rules verified in Coq for users, we also provide tactics in Coq by which minor steps of reasoning are solved automatically."
  },
  {
    "Title": "A machine-checked proof of the odd order theorem",
    "URL": "https://dl.acm.org/doi/10.1007/978-3-642-39634-2_14",
    "Full Abstract": "This paper reports on a six-year collaborative effort that culminated in a complete formalization of a proof of the Feit-Thompson Odd Order Theorem in the Coq proof assistant. The formalized proof is constructive, and relies on nothing but the axioms and rules of the foundational framework implemented by Coq. To support the formalization, we developed a comprehensive set of reusable libraries of formalized mathematics, including results in finite group theory, linear algebra, Galois theory, and the theories of the real and complex algebraic numbers."
  },
  {
    "Title": "Fixed Precision Patterns for the Formal Verification of Mathematical Constant Approximations",
    "URL": "https://dl.acm.org/doi/10.1145/2676724.2693172",
    "Full Abstract": "We describe two approaches for the computation of mathematical constant approximations inside interactive theorem provers. These two approaches share the same basis of fixed point computation and differ only in the way the proofs of correctness of the approximations are described. The first approach performs interval computations, while the second approach relies on bounding errors, for example with the help of derivatives. As an illustration, we show how to describe good approximations of the logarithm function and we compute -- to a precision of a million decimals inside the proof system, with a guarantee that all digits up to the millionth decimal are correct. All these experiments are performed with the Coq system, but most of the steps should apply to any interactive theorem prover."
  },
  {
    "Title": "Formal proofs of transcendence for e and pi as an application of multivariate and symmetric polynomials",
    "URL": "https://dl.acm.org/doi/10.1145/2854065.2854072",
    "Full Abstract": "We describe the formalisation in Coq of a proof that the numbers `e` and `pi` are transcendental. This proof lies at the interface of two domains of mathematics that are often considered separately: calculus (real and elementary complex analysis) and algebra. For the work on calculus, we rely on the Coquelicot library and for the work on algebra, we rely on the Mathematical Components library. Moreover, some of the elements of our formalized proof originate in the more ancient library for real numbers included in the Coq distribution. The case of `pi` relies extensively on properties of multivariate polynomials and this experiment was also an occasion to put to test a newly developed library for these multivariate polynomials."
  },
  {
    "Title": "Distant Decimals of $$\\pi $$ź",
    "URL": "https://dl.acm.org/doi/10.1007/s10817-017-9444-2",
    "Full Abstract": "We describe how to compute very far decimals of $$\\pi $$ź and how to provide formal guarantees that the decimals we compute are correct. In particular, we report on an experiment where 1 million decimals of $$\\pi $$ź and the billionth hexadecimal (without the preceding ones) have been computed in a formally verified way. Three methods have been studied, the first one relying on a spigot formula to obtain at a reasonable cost only one distant digit (more precisely a hexadecimal digit, because the numeration basis is 16) and the other two relying on arithmetic---geometric means. All proofs and computations can be made inside the Coq system. We detail the new formalized material that was necessary for this achievement and the techniques employed to guarantee the accuracy of the computed digits, in spite of the necessity to work with fixed precision numerical computation."
  },
  {
    "Title": "Trends and Applications in Knowledge Discovery and Data Mining",
    "URL": "https://dl.acm.org/doi/book/10.5555/3002432",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Decision procedures for queues with integer constraints",
    "URL": "https://dl.acm.org/doi/10.1007/11590156_18",
    "Full Abstract": "Queues are a widely used data structure in programming languages. They also provide an important synchronization mechanism in modeling distributed protocols. In this paper we extend the theory of queues with a length function that maps a queue to its size, resulting in a combined theory of queues and Presburger arithmetic. This extension provides a natural but tight coupling between the two theories, and hence the general Nelson-Oppen combination method for decision procedures is not applicable. We present a decision procedure for the quantifier-free theory and a quantifier elimination procedure for the first-order theory that can remove a block of existential quantifiers in one step."
  },
  {
    "Title": "What's decidable about arrays?",
    "URL": "https://dl.acm.org/doi/10.1007/11609773_28",
    "Full Abstract": "Motivated by applications to program verification, we study a decision procedure for satisfiability in an expressive fragment of a theory of arrays, which is parameterized by the theories of the array elements. The decision procedure reduces satisfiability of a formula of the fragment to satisfiability of an equisatisfiable quantifier-free formula in the combined theory of equality with uninterpreted functions (EUF), Presburger arithmetic, and the element theories. This fragment allows a constrained use of universal quantification, so that one quantifier alternation is allowed, with some syntactic restrictions. It allows expressing, for example, that an assertion holds for all elements in a given index range, that two arrays are equal in a given range, or that an array is sorted. We demonstrate its expressiveness through applications to verification of sorting algorithms and parameterized systems. We also prove that satisfiability is undecidable for several natural extensions to the fragment. Finally, we describe our implementation in the"
  },
  {
    "Title": "Efficient strongly relational polyhedral analysis",
    "URL": "https://dl.acm.org/doi/10.1007/11609773_8",
    "Full Abstract": "Polyhedral analysis infers invariant linear equalities and inequalities of imperative programs. However, the exponential complexity of polyhedral operations such as image computation and convex hull limits the applicability of polyhedral analysis. Weakly relational domains such as intervals and octagons address the scalability issue by considering polyhedra whose constraints are drawn from a restricted, user-specified class. On the other hand, these domains rely solely on candidate expressions provided by the user. Therefore, they often fail to produce strong invariants."
  },
  {
    "Title": "Fixed point iteration for computing the time elapse operator",
    "URL": "https://dl.acm.org/doi/10.1007/11730637_40",
    "Full Abstract": "We investigate techniques for automatically generating symbolic approximations to the time solution of a system of differential equations. This is an important primitive operation for the safety analysis of continuous and hybrid systems. In this paper we design a"
  },
  {
    "Title": "On efficient distributed deadlock avoidance for real-time and embedded systems",
    "URL": "https://dl.acm.org/doi/10.5555/1898953.1899066",
    "Full Abstract": "Thread allocation is an important problem in distributed real-time and embedded (DRE) systems. A thread allocation policy that is too liberal may cause deadlock, while a policy that is too conservative limits potential parallelism, thus wasting resources. However, achieving (globally) optimal thread utilization, while avoiding deadlock, has been proven impractical in distributed systems: it requires too much communication between components."
  },
  {
    "Title": "Decision procedures for term algebras with integer constraints",
    "URL": "https://dl.acm.org/doi/10.5555/1196027.1196032",
    "Full Abstract": "Term algebras can model recursive data structures which are widely used in programming languages. To verify programs we must be able to reason about these structures. However, as programming languages often involve multiple data domains, in program verification decision procedures for a single theory are usually not applicable. An important class of mixed constraints consists of combinations of data structures with integer constraints on the size of data structures. Such constraints can express memory safety properties such as absence of memory overflow and out-of-bound array access, which are crucial for program correctness. In this paper we extend the theory of term algebras with the length function which maps a term to its size, resulting in a combined theory of term algebras and Presburger arithmetic. This arithmetic extension provides a natural but tight coupling between the two theories, and hence the general purpose combination methods like Nelson-Op-pen combination are not applicable. We present decision procedures for quantifier-free theories in structures with an infinite constant domain and with a finite constant domain. We also present a quantifier elimination procedure for the extended first-order theory that can remove a block of existential quantifiers in one step."
  },
  {
    "Title": "Efficient distributed deadlock avoidance with liveness guarantees",
    "URL": "https://dl.acm.org/doi/10.1145/1176887.1176891",
    "Full Abstract": "We present a deadlock avoidance algorithm for distributed systems that guarantees liveness. Deadlock avoidance in distributed systems is a hard problem and general solutions are considered impractical due to the high communication overhead. In previous work, however, we showed that practical solutions exist when all possible sequences of resource requests are known a priori in the form of call graphs; in this case protocols can be constructed that perform safe resource allocation based on local data only, that is, no communication between components is required. While avoiding deadlock, those protocols, however, did not avoid starvation: they guaranteed that some process could always make progress, but did not guarantee that every individual process would always eventually terminate.In this paper we present a resource allocation mechanism that avoids deadlock and guarantees absence of starvation, without undue loss of concurrency. The only assumption we make is that the local scheduler is fair. We prove the correctness of the algorithm and show how it can be implemented efficiently."
  },
  {
    "Title": "Proving ATL* properties of infinite-state systems",
    "URL": "https://dl.acm.org/doi/10.1007/11921240_17",
    "Full Abstract": "Alternating temporal logic (atl*) was introduced to prove properties of multi-agent systems in which the agents have different objectives and may collaborate to achieve them. Examples include (distributed) controlled systems, security protocols, and contract-signing protocols. Proving atl* properties over finite-state systems was shown decidable by Alur et al., and a model checker for the sublanguage atl implemented in mocha."
  },
  {
    "Title": "Verification constraint problems with strengthening",
    "URL": "https://dl.acm.org/doi/10.1007/11921240_3",
    "Full Abstract": "The deductive method reduces verification of safety properties of programs to, first, proposing inductive assertions and, second, proving the validity of the resulting set of first-order verification conditions. We discuss the transition from"
  },
  {
    "Title": "Distributed priority inheritance for real-time and embedded systems",
    "URL": "https://dl.acm.org/doi/10.1007/11945529_9",
    "Full Abstract": "We study the problem of priority inversion in distributed real-time and embedded systems and propose a solution based on a distributed version of the priority inheritance protocol (PIP). Previous approaches to priority inversions in distributed systems use variations of the priority ceiling protocol (PCP), originally designed for centralized systems as a modification of PIP that also prevents deadlock. PCP, however, requires maintaining a global view of the acquired resources, which in distributed systems leads to high communication overhead."
  },
  {
    "Title": "A family of distributed deadlock avoidance protocols and their reachable state spaces",
    "URL": "https://dl.acm.org/doi/10.5555/1759394.1759413",
    "Full Abstract": "We study resource management in distributed systems. Incorrect handling of resources may lead to deadlocks, missed deadlines, priority inversions, and other forms of incorrect behavior or degraded performance. While in centralized systems deadlock avoidance is commonly used to ensure correct and efficient resource allocation, distributed deadlock avoidance is harder, and general solutions are considered impractical due to the high communication overhead. However, solutions that use only operations on local data exist if some static information about the possible sequences of remote invocations is known."
  },
  {
    "Title": "Verifying Balanced Trees",
    "URL": "https://dl.acm.org/doi/10.1007/978-3-540-72734-7_26",
    "Full Abstract": "Balanced search trees provide guaranteed worst-case time performance and hence they form a very important class of data structures. However, the self-balancing ability comes at a price; balanced trees are more complex than their unbalanced counterparts both in terms of data structure themselves and related manipulation operations. In this paper we present a framework to model balanced trees in decidable first-order theories of term algebras with Presburger arithmetic. In this framework, a theory of term algebras (i.e., a theory of finite trees) is extended with Presburger arithmetic and with certain connecting functions that map terms (trees) to integers. Our framework is flexible in the sense that we can obtain a variety of decidable theories by tuning the connecting functions. By adding <em>maximal path</em>and <em>minimal path</em>functions, we obtain a theory of red-black trees in which the transition relation of tree self-balancing (rotation) operations is expressible. We then show how to reduce the verification problem of the red-black tree algorithm to constraint satisfiability problems in the extended theory."
  },
  {
    "Title": "The Calculus of Computation",
    "URL": "https://dl.acm.org/doi/book/10.5555/1324777",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "The reaction algebra",
    "URL": "https://dl.acm.org/doi/10.5555/1805839.1805872",
    "Full Abstract": "Event-pattern reactive programs are small programs that process an input stream of events to detect and act upon given temporal patterns. These programs are used in distributed systems to notify components when they must react."
  },
  {
    "Title": "Constructing invariants for hybrid systems",
    "URL": "https://dl.acm.org/doi/10.1007/s10703-007-0046-1",
    "Full Abstract": "We present a new method for generating algebraic invariants of hybrid systems. The method reduces the invariant generation problem to a constraint solving problem using techniques from the theory of ideals over polynomial rings. Starting with a template invariant--a polynomial equality over the system variables with unknown coefficients--constraints are generated on the coefficients guaranteeing that the solutions are inductive invariants. To control the complexity of the constraint solving, several stronger conditions that imply inductiveness are proposed, thus allowing a trade-off between the complexity of the invariant generation process and the strength of the resulting invariants."
  },
  {
    "Title": "Deductive verification of alternating systems",
    "URL": "https://dl.acm.org/doi/10.1007/s00165-008-0075-6",
    "Full Abstract": "Alternating systems are models of computer programs whose behavior is governed by the actions of multiple agents with, potentially, different goals. Examples include control systems, resource schedulers, security protocols, auctions and election mechanisms. Proving properties about such systems has emerged as an important new area of study in formal verification, with the development of logical frameworks such as the alternating temporal logic"
  },
  {
    "Title": "Property-directed incremental invariant generation",
    "URL": "https://dl.acm.org/doi/10.1007/s00165-008-0080-9",
    "Full Abstract": "A fundamental method of analyzing a system such as a program or a circuit is invariance analysis, in which one proves that an assertion holds on all reachable states. Typically, the proof is performed via induction; however, an assertion, while invariant, may not be inductive (provable via induction). Invariant generation procedures construct auxiliary inductive assertions for strengthening the assertion to be inductive. We describe a general method of generating invariants that is incremental and property-directed. Rather than generating one large auxiliary inductive assertion, our method generates many simple assertions, each of which is inductive relative to those generated before it. Incremental generation is amenable to parallelization. Our method is also property-directed in that it generates inductive assertions that are relevant for strengthening the given assertion. We describe two instances of our method: a procedure for generating clausal invariants of finite-state systems and a procedure for generating affine inequalities of numerical infinite-state systems. We provide evidence that our method scales to checking safety properties of some large finite-state systems."
  },
  {
    "Title": "The Logical Basis for Computer Programming",
    "URL": "https://dl.acm.org/doi/book/10.5555/1502271",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Temporal verification of reactive systems",
    "URL": "https://dl.acm.org/doi/10.5555/1880443.1880456",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "The Calculus of Computation",
    "URL": "https://dl.acm.org/doi/book/10.5555/1951719",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Efficient program transformations for resilient parallel computation via randomization (preliminary version)",
    "URL": "https://dl.acm.org/doi/10.1145/129712.129742",
    "Full Abstract": "In this paper, we address the problem of automatically transforming"
  },
  {
    "Title": "Resilient parallel computing on unreliable parallel machines",
    "URL": "https://dl.acm.org/doi/10.5555/165475.165497",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Parallel processing on networks of workstations",
    "URL": "https://dl.acm.org/doi/10.5555/876885.880024",
    "Full Abstract": "Abstract: One of the most sought after software innovation of this decade is the construction of systems using off-the-shelf-workstations that actually deliver and even surpass, the power and reliability of supercomputers. Using completely novel techniques: eager scheduling, evasive memory layouts and dispersed data management it is possible to build an execution environment for parallel programs on workstation networks. These techniques were originally developed in a theoretical framework for an abstract machine which models a shared memory asynchronous multiprocessor. The network of workstations platform presents an inherently asynchronous environment for the execution of our parallel program. This gives rise to substantial problems of correctness of the computation and of proper automatic load balancing of the work amongst the processors, so that a slow processor will not hold up the total computation. A limiting case of asynchrony is when a processor becomes infinitely slow, i.e. fails. Our methodology copes with all these problems, as well as with memory failures. An interesting feature of this system is that it is neither a fault-tolerant system extended for parallel processing nor is it parallel processing system extended for fault tolerance. The same novel mechanisms ensure both properties."
  },
  {
    "Title": "CALYPSO",
    "URL": "https://dl.acm.org/doi/10.5555/822081.823036",
    "Full Abstract": "The importance of adapting networks of workstations for use as parallel processing platforms is well established. However current solutions do not always address important issues that exist in real networks. External factors like the sharing of resources, unpredictable behavior of the network and failures, are present in multiuser networks and must be addressed. CALYPSO is a prototype software system for writing and executing parallel programs on non-dedicated platforms, based on COTS networked workstations operating systems, and compilers. Among notable properties of the system are: (1) simple programming paradigm incorporating shared memory constructs and separating the programming and the execution parallelism, (2) transparent utilization of unreliable shared resources by providing dynamic load balancing and fault tolerance, and (3) effective performance for large classes of coarse-grained computations. We present the system and report our initial experiments and performance results in settings that closely resemble the dynamic behavior of a \"real\" network. Under varying work-load conditions, resource availability and process failures, the efficiency of the test program we present ranged from 84% to 94% bench-marked against a sequential program."
  },
  {
    "Title": "Modeling data-intensive reactive systems with relational transition systems",
    "URL": "https://dl.acm.org/doi/10.1007/s002360050041",
    "Full Abstract": "In this paper, the formalism of"
  },
  {
    "Title": "Parallel Suffix--Prefix-Matching Algorithm and Applications",
    "URL": "https://dl.acm.org/doi/10.1137/S0097539792190157",
    "Full Abstract": "Our main result in this paper is a parallel algorithm for suffix--prefix- (s--p-) matching that has optimal speedup on a concurrent-read/concurrent-write parallel random-access machine (CRCW PRAM). Given a string of length $m$, the algorithm runs in time $O(\\log m)$ using $m/ \\log m$ processors. This algorithm is important because we utilize s--p matching as a fundamental building block to solve several pattern- and string-matching problems, such as the following: {1. string matching; 2. multitext/multipattern string matching; 3. multidimensional pattern matching; 4. pattern-occurrence detection; 5. on-line string matching.} In particular, our techniques and algorithms are the first to preserve optimal speedup in the context of pattern matching in higher dimensions and are the only known ones to do so for dimensions $d > 2$."
  },
  {
    "Title": "KnittingFactory: An Infrastructure for Distributed Web Applications",
    "URL": "https://dl.acm.org/doi/book/10.5555/890254",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Pincer Search",
    "URL": "https://dl.acm.org/doi/10.5555/645338.650396",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Exploiting Application Tunability for Efficient, Predictable, Parallel Resource Management",
    "URL": "https://dl.acm.org/doi/book/10.5555/890298",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Mechanisms for Just-in-Time Allocation of Resources to Adaptive Parallel Programs",
    "URL": "https://dl.acm.org/doi/10.5555/645608.661825",
    "Full Abstract": "Adaptive parallel computations-computations that can adapt to changes in resource availability and requirement- can effectively use networked machines because they dynamically expand as machines become available and dynamically acquire machines as needed. While most parallel programming systems provide the means to develop adaptive programs, they do not provide any functional interface to external resource management systems. Thus, no existing resource management system has the capability to manage resources on commodity system software, arbitrating the demands of multiple adaptive computations written using diverse programming environments.This paper presents a set of novel mechanisms that facilitate dynamic allocation of resources to adaptive parallel computations. The mechanisms are built on low-level features common to many programming systems, and unique in their ability to transparently manage multiple adaptive parallel programs that were not developed to have their resources managed by external systems. We also describe the design and the implementation of the initial prototype of ResourceBroker, a resource management system built to validate these mechanisms."
  },
  {
    "Title": "Exploiting Application Tunability for Efficient, Predictable Parallel Resource Management",
    "URL": "https://dl.acm.org/doi/10.5555/645608.661833",
    "Full Abstract": "Parallel computing is becoming increasing central and mainstream, driven both by the widespread availability of commodity SMP and high-performance cluster platforms, as well as the growing use of parallelism in general-purpose applications such as image recognition, virtual reality, and media processing. In addition to performance requirements, the latter computations impose soft real-time constraints, necessitating efficient, predictable parallel resource management. In this paper, we propose a novel approach for increasing parallel system utilization while meeting application soft real-time deadlines. Our approach exploits the application tunability found in several general-purpose computations. Tunability refers to an application's ability to trade off resource requirements over time, while maintaining a desired level of output quality. We first describe language extensions to support tunability in the Calypso system, then characterize the performance benefits of tunability, using a synthetic task system to systematically identify its benefits. Our results show that application tunability is convenient to express and can significantly improve parallel system utilization for computations with predictability requirements."
  },
  {
    "Title": "Metacomputing with MILAN",
    "URL": "https://dl.acm.org/doi/10.5555/795690.797900",
    "Full Abstract": "The MILAN project, a joint effort involving Arizona State University and New York University, has produced and validated fundamental techniques for the realization of efficient, reliable, predictable virtual machines, that is, metacomputers, on top of environments that consist of an unreliable and dynamically changing set of machines. In addition to the techniques, the principal outcomes of the project include three parallel programming systems- Calypso, Chime, and Charlotte-which enable applications be developed for ideal, shared memory, parallel machines to execute on distributed platforms that are subject to failures, slowdowns, and changing resource availability. The lessons learned from the MILAN project are being used to design Computing Communities, a metacomputing frame-work for general computations."
  },
  {
    "Title": "Charlotte",
    "URL": "https://dl.acm.org/doi/10.1016/S0167-739X%2899%2900009-6",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Exploiting Application Tunability for Efficient, Predictable Resource Management in Parallel and Distributed Systems",
    "URL": "https://dl.acm.org/doi/10.1006/jpdc.2000.1660",
    "Full Abstract": "Parallel and distributed computing is becoming increasingly mainstream, driven both by the widespread availability of commodity small-scale symmetric multiprocessors and high-performance cluster platforms, as well as the growing use of parallelism and distribution in networked applications such as image recognition, media processing, virtual reality, and telepresence. However, many of these applications impose soft timeliness and output quality constraints on top of the traditional performance requirements, necessitating efficient, predictable management of system resources. Existing techniques are inadequate to simultaneously support these twin requirements of efficiency and predictability. In this paper, we propose a novel approach for increasing system efficiency while meeting application timeliness and quality constraints. Our approach exploits the application tunability found in many general-purpose computations. Tunability refers to an application's ability to trade off resource requirements over several dimensions including time, quality, and resource type; the resulting flexibility enables the underlying resource management system to choose an application operating point best suited to available resource characteristics. We describe language and scheduler extensions to support tunability in the MILAN metacomputing environment and then systematically characterize performance benefits of tunability using a parameterizable task system. Our results show that application tunability is easily expressible and can significantly improve resource utilization."
  },
  {
    "Title": "Automatic data and computation decomposition on distributed memory parallel computers",
    "URL": "https://dl.acm.org/doi/10.1145/509705.509706",
    "Full Abstract": "To exploit parallelism on shared memory parallel computers (SMPCs), it is natural to focus on decomposing the computation (mainly by distributing the iterations of the nested Do-Loops). In contrast, on distributed memory parallel computers (DMPCs), the decomposition of computation and the distribution of data must both be handled---in order to balance the computation load and to minimize the migration of data. We propose and validate experimentally a method for handling computations and data synergistically to minimize the overall execution time on DMPCs. The method is based on a number of novel techniques, also presented in this article. The core idea is to rank the \"importance\" of data arrays in a program and specify some of the dominant. The intuition is that the dominant arrays are the ones whose migration would be the most expensive. Using the correspondence between iteration space mapping vectors and distributed dimensions of the dominant data array in each nested Do-loop, allows us to design algorithms for determining data and computation decompositions at the same time. Based on data distribution, computation decomposition for each nested Do-loop is determined based on either the \"owner computes\" rule or the \"owner stores\" rule with respect to the dominant data array. If all temporal dependence relations across iteration partitions are regular, we use tiling to allow pipelining and the overlapping of computation and communication. However, in order to use tiling on DMPCs, we needed to extend the existing techniques for determining tiling vectors and tile sizes, as they were originally suited for SMPCs only. The overall method is illustrated on programs for the 2D heat equation, for the Gaussian elimination with pivoting, and for the 2D fast Fourier transform on a linear processor array and on a 2D processor grid."
  },
  {
    "Title": "Pincer-Search",
    "URL": "https://dl.acm.org/doi/10.1109/TKDE.2002.1000342",
    "Full Abstract": "Discovering frequent itemsets is a key problem in important data mining applications, such as the discovery of association rules, strong rules, episodes, and minimal keys. Typical algorithms for solving this problem operate in a bottom-up, breadth-first search direction. The computation starts from frequent 1-itemsets (the minimum length frequent itemsets) and continues until all maximal (length) frequent itemsets are found. During the execution, every frequent itemset is explicitly considered. Such algorithms perform well when all maximal frequent itemsets are short. However, performance drastically deteriorates when some of the maximal frequent itemsets are long. We present a new algorithm which combines both the bottom-up and the top-down searches. The primary search direction is still bottom-up, but a restricted search is also conducted in the top-down direction. This search is used only for maintaining and updating a new data structure, the maximum frequent candidate set. It is used to prune early candidates that would be normally encountered in the bottom-up search. A very important characteristic of the algorithm is that it does not require explicit examination of every frequent itemset. Therefore, the algorithm performs well even when some maximal frequent itemsets are long. As its output, the algorithm produces the maximum frequent set, i.e., the set containing all maximal frequent itemsets, thus specifying immediately all frequent itemsets. We evaluate the performance of the algorithm using well-known synthetic benchmark databases, real-life census, and stock market databases. The improvement in performance can be up to several orders of magnitude, compared to the best previous algorithms."
  },
  {
    "Title": "Detecting malicious network traffic using inverse distributions of packet contents",
    "URL": "https://dl.acm.org/doi/10.1145/1080173.1080176",
    "Full Abstract": "We study the problem of detecting malicious IP traffic in the network early, by analyzing the contents of packets. Existing systems look at packet contents as a bag of substrings and study characteristics of its"
  },
  {
    "Title": "Sustaining moore's law in embedded computing through probabilistic and approximate design",
    "URL": "https://dl.acm.org/doi/10.1145/1629395.1629397",
    "Full Abstract": "The central theme of our work is the probabilistic and approximate design of embedded computing systems. This novel approach consists of two distinguishing aspects: (i) the design and implementation of embedded systems, using components which are susceptible to perturbations from various sources and (ii) a design methodology which consists of an exploration of a design space which characterizes the trade-off between quality of output and cost, to implement high performance and low energy embedded systems. In contrast with other work, our design methodology does not attempt to correct the errors introduced by components which are susceptible to perturbations, instead we design \"good enough\" systems. Our work has the potential to address challenges and impediments to Moore's law arising from material properties and manufacturing difficulties, which dictate that we shift from the current-day deterministic design paradigm to statistical and probabilistic designs of the future. In this paper, we provide a broad overview of our work on probabilistic and approximate design, present novel results in approximate arithmetic and its impact on digital signal processing algorithms, and sketch future directions for research."
  },
  {
    "Title": "Optimizing energy to minimize errors in dataflow graphs using approximate adders",
    "URL": "https://dl.acm.org/doi/10.1145/1878921.1878948",
    "Full Abstract": "Approximate arithmetic is a promising, new approach to low-energy designs while tackling reliability issues. We present a method to optimally distribute a given energy budget among adders in a dataflow graph so as to minimize expected errors. The method is based on new formal mathematical models and algorithms, which quantitatively characterize the relative importance of the adders in a circuit. We demonstrate this method on a"
  },
  {
    "Title": "Some Perspectives on Complexity-Based Cryptography",
    "URL": "https://dl.acm.org/doi/10.1007/978-3-540-89255-7_4",
    "Full Abstract": "In the 1940's, Shannon applied his information theory to build a mathematical foundation for classical cryptography which studies how information can be securely encrypted and communicated. In the internet age, Turing's theory of computation has been summoned to augment Shannon's model and create new frameworks, under which numerous cryptographic applications have blossomed. Fundamental concepts, such as ``information\" and ``knowledge transfer\", often need to be re-examined and reformulated. The amalgamation process is still on-going in view of the many unsolved security issues. In this talk we give a brief overview of the background, and discuss some of the recent developments in complexity-based cryptography. We also raise some open questions and explore directions for future work."
  },
  {
    "Title": "An approach to energy-error tradeoffs in approximate ripple carry adders",
    "URL": "https://dl.acm.org/doi/10.5555/2016802.2016853",
    "Full Abstract": "Given a 16-bit or 32-bit overclocked ripple-carry adder, we minimize error by allocating multiple supply voltages to the gates. We solve the error minimization problem for a fixed energy budget using a binned geometric program solution (BGPS). A solution found via BGPS outperforms the two best prior approaches, uniform voltage scaling and biased voltage scaling, reducing error by as much as a factor of 2.58X and by a median of 1.58X in 90nm transistor technology."
  },
  {
    "Title": "A note on universal composable zero-knowledge in the common reference string model",
    "URL": "https://dl.acm.org/doi/10.1016/j.tcs.2008.10.027",
    "Full Abstract": "Pass observed that universal composable zero-knowledge (UCZK) protocols in the common reference string (CRS) model lose deniability that is a natural security property and implication of the ZK functionality in accordance with the UC framework. An open problem (or, natural query) raised in the literature is: are there any other essential security properties, other than the well-known deniability property, that could be lost by UCZK in the CRS model, in comparison with the ZK functionality in accordance with the UC framework? In this work, we answer this open question (or, natural query), by showing that when running concurrently with other protocols UCZK in the CRS model can lose proof of knowledge (POK) property that is very essential and core security implication of the ZK functionality. This is demonstrated by concrete attack against naturally existing UCZK protocols in the CRS model. Then, motivated by our attack, we make further clarifications of the underlying reasons beneath the concrete attack, and investigate the precise security guarantee of UC with CRS."
  },
  {
    "Title": "A note on the feasibility of generalised universal composability†",
    "URL": "https://dl.acm.org/doi/10.1017/S0960129508007330",
    "Full Abstract": "In this paper we study (interpret) the precise composability guarantee of the generalised universal composability (GUC) feasibility with global setups that was proposed in the recent paper Canetti"
  },
  {
    "Title": "On the Quantum Query Complexity of Local Search in Two and Three Dimensions",
    "URL": "https://dl.acm.org/doi/10.1007/s00453-008-9170-6",
    "Full Abstract": "The quantum query complexity of searching for local optima has been a subject of much interest in the recent literature. For the"
  },
  {
    "Title": "Communication Complexity and Its Applications",
    "URL": "https://dl.acm.org/doi/10.1007/978-3-642-02270-8_2",
    "Full Abstract": "For any function f(x, y), its communication complexity is the minimum number of bits needed to be exchanged between two parties holding integers x and y respectively. Invented thirty years ago, communication complexity has been a central research area in theoretical computer science with rich applications to algorithmic problems. In this talk, we give an overview of computational complexity, high-lighting several notable recent results and the diverse mathematical techniques needed for deriving such results."
  },
  {
    "Title": "Deniable internet key exchange",
    "URL": "https://dl.acm.org/doi/10.5555/1894302.1894328",
    "Full Abstract": "In this work, we develop a family of non-malleable and deniable Diffie-Hellman key-exchange (DHKE) protocols, named deniable Internet keyexchange (DIKE). The newly developed DIKE protocols are of conceptual clarity, provide much remarkable privacy protection to protocol participants, and are of highly practical (online) efficiency."
  },
  {
    "Title": "Concurrent knowledge extraction in the public-key model",
    "URL": "https://dl.acm.org/doi/10.5555/1880918.1880994",
    "Full Abstract": "Knowledge extraction is a fundamental notion, modeling machine possession of values (witnesses) in a computational complexity sense and enabling one to argue about the internal state of a party in a protocol without probing its internal secret state. However, when transactions are concurrent (e.g., over the Internet) with players possessing public-keys (as is common in cryptography), assuring that entities \"know\" what they claim to know, where adversaries may be well coordinated across different transactions, turns out to be much more subtle and in need of re-examination. Here, we investigate how to formally treat knowledge possession by parties (with registered public-keys) interacting over the Internet. Stated more technically, we look into the relative power of the notion of \"concurrent knowledge-extraction\" (CKE) in the concurrent zero-knowledge (CZK) bare public-key (BPK) model where statements being proven can be dynamically and adaptively chosen by the prover."
  },
  {
    "Title": "Tight Approximation Ratio of a General Greedy Splitting Algorithm for the Minimum ",
    "URL": "https://dl.acm.org/doi/10.5555/1966796.1966799",
    "Full Abstract": "For an edge-weighted connected undirected graph, the minimum"
  },
  {
    "Title": "Tight Approximation Ratio of a General Greedy Splitting Algorithm for the Minimum k-Way Cut Problem",
    "URL": "https://dl.acm.org/doi/10.5555/3118745.3118910",
    "Full Abstract": "For an edge-weighted connected undirected graph, the minimum k-way cut problem is to find a subset of edges of minimum total weight whose removal separates the graph into k connected components. The problem is NP-hard when k is part of the input and W[1]-hard when k is taken as a parameter."
  },
  {
    "Title": "Computationally-Fair group and identity-based key-exchange",
    "URL": "https://dl.acm.org/doi/10.1007/978-3-642-29952-0_26",
    "Full Abstract": "In this work, we re-examine some fundamental group key-exchange and identity-based key-exchange protocols, specifically the Burmester-Desmedet group key-exchange protocol [7] (referred to as the BD-protocol) and the Chen-Kudla identity-based key-exchange protocol [9] (referred to as the CK-protocol). We identify some new attacks on these protocols, showing in particular that these protocols are not computationally fair. Specifically, with our attacks, an adversary can do the following damages:"
  },
  {
    "Title": "Quantum computing",
    "URL": "https://dl.acm.org/doi/10.1007/978-3-642-29952-0_7",
    "Full Abstract": "In recent years, the scientific world has seen much excitement over the development of quantum computing, and the ever increasing possibility of building real quantum computers. What's the advantage of quantum computing? What are the secrets in the atoms that could potentially unleash such enormous power, to be used for computing and information processing? In this talk, we will take a look at quantum computing, and make the case that we are witnessing a great science in the making."
  },
  {
    "Title": "Graph Coloring Applied to Secure Computation in Non-Abelian Groups",
    "URL": "https://dl.acm.org/doi/10.1007/s00145-011-9104-3",
    "Full Abstract": "We study the natural problem of secure"
  },
  {
    "Title": "Online/Offline Signatures for Low-Power Devices",
    "URL": "https://dl.acm.org/doi/10.1109/TIFS.2012.2232653",
    "Full Abstract": "When digital signature is applied on low-power devices, like smart cards, wireless sensors and RFID tags, some specific properties, e.g., better offline storage, more modular and flexible deployment, are desired. To meet these needs, a new variant of the Fiat–Shamir transformation for digital signatures, referred to as $\\Gamma$ -transformation, is introduced and formalized in this work. Following this new transformation approach, some new signature schemes (referred to as $\\Gamma$-signatures) are presented and discussed. In particular, it is shown that the $\\Gamma$-signatures for discrete logarithm problem (DLP) developed in this work combine, in essence, the advantages of both Schnorr's signature and the digital signature standard (DSS), while saving from the disadvantages of them both."
  },
  {
    "Title": "OAKE",
    "URL": "https://dl.acm.org/doi/10.1145/2508859.2516695",
    "Full Abstract": "Cryptographic algorithm standards play an important role both to the practice of information security and to cryptography theory research. Among them, the KEA and OPACITY (KEA/OPACITY, in short) protocols, and the MQV and HMQV ((H)MQV, in short) protocols, are a family of implicitly authenticated Diffie-Hellman key-exchange (IA-DHKE) protocols that are among the most efficient authenticated key-exchange protocols known and are widely standardized. In this work, from some new design insights, we develop a new family of practical IA-DHKE protocols, referred to as OAKE (standing for \"optimal authenticated key-exchange\" in brief). We show that the OAKE protocol family combines, in essence, the advantages of both (H)MQV and KEA/OPACITY, while saving from or alleviating the disadvantages of them both."
  },
  {
    "Title": "Privacy-Preserving Authenticated Key-Exchange Over Internet",
    "URL": "https://dl.acm.org/doi/10.1109/TIFS.2013.2293457",
    "Full Abstract": "Key-exchange, in particular Diffie–Hellman key-exchange (DHKE), is among the core cryptographic mechanisms for ensuring network security. For key-exchange over the Internet, both security and privacy are desired. In this paper, we develop a family of privacy-preserving authenticated DHKE protocols named deniable Internet key-exchange (DIKE), both in the traditional PKI setting and in the identity-based setting. The newly developed DIKE protocols are of conceptual clarity and practical (online) efficiency. They provide useful privacy protection to both protocol participants, and add novelty and new value to the IKE standard. To the best of our knowledge, our protocols are the first provably secure DHKE protocols that additionally enjoy all the following privacy protection advantages: 1) forward deniability, actually concurrent non-malleable statistical zero-knowledge, for both protocol participants simultaneously; 2) the session transcript and session-key can be generated merely from DH-exponents (together with some public values), which thus cannot be traced to the pair of protocol participants; and 3) exchanged messages do not bear peer's identity, and do not explicitly bear player role information."
  },
  {
    "Title": "An ",
    "URL": "https://dl.acm.org/doi/10.5555/2722129.2722137",
    "Full Abstract": "In this paper, we introduce a novel approach for reducing the"
  },
  {
    "Title": "Interdisciplinarity: A View from Theory of Computation",
    "URL": "https://dl.acm.org/doi/10.1145/2820468.2820472",
    "Full Abstract": "Increasingly, the concepts and methods of computer science are being recognized as a source of great intellectual interest, injecting fresh ideas into other scientific disciplines. Through discourses and collaborations, exciting multidisciplinary areas are blossoming. We illustrate this phenomenon from the viewpoint of Theory of Computation."
  },
  {
    "Title": "Concurrent Knowledge Extraction in Public-Key Models",
    "URL": "https://dl.acm.org/doi/10.1007/s00145-014-9191-z",
    "Full Abstract": "Knowledge extraction is a fundamental notion, modeling machine possession of values (witnesses) in a computational complexity sense and enabling one to argue about the internal state of a party in a protocol without probing its internal secret state. However, when transactions are concurrent, say over the Internet, with players possessing public keys (as is common in cryptography), assuring that entities \"know\" what they claim to know, where adversaries may be well coordinated across different transactions, turns out to be much more subtle and in need of re-examination. In such settings, mixing the public-key structure as part of the language and statements is a natural adversarial strategy. Here, we investigate how to formally treat knowledge possession by parties interacting concurrently in the public-key model. More technically, we look into the relative power of the notion of \"concurrent knowledge extraction\" (CKE) for concurrent zero knowledge (CZK) in the bare public-key (BPK) model, where the language and statements being proved can be dynamically and adaptively chosen by the prover and may be possibly based on verifiers' public keys. By concrete attacks against some existing natural protocols, we first show that concurrent soundness and normal arguments of knowledge do not guarantee concurrent verifier security in the public-key setting. Here, roughly speaking, concurrent verifier security says that the malicious concurrent prover should \"know\" all the witnesses to all the possibly public-key-related statements adaptively chosen and successfully proved in the concurrent sessions. These concrete attacks serve as a good motivation for understanding \"possession of knowledge\" for concurrent transactions with registered public keys, i.e., the subtleties of concurrent knowledge extraction in the public-key model. This motivates us to introduce and formalize the notion of CKE, along with clarifications of various subtleties. Two implementations are then presented for constant-round concurrently knowledge extractable concurrent zero-knowledge (CZK---CKE) argument for $$\\mathcal {NP}$$NP in the BPK model: One protocol is generic and based on standard polynomial-time assumptions, whereas the other protocol is computationally efficient and employs complexity leveraging in a novel way. Both protocols can be practically instantiated for some specific number-theoretic languages without going through general $$\\mathcal {NP}$$NP-reductions. Of independent interest are the discussions about the subtleties surrounding the fundamental structure of Feige---Shamir zero knowledge in the BPK model."
  },
  {
    "Title": "Dominant-Strategy versus Bayesian Multi-item Auctions",
    "URL": "https://dl.acm.org/doi/10.1145/3033274.3085120",
    "Full Abstract": "We address two related unanswered questions in maximum revenue multi-item auctions. Is dominant-strategy implementation equivalent to the semantically less stringent Bayesian one (as in the case of Myerson's 1-item auction)? Can one find explicit solutions for non-trivial families of multi-item auctions (as in the 1-item case)? In this paper, we present such natural families whose explicit solutions exhibit a revenue gap between the two implementations. More precisely, consider the"
  },
  {
    "Title": "Towards data-algorithm dependent generalization",
    "URL": "https://dl.acm.org/doi/10.5555/3666122.3669611",
    "Full Abstract": "One of the major open problems in machine learning is to characterize generalization in the overparameterized regime, where most traditional generalization bounds become inconsistent even for overparameterized linear regression [46]. In many scenarios, this failure can be attributed to obscuring the crucial interplay between the training algorithm and the underlying data distribution. This paper demonstrate that the generalization behavior of overparameterized model should be analyzed in a both data-relevant and algorithm-relevant manner. To make a formal characterization, We introduce a notion called data-algorithm compatibility, which considers the generalization behavior of the entire data-dependent training trajectory, instead of traditional last-iterate analysis. We validate our claim by studying the setting of solving overparameterized linear regression with gradient descent. Specifically, we perform a data-dependent trajectory analysis and derive a sufficient condition for compatibility in such a setting. Our theoretical results demonstrate that if we take early stopping iterates into consideration, generalization can hold with significantly weaker restrictions on the problem instance than the previous last-iterate analysis."
  },
  {
    "Title": "Post-WIMP user interfaces",
    "URL": "https://dl.acm.org/doi/10.1145/253671.253708",
    "Full Abstract": "Copyright © 1997 author."
  },
  {
    "Title": "The history of computer graphics standards development",
    "URL": "https://dl.acm.org/doi/10.1145/279389.279434",
    "Full Abstract": "In keeping with the retrospective theme of this issue of"
  },
  {
    "Title": "The shape of things to come",
    "URL": "https://dl.acm.org/doi/10.1145/279389.279446",
    "Full Abstract": "Copyright © 1998 Author."
  },
  {
    "Title": "Look Ma! four hands! new models for interacting with 3D environments",
    "URL": "https://dl.acm.org/doi/10.1145/280953.281554",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Granularity in the design of interactive illustrations",
    "URL": "https://dl.acm.org/doi/10.1145/299649.299794",
    "Full Abstract": "We describe some issues in designing and building educational Java applets for an introductory computer graphics course. The design problem involves balancing educational goals of building intuition about fundamental concepts in a domain against heterogeneity both in subject material and in student backgrounds. We present our design approach for resolving these forces --- fine-grained units addressing small concepts --- and discuss its effects on other areas including hypertext structure, interface design, and software engineering."
  },
  {
    "Title": "Scene graph APIs",
    "URL": "https://dl.acm.org/doi/10.1145/311625.311927",
    "Full Abstract": "No abstract available."
  },
  {
    "Title": "Education",
    "URL": "https://dl.acm.org/doi/10.1145/345966.346038",
    "Full Abstract": "Copyright © 1999 ACM."
  },
  {
    "Title": "Immersive virtual reality for visualizing flow through an artery",
    "URL": "https://dl.acm.org/doi/10.5555/375213.375297",
    "Full Abstract": "Abstract not found or failed to load."
  },
  {
    "Title": "Immersive Virtual Reality for Visualizing Flow Through an Artery",
    "URL": "https://dl.acm.org/doi/10.5555/832272.833917",
    "Full Abstract": "We present an immersive system for exploring numerically simulated flow data through a model of a coronary artery graft. This tightly-coupled interdisciplinary project is aimed at understanding how to reduce the failure rate of these grafts. The visualization system provides a mechanism for exploring the effect of changes to the geometry, to the flow, and for exploring potential sources of future lesions. The system uses gestural and voice interactions exclusively, moving away from more traditional windows/icons/menus/point-and-click (WIMP) interfaces.We present an example session using the system and discuss our experiences developing, testing, and using it. We describe some of the interaction and rendering techniques that we experimented with and describe their level of success. Our experience suggests that systems like this are exciting to clinical researchers, but conclusive evidence of their value is not yet available."
  },
  {
    "Title": "Immersive VR for Scientific Visualization",
    "URL": "https://dl.acm.org/doi/10.1109/38.888006",
    "Full Abstract": "Immersive virtual reality can provide powerful techniques for scientific visualization. The research agenda for the technology sketched here offers a progress report, a hope, and a call to action."
  },
  {
    "Title": "User interfaces",
    "URL": "https://dl.acm.org/doi/10.1145/365181.365192",
    "Full Abstract": "Copyright © 2001 ACM."
  },
  {
    "Title": "Immersive Electronic Books for Surgical Training",
    "URL": "https://dl.acm.org/doi/10.1109/MMUL.2005.48",
    "Full Abstract": "Immersive electronic books (IEBooks) for surgical training will let surgeons explore previous surgical procedures in 3D. The authors describe the techniques and tools for creating IEBook."
  },
  {
    "Title": "Visualization Research Problems in Next-Generation Educational Software",
    "URL": "https://dl.acm.org/doi/10.1109/MCG.2005.118",
    "Full Abstract": "The dream of universal access to high-quality, personalized educational content available both synchronously and asynchronously remains unrealized. For more than four decades, many have said that information technology (IT) would be a key technology in realizing this dream by helping to produce compelling and individualized educational content, the means for delivering it, and effective feedback and assessment mechanisms. Yet today the most visible impact of IT is simple uses of the Web as a delivery mechanism for text and images, as well as for some interactive Java applets, and as a communications medium through blogs and wikis."
  },
  {
    "Title": "Next-generation educational software",
    "URL": "https://dl.acm.org/doi/10.1145/1281500.1281543",
    "Full Abstract": "The dream of universal access to high-quality, personalized educational content that is available both synchronously and asynchronously remains unrealized. For more than four decades, it has been said that information technology would be a key enabling technology for making this dream a reality by providing the ability to produce compelling and individualized content, the means for delivering it, and effective feedback and assessment mechanisms. Although IT has certainly had some impact, it has become a cliché to note that education is the last field to take systematic advantage of IT. There have been some notable successes of innovative software (e.g., the graphing calculator, the Geometer's Sketchpad, and the World Wide Web as an information-storage and -delivery vehicle), but we continue to teach-and students continue to learn-in ways that are virtually unchanged since the invention of the blackboard."
  },
  {
    "Title": "Applications and Issues in Pen-Centric Computing",
    "URL": "https://dl.acm.org/doi/10.1109/MMUL.2008.82",
    "Full Abstract": "As part of the rapidly evolving field of designing more natural user interfaces for multimedia information, pen-centric computing refuses to disappear. As a quite natural and universal interface modality, it presents many challenges. In this article, the pen-centric computing group at Brown University, led by Andries Van Dam, surveys the many prototypes they have designed and implemented, and discuss the research issues in the field still to be explored."
  },
  {
    "Title": "NuSys",
    "URL": "https://dl.acm.org/doi/10.1145/3103010.3121045",
    "Full Abstract": "Knowledge workers consume and annotate digital documents such as PDF files, videos, images and text notes - in some cases collaboratively - to form mental models and gain insight. An abundance of software solutions and utilities that were designed to assist users in stages of this process but not in the process as a whole, which makes knowledge work with documents unnecessarily inefficient. In this paper, we introduce ideas on how to streamline common knowledge worker tasks, such as collaboratively searching, gathering and freely arranging fragments of various media documents to gain understanding and then transforming emergent insights into interactive structured visualizations. Furthermore, we present NuSys, an integrated development environment (IDE) specialized for document-centric workflows, that implements the core of these ideas."
  },
  {
    "Title": "Reflections on an introductory CS course, CS15, at Brown University",
    "URL": "https://dl.acm.org/doi/10.1145/3284639",
    "Full Abstract": "Copyright © 2018 ACM."
  },
  {
    "Title": "Reflections on a Half-Century of Hypertext",
    "URL": "https://dl.acm.org/doi/10.1145/3342220.3344782",
    "Full Abstract": "2019 marks not only the 30th anniversary of the falling of the Berlin Wall, but also the 50th anniversaries of equally momentous events of 1968-1969 in the US and elsewhere. Martin Luther King and Robert Kennedy were assassinated. Hippie \"flower power\" and the closely related anti-Vietnam war movement were socio-political revolutions. In Europe, 2019 marks the 100th anniversary of the end of the \"war to end all wars\" and the 75th anniversary of D-Day. Counterpointing this societal turmoil, technology gave us hope. Neil Armstrong and Buzz Aldrin walked on the moon. Doug Engelbart and his team presented the \"Mother of All Demos\" of NLS at the '68 Fall Joint Computer Conference. Ivan Sutherland's pioneering Sketchpad (that demo'd interactive graphics in 1963) and Engelbart's NLS demo were two landmark events that were early examples of interactive computing in an era of batch computation. Interactive computing on time-sharing systems, combined with microminiaturization, would lead more than a decade later to the birth of the personal computer. It caused a revolution in the dominant model of computing that was centered on large mainframes and minicomputers used for science and engineering, finance and commerce. Interactive computing based on computer graphics and its use in hypermedia systems characterizes most of my research career. In 2019, it is difficult to remember the impact that interaction-based information structuring and sharing had on society; it certainly shaped my research career. In this presentation, I will reflect on the development of five decades of hypermedia systems and will demo three systems that have been highlights of my journey in hyperland. First, I'll show our FRESS hypertext system (still running 50-year old assembly code!), with the database of poetry used by a class of English students in 1976 in what is arguably the first online scholarly community. Next, I will demo our TAG (Touch Art Gallery) used by the Nobel Foundation a few years ago for a traveling exhibition on Alfred Nobel and all the Nobel Laureates. Finally, I'll interweave the hypertext-centric parts of my talk with some source material stored in an unbounded 2D workspace, using our current hypermedia system Dash, which is still under development and in an early but already useful state. These systems will be presented in the context of the research trends that led, ultimately, to the interconnected society in which we live. All of us working on our first hypertext systems in the '60s understood the potential of this technology. What I did not predict is that 50 years later the revolution in human-centered computing would remain far too unfinished in terms of its positive societal impact. Indeed, that impact and utility are increasingly in jeopardy from a variety of forces, both economic and political. I will close with some thoughts on both deliberately designed and unanticipated societal issues of social media that I feel we technologists must urgently help address."
  },
  {
    "Title": "Dash",
    "URL": "https://dl.acm.org/doi/10.1145/3372923.3404807",
    "Full Abstract": "Popular application suites, as well as specialized apps, are designed for workflows in which users focus on a single task for extended periods of time. These application silos slow down the many other workflows that require users to move with agility between tasks in a single working session. This is particularly true for creative people who have personalized patterns of gathering, organizing, and presenting information from a variety of sources. Moreover, each application comes with its own learning curve and data model, restricting users seeking to extend their workflows and in some cases, losing data through poor data transferring mechanisms such as clipboard copy and paste."
  },
  {
    "Title": "50 Years of Changes–How to Brace Yourself!",
    "URL": "https://dl.acm.org/doi/10.1145/3587422.3597996",
    "Full Abstract": "Having lived through the 50 years of changes, the panelists attempt to put them in calibrated perspective, not merely for the sake of fond reminiscence–and fun!–but as a guide to those who face the looming future changes."
  },
  {
    "Title": "Using behavioral data to identify interviewer fabrication in surveys",
    "URL": "https://dl.acm.org/doi/10.1145/2470654.2481404",
    "Full Abstract": "Surveys conducted by human interviewers are one of the principal means of gathering data from all over the world, but the quality of this data can be threatened by interviewer fabrication. In this paper, we investigate a new approach to detecting interviewer fabrication automatically. We instrument electronic data collection software to record logs of low-level behavioral data and show that supervised classification, when applied to features extracted from these logs, can identify interviewer fabrication with an accuracy of up to 96%. We show that even when interviewers know that our approach is being used, have some knowledge of how it works, and are incentivized to avoid detection, it can still achieve an accuracy of 86%. We also demonstrate the robustness of our approach to a moderate amount of label noise and provide practical recommendations, based on empirical evidence, on how much data is needed for our approach to be effective."
  },
  {
    "Title": "Selling in Exclusive Markets",
    "URL": "https://dl.acm.org/doi/10.1145/2465769.2465772",
    "Full Abstract": "We consider prior-free benchmarks in non-matroid settings. In particular, we show that a very desirable benchmark proposed by Hartline and Roughgarden is too strong, in the sense that no truthful mechanism can compete with it even in a very simple non-matroid setting where there are two exclusive markets and the seller can only sell to agents in one of them. On the other hand, we show that there is a mechanism that competes with a symmetrized version of this benchmark. We further investigate the more traditional best fixed price profit benchmark and show that there are mechanisms that compete with it in any downward-closed settings."
  },
  {
    "Title": "On revenue maximization for agents with costly information acquisition",
    "URL": "https://dl.acm.org/doi/10.1007/978-3-642-39212-2_43",
    "Full Abstract": "A prevalent assumption in traditional mechanism design is that buyers know their precise value for an item; however, this assumption is rarely true in practice. In most settings, buyers can \"deliberate\", i.e., spend money or time, in order improve their estimate of an item's value. It is known that the deliberative setting is fundamentally different than the classical one, and desirable properties of a mechanism such as equilibria, revenue maximization, or truthfulness, may no longer hold."
  },
  {
    "Title": "Approximate revenue maximization in interdependent value settings",
    "URL": "https://dl.acm.org/doi/10.1145/2600057.2602858",
    "Full Abstract": "We study revenue maximization in settings where agents' values are interdependent: each agent receives a signal drawn from a correlated distribution and agents' values are functions of all of the signals. We introduce a variant of the generalized VCG auction with reserve prices and random admission, and show that this auction gives a constant approximation to the optimal expected revenue in matroid environments. Our results do not require any assumptions on the signal distributions, however, they require the value functions to satisfy a standard single-crossing property and a concavity-type condition."
  },
  {
    "Title": "Convergence of Position Auctions under Myopic Best-Response Dynamics",
    "URL": "https://dl.acm.org/doi/10.1145/2632226",
    "Full Abstract": "We study the dynamics of multiround position auctions, considering both the case of exogenous click-through rates and the case in which click-through rates are determined by an endogenous consumer search process. In both contexts, we demonstrate that dynamic position auctions converge to their associated static, envy-free equilibria. Furthermore, convergence is efficient, and the entry of low-quality advertisers does not slow convergence. Because our approach predominantly relies on assumptions common in the sponsored search literature, our results suggest that dynamic position auctions converge more generally."
  },
  {
    "Title": "On a competitive secretary problem",
    "URL": "https://dl.acm.org/doi/10.5555/2887007.2887138",
    "Full Abstract": "Consider a scenario in which there are multiple employers competing to hire the best possible employee. How does the competition between the employers affect their hiring strategies or their ability to hire one of the best possible candidates? In this paper, we address this question by studying a generalization of the classical secretary problem from optimal stopping theory: a set of ranked employers compete to hire from the same random stream of employees, and each employer wishes to hire the best candidate in the bunch. We show how to derive subgame-perfect Nash equilibrium strategies in this game and analyze the impact the competition has on the quality of the hires as a function of the rank of the employer. We present numerical results from simulations of these strategies."
  },
  {
    "Title": "Simple pricing schemes for consumers with evolving values",
    "URL": "https://dl.acm.org/doi/10.5555/2884435.2884536",
    "Full Abstract": "We consider a pricing problem where a buyer is interested in purchasing/using a good, such as an app or music or software, repeatedly over time. The consumer discovers his value for the good only as he uses it, and the value evolves with each use. Optimizing for the seller's revenue in such dynamic settings is a complex problem and requires assumptions about how the buyer behaves before learning his future value(s), and in particular, how he reacts to risk. We explore the performance of a class of pricing mechanisms that are extremely simple for both the buyer and the seller to use: the buyer reacts to prices myopically without worrying about how his value evolves in the future; the seller needs to optimize for revenue over a space of only two parameters, and can do so without knowing the buyer's risk profile or fine details of the value evolution process. We present simple-versus-optimal type results, namely that under certain assumptions, simple pricing mechanisms of the above form are approximately optimal"
  },
  {
    "Title": "The FedEx Problem",
    "URL": "https://dl.acm.org/doi/10.1145/2940716.2940752",
    "Full Abstract": "Consider the pricing problem faced by FedEx. Each customer has a package to ship, a deadline $d$ by which he needs his package to arrive, and a value $v$ for a guarantee that the package will arrive by his deadline. FedEx can (and does) offer a number of different shipping options in order to extract more revenue from their customers. In this paper, we solve the optimal (revenue-maximizing) auction problem for the single-agent version of this problem. Our paper adds to the relatively short list of multi-parameter settings for which a closed-form solution is known."
  },
  {
    "Title": "A Prior-Independent Revenue-Maximizing Auction for Multiple Additive Bidders",
    "URL": "https://dl.acm.org/doi/10.1007/978-3-662-54110-4_12",
    "Full Abstract": "Recent work by Babaioff et al.ï ź[1], Yaoï ź[30], and Cai et al.ï ź[7] shows how to construct an approximately optimal auction for additive bidders, given access to the priors from which the bidders' values are drawn. In this paper, building on the single sample approach of Dhangwatnotai et al.ï ź[15], we show how the auctioneer can obtain approximately optimal expected revenue in this setting without knowing the priors, as long as the item distributions are regular."
  },
  {
    "Title": "Stability of service under time-of-use pricing",
    "URL": "https://dl.acm.org/doi/10.1145/3055399.3055455",
    "Full Abstract": "We consider time-of-use pricing as a technique for matching supply and demand of temporal resources with the goal of maximizing social welfare. Relevant examples include energy, computing resources on a cloud computing platform, and charging stations for electric vehicles, among many others. A client/job in this setting has a window of time during which he needs service, and a particular value for obtaining it. We assume a stochastic model for demand, where each job materializes with some probability via an independent Bernoulli trial. Given a per-time-unit pricing of resources, any realized job will first try to get served by the cheapest available resource in its window and, failing that, will try to find service at the next cheapest available resource, and so on. Thus, the natural stochastic fluctuations in demand have the potential to lead to cascading overload events. Our main result shows that setting prices so as to optimally handle the"
  },
  {
    "Title": "A simply exponential upper bound on the maximum number of stable matchings",
    "URL": "https://dl.acm.org/doi/10.1145/3188745.3188848",
    "Full Abstract": "Stable matching is a classical combinatorial problem that has been the subject of intense theoretical and empirical study since its introduction in 1962 in a seminal paper by Gale and Shapley. In this paper, we provide a new upper bound on"
  },
  {
    "Title": "Energy Equilibria in Proof-of-Work Mining",
    "URL": "https://dl.acm.org/doi/10.1145/3328526.3329630",
    "Full Abstract": "The Bitcoin protocol induces miners, through monetary rewards, to expend energy in order to add blocks to the chain. We show that, when energy costs are substantial and taken into account, counterintuitive and unintended strategic behavior results: In a simple bounded-horizon setting with two identical miners there is a unique pure symmetric equilibrium in which both miners first \"slow down\" in order to decrease the crypto complexity and then take advantage of this decrease. If miners have different energy efficiencies and are restricted to choose the same hash rate for many epochs, there is a unique pure equilibrium in which miners either participate at low levels that depend in intricate ways on all the other miners' efficiencies, or choose to abstain from mining if their efficiency is too low. In the general setting in which miners can adapt their hash rates over time, we show that, unless the number of miners is very small, the only possible pure equilibria are rather chaotic, with miners quitting and starting again periodically --- or there is no pure equilibrium at all. We discuss the implications of these results for the stability of proof-of-work protocols."
  },
  {
    "Title": "Combinatorial Auctions with Interdependent Valuations",
    "URL": "https://dl.acm.org/doi/10.1145/3328526.3329759",
    "Full Abstract": "No abstract available."
  },

  {
    "Title": "UnGANable",
    "URL": "https://dl.acm.org/doi/10.5555/3620237.3620641",
    "Full Abstract": "Deepfakes pose severe threats of visual misinformation to our society. One representative deepfake application is face manipulation that modifies a victim's facial attributes in an image, e.g., changing her age or hair color. The state-of-the-art face manipulation techniques rely on Generative Adversarial Networks (GANs). In this paper, we propose the first defense system, namely UnGANable, against GAN-inversion-based face manipulation. In specific, UnGANable focuses on defending GAN inversion, an essential step for face manipulation. Its core technique is to search for alternative images (called cloaked images) around the original images (called target images) in image space. When posted online, these cloaked images can jeopardize the GAN inversion process. We consider two state-of-the-art inversion techniques including optimization-based inversion and hybrid inversion, and design five different defenses under five scenarios depending on the defender's background knowledge. Extensive experiments on four popular GAN models trained on two benchmark face datasets show that UnGANable achieves remarkable effectiveness and utility performance, and outperforms multiple baseline methods. We further investigate four adaptive adversaries to bypass UnGANable and show that some of them are slightly effective."
  },
  {
    "Title": "Unsafe Diffusion: On the Generation of Unsafe Images and Hateful Memes From Text-To-Image Models",
    "URL": "https://dl.acm.org/doi/10.1145/3576915.3616679",
    "Full Abstract": "State-of-the-art Text-to-Image models like Stable Diffusion and DALLE\\cdot2 are revolutionizing how people generate visual content. At the same time, society has serious concerns about how adversaries can exploit such models to generate problematic or unsafe images. In this work, we focus on demystifying the generation of unsafe images and hateful memes from Text-to-Image models. We first construct a typology of unsafe images consisting of five categories (sexually explicit, violent, disturbing, hateful, and political). Then, we assess the proportion of unsafe images generated by four advanced Text-to-Image models using four prompt datasets. We find that Text-to-Image models can generate a substantial percentage of unsafe images; across four models and four prompt datasets, 14.56% of all generated images are unsafe. When comparing the four Text-to-Image models, we find different risk levels, with Stable Diffusion being the most prone to generating unsafe content (18.92% of all generated images are unsafe). Given Stable Diffusion's tendency to generate more unsafe content, we evaluate its potential to generate hateful meme variants if exploited by an adversary to attack a specific individual or community. We employ three image editing methods, DreamBooth, Textual Inversion, and SDEdit, which are supported by Stable Diffusion to generate variants. Our evaluation result shows that 24% of the generated images using DreamBooth are hateful meme variants that present the features of the original hateful meme and the target individual/community; these generated images are comparable to hateful meme variants collected from the real world. Overall, our results demonstrate that the danger of large-scale generation of unsafe images is imminent. We discuss several mitigating measures, such as curating training data, regulating prompts, and implementing safety filters, and encourage better safeguard tools to be developed to prevent unsafe generation.1 Our code is available at https://github.com/YitingQu/unsafe-diffusion."
  },
  {
    "Title": "A Framework for Constructing Single Secret Leader Election from MPC",
    "URL": "https://dl.acm.org/doi/10.1007/978-3-031-17146-8_33",
    "Full Abstract": "The emergence of distributed digital currencies has raised the need for a reliable consensus mechanism. In proof-of-stake cryptocurrencies, the participants periodically choose a closed set of validators, who can vote and append transactions to the blockchain. Each validator can become a leader with the probability proportional to its stake. Keeping the leader private yet unique until it publishes a new block can significantly reduce the attack vector of an adversary and improve the throughput of the network. The problem of Single Secret Leader Election (SSLE) was first formally defined by Boneh et al. in 2020."
  },
  {
    "Title": "FAKEPCD: Fake Point Cloud Detection via Source Attribution",
    "URL": "https://dl.acm.org/doi/10.1145/3634737.3637645",
    "Full Abstract": "To prevent the mischievous use of synthetic (fake) point clouds produced by generative models, we pioneer the study of detecting point cloud authenticity and attributing them to their sources. We propose an attribution framework FakePCD to attribute (fake) point clouds to their respective generative models (or real-world collections). The main idea of FakePCD is to train an attribution model that learns the point cloud features from different sources and further differentiates these sources using an attribution signal. Depending on the characteristics of the training point clouds, namely, sources and shapes, we formulate four attribution scenarios: close-world, open-world, single-shape, and multiple-shape, and evaluate FakePCD's performance in each scenario. Extensive experimental results demonstrate the effectiveness of FakePCD on source attribution across different scenarios. Take the open-world attribution as an example, FakePCD attributes point clouds to known sources with an accuracy of 0.82-0.98 and to unknown sources with an accuracy of 0.73-1.00. Additionally, we introduce an approach to visualize unique patterns (fingerprints) in point clouds associated with each source. This explains how FakePCD recognizes point clouds from various sources by focusing on distinct areas within them. Overall, we hope our study establishes a baseline for the source attribution of (fake) point clouds."
  },
  {
    "Title": "Graph Unlearning",
    "URL": "https://dl.acm.org/doi/10.1145/3548606.3559352",
    "Full Abstract": "Machine unlearning is a process of removing the impact of some training data from the machine learning (ML) models upon receiving removal requests. While straightforward and legitimate, retraining the ML model from scratch incurs a high computational overhead. To address this issue, a number of approximate algorithms have been proposed in the domain of image and text data, among which SISA is the state-of-the-art solution. It randomly partitions the training set into multiple shards and trains a constituent model for each shard. However, directly applying SISA to the graph data can severely damage the graph structural information, and thereby the resulting ML model utility. In this paper, we propose GraphEraser, a novel machine unlearning framework tailored to graph data. Its contributions include two novel graph partition algorithms and a learning-based aggregation method. We conduct extensive experiments on five real-world graph datasets to illustrate the unlearning efficiency and model utility of GraphEraser. It achieves 2.06x (small dataset) to 35.94x (large dataset) unlearning time improvement. On the other hand, GraphEraser achieves up to 62.5% higher F1 score and our proposed learning-based aggregation method achieves up to 112% higher F1 score. https://github.com/MinChen00/Graph-Unlearning."
  },
  {
    "Title": "Finding MNEMON",
    "URL": "https://dl.acm.org/doi/10.1145/3548606.3559358",
    "Full Abstract": "Previous security research efforts orbiting around graphs have been exclusively focusing on either (de-)anonymizing the graphs or understanding the security and privacy issues of graph neural networks. Little attention has been paid to understand the privacy risks of integrating the output from graph embedding models (e.g., node embeddings) with complex downstream machine learning pipelines. In this paper, we fill this gap and propose a novel model-agnostic graph recovery attack that exploits the implicit graph structural information preserved in the embeddings of graph nodes. We show that an adversary can recover edges with decent accuracy by only gaining access to the node embedding matrix of the original graph without interactions with the node embedding models. We demonstrate the effectiveness and applicability of our graph recovery attack through extensive experiments."
  },
  {
    "Title": "Auditing Membership Leakages of Multi-Exit Networks",
    "URL": "https://dl.acm.org/doi/10.1145/3548606.3559359",
    "Full Abstract": "Relying on the truth that not all inputs require the same level of computational cost to produce reliable predictions, multi-exit networks are gaining attention as a prominent approach for pushing the limits of efficient deployment. Multi-exit networks endow a backbone model with early exits, allowing predictions at intermediate layers of the model and thus saving computation time and energy. However, various current designs of multi-exit networks are only considered to achieve the best trade-off between resource usage efficiency and prediction accuracy, the privacy risks stemming from them have never been explored. This prompts the need for a comprehensive investigation of privacy risks in multi-exit networks."
  },
  {
    "Title": "Freely Given Consent?",
    "URL": "https://dl.acm.org/doi/10.1145/3548606.3560564",
    "Full Abstract": "Adopted in May 2018, the European Union's General Data Protection Regulation (GDPR) requires the consent for processing users' personal data to be freely given, specific, informed, and unambiguous. While prior work has shown that this often is not given through automated network traffic analysis, no research has systematically studied how consent notices are currently implemented and whether they conform to GDPR in mobile apps."
  },
  {
    "Title": "Why So Toxic?",
    "URL": "https://dl.acm.org/doi/10.1145/3548606.3560599",
    "Full Abstract": "Chatbots are used in many applications, e.g., automated agents, smart home assistants, interactive characters in online games, etc. Therefore, it is crucial to ensure they do not behave in undesired manners, providing offensive or toxic responses to users. This is not a trivial task as state-of-the-art chatbot models are trained on large, public datasets openly collected from the Internet. This paper presents a first-of-its-kind, large-scale measurement of toxicity in chatbots. We show that publicly available chatbots are prone to providing toxic responses when fed toxic queries. Even more worryingly, some non-toxic queries can trigger toxic responses too. We then set out to design and experiment with an attack, ToxicBuddy, which relies on fine-tuning GPT-2 to generate non-toxic queries that make chatbots respond in a toxic manner. Our extensive experimental evaluation demonstrates that our attack is effective against public chatbot models and outperforms manually-crafted malicious queries proposed by previous work. We also evaluate three defense mechanisms against ToxicBuddy, showing that they either reduce the attack performance at the cost of affecting the chatbot's utility or are only effective at mitigating a portion of the attack. This highlights the need for more research from the computer security and online safety communities to ensure that chatbot models do not hurt their users. Overall, we are confident that ToxicBuddy can be used as an auditing tool and that our work will pave the way toward designing more effective defenses for chatbot safety."
  },
  {
    "Title": "On the Privacy Risks of Cell-Based NAS Architectures",
    "URL": "https://dl.acm.org/doi/10.1145/3548606.3560619",
    "Full Abstract": "Existing studies on neural architecture search (NAS) mainly focus on efficiently and effectively searching for network architectures with better performance. Little progress has been made to systematically understand if the NAS-searched architectures are robust to privacy attacks while abundant work has already shown that human-designed architectures are prone to privacy attacks. In this paper, we fill this gap and systematically measure the privacy risks of NAS architectures. Leveraging the insights from our measurement study, we further explore the cell patterns of cell-based NAS architectures and evaluate how the cell patterns affect the privacy risks of NAS-searched architectures. Through extensive experiments, we shed light on how to design robust NAS architectures against privacy attacks, and also offer a general methodology to understand the hidden correlation between the NAS-searched architectures and other privacy risks."
  },
  {
    "Title": "Membership Inference Attacks by Exploiting Loss Trajectory",
    "URL": "https://dl.acm.org/doi/10.1145/3548606.3560684",
    "Full Abstract": "Machine learning models are vulnerable to membership inference attacks in which an adversary aims to predict whether or not a particular sample was contained in the target model's training dataset. Existing attack methods have commonly exploited the output information (mostly, losses) solely from the given target model. As a result, in practical scenarios where both the member and non-member samples yield similarly small losses, these methods are naturally unable to differentiate between them. To address this limitation, in this paper, we propose a new attack method, called TrajectoryMIA, which can exploit the membership information from the whole training process of the target model for improving the attack performance. To mount the attack in the common black-box setting, we leverage knowledge distillation, and represent the membership information by the losses evaluated on a sequence of intermediate models at different distillation epochs, namely distilled loss trajectory, together with the loss from the given target model. Experimental results over different datasets and model architectures demonstrate the great advantage of our attack in terms of different metrics. For example, on CINIC-10, our attack achieves at least 6 times higher true-positive rate at a low false-positive rate of 0.1% than existing methods. Further analysis demonstrates the general effectiveness of our attack in more strict scenarios."
  },
  {
    "Title": "Pareto-optimal Defenses for the Web Infrastructure: Theory and Practice",
    "URL": "https://dl.acm.org/doi/10.1145/3567595",
    "Full Abstract": "The integrity of the content a user is exposed to when browsing the web relies on a plethora of non-web technologies and an infrastructure of interdependent hosts, communication technologies, and trust relations. Incidents like the Chinese Great Cannon or the MyEtherWallet attack make it painfully clear: the security of end users hinges on the security of the surrounding infrastructure: routing, DNS, content delivery, and the PKI. There are many competing, but isolated proposals to increase security, from the network up to the application layer. So far, researchers have focused on analyzing attacks and defenses on specific layers. We still lack an evaluation of how, given the status quo of the web, these proposals can be combined, how effective they are, and at what cost the increase of security comes. In this work, we propose a graph-based analysis based on Stackelberg planning that considers a rich attacker model and a multitude of proposals from IPsec to DNSSEC and SRI. Our threat model considers the security of billions of users against attackers ranging from small hacker groups to nation-state actors. Analyzing the infrastructure of the Top 5k Alexa domains, we discover that the security mechanisms currently deployed are ineffective and that some infrastructure providers have a comparable threat potential to nations. We find a considerable increase of security (up to 13% protected web visits) is possible at a relatively modest cost, due to the effectiveness of mitigations at the application and transport layer, which dominate expensive infrastructure enhancements such as DNSSEC and IPsec."
  },
  {
    "Title": "SEAL: Capability-Based Access Control for Data-Analytic Scenarios",
    "URL": "https://dl.acm.org/doi/10.1145/3589608.3593838",
    "Full Abstract": "Data science is the basis for various disciplines in the Big-Data era. Due to the high volume, velocity, and variety of big data, data owners often store their data in data servers. Past few years, many computation techniques have emerged to protect the security and privacy of such shared data while enabling analysis thereon. Hence, access-control systems must provide a fine-grained, multi-layer mechanism to protect data. However, the existing systems and frameworks fail to satisfy all these requirements and resolve the trust issue between data owners and analysts."
  },
  {
    "Title": "On Simulatability Soundness and Mapping Soundness of Symbolic Cryptography",
    "URL": "https://dl.acm.org/doi/10.1007/978-3-540-77050-3_9",
    "Full Abstract": "The abstraction of cryptographic operations by term algebras, called Dolev-Yao models or symbolic cryptography, is essential in almost all tool- supported methods for proving security protocols. Recently significant progress was made – using two conceptually different approaches – in proving that Dolev-Yao models can be sound with respect to actual cryptographic realizations and security definitions. One such approach is grounded on the notion of simulatability, which constitutes a salient technique of Modern Cryptography with a longstanding history for a variety of different tasks. The other approach strives for the so-called mapping soundness – a more recent technique that is tailored to the soundness of specific security properties in Dolev-Yao models, and that can be established using more compact proofs. Typically, both notions of soundness for similar Dolev-Yao models are established separately in independent papers."
  },
  {
    "Title": "Data poisoning attacks against multimodal encoders",
    "URL": "https://dl.acm.org/doi/10.5555/3618408.3620047",
    "Full Abstract": "Recently, the newly emerged multimodal models, which leverage both visual and linguistic modalities to train powerful encoders, have gained increasing attention. However, learning from a large-scale unlabeled dataset also exposes the model to the risk of potential poisoning attacks, whereby the adversary aims to perturb the model's training data to trigger malicious behaviors in it. In contrast to previous work, only poisoning visual modality, in this work, we take the first step to studying poisoning attacks against multimodal models in both visual and linguistic modalities. Specially, we focus on answering two questions: (1)"
  },
  {
    "Title": "Generated graph detection",
    "URL": "https://dl.acm.org/doi/10.5555/3618408.3619384",
    "Full Abstract": "Graph generative models become increasingly effective for data distribution approximation and data augmentation. While they have aroused public concerns about their malicious misuses or misinformation broadcasts, just as what"
  },
  {
    "Title": "PrivTrace",
    "URL": "https://dl.acm.org/doi/10.5555/3620237.3620330",
    "Full Abstract": "Publishing trajectory data (individual's movement information) is very useful, but it also raises privacy concerns. To handle the privacy concern, in this paper, we apply differential privacy, the standard technique for data privacy, together with Markov chain model, to generate synthetic trajectories. We notice that existing studies all use Markov chain model and thus propose a framework to analyze the usage of the Markov chain model in this problem. Based on the analysis, we come up with an effective algorithm PrivTrace that uses the first-order and second-order Markov model adaptively. We evaluate PrivTrace and existing methods on synthetic and real-world datasets to demonstrate the superiority of our method."
  },
  {
    "Title": "Two-in-one",
    "URL": "https://dl.acm.org/doi/10.5555/3620237.3620362",
    "Full Abstract": "Machine learning has progressed significantly in various applications ranging from face recognition to text generation. However, its success has been accompanied by different attacks. Recently a new attack has been proposed which raises both accountability and parasitic computing risks, namely the model hijacking attack. Nevertheless, this attack has only focused on image classification tasks. In this work, we broaden the scope of this attack to include text generation and classification models, hence showing its broader applicability. More concretely, we propose a new model hijacking attack, Ditto, that can hijack different text classification tasks into multiple generation ones, e.g., language translation, text summarization, and language modeling. We use a range of text benchmark datasets such as SST-2, TweetEval, AGnews, QNLI, and IMDB to evaluate the performance of our attacks. Our results show that by using Ditto, an adversary can successfully hijack text generation models without jeopardizing their utility."
  },
  {
    "Title": "Bilingual problems",
    "URL": "https://dl.acm.org/doi/10.5555/3620237.3620580",
    "Full Abstract": "Scripting languages are continuously gaining popularity due to their ease of use and the flourishing software ecosystems surrounding them. These languages o_er crash and memory safety by design. Thus, developers do not need to understand and prevent low-level security issues like the ones plaguing the C code. However, scripting languages often allow"
  },
  {
    "Title": "FACE-AUDITOR",
    "URL": "https://dl.acm.org/doi/10.5555/3620237.3620640",
    "Full Abstract": "Few-shot-based facial recognition systems have gained increasing attention due to their scalability and ability to work with a few face images during the model deployment phase. However, the power of facial recognition systems enables entities with moderate resources to canvas the Internet and build well-performed facial recognition models without people's awareness and consent. To prevent the face images from being misused, one straightforward approach is to modify the raw face images before sharing them, which inevitably destroys the semantic information, increases the difficulty of retroactivity, and is still prone to adaptive attacks. Therefore, an auditing method that does not interfere with the facial recognition model's utility and cannot be quickly bypassed is urgently needed."
  },
  {
    "Title": "Fairwalk",
    "URL": "https://dl.acm.org/doi/10.5555/3367471.3367498",
    "Full Abstract": "Graph embeddings have gained huge popularity in the recent years as a powerful tool to analyze social networks. However, no prior works have studied potential bias issues inherent within graph embedding. In this paper, we make a first attempt in this direction. In particular, we concentrate on the fairness of node2vec, a popular graph embedding method. Our analyses on two real-world datasets demonstrate the existence of bias in node2vec when used for friendship recommendation. We therefore propose a fairness-aware embedding method, namely"
  },
  {
    "Title": "MemGuard",
    "URL": "https://dl.acm.org/doi/10.1145/3319535.3363201",
    "Full Abstract": "In a membership inference attack, an attacker aims to infer whether a data sample is in a target classifier's training dataset or not. Specifically, given a black-box access to the target classifier, the attacker trains a binary classifier, which takes a data sample's confidence score vector predicted by the target classifier as an input and predicts the data sample to be a member or non-member of the target classifier's training dataset. Membership inference attacks pose severe privacy and security threats to the training dataset. Most existing defenses leverage differential privacy when training the target classifier or regularize the training process of the target classifier. These defenses suffer from two key limitations: 1) they do not have formal utility-loss guarantees of the confidence score vectors, and 2) they achieve suboptimal privacy-utility tradeoffs. In this work, we propose MemGuard,the first defense with formal utility-loss guarantees against black-box membership inference attacks. Instead of tampering the training process of the target classifier, MemGuard adds noise to each confidence score vector predicted by the target classifier. Our key observation is that attacker uses a classifier to predict member or non-member and classifier is vulnerable to adversarial examples.Based on the observation, we propose to add a carefully crafted noise vector to a confidence score vector to turn it into an adversarial example that misleads the attacker's classifier. Specifically, MemGuard works in two phases. In Phase I, MemGuard finds a carefully crafted noise vector that can turn a confidence score vector into an adversarial example, which is likely to mislead the attacker's classifier to make a random guessing at member or non-member. We find such carefully crafted noise vector via a new method that we design to incorporate the unique utility-loss constraints on the noise vector. In Phase II, MemGuard adds the noise vector to the confidence score vector with a certain probability, which is selected to satisfy a given utility-loss budget on the confidence score vector. Our experimental results on three datasets show that MemGuard can effectively defend against membership inference attacks and achieve better privacy-utility tradeoffs than existing defenses. Our work is the first one to show that adversarial examples can be used as defensive mechanisms to defend against membership inference attacks."
  },
  {
    "Title": "HideNoSeek",
    "URL": "https://dl.acm.org/doi/10.1145/3319535.3345656",
    "Full Abstract": "In the malware field, learning-based systems have become popular to detect new malicious variants. Nevertheless, attackers with specific and internal knowledge of a target system may be able to produce input samples which are misclassified. In practice, the assumption of strong attackers is not realistic as it implies access to insider information. We instead propose HideNoSeek, a novel and generic camouflage attack, which evades the entire class of detectors based on syntactic features, without needing any information about the system it is trying to evade. Our attack consists of changing the constructs of malicious JavaScript samples to reproduce a benign syntax. For this purpose, we automatically rewrite the Abstract Syntax Trees (ASTs) of malicious JavaScript inputs into existing benign ones. In particular, HideNoSeek uses malicious seeds and searches for isomorphic subgraphs between the seeds and traditional benign scripts. Specifically, it replaces benign sub-ASTs by their malicious equivalents (same syntactic structure) and adjusts the benign data dependencies--without changing the AST--so that the malicious semantics is kept. In practice, we leveraged 23 malicious seeds to generate 91,020 malicious scripts, which perfectly reproduce ASTs of Alexa top 10,000 web pages. Also, we can produce on average 14 different malicious samples with the same AST as each Alexa top 10. Overall, a standard trained classifier has 99.98% false negatives with HideNoSeek inputs, while a classifier trained on such samples has over 88.74% false positives, rendering the targeted static detectors unreliable."
  },
  {
    "Title": "Adversarial Attacks on Classifiers for Eye-based User Modelling",
    "URL": "https://dl.acm.org/doi/10.1145/3379157.3390511",
    "Full Abstract": "An ever-growing body of work has demonstrated the rich information content available in eye movements for user modelling, e.g. for predicting users’ activities, cognitive processes, or even personality traits. We show that state-of-the-art classifiers for eye-based user modelling are highly vulnerable to adversarial examples: small artificial perturbations in gaze input that can dramatically change a classifier’s predictions. On the sample task of eye-based document type recognition we study the success of adversarial attacks with and without targeting the attack to a specific class."
  },
  {
    "Title": "JStap",
    "URL": "https://dl.acm.org/doi/10.1145/3359789.3359813",
    "Full Abstract": "Given the success of the Web platform, attackers have abused its main programming language, namely JavaScript, to mount different types of attacks on their victims. Due to the large volume of such malicious scripts, detection systems rely on static analyses to quickly process the vast majority of samples. These static approaches are not infallible though and lead to misclassifications. Also, they lack semantic information to go beyond purely syntactic approaches. In this paper, we propose JStap, a modular static JavaScript detection system, which extends the detection capability of existing lexical and AST-based pipelines by also leveraging control and data flow information. Our detector is composed of ten modules, including five different ways of abstracting code, with differing levels of context and semantic information, and two ways of extracting features. Based on the frequency of these specific patterns, we train a random forest classifier for each module. In practice, JStap outperforms existing systems, which we reimplemented and tested on our dataset totaling over 270,000 samples. To improve the detection, we also combine the predictions of several modules. A first layer of unanimous voting classifies 93% of our dataset with an accuracy of 99.73%, while a second layer-based on an alternative modules' combination-labels another 6.5% of our initial dataset with an accuracy over 99%. This way, JStap can be used as a precise pre-filter, meaning that it would only need to forward less than 1% of samples to additional analyses. For reproducibility and direct deployability of our modules, we make our system publicly available."
  },
  {
    "Title": "Membership Privacy for Fully Dynamic Group Signatures",
    "URL": "https://dl.acm.org/doi/10.1145/3319535.3354257",
    "Full Abstract": "Group signatures present a compromise between the traditional goals of digital signatures and the need for signer privacy, allowing for the creation of unforgeable signatures in the name of a group which reveal nothing about the actual signer's identity beyond their group membership. An important consideration that is absent in prevalent models is that group membership itself may be sensitive information, especially if group membership is dynamic, i.e. membership status may change over time. We address this issue by introducing formal notions of membership privacy for fully dynamic group signature schemes, which can be easily integrated into the most expressive models of group signature security to date. We then propose a generic construction for a fully dynamic group signature scheme with membership privacy that is based on signatures with flexible public key (SFPK) and signatures on equivalence classes (SPSEQ). Finally, we devise novel techniques for SFPK to construct a highly efficient standard model scheme (i.e. without random oracles) that provides shorter signatures than even the non-private state-of-the-art from standard assumptions. This shows that, although the strictly stronger security notions we introduce have been completely unexplored in the study of fully dynamic group signatures so far, they do not come at an additional cost in practice."
  },
  {
    "Title": "A tale of two headers",
    "URL": "https://dl.acm.org/doi/10.5555/3489212.3489251",
    "Full Abstract": "Click-jacking protection on the modern Web is commonly enforced via client-side security mechanisms for framing control, like the X-Frame-Options header (XFO) and Content Security Policy (CSP). Though these client-side security mechanisms are certainly useful and successful, delegating protection to web browsers opens room for inconsistencies in the security guarantees offered to users of different browsers. In particular, inconsistencies might arise due to the lack of support for CSP and the different implementations of the underspecified XFO header. In this paper, we formally study the problem of inconsistencies in framing control policies across different browsers and we implement an automated policy analyzer based on our theory, which we use to assess the state of click-jacking protection on the Web. Our analysis shows that 10% of the (distinct) framing control policies in the wild are inconsistent and most often do not provide any level of protection to at least one browser. We thus propose recommendations for web developers and browser vendors to mitigate this issue. Finally, we design and implement a server-side proxy to retrofit security in web applications."
  },
  {
    "Title": "Updates-leak",
    "URL": "https://dl.acm.org/doi/10.5555/3489212.3489285",
    "Full Abstract": "Machine learning (ML) has progressed rapidly during the past decade and the major factor that drives such development is the unprecedented large-scale data. As data generation is a continuous process, this leads to ML model owners updating their models frequently with newly-collected data in an online learning scenario. In consequence, if an ML model is queried with the same set of data samples at two different points in time, it will provide different results."
  },
  {
    "Title": "Assessing the Impact of Script Gadgets on CSP at Scale",
    "URL": "https://dl.acm.org/doi/10.1145/3320269.3372201",
    "Full Abstract": "The Web, as one of the core technologies of modern society, has profoundly changed the way we interact with people and data. One of the worst attacks on the Web is Cross-Site Scripting (XSS), in which an attacker is able to inject their malicious JavaScript code into a Web application, giving this code full access to the victimized site. To mitigate the impact of markup injection flaws that cause XSS, support for the Content Security Policy (CSP) is nowadays shipped in all browsers. Deploying such a policy enables a Web developer to whitelist from where script code can be loaded, essentially constraining the capabilities of the attacker to only be able to execute injected code from the said whitelist. As recently shown by Lekies et al., injecting script markup is not a necessary prerequisite for a successful attack in the presence of so-called script gadgets. These small snippets of benign JavaScript code transform non-script markup contained in a page into executable JavaScript, opening the door for bypasses of a deployed CSP. Especially in combination with CSP's logic in handling redirected resources, script gadgets enable attackers to bypass an otherwise secure policy. In this paper, we, therefore, ask the question: is securely deploying CSP even possible without a priori knowledge of all files hosted on even a partially trusted origin? To answer this question, we investigate the severity of the findings of Lekies et al., showing real-world Web sites on which, even in the presence of CSP and without code containing such gadgets being added by the developer, an attacker can sideload libraries with known script gadgets, as long as the hosting site is whitelisted in the CSP. In combination with CSPs matching logic for redirects, this enables us to bypass 10% of otherwise secure policies in the wild. To further answer our main research question, we conduct a hypothetical what-if analysis. Doing so, we automatically generate sensible CSPs for all of the Top 10,000 sites and show that around one-third of all sites would still be susceptible to a bypass through script gadget sideloading due to heavy reliance on third parties that also host such libraries."
  },
  {
    "Title": "TrollThrottle —Raising the Cost of Astroturfing",
    "URL": "https://dl.acm.org/doi/10.1007/978-3-030-57878-7_22",
    "Full Abstract": "Astroturfing, i.e., the fabrication of public discourse by private or state-controlled sponsors via the creation of fake online accounts, has become incredibly widespread in recent years. It gives a disproportionally strong voice to wealthy and technology-savvy actors, permits targeted attacks on public forums and could in the long run harm the trust users have in the internet as a communication platform."
  },
  {
    "Title": "On the Security Relevance of Initial Weights in Deep Neural Networks",
    "URL": "https://dl.acm.org/doi/10.1007/978-3-030-61609-0_1",
    "Full Abstract": "Recently, a weight-based attack on stochastic gradient descent inducing overfitting has been proposed. We show that the threat is broader: A task-independent permutation on the initial weights suffices to limit the achieved accuracy to for example 50% on the Fashion MNIST dataset from initially more than 90%. These findings are supported on MNIST and CIFAR. We formally confirm that the attack succeeds with high likelihood and does not depend on the data. Empirically, weight statistics and loss appear unsuspicious, making it hard to detect the attack if the user is not aware. Our paper is thus a call for action to acknowledge the importance of the initial weights in deep learning."
  },
  {
    "Title": "Measuring User Perception for Detecting Unexpected Access to Sensitive Resource in Mobile Apps",
    "URL": "https://dl.acm.org/doi/10.1145/3433210.3437511",
    "Full Abstract": "Understanding users' perception of app behaviors is an important step to detect data access that violates user expectations. While existing works have used various proxies to infer user expectations (e.g., by analyzing app descriptions), how real-world users perceive an app's data access when they interact with graphical user interfaces (UI) has not been fully explored."
  },
  {
    "Title": "DoubleX: Statically Detecting Vulnerable Data Flows in Browser Extensions at Scale",
    "URL": "https://dl.acm.org/doi/10.1145/3460120.3484745",
    "Full Abstract": "Browser extensions are popular to enhance users' browsing experience. By design, they have access to security- and privacy-critical APIs to perform tasks that web applications cannot traditionally do. Even though web pages and extensions are isolated, they can communicate through messages. Specifically, a vulnerable extension can receive messages from another extension or web page, under the control of an attacker. Thus, these communication channels are a way for a malicious actor to elevate their privileges to the capabilities of an extension, which can lead to, e.g., universal cross-site scripting or sensitive user data exfiltration. To automatically detect such security and privacy threats in benign-but-buggy extensions, we propose our static analyzer DoubleX. DoubleX defines an Extension Dependence Graph (EDG), which abstracts extension code with control and data flows, pointer analysis, and models the message interactions within and outside of an extension. This way, we can leverage this graph to track and detect suspicious data flows between external actors and sensitive APIs in browser extensions. We evaluated DoubleX on 154,484 Chrome extensions, where it flags 278 extensions as having a suspicious data flow. Overall, we could verify that 89% of these flows can be influenced by external actors (i.e., an attacker). Based on our threat model, we subsequently demonstrate exploitability for 184 extensions. Finally, we evaluated DoubleX on a labeled vulnerable extension set, where it accurately detects almost 93% of known flaws."
  },
  {
    "Title": "Up2Dep: Android Tool Support to Fix Insecure Code Dependencies",
    "URL": "https://dl.acm.org/doi/10.1145/3427228.3427658",
    "Full Abstract": "Third-party libraries, especially outdated versions, can introduce and multiply security & privacy related issues to Android applications. While prior work has shown the need for tool support for developers to avoid libraries with security problems, no such a solution has yet been brought forward to Android. It is unclear how such a solution would work and which challenges need to be solved in realizing it."
  },
  {
    "Title": "When Machine Unlearning Jeopardizes Privacy",
    "URL": "https://dl.acm.org/doi/10.1145/3460120.3484756",
    "Full Abstract": "The right to be forgotten states that a data owner has the right to erase their data from an entity storing it. In the context of machine learning (ML), the right to be forgotten requires an ML model owner to remove the data owner's data from the training set used to build the ML model, a process known asmachine unlearning. While originally designed to protect the privacy of the data owner, we argue that machine unlearning may leave some imprint of the data in the ML model and thus create unintended privacy risks. In this paper, we perform the first study on investigating the unintended information leakage caused by machine unlearning. We propose a novel membership inference attack that leverages the different outputs of an ML model's two versions to infer whether a target sample is part of the training set of the original model but out of the training set of the corresponding unlearned model. Our experiments demonstrate that the proposed membership inference attack achieves strong performance. More importantly, we show that our attack in multiple cases outperforms the classical membership inference attack on the original ML model, which indicates that machine unlearning can have counterproductive effects on privacy. We notice that the privacy degradation is especially significant for well-generalized ML models where classical membership inference does not perform well. We further investigate four mechanisms to mitigate the newly discovered privacy risks and show that releasing the predicted label only, temperature scaling, and differential privacy are effective. We believe that our results can help improve privacy protection in practical implementations of machine unlearning. \\footnoteOur code is available at \\urlhttps://github.com/MinChen00/UnlearningLeaks."
  },
  {
    "Title": "12 Angry Developers - A Qualitative Study on Developers' Struggles with CSP",
    "URL": "https://dl.acm.org/doi/10.1145/3460120.3484780",
    "Full Abstract": "The Web has improved our ways of communicating, collaborating, teaching, and entertaining us and our fellow human beings. However, this cornerstone of our modern society is also one of the main targets of attacks, most prominently Cross-Site Scripting (XSS). A correctly crafted Content Security Policy (CSP) is capable of effectively mitigating the effect of those Cross-Site Scripting attacks. However, research has shown that the vast majority of all policies in the wild are trivially bypassable."
  },
  {
    "Title": "Adversarial vulnerability bounds for Gaussian process classification",
    "URL": "https://dl.acm.org/doi/10.1007/s10994-022-06224-6",
    "Full Abstract": "Protecting ML classifiers from adversarial examples is crucial. We propose that the main threat is an attacker perturbing a"
  },
  {
    "Title": "Industrial practitioners' mental models of adversarial machine learning",
    "URL": "https://dl.acm.org/doi/10.5555/3563609.3563615",
    "Full Abstract": "Although machine learning is widely used in practice, little is known about practitioners' understanding of potential security challenges. In this work, we close this substantial gap and contribute a qualitative study focusing on developers' mental models of the machine learning pipeline and potentially vulnerable components. Similar studies have helped in other security fields to discover root causes or improve risk communication. Our study reveals two facets of practitioners' mental models of machine learning security. Firstly, practitioners often confuse machine learning security with threats and defences that are not directly related to machine learning. Secondly, in contrast to most academic research, our participants perceive security of machine learning as not solely related to individual models, but rather in the context of entire workflows that consist of multiple components. Jointly with our additional findings, these two facets provide a foundation to substantiate mental models for machine learning security and have implications for the integration of adversarial machine learning into corporate workflows, decreasing practitioners' reported uncertainty, and appropriate regulatory frameworks for machine learning security."
  },
  {
    "Title": "POSTER",
    "URL": "https://dl.acm.org/doi/10.1145/2976749.2989057",
    "Full Abstract": "The Internet is an ever-growing ecosystem with diverse software and hardware applications deployed in numerous countries around the globe. This heterogenous structure, however, is reduced to a homogenous means of addressing servers, i.e., their IP address. Due to this, analyzing different Internet services for vulnerabilities at scale is easy, leading to many researcher focusing on large-scale detection of many types of flaws. On the other hand, the persons responsible for the administration of said services are as heterogenous as the Internet architecture itself: be it in spoken languages or knowledge of technical details of the services. The notification of vulnerable services has long been treated as a side note in research. Recently, the community has focussed more not only the detection of flaws, but also on the notification of affected parties. These works, however, only analyze a small segment of the problem space. Hence, in this paper, we investigate the issues encountered by the previous works and provide a number of future directions for research, ultimately aiming to allow for an easier means of notifying affected parties about vulnerabilities at scale."
  },
  {
    "Title": "Backdoor smoothing",
    "URL": "https://dl.acm.org/doi/10.1016/j.cose.2022.102814",
    "Full Abstract": "Backdoor attacks mislead machine-learning models to output an attacker-specified class when presented a specific trigger at test time. These attacks require poisoning the training data to compromise the learning algorithm, e.g., by injecting poisoning samples containing the trigger into the training set, along with the desired class label. Despite the increasing number of studies on backdoor attacks and defenses, the underlying factors affecting the success of backdoor attacks, along with their impact on the learning algorithm, are not yet well understood. In this work, we aim to shed light on this issue by unveiling that backdoor attacks induce a smoother decision function around the triggered samples – a phenomenon which we refer to as"
  },
  {
    "Title": "BadNL: Backdoor Attacks against NLP Models with Semantic-preserving Improvements",
    "URL": "https://dl.acm.org/doi/10.1145/3485832.3485837",
    "Full Abstract": "Deep neural networks (DNNs) have progressed rapidly during the past decade and have been deployed in various real-world applications. Meanwhile, DNN models have been shown to be vulnerable to security and privacy attacks. One such attack that has attracted a great deal of attention recently is the backdoor attack. Specifically, the adversary poisons the target model’s training set to mislead any input with an added secret trigger to a target class."
  },
  {
    "Title": "On Profile Linkability despite Anonymity in Social Media Systems",
    "URL": "https://dl.acm.org/doi/10.1145/2994620.2994629",
    "Full Abstract": "A number of works have recently shown that the privacy offered by pseudonymous identities on social media systems like Twitter or Reddit is threatened by cross-site identity linking attacks. Such attacks link the identities of the same user across websites. Therefore, assessing linkability, i.e., the risk that identities are linked across different websites, remains an important open problem. In this work, we analyze whether anonymity within a single social media site can protect a user from being linked across sites. To this end, we first introduce a relative linkability measure ranking identities within a social media site by their anonymity. We show that anonymity alone is not sufficient to assess linkability risks, by evaluating this measure on a data set comprising 15 million comments gathered from the Reddit social media system."
  },
  {
    "Title": "How Internet Resources Might Be Helping You Develop Faster but Less Securely",
    "URL": "https://dl.acm.org/doi/10.1109/MSP.2017.24",
    "Full Abstract": "In this experimental study, Android developers using Stack Overflow to solve common security issues were more likely to produce functional--but less secure--code. Given today's time constraints and economic pressures, developers need improved official documentation that's both secure and usable."
  },
  {
    "Title": "Who Controls the Internet?",
    "URL": "https://dl.acm.org/doi/10.1145/3038912.3052587",
    "Full Abstract": "The Internet is built on top of intertwined network services, e.g., email, DNS, and content distribution networks operated by private or governmental organizations. Recent events have shown that these organizations may, knowingly or unknowingly, be part of global-scale security incidents including state-sponsored mass surveillance programs and large-scale DDoS attacks. For example, in March 2015 the Great Cannon attack has shown that an Internet service provider can weaponize millions of Web browsers and turn them into DDoS bots by injecting malicious JavaScript code into transiting TCP connections."
  },
  {
    "Title": "Lessons learned from using an online platform to conduct large-scale, online controlled security experiments with software developers",
    "URL": "https://dl.acm.org/doi/10.5555/3241074.3241080",
    "Full Abstract": "Security and privacy researchers are increasingly conducting controlled experiments focusing on IT professionals, such as software developers and system administrators. These professionals are typically more difficult to recruit than general end-users. In order to allow for distributed recruitment of IT professionals for security user studies, we designed Developer Observatory, a browser-based virtual laboratory platform that enables controlled programming experiments while retaining most of the observational power of lab studies. The Developer Observatory can be used to conduct largescale, reliable online programming studies with reasonable external validity. We report on our experiences and lessons learned from two controlled programming experiments (n>200) conducted using Developer Observatory."
  },
  {
    "Title": "How the web tangled itself",
    "URL": "https://dl.acm.org/doi/10.5555/3241189.3241265",
    "Full Abstract": "While in its early days, the Web was mostly static, it has organically grown into a full-fledged technology stack. This evolution has not followed a security blueprint, resulting in many classes of vulnerabilities specific to the Web. Even though the server-side code of the past has long since vanished, the Internet Archive gives us a unique view on the historical development of the Web's client side and its (in)security. Uncovering the insights which fueled this development bears the potential to not only gain a historical perspective on client-side Web security, but also to outline better practices going forward."
  },
  {
    "Title": "Deemon",
    "URL": "https://dl.acm.org/doi/10.1145/3133956.3133959",
    "Full Abstract": "Cross-Site Request Forgery (CSRF) vulnerabilities are a severe class of web vulnerabilities that have received only marginal attention from the research and security testing communities. While much effort has been spent on countermeasures and detection of XSS and SQLi, to date, the detection of CSRF vulnerabilities is still performed predominantly manually."
  },
  {
    "Title": "walk2friends",
    "URL": "https://dl.acm.org/doi/10.1145/3133956.3133972",
    "Full Abstract": "The development of positioning technologies has resulted in an increasing amount of mobility data being available. While bringing a lot of convenience to people's life, such availability also raises serious concerns about privacy. In this paper, we concentrate on one of the most sensitive information that can be inferred from mobility data, namely social relationships. We propose a novel social relation inference attack that relies on an advanced feature learning technique to automatically summarize users' mobility features. Compared to existing approaches, our attack is able to predict any two individuals' social relation, and it does not require the adversary to have any prior knowledge on existing social relations. These advantages significantly increase the applicability of our attack and the scope of the privacy assessment. Extensive experiments conducted on a large dataset demonstrate that our inference attack is effective, and achieves between 13% to 20% improvement over the best state-of-the-art scheme. We propose three defense mechanisms -- hiding, replacement and generalization -- and evaluate their effectiveness for mitigating the social link privacy risks stemming from mobility data sharing. Our experimental results show that both hiding and replacement mechanisms outperform generalization. Moreover, hiding and replacement achieve a comparable trade-off between utility and privacy, the former preserving better utility and the latter providing better privacy."
  },
  {
    "Title": "A Stitch in Time",
    "URL": "https://dl.acm.org/doi/10.1145/3133956.3133977",
    "Full Abstract": "Despite security advice in the official documentation and an extensive body of security research about vulnerabilities and exploits, many developers still fail to write secure Android applications. Frequently, Android developers fail to adhere to security best practices, leaving applications vulnerable to a multitude of attacks. We point out the advantage of a low-time-cost tool both to teach better secure coding and to improve app security. Using the FixDroid IDE plug-in, we show that professional and hobby app developers can work with and learn from an in-environment tool without it impacting their normal work; and by performing studies with both students and professional developers, we identify key UI requirements and demonstrate that code delivered with such a tool by developers previously inexperienced in security contains significantly less security problems. Perfecting and adding such tools to the Android development environment is an essential step in getting both security and privacy for the next generation of apps."
  },
  {
    "Title": "The ART of App Compartmentalization",
    "URL": "https://dl.acm.org/doi/10.1145/3133956.3134064",
    "Full Abstract": "Third-party libraries are commonly used by app developers for alleviating the development efforts and for monetizing their apps. On Android, the host app and its third-party libraries reside in the same sandbox and share all privileges awarded to the host app by the user, putting the users' privacy at risk of intrusions by third-party libraries. In this paper, we introduce a new privilege separation approach for third-party libraries on stock Android. Our solution partitions Android applications at compile-time into isolated, privilege-separated compartments for the host app and the included third-party libraries. A particular benefit of our approach is that it leverages compiler-based instrumentation available on stock Android versions and thus abstains from modification of the SDK, the app bytecode, or the device firmware. A particular challenge for separating libraries from their host apps is the reconstruction of the communication channels and the preservation of visual fidelity between the now separated app and its libraries. We solve this challenge through new IPC-based protocols to synchronize layout and lifecycle management between different sandboxes. Finally, we demonstrate the efficiency and effectiveness of our solution by applying it to real world apps from the Google Play Store that contain advertisements."
  },
  {
    "Title": "A Survey on Routing in Anonymous Communication Protocols",
    "URL": "https://dl.acm.org/doi/10.1145/3182658",
    "Full Abstract": "The Internet has undergone dramatic changes in the past 2 decades and now forms a global communication platform that billions of users rely on for their daily activities. While this transformation has brought tremendous benefits to society, it has also created new threats to online privacy, such as omnipotent governmental surveillance. As a result, public interest in systems for anonymous communication has drastically increased. In this work, we survey previous research on designing, developing, and deploying systems for anonymous communication. Our taxonomy and comparative assessment provide important insights about the differences between the existing classes of anonymous communication protocols."
  },
  {
    "Title": "Keep me Updated",
    "URL": "https://dl.acm.org/doi/10.1145/3133956.3134059",
    "Full Abstract": "Third-party libraries in Android apps have repeatedly been shown to be hazards to the users' privacy and an amplification of their host apps' attack surface. A particularly aggravating factor to this situation is that the libraries' version included in apps are very often outdated."
  },
  {
    "Title": "Tagvisor",
    "URL": "https://dl.acm.org/doi/10.1145/3178876.3186095",
    "Full Abstract": "Hashtag has emerged as a widely used concept of popular culture and campaigns, but its implications on people»s privacy have not been investigated so far. In this paper, we present the first systematic analysis of privacy issues induced by hashtags. We concentrate in particular on location, which is recognized as one of the key privacy concerns in the Internet era. By relying on a random forest model, we show that we can infer a user»s precise location from hashtags with accuracy of 70% to 76%, depending on the city. To remedy this situation, we introduce a system called Tagvisor that systematically suggests alternative hashtags if the user-selected ones constitute a threat to location privacy. Tagvisor realizes this by means of three conceptually different obfuscation techniques and a semantics-based metric for measuring the consequent utility loss. Our findings show that obfuscating as little as two hashtags already provides a near-optimal trade-off between privacy and utility in our dataset. This in particular renders Tagvisor highly time-efficient, and thus, practical in real-world settings."
  },
  {
    "Title": "Stackelberg planning",
    "URL": "https://dl.acm.org/doi/10.5555/3504035.3504805",
    "Full Abstract": "Inspired by work on Stackelberg security games, we introduce Stackelberg planning, where a"
  },
  {
    "Title": "Better managed than memorized? studying the impact of managers on password strength and reuse",
    "URL": "https://dl.acm.org/doi/10.5555/3277203.3277220",
    "Full Abstract": "Despite their well-known security problems, passwords are still the incumbent authentication method for virtually all online services. To remedy the situation, users are very often referred to password managers as a solution to the password reuse and weakness problems. However, to date the actual impact of password managers on password strength and reuse has not been studied systematically."
  },
  {
    "Title": "Simulating the Large-Scale Erosion of Genomic Privacy Over Time",
    "URL": "https://dl.acm.org/doi/10.1109/TCBB.2018.2859380",
    "Full Abstract": "The dramatically decreasing costs of DNA sequencing have triggered more than a million humans to have their genotypes sequenced. Moreover, these individuals increasingly make their genomic data publicly available, thereby creating privacy threats for themselves and their relatives because of their DNA similarities. More generally, an entity that gains access to a significant fraction of sequenced genotypes might be able to infer even the genomes of unsequenced individuals. In this paper, we propose a simulation-based model for quantifying the impact of continuously sequencing and publicizing personal genomic data on a population's genomic privacy. Our simulation probabilistically models data sharing and takes into account events such as migration and interracial mating. We exemplarily instantiate our simulation with a sample population of 1,000 individuals and evaluate the privacy under multiple settings over 6,000 genomic variants and a subset of phenotype-related variants. Our findings demonstrate that an increasing sharing rate in the future entails a substantial negative effect on the privacy of all older generations. Moreover, we find that mixed populations face a less severe erosion of privacy over time than more homogeneous populations. Finally, we demonstrate that genomic-data sharing can be much more detrimental for the privacy of the phenotype-related variants."
  },
  {
    "Title": "Ring Signatures: Logarithmic-Size, No Setup—from Standard Assumptions",
    "URL": "https://dl.acm.org/doi/10.1007/978-3-030-17659-4_10",
    "Full Abstract": "Ring signatures allow for creating signatures on behalf of an ad hoc group of signers, hiding the true identity of the signer among the group. A natural goal is to construct a ring signature scheme for which the signature size is short in the number of ring members. Moreover, such a construction should not rely on a trusted setup and be proven secure under falsifiable standard assumptions. Despite many years of research this question is still open."
  },
  {
    "Title": "Efficient Non-Interactive Zero-Knowledge Proofs in Cross-Domains Without Trusted Setup",
    "URL": "https://dl.acm.org/doi/10.1007/978-3-030-17253-4_10",
    "Full Abstract": "With the recent emergence of efficient zero-knowledge (ZK) proofs for general circuits, while efficient zero-knowledge proofs of algebraic statements have existed for decades, a natural challenge arose to combine algebraic and non-algebraic statements. Chase et al. (CRYPTO 2016) proposed an interactive ZK proof system for this cross-domain problem. As a use case they show that their system can be used to prove knowledge of a RSA/DSA signature on a message"
  },
  {
    "Title": "Signatures with Flexible Public Key: Introducing Equivalence Classes for Public Keys",
    "URL": "https://dl.acm.org/doi/10.1007/978-3-030-03329-3_14",
    "Full Abstract": "We introduce a new cryptographic primitive called signatures with flexible public key . We divide the key space into equivalence classes induced by a relation . A signer can efficiently change his or her key pair to a different representatives of the same class, but without a trapdoor it is hard to distinguish if two public keys are related. Our primitive is motivated by structure-preserving signatures on equivalence classes (), where the partitioning is done on the message space. Therefore, both definitions are complementary and their combination has various applications."
  },
  {
    "Title": "POSTER",
    "URL": "https://dl.acm.org/doi/10.1145/2810103.2810115",
    "Full Abstract": "Recently, the live-monitor MATor for formally analyzing user anonymity within the Tor network has been proposed (CCS'14). However, this monitor only considers adversaries that compromise part of the Tor network itself, not Internet infrastructural adversaries. In this work we present a formal technique for analyzing Tor against malicious or overly curious network infrastructure."
  },
  {
    "Title": "Towards automated network mitigation analysis",
    "URL": "https://dl.acm.org/doi/10.1145/3297280.3297473",
    "Full Abstract": "Penetration testing is a well-established practical concept for the identification of potentially exploitable security weaknesses and an important component of a security audit. Providing a holistic security assessment for networks consisting of several hundreds hosts is hardly feasible though without some sort of mechanization. Mitigation, prioritizing counter-measures subject to a given budget, currently lacks a solid theoretical understanding and is hence more art than science. In this work, we propose the first approach for conducting comprehensive what-if analyses in order to reason about mitigation in a conceptually well-founded manner. To evaluate and compare mitigation strategies, we use"
  },
  {
    "Title": "Computational Soundness for Interactive Primitives",
    "URL": "https://dl.acm.org/doi/10.1007/978-3-319-24174-6_7",
    "Full Abstract": "We present a generic computational soundness result for interactive cryptographic primitives. Our abstraction of interactive primitives leverages the Universal Composability (UC) framework, and thereby offers strong composability properties for our computational soundness result: given a computationally sound Dolev-Yao model for non-interactive primitives, and given UC-secure interactive primitives, we obtain computational soundness for the combined model that encompasses both the non-interactive and the interactive primitives. Our generic result is formulated in the CoSP framework for computational soundness proofs and supports any equivalence property expressible in CoSP such as strong secrecy and anonymity."
  },
  {
    "Title": "POSTER",
    "URL": "https://dl.acm.org/doi/10.1145/2810103.2810129",
    "Full Abstract": "Dynamic analysis and taint tracking on Android was typically implemented by instrumenting the Dalvik Virtual Machine. However, the new Android Runtime (ART) introduced in Android 5 replaces the interpreter with an on-device compiler suite. Therefore as of Android 5, the applicability of interpreter instrumentation-based approaches like TaintDroid is limited to Android versions up to 4.4 Kitkat. In this poster, we present ongoing work on re-enabling taint tracking for apps by instrumenting the Optimizing backend, used by the new ART compiler suite for code generation. As Android now compiles apps ahead-of-time from dex bytecode to platform specific native code on the device itself, an instrumented compiler provides the opportunity to emit additional instructions that enable the actual taint tracking. The result is a custom compiler that takes arbitrary app APKs and transforms them into self-taint tracking native code, executable by the Android Runtime."
  },
  {
    "Title": "Delegatable Functional Signatures",
    "URL": "https://dl.acm.org/doi/10.1007/978-3-662-49384-7_14",
    "Full Abstract": "We introduce delegatable functional signatures DFS which support the delegation of signing capabilities to another party, called the evaluator, with respect to a functionality $$\\mathcal {F} $$F. In a DFS, the signer of a message can choose an evaluator, specify how the evaluator can modify the signature without voiding its validity, allow additional input, and decide how the evaluator can further delegate its capabilities. Technically, DFS unify several seemingly different signature primitives, including functional signatures and policy-based signatures PKC'14, sanitizable signatures, identity based signatures, and blind signatures. We characterize the instantiability of DFS with respect to the corresponding security notions of unforgeability and privacy. On the positive side we show that privacy-free DFS can be constructed from one-way functions. Furthermore, we show that unforgeable and private DFS can be constructed from doubly-enhanced trapdoor permutations. On the negative side we show that the previous result is optimal regarding its underlying assumptions presenting an impossibility result for unforgeable private DFS from one-way permutations."
  },
  {
    "Title": "From Zoos to Safaris--From Closed-World Enforcement to Open-World Assessment of Privacy",
    "URL": "https://dl.acm.org/doi/10.1007/978-3-319-43005-8_3",
    "Full Abstract": "In this paper, we develop a user-centric privacy framework for quantitatively assessing the exposure of personal information in open settings. Our formalization addresses key-challenges posed by such open settings, such as the necessity of user- and context-dependent privacy requirements. As a sanity check, we show that hard non-disclosure guarantees are impossible to achieve in open settings."
  },
  {
    "Title": "R-Droid",
    "URL": "https://dl.acm.org/doi/10.1145/2897845.2897927",
    "Full Abstract": "Today's feature-rich smartphone apps intensively rely on access to highly sensitive (personal) data. This puts the user's privacy at risk of being violated by overly curious apps or libraries (like advertisements). Central app markets conceptually represent a first line of defense against such invasions of the user's privacy, but unfortunately we are still lacking full support for automatic analysis of apps' internal data flows and supporting analysts in statically assessing apps' behavior. In this paper we present a novel slice-optimization approach to leverage static analysis of Android applications. Building on top of precise application lifecycle models, we employ a slicing-based analysis to generate data-dependent statements for arbitrary points of interest in an application. As a result of our optimization, the produced slices are, on average, 49% smaller than standard slices, thus facilitating code understanding and result validation by security analysts. Moreover, by re-targeting strings, our approach enables automatic assessments for a larger number of use-cases than prior work. We consolidate our improvements on statically analyzing Android apps into a tool called R-Droid and conducted a large-scale data-leak analysis on a set of 22,700 Android apps from Google Play. R-Droid managed to identify a significantly larger set of potential privacy-violating information flows than previous work, including 2,157 sensitive flows of password-flagged UI widgets in 256 distinct apps."
  },
  {
    "Title": "Implementation-level analysis of the JavaScript helios voting client",
    "URL": "https://dl.acm.org/doi/10.1145/2851613.2851800",
    "Full Abstract": "We perform the first automated security analysis of the actual JavaScript implementation of the Helios voting client, a state-of-the-art, web-based, open-audit voting system that is continuously being deployed for real-life elections. While its concept has been exhaustively analyzed by the security community, we actively analyze its actual JavaScript"
  },
  {
    "Title": "RamCrypt",
    "URL": "https://dl.acm.org/doi/10.1145/2897845.2897924",
    "Full Abstract": "We present RamCrypt, a solution that allows unmodified Linux processes to transparently work on encrypted data. RamCrypt can be deployed and enabled on a per-process basis without recompiling user-mode applications. In every enabled process, data is only stored in cleartext for the moment it is processed, and otherwise stays encrypted in RAM. In particular, the required encryption keys do not reside in RAM, but are stored in CPU registers only. Hence, RamCrypt effectively thwarts memory disclosure attacks, which grant unauthorized access to process memory, as well as physical attacks such as cold boot and DMA attacks. In its default configuration, RamCrypt exposes only up to 4 memory pages in cleartext at the same time. For the nginx web server serving encrypted HTTPS pages under heavy load, the necessary TLS secret key is hidden for 97% of its time."
  },
  {
    "Title": "Data Lineage in Malicious Environments",
    "URL": "https://dl.acm.org/doi/10.1109/TDSC.2015.2399296",
    "Full Abstract": "Intentional or unintentional leakage of confidential data is undoubtedly one of the most severe security threats that organizations face in the digital era. The threat now extends to our personal lives: a plethora of personal information is available to social networks and smartphone providers and is indirectly transferred to untrustworthy third party and fourth party applications. In this work, we present a generic data lineage framework <sc>Lime</sc> for data flow across multiple entities that take two characteristic, principal roles (i.e., owner and consumer). We define the exact security guarantees required by such a data lineage mechanism toward identification of a guilty entity, and identify the simplifying non-repudiation and honesty assumptions. We then develop and analyze a novel accountable data transfer protocol between two entities within a malicious environment by building upon oblivious transfer, robust watermarking, and signature primitives. Finally, we perform an experimental evaluation to demonstrate the practicality of our protocol and apply our framework to the important data leakage scenarios of data outsourcing and social networks. In general, we consider <sc>Lime</sc>, our lineage framework for data transfer, to be an key step towards achieving <italic>accountability by design</italic>."
  },
  {
    "Title": "Detecting Hardware-Assisted Virtualization",
    "URL": "https://dl.acm.org/doi/10.1007/978-3-319-40667-1_11",
    "Full Abstract": "Virtualization has become an indispensable technique for scaling up the analysis of malicious code, such as for malware analysis or shellcode detection systems. Frameworks like Ether, ShellOS and an ever-increasing number of commercially-operated malware sandboxes rely on hardware-assisted virtualization. A core technology is Intel's VT-x, which -- compared to software-emulated virtulization -- is believed to be stealthier, especially against evasive attackers that aim to detect virtualized systems to hide the malicious behavior of their code."
  },
  {
    "Title": "What cannot be read, cannot be leveraged ? revisiting assumptions of JIT-ROP defenses",
    "URL": "https://dl.acm.org/doi/10.5555/3241094.3241106",
    "Full Abstract": "Despite numerous attempts to mitigate code-reuse attacks, Return-Oriented Programming (ROP) is still at the core of exploiting memory corruption vulnerabilities. Most notably, in JIT-ROP, an attacker dynamically searches for suitable gadgets in executable code pages, even if they have been randomized. JIT-ROP seemingly requires that (i) code is"
  },
  {
    "Title": "Hey, you have a problem",
    "URL": "https://dl.acm.org/doi/10.5555/3241094.3241173",
    "Full Abstract": "Large-scale discovery of thousands of vulnerable Web sites has become a frequent event, thanks to recent advances in security research and the rise in maturity of Internet-wide scanning tools. The issues related to disclosing the vulnerability information to the affected parties, however, have only been treated as a side note in prior research."
  },
  {
    "Title": "On demystifying the android application framework",
    "URL": "https://dl.acm.org/doi/10.5555/3241094.3241180",
    "Full Abstract": "In contrast to the Android application layer, Android's application framework's internals and their influence on the platform security and user privacy are still largely a black box for us. In this paper, we establish a static runtime model of the application framework in order to study its internals and provide the first high-level classification of the framework's protected resources. We thereby uncover design patterns that differ highly from the runtime model at the application layer. We demonstrate the benefits of our insights for security-focused analysis of the framework by re-visiting the important use-case of mapping Android permissions to framework/SDK API methods. We, in particular, present a novel mapping based on our findings that significantly improves on prior results in this area that were established based on insufficient knowledge about the framework's internals. Moreover, we introduce the concept of permission locality to show that although framework services follow the principle of separation of duty, the accompanying permission checks to guard sensitive operations violate it."
  },
  {
    "Title": "Privacy in epigenetics",
    "URL": "https://dl.acm.org/doi/10.5555/3241094.3241188",
    "Full Abstract": "The decreasing cost of molecular profiling tests, such as DNA sequencing, and the consequent increasing availability of biological data are revolutionizing medicine, but at the same time create novel privacy risks. The research community has already proposed a plethora of methods for protecting"
  },
  {
    "Title": "Identifying the Scan and Attack Infrastructures Behind Amplification DDoS Attacks",
    "URL": "https://dl.acm.org/doi/10.1145/2976749.2978293",
    "Full Abstract": "Amplification DDoS attacks have gained popularity and become a serious threat to Internet participants. However, little is known about where these attacks originate, and revealing the attack sources is a non-trivial problem due to the spoofed nature of the traffic."
  },
  {
    "Title": "Reliable Third-Party Library Detection in Android and its Security Applications",
    "URL": "https://dl.acm.org/doi/10.1145/2976749.2978333",
    "Full Abstract": "Third-party libraries on Android have been shown to be security and privacy hazards by adding security vulnerabilities to their host apps or by misusing inherited access rights. Correctly attributing improper app behavior either to app or library developer code or isolating library code from their host apps would be highly desirable to mitigate these problems, but is impeded by the absence of a third-party library detection that is effective and reliable in spite of obfuscated code. This paper proposes a library detection technique that is resilient against common code obfuscations and that is capable of pinpointing the exact library version used in apps. Libraries are detected with profiles from a comprehensive library database that we generated from the original library SDKs. We apply our technique to the top apps on Google Play and their complete histories to conduct a longitudinal study of library usage and evolution in apps. Our results particularly show that app developers only slowly adapt new library versions, exposing their end-users to large windows of vulnerability. For instance, we discovered that two long-known security vulnerabilities in popular libs are still present in the current top apps. Moreover, we find that misuse of cryptographic APIs in advertising libs, which increases the host apps' attack surface, affects 296 top apps with a cumulative install base of 3.7bn devices according to Play. To the best of our knowledge, our work is first to quantify the security impact of third-party libs on the Android ecosystem."
  },
  {
    "Title": "Membership Privacy in MicroRNA-based Studies",
    "URL": "https://dl.acm.org/doi/10.1145/2976749.2978355",
    "Full Abstract": "The continuous decrease in cost of molecular profiling tests is revolutionizing medical research and practice, but it also raises new privacy concerns. One of the first attacks against privacy of biological data, proposed by Homer et al. in 2008, showed that, by knowing parts of the genome of a given individual and summary statistics of a genome-based study, it is possible to detect if this individual participated in the study. Since then, a lot of work has been carried out to further study the theoretical limits and to counter the genome-based membership inference attack. However, genomic data are by no means the only or the most influential biological data threatening personal privacy. For instance, whereas the genome informs us about the risk of developing some diseases in the future, epigenetic biomarkers, such as microRNAs, are directly and deterministically affected by our health condition including most common severe diseases. In this paper, we show that the membership inference attack also threatens the privacy of individuals contributing their microRNA expressions to scientific studies. Our results on real and public microRNA expression data demonstrate that disease-specific datasets are especially prone to membership detection, offering a true-positive rate of up to 77% at a false-negative rate of less than 1%. We present two attacks: one relying on the L_1 distance and the other based on the likelihood-ratio test. We show that the likelihood-ratio test provides the highest adversarial success and we derive a theoretical limit on this success. In order to mitigate the membership inference, we propose and evaluate both a differentially private mechanism and a hiding mechanism. We also consider two types of adversarial prior knowledge for the differentially private mechanism and show that, for relatively large datasets, this mechanism can protect the privacy of participants in miRNA-based studies against strong adversaries without degrading the data utility too much. Based on our findings and given the current number of miRNAs, we recommend to only release summary statistics of datasets containing at least a couple of hundred individuals."
  },
  {
    "Title": "Computational soundness of symbolic zero-knowledge proofs",
    "URL": "https://dl.acm.org/doi/10.1007/978-3-642-36830-1_11",
    "Full Abstract": "The abstraction of cryptographic operations by term algebras, called symbolic models, is essential in almost all tool-supported methods for analyzing security protocols. Significant progress was made in proving that symbolic models offering basic cryptographic operations such as encryption and digital signatures can be sound with respect to actual cryptographic realizations and security definitions. Even abstractions of sophisticated modern cryptographic primitives such as zero-knowledge (ZK) proofs were shown to have a computationally sound cryptographic realization, but only in ad-hoc formalisms and at the cost of placing strong assumptions on the underlying cryptography, which leaves only highly inefficient realizations."
  },
  {
    "Title": "Boxify",
    "URL": "https://dl.acm.org/doi/10.5555/2831143.2831187",
    "Full Abstract": "We present the first concept for full-fledged app sandboxing on stock Android. Our approach is based on application virtualization and process-based privilege separation to securely encapsulate untrusted apps in an isolated environment. In contrast to all related work on stock Android, we eliminate the necessity to modify the code of monitored apps, and thereby overcome existing legal concerns and deployment problems that rewriting-based approaches have been facing. We realize our concept as a regular Android app called Boxify that can be deployed without firmware modifications or root privileges. A systematic evaluation of Boxify demonstrates its capability to enforce established security policies without incurring a significant runtime performance overhead."
  },
  {
    "Title": "POSTER",
    "URL": "https://dl.acm.org/doi/10.1145/2976749.2989056",
    "Full Abstract": "On Android, advertising libraries are commonly integrated with their host apps. Since the host and advertising components share the application's sandbox, advertisement code inherits all permissions and can access host resources with no further approval needed. Motivated by the privacy risks of advertisement libraries as already shown in the literature, this poster introduces an Android Runtime (ART) based app compartmentalization mechanism to achieve separation between trusted app code and untrusted library code without system modification and application rewriting. With our approach, advertising libraries will be isolated from the host app and the original app will be partitioned into two sub-apps that run independently, with the host app's resources and permissions being protected by Android's app sandboxing mechanism. ARTist [1], a compiler-based Android app instrumentation framework, is utilized here to recreate the communication channels between host and advertisement library. The result is a robust toolchain on device which provides a clean separation of developer-written app code and third-party advertisement code, allowing for finer-grained access control policies and information flow control without OS customization and application rebuilding."
  },
  {
    "Title": "Computational Soundness for Dalvik Bytecode",
    "URL": "https://dl.acm.org/doi/10.1145/2976749.2978418",
    "Full Abstract": "Automatically analyzing information flow within Android applications that rely on cryptographic operations with their computational security guarantees imposes formidable challenges that existing approaches for understanding an app's behavior struggle to meet. These approaches do not distinguish cryptographic and non-cryptographic operations, and hence do not account for cryptographic protections: f(m) is considered sensitive for a sensitive message m irrespective of potential secrecy properties offered by a cryptographic operation f. These approaches consequently provide a safe approximation of the app's behavior, but they mistakenly classify a large fraction of apps as potentially insecure and consequently yield overly pessimistic results. In this paper, we show how cryptographic operations can be faithfully included into existing approaches for automated app analysis. To this end, we first show how cryptographic operations can be expressed as symbolic abstractions within the comprehensive Dalvik bytecode language. These abstractions are accessible to automated analysis and can be conveniently added to existing app analysis tools using minor changes in their semantics. Second, we show that our abstractions are faithful by providing the first computational soundness result for Dalvik bytecode, i.e., the absence of attacks against our symbolically abstracted program entails the absence of any attacks against a suitable cryptographic program realization. We cast our computational soundness result in the CoSP framework, which makes the result modular and composable."
  },
  {
    "Title": "Efficient Cryptographic Password Hardening Services from Partially Oblivious Commitments",
    "URL": "https://dl.acm.org/doi/10.1145/2976749.2978375",
    "Full Abstract": "Password authentication still constitutes the most widespread authentication concept on the Internet today, but the human incapability to memorize safe passwords has left this concept vulnerable to various attacks ever since. Affected enterprises such as Facebook now strive to mitigate such attacks by involving external cryptographic services that harden passwords. Everspaugh et al.~provided the first comprehensive formal treatment of such a service, and proposed the Pythia PRF-Service as a cryptographically secure solution (Usenix Security'15). Pythia relies on a novel cryptographic primitive called partially oblivious pseudorandom functions and its security is proven under a strong new interactive assumption in the random oracle model."
  },
  {
    "Title": "AnoA",
    "URL": "https://dl.acm.org/doi/10.1109/CSF.2013.18",
    "Full Abstract": "Protecting individuals' privacy in online communications has become a challenge of paramount importance. To this end, anonymous communication (AC) protocols such as the widely used Tor network have been designed to provide anonymity to their participating users. While AC protocols have been the subject of several security and anonymity analyses in the last years, there still does not exist a framework for analyzing complex systems such as Tor and their different anonymity properties in a unified manner.In this work we present AnoA: a generic framework for defining, analyzing, and quantifying anonymity properties for AC protocols. AnoA relies on a novel relaxation of the notion of (computational) differential privacy, and thereby enables a unified quantitative analysis of well-established anonymity properties, such as sender anonymity, sender unlinkability, and relationship anonymity. While an anonymity analysis in AnoA can be conducted in a purely information theoretical manner, we show that the protocol's anonymity properties established in AnoA carry over to secure cryptographic instantiations of the protocol.We exemplify the applicability of AnoA for analyzing real-life systems by conducting a thorough analysis of the anonymity properties provided by the Tor network against passive attackers. Our analysis significantly improves on known anonymity results from the literature."
  },
  {
    "Title": "Using mobile device communication to strengthen e-Voting protocols",
    "URL": "https://dl.acm.org/doi/10.1145/2517840.2517863",
    "Full Abstract": "Remote e-voting protocols strive to achieve sophisticated security properties. However, the inherent complexity of this level of sophistication typically comes at a cost: Protocols must either accept trade-offs in terms of security or are impractical. In this paper, we show how the additional communication capabilities given by the pervasive availability of mobile phones today can be used to strengthen the security offered by remote e-voting protocols. More precisely, the presence of two separate channels between the voter and the election authorities, namely the possibility for voters to communicate with authorities using both their computers and their mobile phones, opens up useful possibilities to significantly improve the security of remote e-voting with little cost in practicality."
  },
  {
    "Title": "Verifiable delegation of computation on outsourced data",
    "URL": "https://dl.acm.org/doi/10.1145/2508859.2516681",
    "Full Abstract": "We address the problem in which a client stores a large amount of data with an untrusted server in such a way that, at any moment, the client can ask the server to compute a function on some portion of its outsourced data. In this scenario, the client must be able to efficiently verify the correctness of the result despite no longer knowing the inputs of the delegated computation, it must be able to keep adding elements to its remote storage, and it does not have to fix in advance (i.e., at data outsourcing time) the functions that it will delegate. Even more ambitiously, clients should be able to verify in time independent of the input-size -- a very appealing property for computations over huge amounts of data."
  },
  {
    "Title": "Differentially Private Smart Metering with Battery Recharging",
    "URL": "https://dl.acm.org/doi/10.1007/978-3-642-54568-9_13",
    "Full Abstract": "The energy industry has recently begun using smart meters to take fine-grained readings of energy usage. These smart meters enable flexible time-of-use billing, forecasting, and demand response, but they also raise serious user privacy concerns. We propose a novel technique for provably hiding sensitive power consumption information in the overall power consumption stream. Our technique relies on a rechargeable battery that is connected to the household's power supply. This battery is used to modify the household's power consumption by adding or subtracting noise (i.e., increasing or decreasing power consumption), in order to establish strong privacy guarantees in the sense of differential privacy. To achieve these privacy guarantees in realistic settings, we first investigate the influence of, and the interplay between, capacity and throughput bounds that batteries face in reality. We then propose an integrated method based on noise cascading that allows for recharging the battery on-the-fly so that differential privacy is retained, while adhering to capacity and throughput constraints, and while keeping the additional consumption of energy induced by our technique to a minimum."
  },
  {
    "Title": "AppGuard  Fine-Grained Policy Enforcement for Untrusted Android Applications",
    "URL": "https://dl.acm.org/doi/10.1007/978-3-642-54568-9_14",
    "Full Abstract": "Android's success makes it a prominent target for malicious software. However, the user has very limited control over security-relevant operations. This work presents AppGuard, a powerful and flexible security system that overcomes these deficiencies. It enforces user-defined security policies on untrusted Android applications without requiring any changes to a smartphone's firmware, root access, or the like. Fine-grained and stateful security policies are expressed in a formal specification language, which also supports secrecy requirements. Our system offers complete mediation of security-relevant methods based on callee-site inline reference monitoring and supports widespread deployment. In the experimental analysis we demonstrate the removal of permissions for overly curious apps as well as how to defend against several recent real-world attacks on Android phones. Our technique exhibits very little space and runtime overhead. The utility of AppGuard has already been demonstrated by more than 1,000,000 downloads."
  }
]
